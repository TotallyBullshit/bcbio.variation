<!DOCTYPE html>
<html><head><meta charset="utf-8" content="text/html" http-equiv="Content-Type" /><meta content="Toolkit to analyze genomic variation data, built on the GATK with Clojure" name="description" /><style type="text/css">/**
 * SyntaxHighlighter
 * http://alexgorbatchev.com/SyntaxHighlighter
 *
 * SyntaxHighlighter is donationware. If you are using it, please donate.
 * http://alexgorbatchev.com/SyntaxHighlighter/donate.html
 *
 * @version
 * 3.0.83 (July 02 2010)
 * 
 * @copyright
 * Copyright (C) 2004-2010 Alex Gorbatchev.
 *
 * @license
 * Dual licensed under the MIT and GPL licenses.
 */
.syntaxhighlighter a,
.syntaxhighlighter div,
.syntaxhighlighter code,
.syntaxhighlighter table,
.syntaxhighlighter table td,
.syntaxhighlighter table tr,
.syntaxhighlighter table tbody,
.syntaxhighlighter table thead,
.syntaxhighlighter table caption,
.syntaxhighlighter textarea {
  -moz-border-radius: 0 0 0 0 !important;
  -webkit-border-radius: 0 0 0 0 !important;
  background: none !important;
  border: 0 !important;
  bottom: auto !important;
  float: none !important;
  height: auto !important;
  left: auto !important;
  line-height: 1.1em !important;
/*  margin: 0 !important; */
  outline: 0 !important;
  overflow: visible !important;
  padding: 0 !important;
  position: static !important;
  right: auto !important;
  text-align: left !important;
  top: auto !important;
  vertical-align: baseline !important;
  width: auto !important;
  box-sizing: content-box !important;
  font-family: "Consolas", "Bitstream Vera Sans Mono", "Courier New", Courier, monospace !important;
  font-weight: normal !important;
  font-style: normal !important;
  min-height: inherit !important;
  min-height: auto !important;
}

.syntaxhighlighter {
/*  width: 100% !important; */
  margin: 1em 0 1em 0 !important;
  position: relative !important;
  overflow: auto !important;
}
.syntaxhighlighter.source {
  overflow: hidden !important;
}
.syntaxhighlighter .bold {
  font-weight: bold !important;
}
.syntaxhighlighter .italic {
  font-style: italic !important;
}
.syntaxhighlighter .line {
  white-space: pre !important;
}
.syntaxhighlighter table {
/*    width: 100% !important;*/
}
.syntaxhighlighter table caption {
  text-align: left !important;
  padding: .5em 0 0.5em 1em !important;
}
.syntaxhighlighter table td.code {
  width: 100% !important;
}
.syntaxhighlighter table td.code .container {
  position: relative !important;
}
.syntaxhighlighter table td.code .container textarea {
  box-sizing: border-box !important;
  position: absolute !important;
  left: 0 !important;
  top: 0 !important;
  width: 100% !important;
  height: 100% !important;
  border: none !important;
  background: white !important;
  padding-left: 1em !important;
  overflow: hidden !important;
  white-space: pre !important;
}
.syntaxhighlighter table td.gutter .line {
  text-align: right !important;
  padding: 0 0.5em 0 1em !important;
}
.syntaxhighlighter table td.code .line {
  padding: 0 1em !important;
}
.syntaxhighlighter.nogutter td.code .container textarea, .syntaxhighlighter.nogutter td.code .line {
  padding-left: 0em !important;
}
.syntaxhighlighter.show {
  display: block !important;
}
.syntaxhighlighter.collapsed table {
  display: none !important;
}
.syntaxhighlighter.collapsed .toolbar {
    display: none;
/*  padding: 0.1em 0.8em 0em 0.8em !important;
  font-size: 1em !important;
  position: static !important;
  width: auto !important;
  height: auto !important;*/
}
.syntaxhighlighter.collapsed .toolbar span {
  display: inline !important;
  margin-right: 1em !important;
}
.syntaxhighlighter.collapsed .toolbar span a {
  padding: 0 !important;
  display: none !important;
}
.syntaxhighlighter.collapsed .toolbar span a.expandSource {
  display: inline !important;
}
.syntaxhighlighter .toolbar {
    display: none;
/*  position: absolute !important;
  right: 1px !important;
  top: 1px !important;
  width: 11px !important;
  height: 11px !important;
  font-size: 10px !important;
  z-index: 10 !important;*/
}
.syntaxhighlighter .toolbar span.title {
  display: inline !important;
}
.syntaxhighlighter .toolbar a {
  display: block !important;
  text-align: center !important;
  text-decoration: none !important;
  padding-top: 1px !important;
}
.syntaxhighlighter .toolbar a.expandSource {
  display: none !important;
}
.syntaxhighlighter.ie {
  font-size: .9em !important;
  padding: 1px 0 1px 0 !important;
}
.syntaxhighlighter.ie .toolbar {
  line-height: 8px !important;
}
.syntaxhighlighter.ie .toolbar a {
  padding-top: 0px !important;
}
.syntaxhighlighter.printing .line.alt1 .content,
.syntaxhighlighter.printing .line.alt2 .content,
.syntaxhighlighter.printing .line.highlighted .number,
.syntaxhighlighter.printing .line.highlighted.alt1 .content,
.syntaxhighlighter.printing .line.highlighted.alt2 .content {
  background: none !important;
}
.syntaxhighlighter.printing .line .number {
  color: #bbbbbb !important;
}
.syntaxhighlighter.printing .line .content {
  color: black !important;
}
.syntaxhighlighter.printing .toolbar {
  display: none !important;
}
.syntaxhighlighter.printing a {
  text-decoration: none !important;
}
.syntaxhighlighter.printing .plain, .syntaxhighlighter.printing .plain a {
  color: black !important;
}
.syntaxhighlighter.printing .comments, .syntaxhighlighter.printing .comments a {
  color: #008200 !important;
}
.syntaxhighlighter.printing .string, .syntaxhighlighter.printing .string a {
  color: blue !important;
}
.syntaxhighlighter.printing .keyword {
  color: #006699 !important;
  font-weight: bold !important;
}
.syntaxhighlighter.printing .preprocessor {
  color: gray !important;
}
.syntaxhighlighter.printing .variable {
  color: #aa7700 !important;
}
.syntaxhighlighter.printing .value {
  color: #009900 !important;
}
.syntaxhighlighter.printing .functions {
  color: #ff1493 !important;
}
.syntaxhighlighter.printing .constants {
  color: #0066cc !important;
}
.syntaxhighlighter.printing .script {
  font-weight: bold !important;
}
.syntaxhighlighter.printing .color1, .syntaxhighlighter.printing .color1 a {
  color: gray !important;
}
.syntaxhighlighter.printing .color2, .syntaxhighlighter.printing .color2 a {
  color: #ff1493 !important;
}
.syntaxhighlighter.printing .color3, .syntaxhighlighter.printing .color3 a {
  color: red !important;
}
.syntaxhighlighter.printing .break, .syntaxhighlighter.printing .break a {
  color: black !important;
}
</style><style type="text/css">.syntaxhighlighter{overflow:hidden !important;}</style><style type="text/css">/**
 * http://alexgorbatchev.com/SyntaxHighlighter/donate.html
 *
 * @version
 * 3.0.83 (July 02 2010)
 * 
 * @copyright
 * Copyright (C) 2004-2010 Alex Gorbatchev.
 *
 * @license
 * Dual licensed under the MIT and GPL licenses.
 */
.syntaxhighlighter {
  background-color: transparent !important;
}
.syntaxhighlighter .line.alt1 {
  background-color: transparent !important;
}
.syntaxhighlighter .line.alt2 {
  background-color: transparent !important;
}
.syntaxhighlighter .line.highlighted.alt1, .syntaxhighlighter .line.highlighted.alt2 {
  background-color: #c3defe !important;
}
.syntaxhighlighter .line.highlighted.number {
  color: white !important;
}
.syntaxhighlighter table caption {
  color: black !important;
}
.syntaxhighlighter .gutter {
  color: #787878 !important;
}
.syntaxhighlighter .gutter .line {
  border-right: 3px solid #d4d0c8 !important;
}
.syntaxhighlighter .gutter .line.highlighted {
  background-color: #d4d0c8 !important;
  color: white !important;
}
.syntaxhighlighter.printing .line .content {
  border: none !important;
}
.syntaxhighlighter.collapsed {
  overflow: visible !important;
}
.syntaxhighlighter.collapsed .toolbar {
  color: #3f5fbf !important;
  background: white !important;
  border: 1px solid #d4d0c8 !important;
}
.syntaxhighlighter.collapsed .toolbar a {
  color: #3f5fbf !important;
}
.syntaxhighlighter.collapsed .toolbar a:hover {
  color: #aa7700 !important;
}
.syntaxhighlighter .toolbar {
  color: #a0a0a0 !important;
  background: #d4d0c8 !important;
  border: none !important;
}
.syntaxhighlighter .toolbar a {
  color: #a0a0a0 !important;
}
.syntaxhighlighter .toolbar a:hover {
  color: red !important;
}
.syntaxhighlighter .plain, .syntaxhighlighter .plain a {
  color: black !important;
}
.syntaxhighlighter .comments, .syntaxhighlighter .comments a {
  color: #3f5fbf !important;
}
.syntaxhighlighter .string, .syntaxhighlighter .string a {
  color: #2a00ff !important;
}
.syntaxhighlighter .keyword {
  color: #7f0055 !important;
}
.syntaxhighlighter .preprocessor {
  color: #646464 !important;
}
.syntaxhighlighter .variable {
  color: #aa7700 !important;
}
.syntaxhighlighter .value {
  color: #009900 !important;
}
.syntaxhighlighter .functions {
  color: #ff1493 !important;
}
.syntaxhighlighter .constants {
  color: #0066cc !important;
}
.syntaxhighlighter .script {
  font-weight: bold !important;
  color: #7f0055 !important;
  background-color: none !important;
}
.syntaxhighlighter .color1, .syntaxhighlighter .color1 a {
  color: gray !important;
}
.syntaxhighlighter .color2, .syntaxhighlighter .color2 a {
  color: #ff1493 !important;
}
.syntaxhighlighter .color3, .syntaxhighlighter .color3 a {
  color: red !important;
}

.syntaxhighlighter .xml .keyword {
  color: #3f7f7f !important;
  font-weight: normal !important;
}
.syntaxhighlighter .xml .color1, .syntaxhighlighter .xml .color1 a {
  color: #7f007f !important;
}
.syntaxhighlighter .xml .string {
  font-style: italic !important;
  color: #2a00ff !important;
}

.clojure.syntaxhighlighter .invalid { 
   background-color: #FAA !important;
}

.clojure.syntaxhighlighter .quoted {      
    font-style: italic !important;
}

.syntaxhighlighter .clojure.variable,
.syntaxhighlighter .clojure.symbol,
.syntaxhighlighter .clojure.value
{
    color: #006060 !important;
}

.syntaxhighlighter .clojure.string {
    color: #55B !important;
}

.syntaxhighlighter .clojure.functions {
    color: black !important;
}

.syntaxhighlighter .clojure.color1 {
    color: #666 !important;
}

.syntaxhighlighter .clojure.color3 {
    color: #900 !important;
}

.syntaxhighlighter .clojure.constants {
    color: #1A734D !important;
}

</style><style type="text/css">html{margin:0;padding:0;}h1{margin:0;padding:0;}h2{margin:0;padding:0;}h3{margin:0;padding:0;}h4{margin:0;padding:0;}a{color:#261A3B;}a:visited{color:#261A3B;}</style><style type="text/css">.header{margin-top:30px;}h1.project-name{display:inline;font-size:34px;}h2.project-version{display:inline;margin-left:10px;margin-top:0;font-size:18px;}.toc-link{margin-left:10px;color:#252519;font-size:12px;text-decoration:none;}.toc-link:hover{color:#5050A6;}.toc h1{margin:0;font-size:34px;}.docs-header{margin-bottom:25px;padding-bottom:10px;border-bottom:dotted #aaa 1px;}.toc h1{font-size:24px;}.toc{margin-bottom:40px;border-bottom:solid #bbb 1px;}.toc ul{padding-left:0px;margin-left:20px;margin-top:0;padding-top:0;}.toc li{padding-left:0;list-style-type:none;}.dependencies{}.dependencies table{border:none;width:99.99%;margin-left:20px;font-size:16px;}.dependencies td{padding-right:20px;;white-space:nowrap;}.dependencies .dotted{width:99%;}.dependencies .dotted hr{margin-bottom:-6px;noshade:noshade;border-top:none;color:transparent;border-left:none;border-bottom:dotted #bbb 1px;border-right:none;background-color:transparent;height:0;}.dependencies .dep-version{text-align:right;}.plugins ul{padding-left:0px;margin-left:20px;margin-top:0;padding-top:0;}.plugins li{padding-left:0;list-style-type:none;}.header p{margin-left:20px;}</style><style type="text/css">#floating-toc{position:fixed;text-align:right;overflow:hidden;top:10px;right:20px;height:20px;}#floating-toc li{margin:0;padding:0;list-style-type:none;}</style><style type="text/css">body{margin:0;padding:0;color:#252519;font-size:16px;background-color:#F5F5FF;font-family:'Palatino Linotype', 'Book Antiqua', Palatino, FreeSerif, serif;;}h1{margin-top:0;font-size:20px;}a.anchor{color:#252519;text-decoration:none;}a.anchor:hover{color:#5050A6;}table{margin-bottom:10px;border-bottom:solid #ddd 1px;;border-spacing:0;}code{display:inline;}p{margin-top:8px;}tr{margin:0px;padding:0px;}td.docs{border:none;margin:0px;padding-left:55px;width:410px;padding-right:20px;vertical-align:top;max-width:410px;background-color:#FFF;}td.docs pre{font-size:12px;overflow:hidden;}td.codes{border:none;margin:0px;padding-left:20px;width:55%;border-left:solid #E5E5EE 1px;font-size:10pt;vertical-align:top;overflow:hidden;background-color:#F5F5FF;}td.spacer{padding-bottom:40px;}pre code{display:block;padding:4px;}code{border:solid #DEDEDE 1px;padding-left:3px;padding-right:3px;font-size:14px;background-color:ghostWhite;}.syntaxhighlighter code{font-size:13px;}.footer{text-align:center;}</style><script type="text/javascript">/*!
 * jQuery JavaScript Library v1.4.4
 * http://jquery.com/
 *
 * Copyright 2010, John Resig
 * Dual licensed under the MIT or GPL Version 2 licenses.
 * http://jquery.org/license
 *
 * Includes Sizzle.js
 * http://sizzlejs.com/
 * Copyright 2010, The Dojo Foundation
 * Released under the MIT, BSD, and GPL Licenses.
 *
 * Date: Thu Nov 11 19:04:53 2010 -0500
 */
(function(E,B){function ka(a,b,d){if(d===B&&a.nodeType===1){d=a.getAttribute("data-"+b);if(typeof d==="string"){try{d=d==="true"?true:d==="false"?false:d==="null"?null:!c.isNaN(d)?parseFloat(d):Ja.test(d)?c.parseJSON(d):d}catch(e){}c.data(a,b,d)}else d=B}return d}function U(){return false}function ca(){return true}function la(a,b,d){d[0].type=a;return c.event.handle.apply(b,d)}function Ka(a){var b,d,e,f,h,l,k,o,x,r,A,C=[];f=[];h=c.data(this,this.nodeType?"events":"__events__");if(typeof h==="function")h=
h.events;if(!(a.liveFired===this||!h||!h.live||a.button&&a.type==="click")){if(a.namespace)A=RegExp("(^|\\.)"+a.namespace.split(".").join("\\.(?:.*\\.)?")+"(\\.|$)");a.liveFired=this;var J=h.live.slice(0);for(k=0;k<J.length;k++){h=J[k];h.origType.replace(X,"")===a.type?f.push(h.selector):J.splice(k--,1)}f=c(a.target).closest(f,a.currentTarget);o=0;for(x=f.length;o<x;o++){r=f[o];for(k=0;k<J.length;k++){h=J[k];if(r.selector===h.selector&&(!A||A.test(h.namespace))){l=r.elem;e=null;if(h.preType==="mouseenter"||
h.preType==="mouseleave"){a.type=h.preType;e=c(a.relatedTarget).closest(h.selector)[0]}if(!e||e!==l)C.push({elem:l,handleObj:h,level:r.level})}}}o=0;for(x=C.length;o<x;o++){f=C[o];if(d&&f.level>d)break;a.currentTarget=f.elem;a.data=f.handleObj.data;a.handleObj=f.handleObj;A=f.handleObj.origHandler.apply(f.elem,arguments);if(A===false||a.isPropagationStopped()){d=f.level;if(A===false)b=false;if(a.isImmediatePropagationStopped())break}}return b}}function Y(a,b){return(a&&a!=="*"?a+".":"")+b.replace(La,
"`").replace(Ma,"&")}function ma(a,b,d){if(c.isFunction(b))return c.grep(a,function(f,h){return!!b.call(f,h,f)===d});else if(b.nodeType)return c.grep(a,function(f){return f===b===d});else if(typeof b==="string"){var e=c.grep(a,function(f){return f.nodeType===1});if(Na.test(b))return c.filter(b,e,!d);else b=c.filter(b,e)}return c.grep(a,function(f){return c.inArray(f,b)>=0===d})}function na(a,b){var d=0;b.each(function(){if(this.nodeName===(a[d]&&a[d].nodeName)){var e=c.data(a[d++]),f=c.data(this,
e);if(e=e&&e.events){delete f.handle;f.events={};for(var h in e)for(var l in e[h])c.event.add(this,h,e[h][l],e[h][l].data)}}})}function Oa(a,b){b.src?c.ajax({url:b.src,async:false,dataType:"script"}):c.globalEval(b.text||b.textContent||b.innerHTML||"");b.parentNode&&b.parentNode.removeChild(b)}function oa(a,b,d){var e=b==="width"?a.offsetWidth:a.offsetHeight;if(d==="border")return e;c.each(b==="width"?Pa:Qa,function(){d||(e-=parseFloat(c.css(a,"padding"+this))||0);if(d==="margin")e+=parseFloat(c.css(a,
"margin"+this))||0;else e-=parseFloat(c.css(a,"border"+this+"Width"))||0});return e}function da(a,b,d,e){if(c.isArray(b)&&b.length)c.each(b,function(f,h){d||Ra.test(a)?e(a,h):da(a+"["+(typeof h==="object"||c.isArray(h)?f:"")+"]",h,d,e)});else if(!d&&b!=null&&typeof b==="object")c.isEmptyObject(b)?e(a,""):c.each(b,function(f,h){da(a+"["+f+"]",h,d,e)});else e(a,b)}function S(a,b){var d={};c.each(pa.concat.apply([],pa.slice(0,b)),function(){d[this]=a});return d}function qa(a){if(!ea[a]){var b=c("<"+
a+">").appendTo("body"),d=b.css("display");b.remove();if(d==="none"||d==="")d="block";ea[a]=d}return ea[a]}function fa(a){return c.isWindow(a)?a:a.nodeType===9?a.defaultView||a.parentWindow:false}var t=E.document,c=function(){function a(){if(!b.isReady){try{t.documentElement.doScroll("left")}catch(j){setTimeout(a,1);return}b.ready()}}var b=function(j,s){return new b.fn.init(j,s)},d=E.jQuery,e=E.$,f,h=/^(?:[^<]*(<[\w\W]+>)[^>]*$|#([\w\-]+)$)/,l=/\S/,k=/^\s+/,o=/\s+$/,x=/\W/,r=/\d/,A=/^<(\w+)\s*\/?>(?:<\/\1>)?$/,
C=/^[\],:{}\s]*$/,J=/\\(?:["\\\/bfnrt]|u[0-9a-fA-F]{4})/g,w=/"[^"\\\n\r]*"|true|false|null|-?\d+(?:\.\d*)?(?:[eE][+\-]?\d+)?/g,I=/(?:^|:|,)(?:\s*\[)+/g,L=/(webkit)[ \/]([\w.]+)/,g=/(opera)(?:.*version)?[ \/]([\w.]+)/,i=/(msie) ([\w.]+)/,n=/(mozilla)(?:.*? rv:([\w.]+))?/,m=navigator.userAgent,p=false,q=[],u,y=Object.prototype.toString,F=Object.prototype.hasOwnProperty,M=Array.prototype.push,N=Array.prototype.slice,O=String.prototype.trim,D=Array.prototype.indexOf,R={};b.fn=b.prototype={init:function(j,
s){var v,z,H;if(!j)return this;if(j.nodeType){this.context=this[0]=j;this.length=1;return this}if(j==="body"&&!s&&t.body){this.context=t;this[0]=t.body;this.selector="body";this.length=1;return this}if(typeof j==="string")if((v=h.exec(j))&&(v[1]||!s))if(v[1]){H=s?s.ownerDocument||s:t;if(z=A.exec(j))if(b.isPlainObject(s)){j=[t.createElement(z[1])];b.fn.attr.call(j,s,true)}else j=[H.createElement(z[1])];else{z=b.buildFragment([v[1]],[H]);j=(z.cacheable?z.fragment.cloneNode(true):z.fragment).childNodes}return b.merge(this,
j)}else{if((z=t.getElementById(v[2]))&&z.parentNode){if(z.id!==v[2])return f.find(j);this.length=1;this[0]=z}this.context=t;this.selector=j;return this}else if(!s&&!x.test(j)){this.selector=j;this.context=t;j=t.getElementsByTagName(j);return b.merge(this,j)}else return!s||s.jquery?(s||f).find(j):b(s).find(j);else if(b.isFunction(j))return f.ready(j);if(j.selector!==B){this.selector=j.selector;this.context=j.context}return b.makeArray(j,this)},selector:"",jquery:"1.4.4",length:0,size:function(){return this.length},
toArray:function(){return N.call(this,0)},get:function(j){return j==null?this.toArray():j<0?this.slice(j)[0]:this[j]},pushStack:function(j,s,v){var z=b();b.isArray(j)?M.apply(z,j):b.merge(z,j);z.prevObject=this;z.context=this.context;if(s==="find")z.selector=this.selector+(this.selector?" ":"")+v;else if(s)z.selector=this.selector+"."+s+"("+v+")";return z},each:function(j,s){return b.each(this,j,s)},ready:function(j){b.bindReady();if(b.isReady)j.call(t,b);else q&&q.push(j);return this},eq:function(j){return j===
-1?this.slice(j):this.slice(j,+j+1)},first:function(){return this.eq(0)},last:function(){return this.eq(-1)},slice:function(){return this.pushStack(N.apply(this,arguments),"slice",N.call(arguments).join(","))},map:function(j){return this.pushStack(b.map(this,function(s,v){return j.call(s,v,s)}))},end:function(){return this.prevObject||b(null)},push:M,sort:[].sort,splice:[].splice};b.fn.init.prototype=b.fn;b.extend=b.fn.extend=function(){var j,s,v,z,H,G=arguments[0]||{},K=1,Q=arguments.length,ga=false;
if(typeof G==="boolean"){ga=G;G=arguments[1]||{};K=2}if(typeof G!=="object"&&!b.isFunction(G))G={};if(Q===K){G=this;--K}for(;K<Q;K++)if((j=arguments[K])!=null)for(s in j){v=G[s];z=j[s];if(G!==z)if(ga&&z&&(b.isPlainObject(z)||(H=b.isArray(z)))){if(H){H=false;v=v&&b.isArray(v)?v:[]}else v=v&&b.isPlainObject(v)?v:{};G[s]=b.extend(ga,v,z)}else if(z!==B)G[s]=z}return G};b.extend({noConflict:function(j){E.$=e;if(j)E.jQuery=d;return b},isReady:false,readyWait:1,ready:function(j){j===true&&b.readyWait--;
if(!b.readyWait||j!==true&&!b.isReady){if(!t.body)return setTimeout(b.ready,1);b.isReady=true;if(!(j!==true&&--b.readyWait>0))if(q){var s=0,v=q;for(q=null;j=v[s++];)j.call(t,b);b.fn.trigger&&b(t).trigger("ready").unbind("ready")}}},bindReady:function(){if(!p){p=true;if(t.readyState==="complete")return setTimeout(b.ready,1);if(t.addEventListener){t.addEventListener("DOMContentLoaded",u,false);E.addEventListener("load",b.ready,false)}else if(t.attachEvent){t.attachEvent("onreadystatechange",u);E.attachEvent("onload",
b.ready);var j=false;try{j=E.frameElement==null}catch(s){}t.documentElement.doScroll&&j&&a()}}},isFunction:function(j){return b.type(j)==="function"},isArray:Array.isArray||function(j){return b.type(j)==="array"},isWindow:function(j){return j&&typeof j==="object"&&"setInterval"in j},isNaN:function(j){return j==null||!r.test(j)||isNaN(j)},type:function(j){return j==null?String(j):R[y.call(j)]||"object"},isPlainObject:function(j){if(!j||b.type(j)!=="object"||j.nodeType||b.isWindow(j))return false;if(j.constructor&&
!F.call(j,"constructor")&&!F.call(j.constructor.prototype,"isPrototypeOf"))return false;for(var s in j);return s===B||F.call(j,s)},isEmptyObject:function(j){for(var s in j)return false;return true},error:function(j){throw j;},parseJSON:function(j){if(typeof j!=="string"||!j)return null;j=b.trim(j);if(C.test(j.replace(J,"@").replace(w,"]").replace(I,"")))return E.JSON&&E.JSON.parse?E.JSON.parse(j):(new Function("return "+j))();else b.error("Invalid JSON: "+j)},noop:function(){},globalEval:function(j){if(j&&
l.test(j)){var s=t.getElementsByTagName("head")[0]||t.documentElement,v=t.createElement("script");v.type="text/javascript";if(b.support.scriptEval)v.appendChild(t.createTextNode(j));else v.text=j;s.insertBefore(v,s.firstChild);s.removeChild(v)}},nodeName:function(j,s){return j.nodeName&&j.nodeName.toUpperCase()===s.toUpperCase()},each:function(j,s,v){var z,H=0,G=j.length,K=G===B||b.isFunction(j);if(v)if(K)for(z in j){if(s.apply(j[z],v)===false)break}else for(;H<G;){if(s.apply(j[H++],v)===false)break}else if(K)for(z in j){if(s.call(j[z],
z,j[z])===false)break}else for(v=j[0];H<G&&s.call(v,H,v)!==false;v=j[++H]);return j},trim:O?function(j){return j==null?"":O.call(j)}:function(j){return j==null?"":j.toString().replace(k,"").replace(o,"")},makeArray:function(j,s){var v=s||[];if(j!=null){var z=b.type(j);j.length==null||z==="string"||z==="function"||z==="regexp"||b.isWindow(j)?M.call(v,j):b.merge(v,j)}return v},inArray:function(j,s){if(s.indexOf)return s.indexOf(j);for(var v=0,z=s.length;v<z;v++)if(s[v]===j)return v;return-1},merge:function(j,
s){var v=j.length,z=0;if(typeof s.length==="number")for(var H=s.length;z<H;z++)j[v++]=s[z];else for(;s[z]!==B;)j[v++]=s[z++];j.length=v;return j},grep:function(j,s,v){var z=[],H;v=!!v;for(var G=0,K=j.length;G<K;G++){H=!!s(j[G],G);v!==H&&z.push(j[G])}return z},map:function(j,s,v){for(var z=[],H,G=0,K=j.length;G<K;G++){H=s(j[G],G,v);if(H!=null)z[z.length]=H}return z.concat.apply([],z)},guid:1,proxy:function(j,s,v){if(arguments.length===2)if(typeof s==="string"){v=j;j=v[s];s=B}else if(s&&!b.isFunction(s)){v=
s;s=B}if(!s&&j)s=function(){return j.apply(v||this,arguments)};if(j)s.guid=j.guid=j.guid||s.guid||b.guid++;return s},access:function(j,s,v,z,H,G){var K=j.length;if(typeof s==="object"){for(var Q in s)b.access(j,Q,s[Q],z,H,v);return j}if(v!==B){z=!G&&z&&b.isFunction(v);for(Q=0;Q<K;Q++)H(j[Q],s,z?v.call(j[Q],Q,H(j[Q],s)):v,G);return j}return K?H(j[0],s):B},now:function(){return(new Date).getTime()},uaMatch:function(j){j=j.toLowerCase();j=L.exec(j)||g.exec(j)||i.exec(j)||j.indexOf("compatible")<0&&n.exec(j)||
[];return{browser:j[1]||"",version:j[2]||"0"}},browser:{}});b.each("Boolean Number String Function Array Date RegExp Object".split(" "),function(j,s){R["[object "+s+"]"]=s.toLowerCase()});m=b.uaMatch(m);if(m.browser){b.browser[m.browser]=true;b.browser.version=m.version}if(b.browser.webkit)b.browser.safari=true;if(D)b.inArray=function(j,s){return D.call(s,j)};if(!/\s/.test("\u00a0")){k=/^[\s\xA0]+/;o=/[\s\xA0]+$/}f=b(t);if(t.addEventListener)u=function(){t.removeEventListener("DOMContentLoaded",u,
false);b.ready()};else if(t.attachEvent)u=function(){if(t.readyState==="complete"){t.detachEvent("onreadystatechange",u);b.ready()}};return E.jQuery=E.$=b}();(function(){c.support={};var a=t.documentElement,b=t.createElement("script"),d=t.createElement("div"),e="script"+c.now();d.style.display="none";d.innerHTML="   <link/><table></table><a href='/a' style='color:red;float:left;opacity:.55;'>a</a><input type='checkbox'/>";var f=d.getElementsByTagName("*"),h=d.getElementsByTagName("a")[0],l=t.createElement("select"),
k=l.appendChild(t.createElement("option"));if(!(!f||!f.length||!h)){c.support={leadingWhitespace:d.firstChild.nodeType===3,tbody:!d.getElementsByTagName("tbody").length,htmlSerialize:!!d.getElementsByTagName("link").length,style:/red/.test(h.getAttribute("style")),hrefNormalized:h.getAttribute("href")==="/a",opacity:/^0.55$/.test(h.style.opacity),cssFloat:!!h.style.cssFloat,checkOn:d.getElementsByTagName("input")[0].value==="on",optSelected:k.selected,deleteExpando:true,optDisabled:false,checkClone:false,
scriptEval:false,noCloneEvent:true,boxModel:null,inlineBlockNeedsLayout:false,shrinkWrapBlocks:false,reliableHiddenOffsets:true};l.disabled=true;c.support.optDisabled=!k.disabled;b.type="text/javascript";try{b.appendChild(t.createTextNode("window."+e+"=1;"))}catch(o){}a.insertBefore(b,a.firstChild);if(E[e]){c.support.scriptEval=true;delete E[e]}try{delete b.test}catch(x){c.support.deleteExpando=false}a.removeChild(b);if(d.attachEvent&&d.fireEvent){d.attachEvent("onclick",function r(){c.support.noCloneEvent=
false;d.detachEvent("onclick",r)});d.cloneNode(true).fireEvent("onclick")}d=t.createElement("div");d.innerHTML="<input type='radio' name='radiotest' checked='checked'/>";a=t.createDocumentFragment();a.appendChild(d.firstChild);c.support.checkClone=a.cloneNode(true).cloneNode(true).lastChild.checked;c(function(){var r=t.createElement("div");r.style.width=r.style.paddingLeft="1px";t.body.appendChild(r);c.boxModel=c.support.boxModel=r.offsetWidth===2;if("zoom"in r.style){r.style.display="inline";r.style.zoom=
1;c.support.inlineBlockNeedsLayout=r.offsetWidth===2;r.style.display="";r.innerHTML="<div style='width:4px;'></div>";c.support.shrinkWrapBlocks=r.offsetWidth!==2}r.innerHTML="<table><tr><td style='padding:0;display:none'></td><td>t</td></tr></table>";var A=r.getElementsByTagName("td");c.support.reliableHiddenOffsets=A[0].offsetHeight===0;A[0].style.display="";A[1].style.display="none";c.support.reliableHiddenOffsets=c.support.reliableHiddenOffsets&&A[0].offsetHeight===0;r.innerHTML="";t.body.removeChild(r).style.display=
"none"});a=function(r){var A=t.createElement("div");r="on"+r;var C=r in A;if(!C){A.setAttribute(r,"return;");C=typeof A[r]==="function"}return C};c.support.submitBubbles=a("submit");c.support.changeBubbles=a("change");a=b=d=f=h=null}})();var ra={},Ja=/^(?:\{.*\}|\[.*\])$/;c.extend({cache:{},uuid:0,expando:"jQuery"+c.now(),noData:{embed:true,object:"clsid:D27CDB6E-AE6D-11cf-96B8-444553540000",applet:true},data:function(a,b,d){if(c.acceptData(a)){a=a==E?ra:a;var e=a.nodeType,f=e?a[c.expando]:null,h=
c.cache;if(!(e&&!f&&typeof b==="string"&&d===B)){if(e)f||(a[c.expando]=f=++c.uuid);else h=a;if(typeof b==="object")if(e)h[f]=c.extend(h[f],b);else c.extend(h,b);else if(e&&!h[f])h[f]={};a=e?h[f]:h;if(d!==B)a[b]=d;return typeof b==="string"?a[b]:a}}},removeData:function(a,b){if(c.acceptData(a)){a=a==E?ra:a;var d=a.nodeType,e=d?a[c.expando]:a,f=c.cache,h=d?f[e]:e;if(b){if(h){delete h[b];d&&c.isEmptyObject(h)&&c.removeData(a)}}else if(d&&c.support.deleteExpando)delete a[c.expando];else if(a.removeAttribute)a.removeAttribute(c.expando);
else if(d)delete f[e];else for(var l in a)delete a[l]}},acceptData:function(a){if(a.nodeName){var b=c.noData[a.nodeName.toLowerCase()];if(b)return!(b===true||a.getAttribute("classid")!==b)}return true}});c.fn.extend({data:function(a,b){var d=null;if(typeof a==="undefined"){if(this.length){var e=this[0].attributes,f;d=c.data(this[0]);for(var h=0,l=e.length;h<l;h++){f=e[h].name;if(f.indexOf("data-")===0){f=f.substr(5);ka(this[0],f,d[f])}}}return d}else if(typeof a==="object")return this.each(function(){c.data(this,
a)});var k=a.split(".");k[1]=k[1]?"."+k[1]:"";if(b===B){d=this.triggerHandler("getData"+k[1]+"!",[k[0]]);if(d===B&&this.length){d=c.data(this[0],a);d=ka(this[0],a,d)}return d===B&&k[1]?this.data(k[0]):d}else return this.each(function(){var o=c(this),x=[k[0],b];o.triggerHandler("setData"+k[1]+"!",x);c.data(this,a,b);o.triggerHandler("changeData"+k[1]+"!",x)})},removeData:function(a){return this.each(function(){c.removeData(this,a)})}});c.extend({queue:function(a,b,d){if(a){b=(b||"fx")+"queue";var e=
c.data(a,b);if(!d)return e||[];if(!e||c.isArray(d))e=c.data(a,b,c.makeArray(d));else e.push(d);return e}},dequeue:function(a,b){b=b||"fx";var d=c.queue(a,b),e=d.shift();if(e==="inprogress")e=d.shift();if(e){b==="fx"&&d.unshift("inprogress");e.call(a,function(){c.dequeue(a,b)})}}});c.fn.extend({queue:function(a,b){if(typeof a!=="string"){b=a;a="fx"}if(b===B)return c.queue(this[0],a);return this.each(function(){var d=c.queue(this,a,b);a==="fx"&&d[0]!=="inprogress"&&c.dequeue(this,a)})},dequeue:function(a){return this.each(function(){c.dequeue(this,
a)})},delay:function(a,b){a=c.fx?c.fx.speeds[a]||a:a;b=b||"fx";return this.queue(b,function(){var d=this;setTimeout(function(){c.dequeue(d,b)},a)})},clearQueue:function(a){return this.queue(a||"fx",[])}});var sa=/[\n\t]/g,ha=/\s+/,Sa=/\r/g,Ta=/^(?:href|src|style)$/,Ua=/^(?:button|input)$/i,Va=/^(?:button|input|object|select|textarea)$/i,Wa=/^a(?:rea)?$/i,ta=/^(?:radio|checkbox)$/i;c.props={"for":"htmlFor","class":"className",readonly:"readOnly",maxlength:"maxLength",cellspacing:"cellSpacing",rowspan:"rowSpan",
colspan:"colSpan",tabindex:"tabIndex",usemap:"useMap",frameborder:"frameBorder"};c.fn.extend({attr:function(a,b){return c.access(this,a,b,true,c.attr)},removeAttr:function(a){return this.each(function(){c.attr(this,a,"");this.nodeType===1&&this.removeAttribute(a)})},addClass:function(a){if(c.isFunction(a))return this.each(function(x){var r=c(this);r.addClass(a.call(this,x,r.attr("class")))});if(a&&typeof a==="string")for(var b=(a||"").split(ha),d=0,e=this.length;d<e;d++){var f=this[d];if(f.nodeType===
1)if(f.className){for(var h=" "+f.className+" ",l=f.className,k=0,o=b.length;k<o;k++)if(h.indexOf(" "+b[k]+" ")<0)l+=" "+b[k];f.className=c.trim(l)}else f.className=a}return this},removeClass:function(a){if(c.isFunction(a))return this.each(function(o){var x=c(this);x.removeClass(a.call(this,o,x.attr("class")))});if(a&&typeof a==="string"||a===B)for(var b=(a||"").split(ha),d=0,e=this.length;d<e;d++){var f=this[d];if(f.nodeType===1&&f.className)if(a){for(var h=(" "+f.className+" ").replace(sa," "),
l=0,k=b.length;l<k;l++)h=h.replace(" "+b[l]+" "," ");f.className=c.trim(h)}else f.className=""}return this},toggleClass:function(a,b){var d=typeof a,e=typeof b==="boolean";if(c.isFunction(a))return this.each(function(f){var h=c(this);h.toggleClass(a.call(this,f,h.attr("class"),b),b)});return this.each(function(){if(d==="string")for(var f,h=0,l=c(this),k=b,o=a.split(ha);f=o[h++];){k=e?k:!l.hasClass(f);l[k?"addClass":"removeClass"](f)}else if(d==="undefined"||d==="boolean"){this.className&&c.data(this,
"__className__",this.className);this.className=this.className||a===false?"":c.data(this,"__className__")||""}})},hasClass:function(a){a=" "+a+" ";for(var b=0,d=this.length;b<d;b++)if((" "+this[b].className+" ").replace(sa," ").indexOf(a)>-1)return true;return false},val:function(a){if(!arguments.length){var b=this[0];if(b){if(c.nodeName(b,"option")){var d=b.attributes.value;return!d||d.specified?b.value:b.text}if(c.nodeName(b,"select")){var e=b.selectedIndex;d=[];var f=b.options;b=b.type==="select-one";
if(e<0)return null;var h=b?e:0;for(e=b?e+1:f.length;h<e;h++){var l=f[h];if(l.selected&&(c.support.optDisabled?!l.disabled:l.getAttribute("disabled")===null)&&(!l.parentNode.disabled||!c.nodeName(l.parentNode,"optgroup"))){a=c(l).val();if(b)return a;d.push(a)}}return d}if(ta.test(b.type)&&!c.support.checkOn)return b.getAttribute("value")===null?"on":b.value;return(b.value||"").replace(Sa,"")}return B}var k=c.isFunction(a);return this.each(function(o){var x=c(this),r=a;if(this.nodeType===1){if(k)r=
a.call(this,o,x.val());if(r==null)r="";else if(typeof r==="number")r+="";else if(c.isArray(r))r=c.map(r,function(C){return C==null?"":C+""});if(c.isArray(r)&&ta.test(this.type))this.checked=c.inArray(x.val(),r)>=0;else if(c.nodeName(this,"select")){var A=c.makeArray(r);c("option",this).each(function(){this.selected=c.inArray(c(this).val(),A)>=0});if(!A.length)this.selectedIndex=-1}else this.value=r}})}});c.extend({attrFn:{val:true,css:true,html:true,text:true,data:true,width:true,height:true,offset:true},
attr:function(a,b,d,e){if(!a||a.nodeType===3||a.nodeType===8)return B;if(e&&b in c.attrFn)return c(a)[b](d);e=a.nodeType!==1||!c.isXMLDoc(a);var f=d!==B;b=e&&c.props[b]||b;var h=Ta.test(b);if((b in a||a[b]!==B)&&e&&!h){if(f){b==="type"&&Ua.test(a.nodeName)&&a.parentNode&&c.error("type property can't be changed");if(d===null)a.nodeType===1&&a.removeAttribute(b);else a[b]=d}if(c.nodeName(a,"form")&&a.getAttributeNode(b))return a.getAttributeNode(b).nodeValue;if(b==="tabIndex")return(b=a.getAttributeNode("tabIndex"))&&
b.specified?b.value:Va.test(a.nodeName)||Wa.test(a.nodeName)&&a.href?0:B;return a[b]}if(!c.support.style&&e&&b==="style"){if(f)a.style.cssText=""+d;return a.style.cssText}f&&a.setAttribute(b,""+d);if(!a.attributes[b]&&a.hasAttribute&&!a.hasAttribute(b))return B;a=!c.support.hrefNormalized&&e&&h?a.getAttribute(b,2):a.getAttribute(b);return a===null?B:a}});var X=/\.(.*)$/,ia=/^(?:textarea|input|select)$/i,La=/\./g,Ma=/ /g,Xa=/[^\w\s.|`]/g,Ya=function(a){return a.replace(Xa,"\\$&")},ua={focusin:0,focusout:0};
c.event={add:function(a,b,d,e){if(!(a.nodeType===3||a.nodeType===8)){if(c.isWindow(a)&&a!==E&&!a.frameElement)a=E;if(d===false)d=U;else if(!d)return;var f,h;if(d.handler){f=d;d=f.handler}if(!d.guid)d.guid=c.guid++;if(h=c.data(a)){var l=a.nodeType?"events":"__events__",k=h[l],o=h.handle;if(typeof k==="function"){o=k.handle;k=k.events}else if(!k){a.nodeType||(h[l]=h=function(){});h.events=k={}}if(!o)h.handle=o=function(){return typeof c!=="undefined"&&!c.event.triggered?c.event.handle.apply(o.elem,
arguments):B};o.elem=a;b=b.split(" ");for(var x=0,r;l=b[x++];){h=f?c.extend({},f):{handler:d,data:e};if(l.indexOf(".")>-1){r=l.split(".");l=r.shift();h.namespace=r.slice(0).sort().join(".")}else{r=[];h.namespace=""}h.type=l;if(!h.guid)h.guid=d.guid;var A=k[l],C=c.event.special[l]||{};if(!A){A=k[l]=[];if(!C.setup||C.setup.call(a,e,r,o)===false)if(a.addEventListener)a.addEventListener(l,o,false);else a.attachEvent&&a.attachEvent("on"+l,o)}if(C.add){C.add.call(a,h);if(!h.handler.guid)h.handler.guid=
d.guid}A.push(h);c.event.global[l]=true}a=null}}},global:{},remove:function(a,b,d,e){if(!(a.nodeType===3||a.nodeType===8)){if(d===false)d=U;var f,h,l=0,k,o,x,r,A,C,J=a.nodeType?"events":"__events__",w=c.data(a),I=w&&w[J];if(w&&I){if(typeof I==="function"){w=I;I=I.events}if(b&&b.type){d=b.handler;b=b.type}if(!b||typeof b==="string"&&b.charAt(0)==="."){b=b||"";for(f in I)c.event.remove(a,f+b)}else{for(b=b.split(" ");f=b[l++];){r=f;k=f.indexOf(".")<0;o=[];if(!k){o=f.split(".");f=o.shift();x=RegExp("(^|\\.)"+
c.map(o.slice(0).sort(),Ya).join("\\.(?:.*\\.)?")+"(\\.|$)")}if(A=I[f])if(d){r=c.event.special[f]||{};for(h=e||0;h<A.length;h++){C=A[h];if(d.guid===C.guid){if(k||x.test(C.namespace)){e==null&&A.splice(h--,1);r.remove&&r.remove.call(a,C)}if(e!=null)break}}if(A.length===0||e!=null&&A.length===1){if(!r.teardown||r.teardown.call(a,o)===false)c.removeEvent(a,f,w.handle);delete I[f]}}else for(h=0;h<A.length;h++){C=A[h];if(k||x.test(C.namespace)){c.event.remove(a,r,C.handler,h);A.splice(h--,1)}}}if(c.isEmptyObject(I)){if(b=
w.handle)b.elem=null;delete w.events;delete w.handle;if(typeof w==="function")c.removeData(a,J);else c.isEmptyObject(w)&&c.removeData(a)}}}}},trigger:function(a,b,d,e){var f=a.type||a;if(!e){a=typeof a==="object"?a[c.expando]?a:c.extend(c.Event(f),a):c.Event(f);if(f.indexOf("!")>=0){a.type=f=f.slice(0,-1);a.exclusive=true}if(!d){a.stopPropagation();c.event.global[f]&&c.each(c.cache,function(){this.events&&this.events[f]&&c.event.trigger(a,b,this.handle.elem)})}if(!d||d.nodeType===3||d.nodeType===
8)return B;a.result=B;a.target=d;b=c.makeArray(b);b.unshift(a)}a.currentTarget=d;(e=d.nodeType?c.data(d,"handle"):(c.data(d,"__events__")||{}).handle)&&e.apply(d,b);e=d.parentNode||d.ownerDocument;try{if(!(d&&d.nodeName&&c.noData[d.nodeName.toLowerCase()]))if(d["on"+f]&&d["on"+f].apply(d,b)===false){a.result=false;a.preventDefault()}}catch(h){}if(!a.isPropagationStopped()&&e)c.event.trigger(a,b,e,true);else if(!a.isDefaultPrevented()){var l;e=a.target;var k=f.replace(X,""),o=c.nodeName(e,"a")&&k===
"click",x=c.event.special[k]||{};if((!x._default||x._default.call(d,a)===false)&&!o&&!(e&&e.nodeName&&c.noData[e.nodeName.toLowerCase()])){try{if(e[k]){if(l=e["on"+k])e["on"+k]=null;c.event.triggered=true;e[k]()}}catch(r){}if(l)e["on"+k]=l;c.event.triggered=false}}},handle:function(a){var b,d,e,f;d=[];var h=c.makeArray(arguments);a=h[0]=c.event.fix(a||E.event);a.currentTarget=this;b=a.type.indexOf(".")<0&&!a.exclusive;if(!b){e=a.type.split(".");a.type=e.shift();d=e.slice(0).sort();e=RegExp("(^|\\.)"+
d.join("\\.(?:.*\\.)?")+"(\\.|$)")}a.namespace=a.namespace||d.join(".");f=c.data(this,this.nodeType?"events":"__events__");if(typeof f==="function")f=f.events;d=(f||{})[a.type];if(f&&d){d=d.slice(0);f=0;for(var l=d.length;f<l;f++){var k=d[f];if(b||e.test(k.namespace)){a.handler=k.handler;a.data=k.data;a.handleObj=k;k=k.handler.apply(this,h);if(k!==B){a.result=k;if(k===false){a.preventDefault();a.stopPropagation()}}if(a.isImmediatePropagationStopped())break}}}return a.result},props:"altKey attrChange attrName bubbles button cancelable charCode clientX clientY ctrlKey currentTarget data detail eventPhase fromElement handler keyCode layerX layerY metaKey newValue offsetX offsetY pageX pageY prevValue relatedNode relatedTarget screenX screenY shiftKey srcElement target toElement view wheelDelta which".split(" "),
fix:function(a){if(a[c.expando])return a;var b=a;a=c.Event(b);for(var d=this.props.length,e;d;){e=this.props[--d];a[e]=b[e]}if(!a.target)a.target=a.srcElement||t;if(a.target.nodeType===3)a.target=a.target.parentNode;if(!a.relatedTarget&&a.fromElement)a.relatedTarget=a.fromElement===a.target?a.toElement:a.fromElement;if(a.pageX==null&&a.clientX!=null){b=t.documentElement;d=t.body;a.pageX=a.clientX+(b&&b.scrollLeft||d&&d.scrollLeft||0)-(b&&b.clientLeft||d&&d.clientLeft||0);a.pageY=a.clientY+(b&&b.scrollTop||
d&&d.scrollTop||0)-(b&&b.clientTop||d&&d.clientTop||0)}if(a.which==null&&(a.charCode!=null||a.keyCode!=null))a.which=a.charCode!=null?a.charCode:a.keyCode;if(!a.metaKey&&a.ctrlKey)a.metaKey=a.ctrlKey;if(!a.which&&a.button!==B)a.which=a.button&1?1:a.button&2?3:a.button&4?2:0;return a},guid:1E8,proxy:c.proxy,special:{ready:{setup:c.bindReady,teardown:c.noop},live:{add:function(a){c.event.add(this,Y(a.origType,a.selector),c.extend({},a,{handler:Ka,guid:a.handler.guid}))},remove:function(a){c.event.remove(this,
Y(a.origType,a.selector),a)}},beforeunload:{setup:function(a,b,d){if(c.isWindow(this))this.onbeforeunload=d},teardown:function(a,b){if(this.onbeforeunload===b)this.onbeforeunload=null}}}};c.removeEvent=t.removeEventListener?function(a,b,d){a.removeEventListener&&a.removeEventListener(b,d,false)}:function(a,b,d){a.detachEvent&&a.detachEvent("on"+b,d)};c.Event=function(a){if(!this.preventDefault)return new c.Event(a);if(a&&a.type){this.originalEvent=a;this.type=a.type}else this.type=a;this.timeStamp=
c.now();this[c.expando]=true};c.Event.prototype={preventDefault:function(){this.isDefaultPrevented=ca;var a=this.originalEvent;if(a)if(a.preventDefault)a.preventDefault();else a.returnValue=false},stopPropagation:function(){this.isPropagationStopped=ca;var a=this.originalEvent;if(a){a.stopPropagation&&a.stopPropagation();a.cancelBubble=true}},stopImmediatePropagation:function(){this.isImmediatePropagationStopped=ca;this.stopPropagation()},isDefaultPrevented:U,isPropagationStopped:U,isImmediatePropagationStopped:U};
var va=function(a){var b=a.relatedTarget;try{for(;b&&b!==this;)b=b.parentNode;if(b!==this){a.type=a.data;c.event.handle.apply(this,arguments)}}catch(d){}},wa=function(a){a.type=a.data;c.event.handle.apply(this,arguments)};c.each({mouseenter:"mouseover",mouseleave:"mouseout"},function(a,b){c.event.special[a]={setup:function(d){c.event.add(this,b,d&&d.selector?wa:va,a)},teardown:function(d){c.event.remove(this,b,d&&d.selector?wa:va)}}});if(!c.support.submitBubbles)c.event.special.submit={setup:function(){if(this.nodeName.toLowerCase()!==
"form"){c.event.add(this,"click.specialSubmit",function(a){var b=a.target,d=b.type;if((d==="submit"||d==="image")&&c(b).closest("form").length){a.liveFired=B;return la("submit",this,arguments)}});c.event.add(this,"keypress.specialSubmit",function(a){var b=a.target,d=b.type;if((d==="text"||d==="password")&&c(b).closest("form").length&&a.keyCode===13){a.liveFired=B;return la("submit",this,arguments)}})}else return false},teardown:function(){c.event.remove(this,".specialSubmit")}};if(!c.support.changeBubbles){var V,
xa=function(a){var b=a.type,d=a.value;if(b==="radio"||b==="checkbox")d=a.checked;else if(b==="select-multiple")d=a.selectedIndex>-1?c.map(a.options,function(e){return e.selected}).join("-"):"";else if(a.nodeName.toLowerCase()==="select")d=a.selectedIndex;return d},Z=function(a,b){var d=a.target,e,f;if(!(!ia.test(d.nodeName)||d.readOnly)){e=c.data(d,"_change_data");f=xa(d);if(a.type!=="focusout"||d.type!=="radio")c.data(d,"_change_data",f);if(!(e===B||f===e))if(e!=null||f){a.type="change";a.liveFired=
B;return c.event.trigger(a,b,d)}}};c.event.special.change={filters:{focusout:Z,beforedeactivate:Z,click:function(a){var b=a.target,d=b.type;if(d==="radio"||d==="checkbox"||b.nodeName.toLowerCase()==="select")return Z.call(this,a)},keydown:function(a){var b=a.target,d=b.type;if(a.keyCode===13&&b.nodeName.toLowerCase()!=="textarea"||a.keyCode===32&&(d==="checkbox"||d==="radio")||d==="select-multiple")return Z.call(this,a)},beforeactivate:function(a){a=a.target;c.data(a,"_change_data",xa(a))}},setup:function(){if(this.type===
"file")return false;for(var a in V)c.event.add(this,a+".specialChange",V[a]);return ia.test(this.nodeName)},teardown:function(){c.event.remove(this,".specialChange");return ia.test(this.nodeName)}};V=c.event.special.change.filters;V.focus=V.beforeactivate}t.addEventListener&&c.each({focus:"focusin",blur:"focusout"},function(a,b){function d(e){e=c.event.fix(e);e.type=b;return c.event.trigger(e,null,e.target)}c.event.special[b]={setup:function(){ua[b]++===0&&t.addEventListener(a,d,true)},teardown:function(){--ua[b]===
0&&t.removeEventListener(a,d,true)}}});c.each(["bind","one"],function(a,b){c.fn[b]=function(d,e,f){if(typeof d==="object"){for(var h in d)this[b](h,e,d[h],f);return this}if(c.isFunction(e)||e===false){f=e;e=B}var l=b==="one"?c.proxy(f,function(o){c(this).unbind(o,l);return f.apply(this,arguments)}):f;if(d==="unload"&&b!=="one")this.one(d,e,f);else{h=0;for(var k=this.length;h<k;h++)c.event.add(this[h],d,l,e)}return this}});c.fn.extend({unbind:function(a,b){if(typeof a==="object"&&!a.preventDefault)for(var d in a)this.unbind(d,
a[d]);else{d=0;for(var e=this.length;d<e;d++)c.event.remove(this[d],a,b)}return this},delegate:function(a,b,d,e){return this.live(b,d,e,a)},undelegate:function(a,b,d){return arguments.length===0?this.unbind("live"):this.die(b,null,d,a)},trigger:function(a,b){return this.each(function(){c.event.trigger(a,b,this)})},triggerHandler:function(a,b){if(this[0]){var d=c.Event(a);d.preventDefault();d.stopPropagation();c.event.trigger(d,b,this[0]);return d.result}},toggle:function(a){for(var b=arguments,d=
1;d<b.length;)c.proxy(a,b[d++]);return this.click(c.proxy(a,function(e){var f=(c.data(this,"lastToggle"+a.guid)||0)%d;c.data(this,"lastToggle"+a.guid,f+1);e.preventDefault();return b[f].apply(this,arguments)||false}))},hover:function(a,b){return this.mouseenter(a).mouseleave(b||a)}});var ya={focus:"focusin",blur:"focusout",mouseenter:"mouseover",mouseleave:"mouseout"};c.each(["live","die"],function(a,b){c.fn[b]=function(d,e,f,h){var l,k=0,o,x,r=h||this.selector;h=h?this:c(this.context);if(typeof d===
"object"&&!d.preventDefault){for(l in d)h[b](l,e,d[l],r);return this}if(c.isFunction(e)){f=e;e=B}for(d=(d||"").split(" ");(l=d[k++])!=null;){o=X.exec(l);x="";if(o){x=o[0];l=l.replace(X,"")}if(l==="hover")d.push("mouseenter"+x,"mouseleave"+x);else{o=l;if(l==="focus"||l==="blur"){d.push(ya[l]+x);l+=x}else l=(ya[l]||l)+x;if(b==="live"){x=0;for(var A=h.length;x<A;x++)c.event.add(h[x],"live."+Y(l,r),{data:e,selector:r,handler:f,origType:l,origHandler:f,preType:o})}else h.unbind("live."+Y(l,r),f)}}return this}});
c.each("blur focus focusin focusout load resize scroll unload click dblclick mousedown mouseup mousemove mouseover mouseout mouseenter mouseleave change select submit keydown keypress keyup error".split(" "),function(a,b){c.fn[b]=function(d,e){if(e==null){e=d;d=null}return arguments.length>0?this.bind(b,d,e):this.trigger(b)};if(c.attrFn)c.attrFn[b]=true});E.attachEvent&&!E.addEventListener&&c(E).bind("unload",function(){for(var a in c.cache)if(c.cache[a].handle)try{c.event.remove(c.cache[a].handle.elem)}catch(b){}});
(function(){function a(g,i,n,m,p,q){p=0;for(var u=m.length;p<u;p++){var y=m[p];if(y){var F=false;for(y=y[g];y;){if(y.sizcache===n){F=m[y.sizset];break}if(y.nodeType===1&&!q){y.sizcache=n;y.sizset=p}if(y.nodeName.toLowerCase()===i){F=y;break}y=y[g]}m[p]=F}}}function b(g,i,n,m,p,q){p=0;for(var u=m.length;p<u;p++){var y=m[p];if(y){var F=false;for(y=y[g];y;){if(y.sizcache===n){F=m[y.sizset];break}if(y.nodeType===1){if(!q){y.sizcache=n;y.sizset=p}if(typeof i!=="string"){if(y===i){F=true;break}}else if(k.filter(i,
[y]).length>0){F=y;break}}y=y[g]}m[p]=F}}}var d=/((?:\((?:\([^()]+\)|[^()]+)+\)|\[(?:\[[^\[\]]*\]|['"][^'"]*['"]|[^\[\]'"]+)+\]|\\.|[^ >+~,(\[\\]+)+|[>+~])(\s*,\s*)?((?:.|\r|\n)*)/g,e=0,f=Object.prototype.toString,h=false,l=true;[0,0].sort(function(){l=false;return 0});var k=function(g,i,n,m){n=n||[];var p=i=i||t;if(i.nodeType!==1&&i.nodeType!==9)return[];if(!g||typeof g!=="string")return n;var q,u,y,F,M,N=true,O=k.isXML(i),D=[],R=g;do{d.exec("");if(q=d.exec(R)){R=q[3];D.push(q[1]);if(q[2]){F=q[3];
break}}}while(q);if(D.length>1&&x.exec(g))if(D.length===2&&o.relative[D[0]])u=L(D[0]+D[1],i);else for(u=o.relative[D[0]]?[i]:k(D.shift(),i);D.length;){g=D.shift();if(o.relative[g])g+=D.shift();u=L(g,u)}else{if(!m&&D.length>1&&i.nodeType===9&&!O&&o.match.ID.test(D[0])&&!o.match.ID.test(D[D.length-1])){q=k.find(D.shift(),i,O);i=q.expr?k.filter(q.expr,q.set)[0]:q.set[0]}if(i){q=m?{expr:D.pop(),set:C(m)}:k.find(D.pop(),D.length===1&&(D[0]==="~"||D[0]==="+")&&i.parentNode?i.parentNode:i,O);u=q.expr?k.filter(q.expr,
q.set):q.set;if(D.length>0)y=C(u);else N=false;for(;D.length;){q=M=D.pop();if(o.relative[M])q=D.pop();else M="";if(q==null)q=i;o.relative[M](y,q,O)}}else y=[]}y||(y=u);y||k.error(M||g);if(f.call(y)==="[object Array]")if(N)if(i&&i.nodeType===1)for(g=0;y[g]!=null;g++){if(y[g]&&(y[g]===true||y[g].nodeType===1&&k.contains(i,y[g])))n.push(u[g])}else for(g=0;y[g]!=null;g++)y[g]&&y[g].nodeType===1&&n.push(u[g]);else n.push.apply(n,y);else C(y,n);if(F){k(F,p,n,m);k.uniqueSort(n)}return n};k.uniqueSort=function(g){if(w){h=
l;g.sort(w);if(h)for(var i=1;i<g.length;i++)g[i]===g[i-1]&&g.splice(i--,1)}return g};k.matches=function(g,i){return k(g,null,null,i)};k.matchesSelector=function(g,i){return k(i,null,null,[g]).length>0};k.find=function(g,i,n){var m;if(!g)return[];for(var p=0,q=o.order.length;p<q;p++){var u,y=o.order[p];if(u=o.leftMatch[y].exec(g)){var F=u[1];u.splice(1,1);if(F.substr(F.length-1)!=="\\"){u[1]=(u[1]||"").replace(/\\/g,"");m=o.find[y](u,i,n);if(m!=null){g=g.replace(o.match[y],"");break}}}}m||(m=i.getElementsByTagName("*"));
return{set:m,expr:g}};k.filter=function(g,i,n,m){for(var p,q,u=g,y=[],F=i,M=i&&i[0]&&k.isXML(i[0]);g&&i.length;){for(var N in o.filter)if((p=o.leftMatch[N].exec(g))!=null&&p[2]){var O,D,R=o.filter[N];D=p[1];q=false;p.splice(1,1);if(D.substr(D.length-1)!=="\\"){if(F===y)y=[];if(o.preFilter[N])if(p=o.preFilter[N](p,F,n,y,m,M)){if(p===true)continue}else q=O=true;if(p)for(var j=0;(D=F[j])!=null;j++)if(D){O=R(D,p,j,F);var s=m^!!O;if(n&&O!=null)if(s)q=true;else F[j]=false;else if(s){y.push(D);q=true}}if(O!==
B){n||(F=y);g=g.replace(o.match[N],"");if(!q)return[];break}}}if(g===u)if(q==null)k.error(g);else break;u=g}return F};k.error=function(g){throw"Syntax error, unrecognized expression: "+g;};var o=k.selectors={order:["ID","NAME","TAG"],match:{ID:/#((?:[\w\u00c0-\uFFFF\-]|\\.)+)/,CLASS:/\.((?:[\w\u00c0-\uFFFF\-]|\\.)+)/,NAME:/\[name=['"]*((?:[\w\u00c0-\uFFFF\-]|\\.)+)['"]*\]/,ATTR:/\[\s*((?:[\w\u00c0-\uFFFF\-]|\\.)+)\s*(?:(\S?=)\s*(['"]*)(.*?)\3|)\s*\]/,TAG:/^((?:[\w\u00c0-\uFFFF\*\-]|\\.)+)/,CHILD:/:(only|nth|last|first)-child(?:\((even|odd|[\dn+\-]*)\))?/,
POS:/:(nth|eq|gt|lt|first|last|even|odd)(?:\((\d*)\))?(?=[^\-]|$)/,PSEUDO:/:((?:[\w\u00c0-\uFFFF\-]|\\.)+)(?:\((['"]?)((?:\([^\)]+\)|[^\(\)]*)+)\2\))?/},leftMatch:{},attrMap:{"class":"className","for":"htmlFor"},attrHandle:{href:function(g){return g.getAttribute("href")}},relative:{"+":function(g,i){var n=typeof i==="string",m=n&&!/\W/.test(i);n=n&&!m;if(m)i=i.toLowerCase();m=0;for(var p=g.length,q;m<p;m++)if(q=g[m]){for(;(q=q.previousSibling)&&q.nodeType!==1;);g[m]=n||q&&q.nodeName.toLowerCase()===
i?q||false:q===i}n&&k.filter(i,g,true)},">":function(g,i){var n,m=typeof i==="string",p=0,q=g.length;if(m&&!/\W/.test(i))for(i=i.toLowerCase();p<q;p++){if(n=g[p]){n=n.parentNode;g[p]=n.nodeName.toLowerCase()===i?n:false}}else{for(;p<q;p++)if(n=g[p])g[p]=m?n.parentNode:n.parentNode===i;m&&k.filter(i,g,true)}},"":function(g,i,n){var m,p=e++,q=b;if(typeof i==="string"&&!/\W/.test(i)){m=i=i.toLowerCase();q=a}q("parentNode",i,p,g,m,n)},"~":function(g,i,n){var m,p=e++,q=b;if(typeof i==="string"&&!/\W/.test(i)){m=
i=i.toLowerCase();q=a}q("previousSibling",i,p,g,m,n)}},find:{ID:function(g,i,n){if(typeof i.getElementById!=="undefined"&&!n)return(g=i.getElementById(g[1]))&&g.parentNode?[g]:[]},NAME:function(g,i){if(typeof i.getElementsByName!=="undefined"){for(var n=[],m=i.getElementsByName(g[1]),p=0,q=m.length;p<q;p++)m[p].getAttribute("name")===g[1]&&n.push(m[p]);return n.length===0?null:n}},TAG:function(g,i){return i.getElementsByTagName(g[1])}},preFilter:{CLASS:function(g,i,n,m,p,q){g=" "+g[1].replace(/\\/g,
"")+" ";if(q)return g;q=0;for(var u;(u=i[q])!=null;q++)if(u)if(p^(u.className&&(" "+u.className+" ").replace(/[\t\n]/g," ").indexOf(g)>=0))n||m.push(u);else if(n)i[q]=false;return false},ID:function(g){return g[1].replace(/\\/g,"")},TAG:function(g){return g[1].toLowerCase()},CHILD:function(g){if(g[1]==="nth"){var i=/(-?)(\d*)n((?:\+|-)?\d*)/.exec(g[2]==="even"&&"2n"||g[2]==="odd"&&"2n+1"||!/\D/.test(g[2])&&"0n+"+g[2]||g[2]);g[2]=i[1]+(i[2]||1)-0;g[3]=i[3]-0}g[0]=e++;return g},ATTR:function(g,i,n,
m,p,q){i=g[1].replace(/\\/g,"");if(!q&&o.attrMap[i])g[1]=o.attrMap[i];if(g[2]==="~=")g[4]=" "+g[4]+" ";return g},PSEUDO:function(g,i,n,m,p){if(g[1]==="not")if((d.exec(g[3])||"").length>1||/^\w/.test(g[3]))g[3]=k(g[3],null,null,i);else{g=k.filter(g[3],i,n,true^p);n||m.push.apply(m,g);return false}else if(o.match.POS.test(g[0])||o.match.CHILD.test(g[0]))return true;return g},POS:function(g){g.unshift(true);return g}},filters:{enabled:function(g){return g.disabled===false&&g.type!=="hidden"},disabled:function(g){return g.disabled===
true},checked:function(g){return g.checked===true},selected:function(g){return g.selected===true},parent:function(g){return!!g.firstChild},empty:function(g){return!g.firstChild},has:function(g,i,n){return!!k(n[3],g).length},header:function(g){return/h\d/i.test(g.nodeName)},text:function(g){return"text"===g.type},radio:function(g){return"radio"===g.type},checkbox:function(g){return"checkbox"===g.type},file:function(g){return"file"===g.type},password:function(g){return"password"===g.type},submit:function(g){return"submit"===
g.type},image:function(g){return"image"===g.type},reset:function(g){return"reset"===g.type},button:function(g){return"button"===g.type||g.nodeName.toLowerCase()==="button"},input:function(g){return/input|select|textarea|button/i.test(g.nodeName)}},setFilters:{first:function(g,i){return i===0},last:function(g,i,n,m){return i===m.length-1},even:function(g,i){return i%2===0},odd:function(g,i){return i%2===1},lt:function(g,i,n){return i<n[3]-0},gt:function(g,i,n){return i>n[3]-0},nth:function(g,i,n){return n[3]-
0===i},eq:function(g,i,n){return n[3]-0===i}},filter:{PSEUDO:function(g,i,n,m){var p=i[1],q=o.filters[p];if(q)return q(g,n,i,m);else if(p==="contains")return(g.textContent||g.innerText||k.getText([g])||"").indexOf(i[3])>=0;else if(p==="not"){i=i[3];n=0;for(m=i.length;n<m;n++)if(i[n]===g)return false;return true}else k.error("Syntax error, unrecognized expression: "+p)},CHILD:function(g,i){var n=i[1],m=g;switch(n){case "only":case "first":for(;m=m.previousSibling;)if(m.nodeType===1)return false;if(n===
"first")return true;m=g;case "last":for(;m=m.nextSibling;)if(m.nodeType===1)return false;return true;case "nth":n=i[2];var p=i[3];if(n===1&&p===0)return true;var q=i[0],u=g.parentNode;if(u&&(u.sizcache!==q||!g.nodeIndex)){var y=0;for(m=u.firstChild;m;m=m.nextSibling)if(m.nodeType===1)m.nodeIndex=++y;u.sizcache=q}m=g.nodeIndex-p;return n===0?m===0:m%n===0&&m/n>=0}},ID:function(g,i){return g.nodeType===1&&g.getAttribute("id")===i},TAG:function(g,i){return i==="*"&&g.nodeType===1||g.nodeName.toLowerCase()===
i},CLASS:function(g,i){return(" "+(g.className||g.getAttribute("class"))+" ").indexOf(i)>-1},ATTR:function(g,i){var n=i[1];n=o.attrHandle[n]?o.attrHandle[n](g):g[n]!=null?g[n]:g.getAttribute(n);var m=n+"",p=i[2],q=i[4];return n==null?p==="!=":p==="="?m===q:p==="*="?m.indexOf(q)>=0:p==="~="?(" "+m+" ").indexOf(q)>=0:!q?m&&n!==false:p==="!="?m!==q:p==="^="?m.indexOf(q)===0:p==="$="?m.substr(m.length-q.length)===q:p==="|="?m===q||m.substr(0,q.length+1)===q+"-":false},POS:function(g,i,n,m){var p=o.setFilters[i[2]];
if(p)return p(g,n,i,m)}}},x=o.match.POS,r=function(g,i){return"\\"+(i-0+1)},A;for(A in o.match){o.match[A]=RegExp(o.match[A].source+/(?![^\[]*\])(?![^\(]*\))/.source);o.leftMatch[A]=RegExp(/(^(?:.|\r|\n)*?)/.source+o.match[A].source.replace(/\\(\d+)/g,r))}var C=function(g,i){g=Array.prototype.slice.call(g,0);if(i){i.push.apply(i,g);return i}return g};try{Array.prototype.slice.call(t.documentElement.childNodes,0)}catch(J){C=function(g,i){var n=0,m=i||[];if(f.call(g)==="[object Array]")Array.prototype.push.apply(m,
g);else if(typeof g.length==="number")for(var p=g.length;n<p;n++)m.push(g[n]);else for(;g[n];n++)m.push(g[n]);return m}}var w,I;if(t.documentElement.compareDocumentPosition)w=function(g,i){if(g===i){h=true;return 0}if(!g.compareDocumentPosition||!i.compareDocumentPosition)return g.compareDocumentPosition?-1:1;return g.compareDocumentPosition(i)&4?-1:1};else{w=function(g,i){var n,m,p=[],q=[];n=g.parentNode;m=i.parentNode;var u=n;if(g===i){h=true;return 0}else if(n===m)return I(g,i);else if(n){if(!m)return 1}else return-1;
for(;u;){p.unshift(u);u=u.parentNode}for(u=m;u;){q.unshift(u);u=u.parentNode}n=p.length;m=q.length;for(u=0;u<n&&u<m;u++)if(p[u]!==q[u])return I(p[u],q[u]);return u===n?I(g,q[u],-1):I(p[u],i,1)};I=function(g,i,n){if(g===i)return n;for(g=g.nextSibling;g;){if(g===i)return-1;g=g.nextSibling}return 1}}k.getText=function(g){for(var i="",n,m=0;g[m];m++){n=g[m];if(n.nodeType===3||n.nodeType===4)i+=n.nodeValue;else if(n.nodeType!==8)i+=k.getText(n.childNodes)}return i};(function(){var g=t.createElement("div"),
i="script"+(new Date).getTime(),n=t.documentElement;g.innerHTML="<a name='"+i+"'/>";n.insertBefore(g,n.firstChild);if(t.getElementById(i)){o.find.ID=function(m,p,q){if(typeof p.getElementById!=="undefined"&&!q)return(p=p.getElementById(m[1]))?p.id===m[1]||typeof p.getAttributeNode!=="undefined"&&p.getAttributeNode("id").nodeValue===m[1]?[p]:B:[]};o.filter.ID=function(m,p){var q=typeof m.getAttributeNode!=="undefined"&&m.getAttributeNode("id");return m.nodeType===1&&q&&q.nodeValue===p}}n.removeChild(g);
n=g=null})();(function(){var g=t.createElement("div");g.appendChild(t.createComment(""));if(g.getElementsByTagName("*").length>0)o.find.TAG=function(i,n){var m=n.getElementsByTagName(i[1]);if(i[1]==="*"){for(var p=[],q=0;m[q];q++)m[q].nodeType===1&&p.push(m[q]);m=p}return m};g.innerHTML="<a href='#'></a>";if(g.firstChild&&typeof g.firstChild.getAttribute!=="undefined"&&g.firstChild.getAttribute("href")!=="#")o.attrHandle.href=function(i){return i.getAttribute("href",2)};g=null})();t.querySelectorAll&&
function(){var g=k,i=t.createElement("div");i.innerHTML="<p class='TEST'></p>";if(!(i.querySelectorAll&&i.querySelectorAll(".TEST").length===0)){k=function(m,p,q,u){p=p||t;m=m.replace(/\=\s*([^'"\]]*)\s*\]/g,"='$1']");if(!u&&!k.isXML(p))if(p.nodeType===9)try{return C(p.querySelectorAll(m),q)}catch(y){}else if(p.nodeType===1&&p.nodeName.toLowerCase()!=="object"){var F=p.getAttribute("id"),M=F||"__sizzle__";F||p.setAttribute("id",M);try{return C(p.querySelectorAll("#"+M+" "+m),q)}catch(N){}finally{F||
p.removeAttribute("id")}}return g(m,p,q,u)};for(var n in g)k[n]=g[n];i=null}}();(function(){var g=t.documentElement,i=g.matchesSelector||g.mozMatchesSelector||g.webkitMatchesSelector||g.msMatchesSelector,n=false;try{i.call(t.documentElement,"[test!='']:sizzle")}catch(m){n=true}if(i)k.matchesSelector=function(p,q){q=q.replace(/\=\s*([^'"\]]*)\s*\]/g,"='$1']");if(!k.isXML(p))try{if(n||!o.match.PSEUDO.test(q)&&!/!=/.test(q))return i.call(p,q)}catch(u){}return k(q,null,null,[p]).length>0}})();(function(){var g=
t.createElement("div");g.innerHTML="<div class='test e'></div><div class='test'></div>";if(!(!g.getElementsByClassName||g.getElementsByClassName("e").length===0)){g.lastChild.className="e";if(g.getElementsByClassName("e").length!==1){o.order.splice(1,0,"CLASS");o.find.CLASS=function(i,n,m){if(typeof n.getElementsByClassName!=="undefined"&&!m)return n.getElementsByClassName(i[1])};g=null}}})();k.contains=t.documentElement.contains?function(g,i){return g!==i&&(g.contains?g.contains(i):true)}:t.documentElement.compareDocumentPosition?
function(g,i){return!!(g.compareDocumentPosition(i)&16)}:function(){return false};k.isXML=function(g){return(g=(g?g.ownerDocument||g:0).documentElement)?g.nodeName!=="HTML":false};var L=function(g,i){for(var n,m=[],p="",q=i.nodeType?[i]:i;n=o.match.PSEUDO.exec(g);){p+=n[0];g=g.replace(o.match.PSEUDO,"")}g=o.relative[g]?g+"*":g;n=0;for(var u=q.length;n<u;n++)k(g,q[n],m);return k.filter(p,m)};c.find=k;c.expr=k.selectors;c.expr[":"]=c.expr.filters;c.unique=k.uniqueSort;c.text=k.getText;c.isXMLDoc=k.isXML;
c.contains=k.contains})();var Za=/Until$/,$a=/^(?:parents|prevUntil|prevAll)/,ab=/,/,Na=/^.[^:#\[\.,]*$/,bb=Array.prototype.slice,cb=c.expr.match.POS;c.fn.extend({find:function(a){for(var b=this.pushStack("","find",a),d=0,e=0,f=this.length;e<f;e++){d=b.length;c.find(a,this[e],b);if(e>0)for(var h=d;h<b.length;h++)for(var l=0;l<d;l++)if(b[l]===b[h]){b.splice(h--,1);break}}return b},has:function(a){var b=c(a);return this.filter(function(){for(var d=0,e=b.length;d<e;d++)if(c.contains(this,b[d]))return true})},
not:function(a){return this.pushStack(ma(this,a,false),"not",a)},filter:function(a){return this.pushStack(ma(this,a,true),"filter",a)},is:function(a){return!!a&&c.filter(a,this).length>0},closest:function(a,b){var d=[],e,f,h=this[0];if(c.isArray(a)){var l,k={},o=1;if(h&&a.length){e=0;for(f=a.length;e<f;e++){l=a[e];k[l]||(k[l]=c.expr.match.POS.test(l)?c(l,b||this.context):l)}for(;h&&h.ownerDocument&&h!==b;){for(l in k){e=k[l];if(e.jquery?e.index(h)>-1:c(h).is(e))d.push({selector:l,elem:h,level:o})}h=
h.parentNode;o++}}return d}l=cb.test(a)?c(a,b||this.context):null;e=0;for(f=this.length;e<f;e++)for(h=this[e];h;)if(l?l.index(h)>-1:c.find.matchesSelector(h,a)){d.push(h);break}else{h=h.parentNode;if(!h||!h.ownerDocument||h===b)break}d=d.length>1?c.unique(d):d;return this.pushStack(d,"closest",a)},index:function(a){if(!a||typeof a==="string")return c.inArray(this[0],a?c(a):this.parent().children());return c.inArray(a.jquery?a[0]:a,this)},add:function(a,b){var d=typeof a==="string"?c(a,b||this.context):
c.makeArray(a),e=c.merge(this.get(),d);return this.pushStack(!d[0]||!d[0].parentNode||d[0].parentNode.nodeType===11||!e[0]||!e[0].parentNode||e[0].parentNode.nodeType===11?e:c.unique(e))},andSelf:function(){return this.add(this.prevObject)}});c.each({parent:function(a){return(a=a.parentNode)&&a.nodeType!==11?a:null},parents:function(a){return c.dir(a,"parentNode")},parentsUntil:function(a,b,d){return c.dir(a,"parentNode",d)},next:function(a){return c.nth(a,2,"nextSibling")},prev:function(a){return c.nth(a,
2,"previousSibling")},nextAll:function(a){return c.dir(a,"nextSibling")},prevAll:function(a){return c.dir(a,"previousSibling")},nextUntil:function(a,b,d){return c.dir(a,"nextSibling",d)},prevUntil:function(a,b,d){return c.dir(a,"previousSibling",d)},siblings:function(a){return c.sibling(a.parentNode.firstChild,a)},children:function(a){return c.sibling(a.firstChild)},contents:function(a){return c.nodeName(a,"iframe")?a.contentDocument||a.contentWindow.document:c.makeArray(a.childNodes)}},function(a,
b){c.fn[a]=function(d,e){var f=c.map(this,b,d);Za.test(a)||(e=d);if(e&&typeof e==="string")f=c.filter(e,f);f=this.length>1?c.unique(f):f;if((this.length>1||ab.test(e))&&$a.test(a))f=f.reverse();return this.pushStack(f,a,bb.call(arguments).join(","))}});c.extend({filter:function(a,b,d){if(d)a=":not("+a+")";return b.length===1?c.find.matchesSelector(b[0],a)?[b[0]]:[]:c.find.matches(a,b)},dir:function(a,b,d){var e=[];for(a=a[b];a&&a.nodeType!==9&&(d===B||a.nodeType!==1||!c(a).is(d));){a.nodeType===1&&
e.push(a);a=a[b]}return e},nth:function(a,b,d){b=b||1;for(var e=0;a;a=a[d])if(a.nodeType===1&&++e===b)break;return a},sibling:function(a,b){for(var d=[];a;a=a.nextSibling)a.nodeType===1&&a!==b&&d.push(a);return d}});var za=/ jQuery\d+="(?:\d+|null)"/g,$=/^\s+/,Aa=/<(?!area|br|col|embed|hr|img|input|link|meta|param)(([\w:]+)[^>]*)\/>/ig,Ba=/<([\w:]+)/,db=/<tbody/i,eb=/<|&#?\w+;/,Ca=/<(?:script|object|embed|option|style)/i,Da=/checked\s*(?:[^=]|=\s*.checked.)/i,fb=/\=([^="'>\s]+\/)>/g,P={option:[1,
"<select multiple='multiple'>","</select>"],legend:[1,"<fieldset>","</fieldset>"],thead:[1,"<table>","</table>"],tr:[2,"<table><tbody>","</tbody></table>"],td:[3,"<table><tbody><tr>","</tr></tbody></table>"],col:[2,"<table><tbody></tbody><colgroup>","</colgroup></table>"],area:[1,"<map>","</map>"],_default:[0,"",""]};P.optgroup=P.option;P.tbody=P.tfoot=P.colgroup=P.caption=P.thead;P.th=P.td;if(!c.support.htmlSerialize)P._default=[1,"div<div>","</div>"];c.fn.extend({text:function(a){if(c.isFunction(a))return this.each(function(b){var d=
c(this);d.text(a.call(this,b,d.text()))});if(typeof a!=="object"&&a!==B)return this.empty().append((this[0]&&this[0].ownerDocument||t).createTextNode(a));return c.text(this)},wrapAll:function(a){if(c.isFunction(a))return this.each(function(d){c(this).wrapAll(a.call(this,d))});if(this[0]){var b=c(a,this[0].ownerDocument).eq(0).clone(true);this[0].parentNode&&b.insertBefore(this[0]);b.map(function(){for(var d=this;d.firstChild&&d.firstChild.nodeType===1;)d=d.firstChild;return d}).append(this)}return this},
wrapInner:function(a){if(c.isFunction(a))return this.each(function(b){c(this).wrapInner(a.call(this,b))});return this.each(function(){var b=c(this),d=b.contents();d.length?d.wrapAll(a):b.append(a)})},wrap:function(a){return this.each(function(){c(this).wrapAll(a)})},unwrap:function(){return this.parent().each(function(){c.nodeName(this,"body")||c(this).replaceWith(this.childNodes)}).end()},append:function(){return this.domManip(arguments,true,function(a){this.nodeType===1&&this.appendChild(a)})},
prepend:function(){return this.domManip(arguments,true,function(a){this.nodeType===1&&this.insertBefore(a,this.firstChild)})},before:function(){if(this[0]&&this[0].parentNode)return this.domManip(arguments,false,function(b){this.parentNode.insertBefore(b,this)});else if(arguments.length){var a=c(arguments[0]);a.push.apply(a,this.toArray());return this.pushStack(a,"before",arguments)}},after:function(){if(this[0]&&this[0].parentNode)return this.domManip(arguments,false,function(b){this.parentNode.insertBefore(b,
this.nextSibling)});else if(arguments.length){var a=this.pushStack(this,"after",arguments);a.push.apply(a,c(arguments[0]).toArray());return a}},remove:function(a,b){for(var d=0,e;(e=this[d])!=null;d++)if(!a||c.filter(a,[e]).length){if(!b&&e.nodeType===1){c.cleanData(e.getElementsByTagName("*"));c.cleanData([e])}e.parentNode&&e.parentNode.removeChild(e)}return this},empty:function(){for(var a=0,b;(b=this[a])!=null;a++)for(b.nodeType===1&&c.cleanData(b.getElementsByTagName("*"));b.firstChild;)b.removeChild(b.firstChild);
return this},clone:function(a){var b=this.map(function(){if(!c.support.noCloneEvent&&!c.isXMLDoc(this)){var d=this.outerHTML,e=this.ownerDocument;if(!d){d=e.createElement("div");d.appendChild(this.cloneNode(true));d=d.innerHTML}return c.clean([d.replace(za,"").replace(fb,'="$1">').replace($,"")],e)[0]}else return this.cloneNode(true)});if(a===true){na(this,b);na(this.find("*"),b.find("*"))}return b},html:function(a){if(a===B)return this[0]&&this[0].nodeType===1?this[0].innerHTML.replace(za,""):null;
else if(typeof a==="string"&&!Ca.test(a)&&(c.support.leadingWhitespace||!$.test(a))&&!P[(Ba.exec(a)||["",""])[1].toLowerCase()]){a=a.replace(Aa,"<$1></$2>");try{for(var b=0,d=this.length;b<d;b++)if(this[b].nodeType===1){c.cleanData(this[b].getElementsByTagName("*"));this[b].innerHTML=a}}catch(e){this.empty().append(a)}}else c.isFunction(a)?this.each(function(f){var h=c(this);h.html(a.call(this,f,h.html()))}):this.empty().append(a);return this},replaceWith:function(a){if(this[0]&&this[0].parentNode){if(c.isFunction(a))return this.each(function(b){var d=
c(this),e=d.html();d.replaceWith(a.call(this,b,e))});if(typeof a!=="string")a=c(a).detach();return this.each(function(){var b=this.nextSibling,d=this.parentNode;c(this).remove();b?c(b).before(a):c(d).append(a)})}else return this.pushStack(c(c.isFunction(a)?a():a),"replaceWith",a)},detach:function(a){return this.remove(a,true)},domManip:function(a,b,d){var e,f,h,l=a[0],k=[];if(!c.support.checkClone&&arguments.length===3&&typeof l==="string"&&Da.test(l))return this.each(function(){c(this).domManip(a,
b,d,true)});if(c.isFunction(l))return this.each(function(x){var r=c(this);a[0]=l.call(this,x,b?r.html():B);r.domManip(a,b,d)});if(this[0]){e=l&&l.parentNode;e=c.support.parentNode&&e&&e.nodeType===11&&e.childNodes.length===this.length?{fragment:e}:c.buildFragment(a,this,k);h=e.fragment;if(f=h.childNodes.length===1?h=h.firstChild:h.firstChild){b=b&&c.nodeName(f,"tr");f=0;for(var o=this.length;f<o;f++)d.call(b?c.nodeName(this[f],"table")?this[f].getElementsByTagName("tbody")[0]||this[f].appendChild(this[f].ownerDocument.createElement("tbody")):
this[f]:this[f],f>0||e.cacheable||this.length>1?h.cloneNode(true):h)}k.length&&c.each(k,Oa)}return this}});c.buildFragment=function(a,b,d){var e,f,h;b=b&&b[0]?b[0].ownerDocument||b[0]:t;if(a.length===1&&typeof a[0]==="string"&&a[0].length<512&&b===t&&!Ca.test(a[0])&&(c.support.checkClone||!Da.test(a[0]))){f=true;if(h=c.fragments[a[0]])if(h!==1)e=h}if(!e){e=b.createDocumentFragment();c.clean(a,b,e,d)}if(f)c.fragments[a[0]]=h?e:1;return{fragment:e,cacheable:f}};c.fragments={};c.each({appendTo:"append",
prependTo:"prepend",insertBefore:"before",insertAfter:"after",replaceAll:"replaceWith"},function(a,b){c.fn[a]=function(d){var e=[];d=c(d);var f=this.length===1&&this[0].parentNode;if(f&&f.nodeType===11&&f.childNodes.length===1&&d.length===1){d[b](this[0]);return this}else{f=0;for(var h=d.length;f<h;f++){var l=(f>0?this.clone(true):this).get();c(d[f])[b](l);e=e.concat(l)}return this.pushStack(e,a,d.selector)}}});c.extend({clean:function(a,b,d,e){b=b||t;if(typeof b.createElement==="undefined")b=b.ownerDocument||
b[0]&&b[0].ownerDocument||t;for(var f=[],h=0,l;(l=a[h])!=null;h++){if(typeof l==="number")l+="";if(l){if(typeof l==="string"&&!eb.test(l))l=b.createTextNode(l);else if(typeof l==="string"){l=l.replace(Aa,"<$1></$2>");var k=(Ba.exec(l)||["",""])[1].toLowerCase(),o=P[k]||P._default,x=o[0],r=b.createElement("div");for(r.innerHTML=o[1]+l+o[2];x--;)r=r.lastChild;if(!c.support.tbody){x=db.test(l);k=k==="table"&&!x?r.firstChild&&r.firstChild.childNodes:o[1]==="<table>"&&!x?r.childNodes:[];for(o=k.length-
1;o>=0;--o)c.nodeName(k[o],"tbody")&&!k[o].childNodes.length&&k[o].parentNode.removeChild(k[o])}!c.support.leadingWhitespace&&$.test(l)&&r.insertBefore(b.createTextNode($.exec(l)[0]),r.firstChild);l=r.childNodes}if(l.nodeType)f.push(l);else f=c.merge(f,l)}}if(d)for(h=0;f[h];h++)if(e&&c.nodeName(f[h],"script")&&(!f[h].type||f[h].type.toLowerCase()==="text/javascript"))e.push(f[h].parentNode?f[h].parentNode.removeChild(f[h]):f[h]);else{f[h].nodeType===1&&f.splice.apply(f,[h+1,0].concat(c.makeArray(f[h].getElementsByTagName("script"))));
d.appendChild(f[h])}return f},cleanData:function(a){for(var b,d,e=c.cache,f=c.event.special,h=c.support.deleteExpando,l=0,k;(k=a[l])!=null;l++)if(!(k.nodeName&&c.noData[k.nodeName.toLowerCase()]))if(d=k[c.expando]){if((b=e[d])&&b.events)for(var o in b.events)f[o]?c.event.remove(k,o):c.removeEvent(k,o,b.handle);if(h)delete k[c.expando];else k.removeAttribute&&k.removeAttribute(c.expando);delete e[d]}}});var Ea=/alpha\([^)]*\)/i,gb=/opacity=([^)]*)/,hb=/-([a-z])/ig,ib=/([A-Z])/g,Fa=/^-?\d+(?:px)?$/i,
jb=/^-?\d/,kb={position:"absolute",visibility:"hidden",display:"block"},Pa=["Left","Right"],Qa=["Top","Bottom"],W,Ga,aa,lb=function(a,b){return b.toUpperCase()};c.fn.css=function(a,b){if(arguments.length===2&&b===B)return this;return c.access(this,a,b,true,function(d,e,f){return f!==B?c.style(d,e,f):c.css(d,e)})};c.extend({cssHooks:{opacity:{get:function(a,b){if(b){var d=W(a,"opacity","opacity");return d===""?"1":d}else return a.style.opacity}}},cssNumber:{zIndex:true,fontWeight:true,opacity:true,
zoom:true,lineHeight:true},cssProps:{"float":c.support.cssFloat?"cssFloat":"styleFloat"},style:function(a,b,d,e){if(!(!a||a.nodeType===3||a.nodeType===8||!a.style)){var f,h=c.camelCase(b),l=a.style,k=c.cssHooks[h];b=c.cssProps[h]||h;if(d!==B){if(!(typeof d==="number"&&isNaN(d)||d==null)){if(typeof d==="number"&&!c.cssNumber[h])d+="px";if(!k||!("set"in k)||(d=k.set(a,d))!==B)try{l[b]=d}catch(o){}}}else{if(k&&"get"in k&&(f=k.get(a,false,e))!==B)return f;return l[b]}}},css:function(a,b,d){var e,f=c.camelCase(b),
h=c.cssHooks[f];b=c.cssProps[f]||f;if(h&&"get"in h&&(e=h.get(a,true,d))!==B)return e;else if(W)return W(a,b,f)},swap:function(a,b,d){var e={},f;for(f in b){e[f]=a.style[f];a.style[f]=b[f]}d.call(a);for(f in b)a.style[f]=e[f]},camelCase:function(a){return a.replace(hb,lb)}});c.curCSS=c.css;c.each(["height","width"],function(a,b){c.cssHooks[b]={get:function(d,e,f){var h;if(e){if(d.offsetWidth!==0)h=oa(d,b,f);else c.swap(d,kb,function(){h=oa(d,b,f)});if(h<=0){h=W(d,b,b);if(h==="0px"&&aa)h=aa(d,b,b);
if(h!=null)return h===""||h==="auto"?"0px":h}if(h<0||h==null){h=d.style[b];return h===""||h==="auto"?"0px":h}return typeof h==="string"?h:h+"px"}},set:function(d,e){if(Fa.test(e)){e=parseFloat(e);if(e>=0)return e+"px"}else return e}}});if(!c.support.opacity)c.cssHooks.opacity={get:function(a,b){return gb.test((b&&a.currentStyle?a.currentStyle.filter:a.style.filter)||"")?parseFloat(RegExp.$1)/100+"":b?"1":""},set:function(a,b){var d=a.style;d.zoom=1;var e=c.isNaN(b)?"":"alpha(opacity="+b*100+")",f=
d.filter||"";d.filter=Ea.test(f)?f.replace(Ea,e):d.filter+" "+e}};if(t.defaultView&&t.defaultView.getComputedStyle)Ga=function(a,b,d){var e;d=d.replace(ib,"-$1").toLowerCase();if(!(b=a.ownerDocument.defaultView))return B;if(b=b.getComputedStyle(a,null)){e=b.getPropertyValue(d);if(e===""&&!c.contains(a.ownerDocument.documentElement,a))e=c.style(a,d)}return e};if(t.documentElement.currentStyle)aa=function(a,b){var d,e,f=a.currentStyle&&a.currentStyle[b],h=a.style;if(!Fa.test(f)&&jb.test(f)){d=h.left;
e=a.runtimeStyle.left;a.runtimeStyle.left=a.currentStyle.left;h.left=b==="fontSize"?"1em":f||0;f=h.pixelLeft+"px";h.left=d;a.runtimeStyle.left=e}return f===""?"auto":f};W=Ga||aa;if(c.expr&&c.expr.filters){c.expr.filters.hidden=function(a){var b=a.offsetHeight;return a.offsetWidth===0&&b===0||!c.support.reliableHiddenOffsets&&(a.style.display||c.css(a,"display"))==="none"};c.expr.filters.visible=function(a){return!c.expr.filters.hidden(a)}}var mb=c.now(),nb=/<script\b[^<]*(?:(?!<\/script>)<[^<]*)*<\/script>/gi,
ob=/^(?:select|textarea)/i,pb=/^(?:color|date|datetime|email|hidden|month|number|password|range|search|tel|text|time|url|week)$/i,qb=/^(?:GET|HEAD)$/,Ra=/\[\]$/,T=/\=\?(&|$)/,ja=/\?/,rb=/([?&])_=[^&]*/,sb=/^(\w+:)?\/\/([^\/?#]+)/,tb=/%20/g,ub=/#.*$/,Ha=c.fn.load;c.fn.extend({load:function(a,b,d){if(typeof a!=="string"&&Ha)return Ha.apply(this,arguments);else if(!this.length)return this;var e=a.indexOf(" ");if(e>=0){var f=a.slice(e,a.length);a=a.slice(0,e)}e="GET";if(b)if(c.isFunction(b)){d=b;b=null}else if(typeof b===
"object"){b=c.param(b,c.ajaxSettings.traditional);e="POST"}var h=this;c.ajax({url:a,type:e,dataType:"html",data:b,complete:function(l,k){if(k==="success"||k==="notmodified")h.html(f?c("<div>").append(l.responseText.replace(nb,"")).find(f):l.responseText);d&&h.each(d,[l.responseText,k,l])}});return this},serialize:function(){return c.param(this.serializeArray())},serializeArray:function(){return this.map(function(){return this.elements?c.makeArray(this.elements):this}).filter(function(){return this.name&&
!this.disabled&&(this.checked||ob.test(this.nodeName)||pb.test(this.type))}).map(function(a,b){var d=c(this).val();return d==null?null:c.isArray(d)?c.map(d,function(e){return{name:b.name,value:e}}):{name:b.name,value:d}}).get()}});c.each("ajaxStart ajaxStop ajaxComplete ajaxError ajaxSuccess ajaxSend".split(" "),function(a,b){c.fn[b]=function(d){return this.bind(b,d)}});c.extend({get:function(a,b,d,e){if(c.isFunction(b)){e=e||d;d=b;b=null}return c.ajax({type:"GET",url:a,data:b,success:d,dataType:e})},
getScript:function(a,b){return c.get(a,null,b,"script")},getJSON:function(a,b,d){return c.get(a,b,d,"json")},post:function(a,b,d,e){if(c.isFunction(b)){e=e||d;d=b;b={}}return c.ajax({type:"POST",url:a,data:b,success:d,dataType:e})},ajaxSetup:function(a){c.extend(c.ajaxSettings,a)},ajaxSettings:{url:location.href,global:true,type:"GET",contentType:"application/x-www-form-urlencoded",processData:true,async:true,xhr:function(){return new E.XMLHttpRequest},accepts:{xml:"application/xml, text/xml",html:"text/html",
script:"text/javascript, application/javascript",json:"application/json, text/javascript",text:"text/plain",_default:"*/*"}},ajax:function(a){var b=c.extend(true,{},c.ajaxSettings,a),d,e,f,h=b.type.toUpperCase(),l=qb.test(h);b.url=b.url.replace(ub,"");b.context=a&&a.context!=null?a.context:b;if(b.data&&b.processData&&typeof b.data!=="string")b.data=c.param(b.data,b.traditional);if(b.dataType==="jsonp"){if(h==="GET")T.test(b.url)||(b.url+=(ja.test(b.url)?"&":"?")+(b.jsonp||"callback")+"=?");else if(!b.data||
!T.test(b.data))b.data=(b.data?b.data+"&":"")+(b.jsonp||"callback")+"=?";b.dataType="json"}if(b.dataType==="json"&&(b.data&&T.test(b.data)||T.test(b.url))){d=b.jsonpCallback||"jsonp"+mb++;if(b.data)b.data=(b.data+"").replace(T,"="+d+"$1");b.url=b.url.replace(T,"="+d+"$1");b.dataType="script";var k=E[d];E[d]=function(m){if(c.isFunction(k))k(m);else{E[d]=B;try{delete E[d]}catch(p){}}f=m;c.handleSuccess(b,w,e,f);c.handleComplete(b,w,e,f);r&&r.removeChild(A)}}if(b.dataType==="script"&&b.cache===null)b.cache=
false;if(b.cache===false&&l){var o=c.now(),x=b.url.replace(rb,"$1_="+o);b.url=x+(x===b.url?(ja.test(b.url)?"&":"?")+"_="+o:"")}if(b.data&&l)b.url+=(ja.test(b.url)?"&":"?")+b.data;b.global&&c.active++===0&&c.event.trigger("ajaxStart");o=(o=sb.exec(b.url))&&(o[1]&&o[1].toLowerCase()!==location.protocol||o[2].toLowerCase()!==location.host);if(b.dataType==="script"&&h==="GET"&&o){var r=t.getElementsByTagName("head")[0]||t.documentElement,A=t.createElement("script");if(b.scriptCharset)A.charset=b.scriptCharset;
A.src=b.url;if(!d){var C=false;A.onload=A.onreadystatechange=function(){if(!C&&(!this.readyState||this.readyState==="loaded"||this.readyState==="complete")){C=true;c.handleSuccess(b,w,e,f);c.handleComplete(b,w,e,f);A.onload=A.onreadystatechange=null;r&&A.parentNode&&r.removeChild(A)}}}r.insertBefore(A,r.firstChild);return B}var J=false,w=b.xhr();if(w){b.username?w.open(h,b.url,b.async,b.username,b.password):w.open(h,b.url,b.async);try{if(b.data!=null&&!l||a&&a.contentType)w.setRequestHeader("Content-Type",
b.contentType);if(b.ifModified){c.lastModified[b.url]&&w.setRequestHeader("If-Modified-Since",c.lastModified[b.url]);c.etag[b.url]&&w.setRequestHeader("If-None-Match",c.etag[b.url])}o||w.setRequestHeader("X-Requested-With","XMLHttpRequest");w.setRequestHeader("Accept",b.dataType&&b.accepts[b.dataType]?b.accepts[b.dataType]+", */*; q=0.01":b.accepts._default)}catch(I){}if(b.beforeSend&&b.beforeSend.call(b.context,w,b)===false){b.global&&c.active--===1&&c.event.trigger("ajaxStop");w.abort();return false}b.global&&
c.triggerGlobal(b,"ajaxSend",[w,b]);var L=w.onreadystatechange=function(m){if(!w||w.readyState===0||m==="abort"){J||c.handleComplete(b,w,e,f);J=true;if(w)w.onreadystatechange=c.noop}else if(!J&&w&&(w.readyState===4||m==="timeout")){J=true;w.onreadystatechange=c.noop;e=m==="timeout"?"timeout":!c.httpSuccess(w)?"error":b.ifModified&&c.httpNotModified(w,b.url)?"notmodified":"success";var p;if(e==="success")try{f=c.httpData(w,b.dataType,b)}catch(q){e="parsererror";p=q}if(e==="success"||e==="notmodified")d||
c.handleSuccess(b,w,e,f);else c.handleError(b,w,e,p);d||c.handleComplete(b,w,e,f);m==="timeout"&&w.abort();if(b.async)w=null}};try{var g=w.abort;w.abort=function(){w&&Function.prototype.call.call(g,w);L("abort")}}catch(i){}b.async&&b.timeout>0&&setTimeout(function(){w&&!J&&L("timeout")},b.timeout);try{w.send(l||b.data==null?null:b.data)}catch(n){c.handleError(b,w,null,n);c.handleComplete(b,w,e,f)}b.async||L();return w}},param:function(a,b){var d=[],e=function(h,l){l=c.isFunction(l)?l():l;d[d.length]=
encodeURIComponent(h)+"="+encodeURIComponent(l)};if(b===B)b=c.ajaxSettings.traditional;if(c.isArray(a)||a.jquery)c.each(a,function(){e(this.name,this.value)});else for(var f in a)da(f,a[f],b,e);return d.join("&").replace(tb,"+")}});c.extend({active:0,lastModified:{},etag:{},handleError:function(a,b,d,e){a.error&&a.error.call(a.context,b,d,e);a.global&&c.triggerGlobal(a,"ajaxError",[b,a,e])},handleSuccess:function(a,b,d,e){a.success&&a.success.call(a.context,e,d,b);a.global&&c.triggerGlobal(a,"ajaxSuccess",
[b,a])},handleComplete:function(a,b,d){a.complete&&a.complete.call(a.context,b,d);a.global&&c.triggerGlobal(a,"ajaxComplete",[b,a]);a.global&&c.active--===1&&c.event.trigger("ajaxStop")},triggerGlobal:function(a,b,d){(a.context&&a.context.url==null?c(a.context):c.event).trigger(b,d)},httpSuccess:function(a){try{return!a.status&&location.protocol==="file:"||a.status>=200&&a.status<300||a.status===304||a.status===1223}catch(b){}return false},httpNotModified:function(a,b){var d=a.getResponseHeader("Last-Modified"),
e=a.getResponseHeader("Etag");if(d)c.lastModified[b]=d;if(e)c.etag[b]=e;return a.status===304},httpData:function(a,b,d){var e=a.getResponseHeader("content-type")||"",f=b==="xml"||!b&&e.indexOf("xml")>=0;a=f?a.responseXML:a.responseText;f&&a.documentElement.nodeName==="parsererror"&&c.error("parsererror");if(d&&d.dataFilter)a=d.dataFilter(a,b);if(typeof a==="string")if(b==="json"||!b&&e.indexOf("json")>=0)a=c.parseJSON(a);else if(b==="script"||!b&&e.indexOf("javascript")>=0)c.globalEval(a);return a}});
if(E.ActiveXObject)c.ajaxSettings.xhr=function(){if(E.location.protocol!=="file:")try{return new E.XMLHttpRequest}catch(a){}try{return new E.ActiveXObject("Microsoft.XMLHTTP")}catch(b){}};c.support.ajax=!!c.ajaxSettings.xhr();var ea={},vb=/^(?:toggle|show|hide)$/,wb=/^([+\-]=)?([\d+.\-]+)(.*)$/,ba,pa=[["height","marginTop","marginBottom","paddingTop","paddingBottom"],["width","marginLeft","marginRight","paddingLeft","paddingRight"],["opacity"]];c.fn.extend({show:function(a,b,d){if(a||a===0)return this.animate(S("show",
3),a,b,d);else{d=0;for(var e=this.length;d<e;d++){a=this[d];b=a.style.display;if(!c.data(a,"olddisplay")&&b==="none")b=a.style.display="";b===""&&c.css(a,"display")==="none"&&c.data(a,"olddisplay",qa(a.nodeName))}for(d=0;d<e;d++){a=this[d];b=a.style.display;if(b===""||b==="none")a.style.display=c.data(a,"olddisplay")||""}return this}},hide:function(a,b,d){if(a||a===0)return this.animate(S("hide",3),a,b,d);else{a=0;for(b=this.length;a<b;a++){d=c.css(this[a],"display");d!=="none"&&c.data(this[a],"olddisplay",
d)}for(a=0;a<b;a++)this[a].style.display="none";return this}},_toggle:c.fn.toggle,toggle:function(a,b,d){var e=typeof a==="boolean";if(c.isFunction(a)&&c.isFunction(b))this._toggle.apply(this,arguments);else a==null||e?this.each(function(){var f=e?a:c(this).is(":hidden");c(this)[f?"show":"hide"]()}):this.animate(S("toggle",3),a,b,d);return this},fadeTo:function(a,b,d,e){return this.filter(":hidden").css("opacity",0).show().end().animate({opacity:b},a,d,e)},animate:function(a,b,d,e){var f=c.speed(b,
d,e);if(c.isEmptyObject(a))return this.each(f.complete);return this[f.queue===false?"each":"queue"](function(){var h=c.extend({},f),l,k=this.nodeType===1,o=k&&c(this).is(":hidden"),x=this;for(l in a){var r=c.camelCase(l);if(l!==r){a[r]=a[l];delete a[l];l=r}if(a[l]==="hide"&&o||a[l]==="show"&&!o)return h.complete.call(this);if(k&&(l==="height"||l==="width")){h.overflow=[this.style.overflow,this.style.overflowX,this.style.overflowY];if(c.css(this,"display")==="inline"&&c.css(this,"float")==="none")if(c.support.inlineBlockNeedsLayout)if(qa(this.nodeName)===
"inline")this.style.display="inline-block";else{this.style.display="inline";this.style.zoom=1}else this.style.display="inline-block"}if(c.isArray(a[l])){(h.specialEasing=h.specialEasing||{})[l]=a[l][1];a[l]=a[l][0]}}if(h.overflow!=null)this.style.overflow="hidden";h.curAnim=c.extend({},a);c.each(a,function(A,C){var J=new c.fx(x,h,A);if(vb.test(C))J[C==="toggle"?o?"show":"hide":C](a);else{var w=wb.exec(C),I=J.cur()||0;if(w){var L=parseFloat(w[2]),g=w[3]||"px";if(g!=="px"){c.style(x,A,(L||1)+g);I=(L||
1)/J.cur()*I;c.style(x,A,I+g)}if(w[1])L=(w[1]==="-="?-1:1)*L+I;J.custom(I,L,g)}else J.custom(I,C,"")}});return true})},stop:function(a,b){var d=c.timers;a&&this.queue([]);this.each(function(){for(var e=d.length-1;e>=0;e--)if(d[e].elem===this){b&&d[e](true);d.splice(e,1)}});b||this.dequeue();return this}});c.each({slideDown:S("show",1),slideUp:S("hide",1),slideToggle:S("toggle",1),fadeIn:{opacity:"show"},fadeOut:{opacity:"hide"},fadeToggle:{opacity:"toggle"}},function(a,b){c.fn[a]=function(d,e,f){return this.animate(b,
d,e,f)}});c.extend({speed:function(a,b,d){var e=a&&typeof a==="object"?c.extend({},a):{complete:d||!d&&b||c.isFunction(a)&&a,duration:a,easing:d&&b||b&&!c.isFunction(b)&&b};e.duration=c.fx.off?0:typeof e.duration==="number"?e.duration:e.duration in c.fx.speeds?c.fx.speeds[e.duration]:c.fx.speeds._default;e.old=e.complete;e.complete=function(){e.queue!==false&&c(this).dequeue();c.isFunction(e.old)&&e.old.call(this)};return e},easing:{linear:function(a,b,d,e){return d+e*a},swing:function(a,b,d,e){return(-Math.cos(a*
Math.PI)/2+0.5)*e+d}},timers:[],fx:function(a,b,d){this.options=b;this.elem=a;this.prop=d;if(!b.orig)b.orig={}}});c.fx.prototype={update:function(){this.options.step&&this.options.step.call(this.elem,this.now,this);(c.fx.step[this.prop]||c.fx.step._default)(this)},cur:function(){if(this.elem[this.prop]!=null&&(!this.elem.style||this.elem.style[this.prop]==null))return this.elem[this.prop];var a=parseFloat(c.css(this.elem,this.prop));return a&&a>-1E4?a:0},custom:function(a,b,d){function e(l){return f.step(l)}
var f=this,h=c.fx;this.startTime=c.now();this.start=a;this.end=b;this.unit=d||this.unit||"px";this.now=this.start;this.pos=this.state=0;e.elem=this.elem;if(e()&&c.timers.push(e)&&!ba)ba=setInterval(h.tick,h.interval)},show:function(){this.options.orig[this.prop]=c.style(this.elem,this.prop);this.options.show=true;this.custom(this.prop==="width"||this.prop==="height"?1:0,this.cur());c(this.elem).show()},hide:function(){this.options.orig[this.prop]=c.style(this.elem,this.prop);this.options.hide=true;
this.custom(this.cur(),0)},step:function(a){var b=c.now(),d=true;if(a||b>=this.options.duration+this.startTime){this.now=this.end;this.pos=this.state=1;this.update();this.options.curAnim[this.prop]=true;for(var e in this.options.curAnim)if(this.options.curAnim[e]!==true)d=false;if(d){if(this.options.overflow!=null&&!c.support.shrinkWrapBlocks){var f=this.elem,h=this.options;c.each(["","X","Y"],function(k,o){f.style["overflow"+o]=h.overflow[k]})}this.options.hide&&c(this.elem).hide();if(this.options.hide||
this.options.show)for(var l in this.options.curAnim)c.style(this.elem,l,this.options.orig[l]);this.options.complete.call(this.elem)}return false}else{a=b-this.startTime;this.state=a/this.options.duration;b=this.options.easing||(c.easing.swing?"swing":"linear");this.pos=c.easing[this.options.specialEasing&&this.options.specialEasing[this.prop]||b](this.state,a,0,1,this.options.duration);this.now=this.start+(this.end-this.start)*this.pos;this.update()}return true}};c.extend(c.fx,{tick:function(){for(var a=
c.timers,b=0;b<a.length;b++)a[b]()||a.splice(b--,1);a.length||c.fx.stop()},interval:13,stop:function(){clearInterval(ba);ba=null},speeds:{slow:600,fast:200,_default:400},step:{opacity:function(a){c.style(a.elem,"opacity",a.now)},_default:function(a){if(a.elem.style&&a.elem.style[a.prop]!=null)a.elem.style[a.prop]=(a.prop==="width"||a.prop==="height"?Math.max(0,a.now):a.now)+a.unit;else a.elem[a.prop]=a.now}}});if(c.expr&&c.expr.filters)c.expr.filters.animated=function(a){return c.grep(c.timers,function(b){return a===
b.elem}).length};var xb=/^t(?:able|d|h)$/i,Ia=/^(?:body|html)$/i;c.fn.offset="getBoundingClientRect"in t.documentElement?function(a){var b=this[0],d;if(a)return this.each(function(l){c.offset.setOffset(this,a,l)});if(!b||!b.ownerDocument)return null;if(b===b.ownerDocument.body)return c.offset.bodyOffset(b);try{d=b.getBoundingClientRect()}catch(e){}var f=b.ownerDocument,h=f.documentElement;if(!d||!c.contains(h,b))return d||{top:0,left:0};b=f.body;f=fa(f);return{top:d.top+(f.pageYOffset||c.support.boxModel&&
h.scrollTop||b.scrollTop)-(h.clientTop||b.clientTop||0),left:d.left+(f.pageXOffset||c.support.boxModel&&h.scrollLeft||b.scrollLeft)-(h.clientLeft||b.clientLeft||0)}}:function(a){var b=this[0];if(a)return this.each(function(x){c.offset.setOffset(this,a,x)});if(!b||!b.ownerDocument)return null;if(b===b.ownerDocument.body)return c.offset.bodyOffset(b);c.offset.initialize();var d,e=b.offsetParent,f=b.ownerDocument,h=f.documentElement,l=f.body;d=(f=f.defaultView)?f.getComputedStyle(b,null):b.currentStyle;
for(var k=b.offsetTop,o=b.offsetLeft;(b=b.parentNode)&&b!==l&&b!==h;){if(c.offset.supportsFixedPosition&&d.position==="fixed")break;d=f?f.getComputedStyle(b,null):b.currentStyle;k-=b.scrollTop;o-=b.scrollLeft;if(b===e){k+=b.offsetTop;o+=b.offsetLeft;if(c.offset.doesNotAddBorder&&!(c.offset.doesAddBorderForTableAndCells&&xb.test(b.nodeName))){k+=parseFloat(d.borderTopWidth)||0;o+=parseFloat(d.borderLeftWidth)||0}e=b.offsetParent}if(c.offset.subtractsBorderForOverflowNotVisible&&d.overflow!=="visible"){k+=
parseFloat(d.borderTopWidth)||0;o+=parseFloat(d.borderLeftWidth)||0}d=d}if(d.position==="relative"||d.position==="static"){k+=l.offsetTop;o+=l.offsetLeft}if(c.offset.supportsFixedPosition&&d.position==="fixed"){k+=Math.max(h.scrollTop,l.scrollTop);o+=Math.max(h.scrollLeft,l.scrollLeft)}return{top:k,left:o}};c.offset={initialize:function(){var a=t.body,b=t.createElement("div"),d,e,f,h=parseFloat(c.css(a,"marginTop"))||0;c.extend(b.style,{position:"absolute",top:0,left:0,margin:0,border:0,width:"1px",
height:"1px",visibility:"hidden"});b.innerHTML="<div style='position:absolute;top:0;left:0;margin:0;border:5px solid #000;padding:0;width:1px;height:1px;'><div></div></div><table style='position:absolute;top:0;left:0;margin:0;border:5px solid #000;padding:0;width:1px;height:1px;' cellpadding='0' cellspacing='0'><tr><td></td></tr></table>";a.insertBefore(b,a.firstChild);d=b.firstChild;e=d.firstChild;f=d.nextSibling.firstChild.firstChild;this.doesNotAddBorder=e.offsetTop!==5;this.doesAddBorderForTableAndCells=
f.offsetTop===5;e.style.position="fixed";e.style.top="20px";this.supportsFixedPosition=e.offsetTop===20||e.offsetTop===15;e.style.position=e.style.top="";d.style.overflow="hidden";d.style.position="relative";this.subtractsBorderForOverflowNotVisible=e.offsetTop===-5;this.doesNotIncludeMarginInBodyOffset=a.offsetTop!==h;a.removeChild(b);c.offset.initialize=c.noop},bodyOffset:function(a){var b=a.offsetTop,d=a.offsetLeft;c.offset.initialize();if(c.offset.doesNotIncludeMarginInBodyOffset){b+=parseFloat(c.css(a,
"marginTop"))||0;d+=parseFloat(c.css(a,"marginLeft"))||0}return{top:b,left:d}},setOffset:function(a,b,d){var e=c.css(a,"position");if(e==="static")a.style.position="relative";var f=c(a),h=f.offset(),l=c.css(a,"top"),k=c.css(a,"left"),o=e==="absolute"&&c.inArray("auto",[l,k])>-1;e={};var x={};if(o)x=f.position();l=o?x.top:parseInt(l,10)||0;k=o?x.left:parseInt(k,10)||0;if(c.isFunction(b))b=b.call(a,d,h);if(b.top!=null)e.top=b.top-h.top+l;if(b.left!=null)e.left=b.left-h.left+k;"using"in b?b.using.call(a,
e):f.css(e)}};c.fn.extend({position:function(){if(!this[0])return null;var a=this[0],b=this.offsetParent(),d=this.offset(),e=Ia.test(b[0].nodeName)?{top:0,left:0}:b.offset();d.top-=parseFloat(c.css(a,"marginTop"))||0;d.left-=parseFloat(c.css(a,"marginLeft"))||0;e.top+=parseFloat(c.css(b[0],"borderTopWidth"))||0;e.left+=parseFloat(c.css(b[0],"borderLeftWidth"))||0;return{top:d.top-e.top,left:d.left-e.left}},offsetParent:function(){return this.map(function(){for(var a=this.offsetParent||t.body;a&&!Ia.test(a.nodeName)&&
c.css(a,"position")==="static";)a=a.offsetParent;return a})}});c.each(["Left","Top"],function(a,b){var d="scroll"+b;c.fn[d]=function(e){var f=this[0],h;if(!f)return null;if(e!==B)return this.each(function(){if(h=fa(this))h.scrollTo(!a?e:c(h).scrollLeft(),a?e:c(h).scrollTop());else this[d]=e});else return(h=fa(f))?"pageXOffset"in h?h[a?"pageYOffset":"pageXOffset"]:c.support.boxModel&&h.document.documentElement[d]||h.document.body[d]:f[d]}});c.each(["Height","Width"],function(a,b){var d=b.toLowerCase();
c.fn["inner"+b]=function(){return this[0]?parseFloat(c.css(this[0],d,"padding")):null};c.fn["outer"+b]=function(e){return this[0]?parseFloat(c.css(this[0],d,e?"margin":"border")):null};c.fn[d]=function(e){var f=this[0];if(!f)return e==null?null:this;if(c.isFunction(e))return this.each(function(l){var k=c(this);k[d](e.call(this,l,k[d]()))});if(c.isWindow(f))return f.document.compatMode==="CSS1Compat"&&f.document.documentElement["client"+b]||f.document.body["client"+b];else if(f.nodeType===9)return Math.max(f.documentElement["client"+
b],f.body["scroll"+b],f.documentElement["scroll"+b],f.body["offset"+b],f.documentElement["offset"+b]);else if(e===B){f=c.css(f,d);var h=parseFloat(f);return c.isNaN(h)?f:h}else return this.css(d,typeof e==="string"?e:e+"px")}})})(window);
</script><script type="text/javascript">//XRegExp 1.5.0 <xregexp.com> MIT License
var XRegExp;if(XRegExp){throw Error("can't load XRegExp twice in the same frame")}(function(){XRegExp=function(w,r){var q=[],u=XRegExp.OUTSIDE_CLASS,x=0,p,s,v,t,y;if(XRegExp.isRegExp(w)){if(r!==undefined){throw TypeError("can't supply flags when constructing one RegExp from another")}return j(w)}if(g){throw Error("can't call the XRegExp constructor within token definition functions")}r=r||"";p={hasNamedCapture:false,captureNames:[],hasFlag:function(z){return r.indexOf(z)>-1},setFlag:function(z){r+=z}};while(x<w.length){s=o(w,x,u,p);if(s){q.push(s.output);x+=(s.match[0].length||1)}else{if(v=m.exec.call(i[u],w.slice(x))){q.push(v[0]);x+=v[0].length}else{t=w.charAt(x);if(t==="["){u=XRegExp.INSIDE_CLASS}else{if(t==="]"){u=XRegExp.OUTSIDE_CLASS}}q.push(t);x++}}}y=RegExp(q.join(""),m.replace.call(r,h,""));y._xregexp={source:w,captureNames:p.hasNamedCapture?p.captureNames:null};return y};XRegExp.version="1.5.0";XRegExp.INSIDE_CLASS=1;XRegExp.OUTSIDE_CLASS=2;var c=/\$(?:(\d\d?|[$&`'])|{([$\w]+)})/g,h=/[^gimy]+|([\s\S])(?=[\s\S]*\1)/g,n=/^(?:[?*+]|{\d+(?:,\d*)?})\??/,g=false,k=[],m={exec:RegExp.prototype.exec,test:RegExp.prototype.test,match:String.prototype.match,replace:String.prototype.replace,split:String.prototype.split},a=m.exec.call(/()??/,"")[1]===undefined,e=function(){var p=/^/g;m.test.call(p,"");return !p.lastIndex}(),f=function(){var p=/x/g;m.replace.call("x",p,"");return !p.lastIndex}(),b=RegExp.prototype.sticky!==undefined,i={};i[XRegExp.INSIDE_CLASS]=/^(?:\\(?:[0-3][0-7]{0,2}|[4-7][0-7]?|x[\dA-Fa-f]{2}|u[\dA-Fa-f]{4}|c[A-Za-z]|[\s\S]))/;i[XRegExp.OUTSIDE_CLASS]=/^(?:\\(?:0(?:[0-3][0-7]{0,2}|[4-7][0-7]?)?|[1-9]\d*|x[\dA-Fa-f]{2}|u[\dA-Fa-f]{4}|c[A-Za-z]|[\s\S])|\(\?[:=!]|[?*+]\?|{\d+(?:,\d*)?}\??)/;XRegExp.addToken=function(s,r,q,p){k.push({pattern:j(s,"g"+(b?"y":"")),handler:r,scope:q||XRegExp.OUTSIDE_CLASS,trigger:p||null})};XRegExp.cache=function(r,p){var q=r+"/"+(p||"");return XRegExp.cache[q]||(XRegExp.cache[q]=XRegExp(r,p))};XRegExp.copyAsGlobal=function(p){return j(p,"g")};XRegExp.escape=function(p){return p.replace(/[-[\]{}()*+?.,\\^$|#\s]/g,"\\$&")};XRegExp.execAt=function(s,r,t,q){r=j(r,"g"+((q&&b)?"y":""));r.lastIndex=t=t||0;var p=r.exec(s);if(q){return(p&&p.index===t)?p:null}else{return p}};XRegExp.freezeTokens=function(){XRegExp.addToken=function(){throw Error("can't run addToken after freezeTokens")}};XRegExp.isRegExp=function(p){return Object.prototype.toString.call(p)==="[object RegExp]"};XRegExp.iterate=function(u,p,v,s){var t=j(p,"g"),r=-1,q;while(q=t.exec(u)){v.call(s,q,++r,u,t);if(t.lastIndex===q.index){t.lastIndex++}}if(p.global){p.lastIndex=0}};XRegExp.matchChain=function(q,p){return function r(s,x){var v=p[x].regex?p[x]:{regex:p[x]},u=j(v.regex,"g"),w=[],t;for(t=0;t<s.length;t++){XRegExp.iterate(s[t],u,function(y){w.push(v.backref?(y[v.backref]||""):y[0])})}return((x===p.length-1)||!w.length)?w:r(w,x+1)}([q],0)};RegExp.prototype.apply=function(q,p){return this.exec(p[0])};RegExp.prototype.call=function(p,q){return this.exec(q)};RegExp.prototype.exec=function(t){var r=m.exec.apply(this,arguments),q,p;if(r){if(!a&&r.length>1&&l(r,"")>-1){p=RegExp(this.source,m.replace.call(d(this),"g",""));m.replace.call(t.slice(r.index),p,function(){for(var u=1;u<arguments.length-2;u++){if(arguments[u]===undefined){r[u]=undefined}}})}if(this._xregexp&&this._xregexp.captureNames){for(var s=1;s<r.length;s++){q=this._xregexp.captureNames[s-1];if(q){r[q]=r[s]}}}if(!e&&this.global&&!r[0].length&&(this.lastIndex>r.index)){this.lastIndex--}}return r};if(!e){RegExp.prototype.test=function(q){var p=m.exec.call(this,q);if(p&&this.global&&!p[0].length&&(this.lastIndex>p.index)){this.lastIndex--}return !!p}}String.prototype.match=function(q){if(!XRegExp.isRegExp(q)){q=RegExp(q)}if(q.global){var p=m.match.apply(this,arguments);q.lastIndex=0;return p}return q.exec(this)};String.prototype.replace=function(r,s){var t=XRegExp.isRegExp(r),q,p,u;if(t&&typeof s.valueOf()==="string"&&s.indexOf("${")===-1&&f){return m.replace.apply(this,arguments)}if(!t){r=r+""}else{if(r._xregexp){q=r._xregexp.captureNames}}if(typeof s==="function"){p=m.replace.call(this,r,function(){if(q){arguments[0]=new String(arguments[0]);for(var v=0;v<q.length;v++){if(q[v]){arguments[0][q[v]]=arguments[v+1]}}}if(t&&r.global){r.lastIndex=arguments[arguments.length-2]+arguments[0].length}return s.apply(null,arguments)})}else{u=this+"";p=m.replace.call(u,r,function(){var v=arguments;return m.replace.call(s,c,function(x,w,A){if(w){switch(w){case"$":return"$";case"&":return v[0];case"`":return v[v.length-1].slice(0,v[v.length-2]);case"'":return v[v.length-1].slice(v[v.length-2]+v[0].length);default:var y="";w=+w;if(!w){return x}while(w>v.length-3){y=String.prototype.slice.call(w,-1)+y;w=Math.floor(w/10)}return(w?v[w]||"":"$")+y}}else{var z=+A;if(z<=v.length-3){return v[z]}z=q?l(q,A):-1;return z>-1?v[z+1]:x}})})}if(t&&r.global){r.lastIndex=0}return p};String.prototype.split=function(u,p){if(!XRegExp.isRegExp(u)){return m.split.apply(this,arguments)}var w=this+"",r=[],v=0,t,q;if(p===undefined||+p<0){p=Infinity}else{p=Math.floor(+p);if(!p){return[]}}u=XRegExp.copyAsGlobal(u);while(t=u.exec(w)){if(u.lastIndex>v){r.push(w.slice(v,t.index));if(t.length>1&&t.index<w.length){Array.prototype.push.apply(r,t.slice(1))}q=t[0].length;v=u.lastIndex;if(r.length>=p){break}}if(u.lastIndex===t.index){u.lastIndex++}}if(v===w.length){if(!m.test.call(u,"")||q){r.push("")}}else{r.push(w.slice(v))}return r.length>p?r.slice(0,p):r};function j(r,q){if(!XRegExp.isRegExp(r)){throw TypeError("type RegExp expected")}var p=r._xregexp;r=XRegExp(r.source,d(r)+(q||""));if(p){r._xregexp={source:p.source,captureNames:p.captureNames?p.captureNames.slice(0):null}}return r}function d(p){return(p.global?"g":"")+(p.ignoreCase?"i":"")+(p.multiline?"m":"")+(p.extended?"x":"")+(p.sticky?"y":"")}function o(v,u,w,p){var r=k.length,y,s,x;g=true;try{while(r--){x=k[r];if((w&x.scope)&&(!x.trigger||x.trigger.call(p))){x.pattern.lastIndex=u;s=x.pattern.exec(v);if(s&&s.index===u){y={output:x.handler.call(p,s,w),match:s};break}}}}catch(q){throw q}finally{g=false}return y}function l(s,q,r){if(Array.prototype.indexOf){return s.indexOf(q,r)}for(var p=r||0;p<s.length;p++){if(s[p]===q){return p}}return -1}XRegExp.addToken(/\(\?#[^)]*\)/,function(p){return m.test.call(n,p.input.slice(p.index+p[0].length))?"":"(?:)"});XRegExp.addToken(/\((?!\?)/,function(){this.captureNames.push(null);return"("});XRegExp.addToken(/\(\?<([$\w]+)>/,function(p){this.captureNames.push(p[1]);this.hasNamedCapture=true;return"("});XRegExp.addToken(/\\k<([\w$]+)>/,function(q){var p=l(this.captureNames,q[1]);return p>-1?"\\"+(p+1)+(isNaN(q.input.charAt(q.index+q[0].length))?"":"(?:)"):q[0]});XRegExp.addToken(/\[\^?]/,function(p){return p[0]==="[]"?"\\b\\B":"[\\s\\S]"});XRegExp.addToken(/^\(\?([imsx]+)\)/,function(p){this.setFlag(p[1]);return""});XRegExp.addToken(/(?:\s+|#.*)+/,function(p){return m.test.call(n,p.input.slice(p.index+p[0].length))?"":"(?:)"},XRegExp.OUTSIDE_CLASS,function(){return this.hasFlag("x")});XRegExp.addToken(/\./,function(){return"[\\s\\S]"},XRegExp.OUTSIDE_CLASS,function(){return this.hasFlag("s")})})();
</script><script type="text/javascript">/**
 * SyntaxHighlighter
 * http://alexgorbatchev.com/SyntaxHighlighter
 *
 * SyntaxHighlighter is donationware. If you are using it, please donate.
 * http://alexgorbatchev.com/SyntaxHighlighter/donate.html
 *
 * @version
 * 3.0.83 (July 02 2010)
 * 
 * @copyright
 * Copyright (C) 2004-2010 Alex Gorbatchev.
 *
 * @license
 * Dual licensed under the MIT and GPL licenses.
 */
//
// Begin anonymous function. This is used to contain local scope variables without polutting global scope.
//
var SyntaxHighlighter = function() { 

// CommonJS
if (typeof(require) != 'undefined' && typeof(XRegExp) == 'undefined')
{
	XRegExp = require('XRegExp').XRegExp;
}

// Shortcut object which will be assigned to the SyntaxHighlighter variable.
// This is a shorthand for local reference in order to avoid long namespace 
// references to SyntaxHighlighter.whatever...
var sh = {
	defaults : {
		/** Additional CSS class names to be added to highlighter elements. */
		'class-name' : '',
		
		/** First line number. */
		'first-line' : 1,
		
		/**
		 * Pads line numbers. Possible values are:
		 *
		 *   false - don't pad line numbers.
		 *   true  - automaticaly pad numbers with minimum required number of leading zeroes.
		 *   [int] - length up to which pad line numbers.
		 */
		'pad-line-numbers' : false,
		
		/** Lines to highlight. */
		'highlight' : null,
		
		/** Title to be displayed above the code block. */
		'title' : null,
		
		/** Enables or disables smart tabs. */
		'smart-tabs' : true,
		
		/** Gets or sets tab size. */
		'tab-size' : 4,
		
		/** Enables or disables gutter. */
		'gutter' : true,
		
		/** Enables or disables toolbar. */
		'toolbar' : true,
		
		/** Enables quick code copy and paste from double click. */
		'quick-code' : true,
		
		/** Forces code view to be collapsed. */
		'collapse' : false,
		
		/** Enables or disables automatic links. */
		'auto-links' : true,
		
		/** Gets or sets light mode. Equavalent to turning off gutter and toolbar. */
		'light' : false,
		
		'html-script' : false
	},
	
	config : {
		space : '&nbsp;',
		
		/** Enables use of <SCRIPT type="syntaxhighlighter" /> tags. */
		useScriptTags : true,
		
		/** Blogger mode flag. */
		bloggerMode : false,
		
		stripBrs : false,
		
		/** Name of the tag that SyntaxHighlighter will automatically look for. */
		tagName : 'pre',
		
		strings : {
			expandSource : 'expand source',
			help : '?',
			alert: 'SyntaxHighlighter\n\n',
			noBrush : 'Can\'t find brush for: ',
			brushNotHtmlScript : 'Brush wasn\'t configured for html-script option: ',
			
			// this is populated by the build script
			aboutDialog : '<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8" /><title>About SyntaxHighlighter</title></head><body style="font-family:Geneva,Arial,Helvetica,sans-serif;background-color:#fff;color:#000;font-size:1em;text-align:center;"><div style="text-align:center;margin-top:1.5em;"><div style="font-size:xx-large;">SyntaxHighlighter</div><div style="font-size:.75em;margin-bottom:3em;"><div>version 3.0.83 (July 02 2010)</div><div><a href="http://alexgorbatchev.com/SyntaxHighlighter" target="_blank" style="color:#005896">http://alexgorbatchev.com/SyntaxHighlighter</a></div><div>JavaScript code syntax highlighter.</div><div>Copyright 2004-2010 Alex Gorbatchev.</div></div><div>If you like this script, please <a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=2930402" style="color:#005896">donate</a> to <br/>keep development active!</div></div></body></html>'
		}
	},
	
	/** Internal 'global' variables. */
	vars : {
		discoveredBrushes : null,
		highlighters : {}
	},
	
	/** This object is populated by user included external brush files. */
	brushes : {},

	/** Common regular expressions. */
	regexLib : {
		multiLineCComments			: /\/\*[\s\S]*?\*\//gm,
		singleLineCComments			: /\/\/.*$/gm,
		singleLinePerlComments		: /#.*$/gm,
		doubleQuotedString			: /"([^\\"\n]|\\.)*"/g,
		singleQuotedString			: /'([^\\'\n]|\\.)*'/g,
		multiLineDoubleQuotedString	: new XRegExp('"([^\\\\"]|\\\\.)*"', 'gs'),
		multiLineSingleQuotedString	: new XRegExp("'([^\\\\']|\\\\.)*'", 'gs'),
		xmlComments					: /(&lt;|<)!--[\s\S]*?--(&gt;|>)/gm,
		url							: /\w+:\/\/[\w-.\/?%&=:@;]*/g,
		
		/** <?= ?> tags. */
		phpScriptTags 				: { left: /(&lt;|<)\?=?/g, right: /\?(&gt;|>)/g },
		
		/** <%= %> tags. */
		aspScriptTags				: { left: /(&lt;|<)%=?/g, right: /%(&gt;|>)/g },
		
		scriptScriptTags			: { left: /(&lt;|<)\s*script.*?(&gt;|>)/gi, right: /(&lt;|<)\/\s*script\s*(&gt;|>)/gi }
	},

	toolbar: {
		/**
		 * Generates HTML markup for the toolbar.
		 * @param {Highlighter} highlighter Highlighter instance.
		 * @return {String} Returns HTML markup.
		 */
		getHtml: function(highlighter)
		{
			var html = '<div class="toolbar">',
				items = sh.toolbar.items,
				list = items.list
				;
			
			function defaultGetHtml(highlighter, name)
			{
				return sh.toolbar.getButtonHtml(highlighter, name, sh.config.strings[name]);
			};
			
			for (var i = 0; i < list.length; i++)
				html += (items[list[i]].getHtml || defaultGetHtml)(highlighter, list[i]);
			
			html += '</div>';
			
			return html;
		},
		
		/**
		 * Generates HTML markup for a regular button in the toolbar.
		 * @param {Highlighter} highlighter Highlighter instance.
		 * @param {String} commandName		Command name that would be executed.
		 * @param {String} label			Label text to display.
		 * @return {String}					Returns HTML markup.
		 */
		getButtonHtml: function(highlighter, commandName, label)
		{
			return '<span><a href="#" class="toolbar_item'
				+ ' command_' + commandName
				+ ' ' + commandName
				+ '">' + label + '</a></span>'
				;
		},
		
		/**
		 * Event handler for a toolbar anchor.
		 */
		handler: function(e)
		{
			var target = e.target,
				className = target.className || ''
				;

			function getValue(name)
			{
				var r = new RegExp(name + '_(\\w+)'),
					match = r.exec(className)
					;

				return match ? match[1] : null;
			};
			
			var highlighter = getHighlighterById(findParentElement(target, '.syntaxhighlighter').id),
				commandName = getValue('command')
				;
			
			// execute the toolbar command
			if (highlighter && commandName)
				sh.toolbar.items[commandName].execute(highlighter);

			// disable default A click behaviour
			e.preventDefault();
		},
		
		/** Collection of toolbar items. */
		items : {
			// Ordered lis of items in the toolbar. Can't expect `for (var n in items)` to be consistent.
			list: ['expandSource', 'help'],

			expandSource: {
				getHtml: function(highlighter)
				{
					if (highlighter.getParam('collapse') != true)
						return '';
						
					var title = highlighter.getParam('title');
					return sh.toolbar.getButtonHtml(highlighter, 'expandSource', title ? title : sh.config.strings.expandSource);
				},
			
				execute: function(highlighter)
				{
					var div = getHighlighterDivById(highlighter.id);
					removeClass(div, 'collapsed');
				}
			},

			/** Command to display the about dialog window. */
			help: {
				execute: function(highlighter)
				{	
					var wnd = popup('', '_blank', 500, 250, 'scrollbars=0'),
						doc = wnd.document
						;
					
					doc.write(sh.config.strings.aboutDialog);
					doc.close();
					wnd.focus();
				}
			}
		}
	},

	/**
	 * Finds all elements on the page which should be processes by SyntaxHighlighter.
	 *
	 * @param {Object} globalParams		Optional parameters which override element's 
	 * 									parameters. Only used if element is specified.
	 * 
	 * @param {Object} element	Optional element to highlight. If none is
	 * 							provided, all elements in the current document 
	 * 							are returned which qualify.
	 *
	 * @return {Array}	Returns list of <code>{ target: DOMElement, params: Object }</code> objects.
	 */
	findElements: function(globalParams, element)
	{
		var elements = element ? [element] : toArray(document.getElementsByTagName(sh.config.tagName)), 
			conf = sh.config,
			result = []
			;

		// support for <SCRIPT TYPE="syntaxhighlighter" /> feature
		if (conf.useScriptTags)
			elements = elements.concat(getSyntaxHighlighterScriptTags());

		if (elements.length === 0) 
			return result;
	
		for (var i = 0; i < elements.length; i++) 
		{
			var item = {
				target: elements[i], 
				// local params take precedence over globals
				params: merge(globalParams, parseParams(elements[i].className))
			};

			if (item.params['brush'] == null)
				continue;
				
			result.push(item);
		}
		
		return result;
	},

	/**
	 * Shorthand to highlight all elements on the page that are marked as 
	 * SyntaxHighlighter source code.
	 * 
	 * @param {Object} globalParams		Optional parameters which override element's 
	 * 									parameters. Only used if element is specified.
	 * 
	 * @param {Object} element	Optional element to highlight. If none is
	 * 							provided, all elements in the current document 
	 * 							are highlighted.
	 */ 
	highlight: function(globalParams, element)
	{
		var elements = this.findElements(globalParams, element),
			propertyName = 'innerHTML', 
			highlighter = null,
			conf = sh.config
			;

		if (elements.length === 0) 
			return;
	
		for (var i = 0; i < elements.length; i++) 
		{
			var element = elements[i],
				target = element.target,
				params = element.params,
				brushName = params.brush,
				code
				;

			if (brushName == null)
				continue;

			// Instantiate a brush
			if (params['html-script'] == 'true' || sh.defaults['html-script'] == true) 
			{
				highlighter = new sh.HtmlScript(brushName);
				brushName = 'htmlscript';
			}
			else
			{
				var brush = findBrush(brushName);
				
				if (brush)
					highlighter = new brush();
				else
					continue;
			}
			
			code = target[propertyName];
			
			// remove CDATA from <SCRIPT/> tags if it's present
			if (conf.useScriptTags)
				code = stripCData(code);
				
			// Inject title if the attribute is present
			if ((target.title || '') != '')
				params.title = target.title;
				
			params['brush'] = brushName;
			highlighter.init(params);
			element = highlighter.getDiv(code);
			
			// carry over ID
			if ((target.id || '') != '')
				element.id = target.id;
			
			target.parentNode.replaceChild(element, target);
		}
	},

	/**
	 * Main entry point for the SyntaxHighlighter.
	 * @param {Object} params Optional params to apply to all highlighted elements.
	 */
	all: function(params)
	{
		attachEvent(
			window,
			'load',
			function() { sh.highlight(params); }
		);
	}
}; // end of sh

sh['all']			= sh.all;
sh['highlight']		= sh.highlight;

/**
 * Checks if target DOM elements has specified CSS class.
 * @param {DOMElement} target Target DOM element to check.
 * @param {String} className Name of the CSS class to check for.
 * @return {Boolean} Returns true if class name is present, false otherwise.
 */
function hasClass(target, className)
{
	return target.className.indexOf(className) != -1;
};

/**
 * Adds CSS class name to the target DOM element.
 * @param {DOMElement} target Target DOM element.
 * @param {String} className New CSS class to add.
 */
function addClass(target, className)
{
	if (!hasClass(target, className))
		target.className += ' ' + className;
};

/**
 * Removes CSS class name from the target DOM element.
 * @param {DOMElement} target Target DOM element.
 * @param {String} className CSS class to remove.
 */
function removeClass(target, className)
{
	target.className = target.className.replace(className, '');
};

/**
 * Converts the source to array object. Mostly used for function arguments and 
 * lists returned by getElementsByTagName() which aren't Array objects.
 * @param {List} source Source list.
 * @return {Array} Returns array.
 */
function toArray(source)
{
	var result = [];
	
	for (var i = 0; i < source.length; i++) 
		result.push(source[i]);
		
	return result;
};

/**
 * Splits block of text into lines.
 * @param {String} block Block of text.
 * @return {Array} Returns array of lines.
 */
function splitLines(block)
{
	return block.split('\n');
}

/**
 * Generates HTML ID for the highlighter.
 * @param {String} highlighterId Highlighter ID.
 * @return {String} Returns HTML ID.
 */
function getHighlighterId(id)
{
	var prefix = 'highlighter_';
	return id.indexOf(prefix) == 0 ? id : prefix + id;
};

/**
 * Finds Highlighter instance by ID.
 * @param {String} highlighterId Highlighter ID.
 * @return {Highlighter} Returns instance of the highlighter.
 */
function getHighlighterById(id)
{
	return sh.vars.highlighters[getHighlighterId(id)];
};

/**
 * Finds highlighter's DIV container.
 * @param {String} highlighterId Highlighter ID.
 * @return {Element} Returns highlighter's DIV element.
 */
function getHighlighterDivById(id)
{
	return document.getElementById(getHighlighterId(id));
};

/**
 * Stores highlighter so that getHighlighterById() can do its thing. Each
 * highlighter must call this method to preserve itself.
 * @param {Highilghter} highlighter Highlighter instance.
 */
function storeHighlighter(highlighter)
{
	sh.vars.highlighters[getHighlighterId(highlighter.id)] = highlighter;
};

/**
 * Looks for a child or parent node which has specified classname.
 * Equivalent to jQuery's $(container).find(".className")
 * @param {Element} target Target element.
 * @param {String} search Class name or node name to look for.
 * @param {Boolean} reverse If set to true, will go up the node tree instead of down.
 * @return {Element} Returns found child or parent element on null.
 */
function findElement(target, search, reverse /* optional */)
{
	if (target == null)
		return null;
		
	var nodes			= reverse != true ? target.childNodes : [ target.parentNode ],
		propertyToFind	= { '#' : 'id', '.' : 'className' }[search.substr(0, 1)] || 'nodeName',
		expectedValue,
		found
		;

	expectedValue = propertyToFind != 'nodeName'
		? search.substr(1)
		: search.toUpperCase()
		;
		
	// main return of the found node
	if ((target[propertyToFind] || '').indexOf(expectedValue) != -1)
		return target;
	
	for (var i = 0; nodes && i < nodes.length && found == null; i++)
		found = findElement(nodes[i], search, reverse);
	
	return found;
};

/**
 * Looks for a parent node which has specified classname.
 * This is an alias to <code>findElement(container, className, true)</code>.
 * @param {Element} target Target element.
 * @param {String} className Class name to look for.
 * @return {Element} Returns found parent element on null.
 */
function findParentElement(target, className)
{
	return findElement(target, className, true);
};

/**
 * Finds an index of element in the array.
 * @ignore
 * @param {Object} searchElement
 * @param {Number} fromIndex
 * @return {Number} Returns index of element if found; -1 otherwise.
 */
function indexOf(array, searchElement, fromIndex)
{
	fromIndex = Math.max(fromIndex || 0, 0);

	for (var i = fromIndex; i < array.length; i++)
		if(array[i] == searchElement)
			return i;
	
	return -1;
};

/**
 * Generates a unique element ID.
 */
function guid(prefix)
{
	return (prefix || '') + Math.round(Math.random() * 1000000).toString();
};

/**
 * Merges two objects. Values from obj2 override values in obj1.
 * Function is NOT recursive and works only for one dimensional objects.
 * @param {Object} obj1 First object.
 * @param {Object} obj2 Second object.
 * @return {Object} Returns combination of both objects.
 */
function merge(obj1, obj2)
{
	var result = {}, name;

	for (name in obj1) 
		result[name] = obj1[name];
	
	for (name in obj2) 
		result[name] = obj2[name];
		
	return result;
};

/**
 * Attempts to convert string to boolean.
 * @param {String} value Input string.
 * @return {Boolean} Returns true if input was "true", false if input was "false" and value otherwise.
 */
function toBoolean(value)
{
	var result = { "true" : true, "false" : false }[value];
	return result == null ? value : result;
};

/**
 * Opens up a centered popup window.
 * @param {String} url		URL to open in the window.
 * @param {String} name		Popup name.
 * @param {int} width		Popup width.
 * @param {int} height		Popup height.
 * @param {String} options	window.open() options.
 * @return {Window}			Returns window instance.
 */
function popup(url, name, width, height, options)
{
	var x = (screen.width - width) / 2,
		y = (screen.height - height) / 2
		;
		
	options +=	', left=' + x + 
				', top=' + y +
				', width=' + width +
				', height=' + height
		;
	options = options.replace(/^,/, '');

	var win = window.open(url, name, options);
	win.focus();
	return win;
};

/**
 * Adds event handler to the target object.
 * @param {Object} obj		Target object.
 * @param {String} type		Name of the event.
 * @param {Function} func	Handling function.
 */
function attachEvent(obj, type, func, scope)
{
	function handler(e)
	{
		e = e || window.event;
		
		if (!e.target)
		{
			e.target = e.srcElement;
			e.preventDefault = function()
			{
				this.returnValue = false;
			};
		}
			
		func.call(scope || window, e);
	};
	
	if (obj.attachEvent) 
	{
		obj.attachEvent('on' + type, handler);
	}
	else 
	{
		obj.addEventListener(type, handler, false);
	}
};

/**
 * Displays an alert.
 * @param {String} str String to display.
 */
function alert(str)
{
	window.alert(sh.config.strings.alert + str);
};

/**
 * Finds a brush by its alias.
 *
 * @param {String} alias		Brush alias.
 * @param {Boolean} showAlert	Suppresses the alert if false.
 * @return {Brush}				Returns bursh constructor if found, null otherwise.
 */
function findBrush(alias, showAlert)
{
	var brushes = sh.vars.discoveredBrushes,
		result = null
		;
	
	if (brushes == null) 
	{
		brushes = {};
		
		// Find all brushes
		for (var brush in sh.brushes) 
		{
			var info = sh.brushes[brush],
				aliases = info.aliases
				;
			
			if (aliases == null) 
				continue;
			
			// keep the brush name
			info.brushName = brush.toLowerCase();
			
			for (var i = 0; i < aliases.length; i++) 
				brushes[aliases[i]] = brush;
		}
		
		sh.vars.discoveredBrushes = brushes;
	}
	
	result = sh.brushes[brushes[alias]];

	if (result == null && showAlert != false)
		alert(sh.config.strings.noBrush + alias);
	
	return result;
};

/**
 * Executes a callback on each line and replaces each line with result from the callback.
 * @param {Object} str			Input string.
 * @param {Object} callback		Callback function taking one string argument and returning a string.
 */
function eachLine(str, callback)
{
	var lines = splitLines(str);
	
	for (var i = 0; i < lines.length; i++)
		lines[i] = callback(lines[i], i);
		
	return lines.join('\n');
};

/**
 * This is a special trim which only removes first and last empty lines
 * and doesn't affect valid leading space on the first line.
 * 
 * @param {String} str   Input string
 * @return {String}      Returns string without empty first and last lines.
 */
function trimFirstAndLastLines(str)
{
	return str.replace(/^[ ]*[\n]+|[\n]*[ ]*$/g, '');
};

/**
 * Parses key/value pairs into hash object.
 * 
 * Understands the following formats:
 * - name: word;
 * - name: [word, word];
 * - name: "string";
 * - name: 'string';
 * 
 * For example:
 *   name1: value; name2: [value, value]; name3: 'value'
 *   
 * @param {String} str    Input string.
 * @return {Object}       Returns deserialized object.
 */
function parseParams(str)
{
	var match, 
		result = {},
		arrayRegex = new XRegExp("^\\[(?<values>(.*?))\\]$"),
		regex = new XRegExp(
			"(?<name>[\\w-]+)" +
			"\\s*:\\s*" +
			"(?<value>" +
				"[\\w-%#]+|" +		// word
				"\\[.*?\\]|" +		// [] array
				'".*?"|' +			// "" string
				"'.*?'" +			// '' string
			")\\s*;?",
			"g"
		)
		;

	while ((match = regex.exec(str)) != null) 
	{
		var value = match.value
			.replace(/^['"]|['"]$/g, '') // strip quotes from end of strings
			;
		
		// try to parse array value
		if (value != null && arrayRegex.test(value))
		{
			var m = arrayRegex.exec(value);
			value = m.values.length > 0 ? m.values.split(/\s*,\s*/) : [];
		}
		
		result[match.name] = value;
	}
	
	return result;
};

/**
 * Wraps each line of the string into <code/> tag with given style applied to it.
 * 
 * @param {String} str   Input string.
 * @param {String} css   Style name to apply to the string.
 * @return {String}      Returns input string with each line surrounded by <span/> tag.
 */
function wrapLinesWithCode(str, css)
{
	if (str == null || str.length == 0 || str == '\n') 
		return str;

	str = str.replace(/</g, '&lt;');

	// Replace two or more sequential spaces with &nbsp; leaving last space untouched.
	str = str.replace(/ {2,}/g, function(m)
	{
		var spaces = '';
		
		for (var i = 0; i < m.length - 1; i++)
			spaces += sh.config.space;
		
		return spaces + ' ';
	});

	// Split each line and apply <span class="...">...</span> to them so that
	// leading spaces aren't included.
	if (css != null) 
		str = eachLine(str, function(line)
		{
			if (line.length == 0) 
				return '';
			
			var spaces = '';
			
			line = line.replace(/^(&nbsp;| )+/, function(s)
			{
				spaces = s;
				return '';
			});
			
			if (line.length == 0) 
				return spaces;
			
			return spaces + '<code class="' + css + '">' + line + '</code>';
		});

	return str;
};

/**
 * Pads number with zeros until it's length is the same as given length.
 * 
 * @param {Number} number	Number to pad.
 * @param {Number} length	Max string length with.
 * @return {String}			Returns a string padded with proper amount of '0'.
 */
function padNumber(number, length)
{
	var result = number.toString();
	
	while (result.length < length)
		result = '0' + result;
	
	return result;
};

/**
 * Replaces tabs with spaces.
 * 
 * @param {String} code		Source code.
 * @param {Number} tabSize	Size of the tab.
 * @return {String}			Returns code with all tabs replaces by spaces.
 */
function processTabs(code, tabSize)
{
	var tab = '';
	
	for (var i = 0; i < tabSize; i++)
		tab += ' ';

	return code.replace(/\t/g, tab);
};

/**
 * Replaces tabs with smart spaces.
 * 
 * @param {String} code    Code to fix the tabs in.
 * @param {Number} tabSize Number of spaces in a column.
 * @return {String}        Returns code with all tabs replaces with roper amount of spaces.
 */
function processSmartTabs(code, tabSize)
{
	var lines = splitLines(code),
		tab = '\t',
		spaces = ''
		;
	
	// Create a string with 1000 spaces to copy spaces from... 
	// It's assumed that there would be no indentation longer than that.
	for (var i = 0; i < 50; i++) 
		spaces += '                    '; // 20 spaces * 50
			
	// This function inserts specified amount of spaces in the string
	// where a tab is while removing that given tab.
	function insertSpaces(line, pos, count)
	{
		return line.substr(0, pos)
			+ spaces.substr(0, count)
			+ line.substr(pos + 1, line.length) // pos + 1 will get rid of the tab
			;
	};

	// Go through all the lines and do the 'smart tabs' magic.
	code = eachLine(code, function(line)
	{
		if (line.indexOf(tab) == -1) 
			return line;
		
		var pos = 0;
		
		while ((pos = line.indexOf(tab)) != -1) 
		{
			// This is pretty much all there is to the 'smart tabs' logic.
			// Based on the position within the line and size of a tab,
			// calculate the amount of spaces we need to insert.
			var spaces = tabSize - pos % tabSize;
			line = insertSpaces(line, pos, spaces);
		}
		
		return line;
	});
	
	return code;
};

/**
 * Performs various string fixes based on configuration.
 */
function fixInputString(str)
{
	var br = /<br\s*\/?>|&lt;br\s*\/?&gt;/gi;
	
	if (sh.config.bloggerMode == true)
		str = str.replace(br, '\n');

	if (sh.config.stripBrs == true)
		str = str.replace(br, '');
		
	return str;
};

/**
 * Removes all white space at the begining and end of a string.
 * 
 * @param {String} str   String to trim.
 * @return {String}      Returns string without leading and following white space characters.
 */
function trim(str)
{
	return str.replace(/^\s+|\s+$/g, '');
};

/**
 * Unindents a block of text by the lowest common indent amount.
 * @param {String} str   Text to unindent.
 * @return {String}      Returns unindented text block.
 */
function unindent(str)
{
	var lines = splitLines(fixInputString(str)),
		indents = new Array(),
		regex = /^\s*/,
		min = 1000
		;
	
	// go through every line and check for common number of indents
	for (var i = 0; i < lines.length && min > 0; i++) 
	{
		var line = lines[i];
		
		if (trim(line).length == 0) 
			continue;
		
		var matches = regex.exec(line);
		
		// In the event that just one line doesn't have leading white space
		// we can't unindent anything, so bail completely.
		if (matches == null) 
			return str;
			
		min = Math.min(matches[0].length, min);
	}
	
	// trim minimum common number of white space from the begining of every line
	if (min > 0) 
		for (var i = 0; i < lines.length; i++) 
			lines[i] = lines[i].substr(min);
	
	return lines.join('\n');
};

/**
 * Callback method for Array.sort() which sorts matches by
 * index position and then by length.
 * 
 * @param {Match} m1	Left object.
 * @param {Match} m2    Right object.
 * @return {Number}     Returns -1, 0 or -1 as a comparison result.
 */
function matchesSortCallback(m1, m2)
{
	// sort matches by index first
	if(m1.index < m2.index)
		return -1;
	else if(m1.index > m2.index)
		return 1;
	else
	{
		// if index is the same, sort by length
		if(m1.length < m2.length)
			return -1;
		else if(m1.length > m2.length)
			return 1;
	}
	
	return 0;
};

/**
 * Executes given regular expression on provided code and returns all
 * matches that are found.
 * 
 * @param {String} code    Code to execute regular expression on.
 * @param {Object} regex   Regular expression item info from <code>regexList</code> collection.
 * @return {Array}         Returns a list of Match objects.
 */ 
function getMatches(code, regexInfo)
{
	function defaultAdd(match, regexInfo)
	{
		return match[0];
	};
	
	var index = 0,
		match = null,
		matches = [],
		func = regexInfo.func ? regexInfo.func : defaultAdd
		;
	
	while((match = regexInfo.regex.exec(code)) != null)
	{
		var resultMatch = func(match, regexInfo);
		
		if (typeof(resultMatch) == 'string')
			resultMatch = [new sh.Match(resultMatch, match.index, regexInfo.css)];

		matches = matches.concat(resultMatch);
	}
	
	return matches;
};

/**
 * Turns all URLs in the code into <a/> tags.
 * @param {String} code Input code.
 * @return {String} Returns code with </a> tags.
 */
function processUrls(code)
{
	var gt = /(.*)((&gt;|&lt;).*)/;
	
	return code.replace(sh.regexLib.url, function(m)
	{
		var suffix = '',
			match = null
			;
		
		// We include &lt; and &gt; in the URL for the common cases like <http://google.com>
		// The problem is that they get transformed into &lt;http://google.com&gt;
		// Where as &gt; easily looks like part of the URL string.
	
		if (match = gt.exec(m))
		{
			m = match[1];
			suffix = match[2];
		}
		
		return '<a href="' + m + '">' + m + '</a>' + suffix;
	});
};

/**
 * Finds all <SCRIPT TYPE="syntaxhighlighter" /> elementss.
 * @return {Array} Returns array of all found SyntaxHighlighter tags.
 */
function getSyntaxHighlighterScriptTags()
{
	var tags = document.getElementsByTagName('script'),
		result = []
		;
	
	for (var i = 0; i < tags.length; i++)
		if (tags[i].type == 'syntaxhighlighter')
			result.push(tags[i]);
			
	return result;
};

/**
 * Strips <![CDATA[]]> from <SCRIPT /> content because it should be used
 * there in most cases for XHTML compliance.
 * @param {String} original	Input code.
 * @return {String} Returns code without leading <![CDATA[]]> tags.
 */
function stripCData(original)
{
	var left = '<![CDATA[',
		right = ']]>',
		// for some reason IE inserts some leading blanks here
		copy = trim(original),
		changed = false,
		leftLength = left.length,
		rightLength = right.length
		;
	
	if (copy.indexOf(left) == 0)
	{
		copy = copy.substring(leftLength);
		changed = true;
	}
	
	var copyLength = copy.length;
	
	if (copy.indexOf(right) == copyLength - rightLength)
	{
		copy = copy.substring(0, copyLength - rightLength);
		changed = true;
	}
	
	return changed ? copy : original;
};


/**
 * Quick code mouse double click handler.
 */
function quickCodeHandler(e)
{
	var target = e.target,
		highlighterDiv = findParentElement(target, '.syntaxhighlighter'),
		container = findParentElement(target, '.container'),
		textarea = document.createElement('textarea'),
		highlighter
		;

	if (!container || !highlighterDiv || findElement(container, 'textarea'))
		return;

	highlighter = getHighlighterById(highlighterDiv.id);
	
	// add source class name
	addClass(highlighterDiv, 'source');

	// Have to go over each line and grab it's text, can't just do it on the
	// container because Firefox loses all \n where as Webkit doesn't.
	var lines = container.childNodes,
		code = []
		;
	
	for (var i = 0; i < lines.length; i++)
		code.push(lines[i].innerText || lines[i].textContent);
	
	// using \r instead of \r or \r\n makes this work equally well on IE, FF and Webkit
	code = code.join('\r');
	
	// inject <textarea/> tag
	textarea.appendChild(document.createTextNode(code));
	container.appendChild(textarea);
	
	// preselect all text
	textarea.focus();
	textarea.select();
	
	// set up handler for lost focus
	attachEvent(textarea, 'blur', function(e)
	{
		textarea.parentNode.removeChild(textarea);
		removeClass(highlighterDiv, 'source');
	});
};

/**
 * Match object.
 */
sh.Match = function(value, index, css)
{
	this.value = value;
	this.index = index;
	this.length = value.length;
	this.css = css;
	this.brushName = null;
};

sh.Match.prototype.toString = function()
{
	return this.value;
};

/**
 * Simulates HTML code with a scripting language embedded.
 * 
 * @param {String} scriptBrushName Brush name of the scripting language.
 */
sh.HtmlScript = function(scriptBrushName)
{
	var brushClass = findBrush(scriptBrushName),
		scriptBrush,
		xmlBrush = new sh.brushes.Xml(),
		bracketsRegex = null,
		ref = this,
		methodsToExpose = 'getDiv getHtml init'.split(' ')
		;

	if (brushClass == null)
		return;
	
	scriptBrush = new brushClass();
	
	for(var i = 0; i < methodsToExpose.length; i++)
		// make a closure so we don't lose the name after i changes
		(function() {
			var name = methodsToExpose[i];
			
			ref[name] = function()
			{
				return xmlBrush[name].apply(xmlBrush, arguments);
			};
		})();
	
	if (scriptBrush.htmlScript == null)
	{
		alert(sh.config.strings.brushNotHtmlScript + scriptBrushName);
		return;
	}
	
	xmlBrush.regexList.push(
		{ regex: scriptBrush.htmlScript.code, func: process }
	);
	
	function offsetMatches(matches, offset)
	{
		for (var j = 0; j < matches.length; j++) 
			matches[j].index += offset;
	}
	
	function process(match, info)
	{
		var code = match.code,
			matches = [],
			regexList = scriptBrush.regexList,
			offset = match.index + match.left.length,
			htmlScript = scriptBrush.htmlScript,
			result
			;

		// add all matches from the code
		for (var i = 0; i < regexList.length; i++)
		{
			result = getMatches(code, regexList[i]);
			offsetMatches(result, offset);
			matches = matches.concat(result);
		}
		
		// add left script bracket
		if (htmlScript.left != null && match.left != null)
		{
			result = getMatches(match.left, htmlScript.left);
			offsetMatches(result, match.index);
			matches = matches.concat(result);
		}
		
		// add right script bracket
		if (htmlScript.right != null && match.right != null)
		{
			result = getMatches(match.right, htmlScript.right);
			offsetMatches(result, match.index + match[0].lastIndexOf(match.right));
			matches = matches.concat(result);
		}
		
		for (var j = 0; j < matches.length; j++)
			matches[j].brushName = brushClass.brushName;
			
		return matches;
	}
};

/**
 * Main Highlither class.
 * @constructor
 */
sh.Highlighter = function()
{
	// not putting any code in here because of the prototype inheritance
};

sh.Highlighter.prototype = {
	/**
	 * Returns value of the parameter passed to the highlighter.
	 * @param {String} name				Name of the parameter.
	 * @param {Object} defaultValue		Default value.
	 * @return {Object}					Returns found value or default value otherwise.
	 */
	getParam: function(name, defaultValue)
	{
		var result = this.params[name];
		return toBoolean(result == null ? defaultValue : result);
	},
	
	/**
	 * Shortcut to document.createElement().
	 * @param {String} name		Name of the element to create (DIV, A, etc).
	 * @return {HTMLElement}	Returns new HTML element.
	 */
	create: function(name)
	{
		return document.createElement(name);
	},
	
	/**
	 * Applies all regular expression to the code and stores all found
	 * matches in the `this.matches` array.
	 * @param {Array} regexList		List of regular expressions.
	 * @param {String} code			Source code.
	 * @return {Array}				Returns list of matches.
	 */
	findMatches: function(regexList, code)
	{
		var result = [];
		
		if (regexList != null)
			for (var i = 0; i < regexList.length; i++) 
				// BUG: length returns len+1 for array if methods added to prototype chain (oising@gmail.com)
				if (typeof (regexList[i]) == "object")
					result = result.concat(getMatches(code, regexList[i]));
		
		// sort and remove nested the matches
		return this.removeNestedMatches(result.sort(matchesSortCallback));
	},
	
	/**
	 * Checks to see if any of the matches are inside of other matches. 
	 * This process would get rid of highligted strings inside comments, 
	 * keywords inside strings and so on.
	 */
	removeNestedMatches: function(matches)
	{
		// Optimized by Jose Prado (http://joseprado.com)
		for (var i = 0; i < matches.length; i++) 
		{ 
			if (matches[i] === null)
				continue;
			
			var itemI = matches[i],
				itemIEndPos = itemI.index + itemI.length
				;
			
			for (var j = i + 1; j < matches.length && matches[i] !== null; j++) 
			{
				var itemJ = matches[j];
				
				if (itemJ === null) 
					continue;
				else if (itemJ.index > itemIEndPos) 
					break;
				else if (itemJ.index == itemI.index && itemJ.length > itemI.length)
					matches[i] = null;
				else if (itemJ.index >= itemI.index && itemJ.index < itemIEndPos) 
					matches[j] = null;
			}
		}
		
		return matches;
	},
	
	/**
	 * Creates an array containing integer line numbers starting from the 'first-line' param.
	 * @return {Array} Returns array of integers.
	 */
	figureOutLineNumbers: function(code)
	{
		var lines = [],
			firstLine = parseInt(this.getParam('first-line'))
			;
		
		eachLine(code, function(line, index)
		{
			lines.push(index + firstLine);
		});
		
		return lines;
	},
	
	/**
	 * Determines if specified line number is in the highlighted list.
	 */
	isLineHighlighted: function(lineNumber)
	{
		var list = this.getParam('highlight', []);
		
		if (typeof(list) != 'object' && list.push == null) 
			list = [ list ];
		
		return indexOf(list, lineNumber.toString()) != -1;
	},
	
	/**
	 * Generates HTML markup for a single line of code while determining alternating line style.
	 * @param {Integer} lineNumber	Line number.
	 * @param {String} code Line	HTML markup.
	 * @return {String}				Returns HTML markup.
	 */
	getLineHtml: function(lineIndex, lineNumber, code)
	{
		var classes = [
			'line',
			'number' + lineNumber,
			'index' + lineIndex,
			'alt' + (lineNumber % 2 == 0 ? 1 : 2).toString()
		];
		
		if (this.isLineHighlighted(lineNumber))
		 	classes.push('highlighted');
		
		if (lineNumber == 0)
			classes.push('break');
			
		return '<div class="' + classes.join(' ') + '">' + code + '</div>';
	},
	
	/**
	 * Generates HTML markup for line number column.
	 * @param {String} code			Complete code HTML markup.
	 * @param {Array} lineNumbers	Calculated line numbers.
	 * @return {String}				Returns HTML markup.
	 */
	getLineNumbersHtml: function(code, lineNumbers)
	{
		var html = '',
			count = splitLines(code).length,
			firstLine = parseInt(this.getParam('first-line')),
			pad = this.getParam('pad-line-numbers')
			;
		
		if (pad == true)
			pad = (firstLine + count - 1).toString().length;
		else if (isNaN(pad) == true)
			pad = 0;
			
		for (var i = 0; i < count; i++)
		{
			var lineNumber = lineNumbers ? lineNumbers[i] : firstLine + i,
				code = lineNumber == 0 ? sh.config.space : padNumber(lineNumber, pad)
				;
				
			html += this.getLineHtml(i, lineNumber, code);
		}
		
		return html;
	},
	
	/**
	 * Splits block of text into individual DIV lines.
	 * @param {String} code			Code to highlight.
	 * @param {Array} lineNumbers	Calculated line numbers.
	 * @return {String}				Returns highlighted code in HTML form.
	 */
	getCodeLinesHtml: function(html, lineNumbers)
	{
		html = trim(html);
		
		var lines = splitLines(html),
			padLength = this.getParam('pad-line-numbers'),
			firstLine = parseInt(this.getParam('first-line')),
			html = '',
			brushName = this.getParam('brush')
			;

		for (var i = 0; i < lines.length; i++)
		{
			var line = lines[i],
				indent = /^(&nbsp;|\s)+/.exec(line),
				spaces = null,
				lineNumber = lineNumbers ? lineNumbers[i] : firstLine + i;
				;

			if (indent != null)
			{
				spaces = indent[0].toString();
				line = line.substr(spaces.length);
				spaces = spaces.replace(' ', sh.config.space);
			}

			line = trim(line);
			
			if (line.length == 0)
				line = sh.config.space;
			
			html += this.getLineHtml(
				i,
				lineNumber, 
				(spaces != null ? '<code class="' + brushName + ' spaces">' + spaces + '</code>' : '') + line
			);
		}
		
		return html;
	},
	
	/**
	 * Returns HTML for the table title or empty string if title is null.
	 */
	getTitleHtml: function(title)
	{
		return title ? '<caption>' + title + '</caption>' : '';
	},
	
	/**
	 * Finds all matches in the source code.
	 * @param {String} code		Source code to process matches in.
	 * @param {Array} matches	Discovered regex matches.
	 * @return {String} Returns formatted HTML with processed mathes.
	 */
	getMatchesHtml: function(code, matches)
	{
		var pos = 0, 
			result = '',
			brushName = this.getParam('brush', '')
			;
		
		function getBrushNameCss(match)
		{
			var result = match ? (match.brushName || brushName) : brushName;
			return result ? result + ' ' : '';
		};
		
		// Finally, go through the final list of matches and pull the all
		// together adding everything in between that isn't a match.
		for (var i = 0; i < matches.length; i++) 
		{
			var match = matches[i],
				matchBrushName
				;
			
			if (match === null || match.length === 0) 
				continue;
			
			matchBrushName = getBrushNameCss(match);
			
			result += wrapLinesWithCode(code.substr(pos, match.index - pos), matchBrushName + 'plain')
					+ wrapLinesWithCode(match.value, matchBrushName + match.css)
					;

			pos = match.index + match.length + (match.offset || 0);
		}

		// don't forget to add whatever's remaining in the string
		result += wrapLinesWithCode(code.substr(pos), getBrushNameCss() + 'plain');

		return result;
	},
	
	/**
	 * Generates HTML markup for the whole syntax highlighter.
	 * @param {String} code Source code.
	 * @return {String} Returns HTML markup.
	 */
	getHtml: function(code)
	{
		var html = '',
			classes = [ 'syntaxhighlighter' ],
			tabSize,
			matches,
			lineNumbers
			;
		
		// process light mode
		if (this.getParam('light') == true)
			this.params.toolbar = this.params.gutter = false;

		className = 'syntaxhighlighter';

		if (this.getParam('collapse') == true)
			classes.push('collapsed');
		
		if ((gutter = this.getParam('gutter')) == false)
			classes.push('nogutter');

		// add custom user style name
		classes.push(this.getParam('class-name'));

		// add brush alias to the class name for custom CSS
		classes.push(this.getParam('brush'));

		code = trimFirstAndLastLines(code)
			.replace(/\r/g, ' ') // IE lets these buggers through
			;

		tabSize = this.getParam('tab-size');

		// replace tabs with spaces
		code = this.getParam('smart-tabs') == true
			? processSmartTabs(code, tabSize)
			: processTabs(code, tabSize)
			;

		// unindent code by the common indentation
		code = unindent(code);

		if (gutter)
			lineNumbers = this.figureOutLineNumbers(code);
		
		// find matches in the code using brushes regex list
		matches = this.findMatches(this.regexList, code);
		// processes found matches into the html
		html = this.getMatchesHtml(code, matches);
		// finally, split all lines so that they wrap well
		html = this.getCodeLinesHtml(html, lineNumbers);

		// finally, process the links
		if (this.getParam('auto-links'))
			html = processUrls(html);
		
		if (typeof(navigator) != 'undefined' && navigator.userAgent && navigator.userAgent.match(/MSIE/))
			classes.push('ie');
		
		html = 
			'<div id="' + getHighlighterId(this.id) + '" class="' + classes.join(' ') + '">'
				+ (this.getParam('toolbar') ? sh.toolbar.getHtml(this) : '')
				+ '<table border="0" cellpadding="0" cellspacing="0">'
					+ this.getTitleHtml(this.getParam('title'))
					+ '<tbody>'
						+ '<tr>'
							+ (gutter ? '<td class="gutter">' + this.getLineNumbersHtml(code) + '</td>' : '')
							+ '<td class="code">'
								+ '<div class="container">'
									+ html
								+ '</div>'
							+ '</td>'
						+ '</tr>'
					+ '</tbody>'
				+ '</table>'
			+ '</div>'
			;
			
		return html;
	},
	
	/**
	 * Highlights the code and returns complete HTML.
	 * @param {String} code     Code to highlight.
	 * @return {Element}        Returns container DIV element with all markup.
	 */
	getDiv: function(code)
	{
		if (code === null) 
			code = '';
		
		this.code = code;

		var div = this.create('div');

		// create main HTML
		div.innerHTML = this.getHtml(code);
		
		// set up click handlers
		if (this.getParam('toolbar'))
			attachEvent(findElement(div, '.toolbar'), 'click', sh.toolbar.handler);
		
		if (this.getParam('quick-code'))
			attachEvent(findElement(div, '.code'), 'dblclick', quickCodeHandler);
		
		return div;
	},
	
	/**
	 * Initializes the highlighter/brush.
	 *
	 * Constructor isn't used for initialization so that nothing executes during necessary
	 * `new SyntaxHighlighter.Highlighter()` call when setting up brush inheritence.
	 *
	 * @param {Hash} params Highlighter parameters.
	 */
	init: function(params)
	{
		this.id = guid();
		
		// register this instance in the highlighters list
		storeHighlighter(this);
		
		// local params take precedence over defaults
		this.params = merge(sh.defaults, params || {})
		
		// process light mode
		if (this.getParam('light') == true)
			this.params.toolbar = this.params.gutter = false;
	},
	
	/**
	 * Converts space separated list of keywords into a regular expression string.
	 * @param {String} str    Space separated keywords.
	 * @return {String}       Returns regular expression string.
	 */
	getKeywords: function(str)
	{
		str = str
			.replace(/^\s+|\s+$/g, '')
			.replace(/\s+/g, '|')
			;
		
		return '\\b(?:' + str + ')\\b';
	},
	
	/**
	 * Makes a brush compatible with the `html-script` functionality.
	 * @param {Object} regexGroup Object containing `left` and `right` regular expressions.
	 */
	forHtmlScript: function(regexGroup)
	{
		this.htmlScript = {
			left : { regex: regexGroup.left, css: 'script' },
			right : { regex: regexGroup.right, css: 'script' },
			code : new XRegExp(
				"(?<left>" + regexGroup.left.source + ")" +
				"(?<code>.*?)" +
				"(?<right>" + regexGroup.right.source + ")",
				"sgi"
				)
		};
	}
}; // end of Highlighter

return sh;
}(); // end of anonymous function

// CommonJS
typeof(exports) != 'undefined' ? exports['SyntaxHighlighter'] = SyntaxHighlighter : null;
</script><script type="text/javascript">// (inc clojure-brush) ;; an improved SyntaxHighlighter brush for clojure
//
// Copyright (C) 2011 Andrew Brehaut
//
// Distributed under the Eclipse Public License, the same as Clojure.
//
// https://github.com/brehaut/inc-clojure-brush
//
// Written by Andrew Brehaut
// V0.9.1, November 2011

if (typeof net == "undefined") net = {};
if (!(net.brehaut)) net.brehaut = {};

net.brehaut.ClojureTools = (function (SH) {
  "use strict";
  // utiliies
  if (!Object.create) Object.create = function object(o) {
    function F() {};
    F.prototype = o;  
    return new F();
  };
        
  // data
  
  function Token(value, index, tag, length) {
    this.value = value;
    this.index = index;
    this.length = length || value.length;
    this.tag = tag;
    this.secondary_tags = {};
  }
  
  // null_token exists so that LispNodes that have not had a closing tag attached
  // can have a dummy token to simplify annotation
  var null_token = new Token("", -1, "null", -1);
  
  /* LispNodes are aggregate nodes for sexpressions. 
   *
   */
  function LispNode(tag, children, opening) {
    this.tag = tag;            // current metadata for syntax inference
    this.parent = null;        // the parent expression
    this.list = children;      // all the child forms in order
    this.opening = opening;    // the token that opens this form.
    this.closing = null_token; // the token that closes this form.
    this.meta = null;          // metadata nodes will be attached here if they are found
  }

  var null_lispnode = new LispNode("null", [], null_token);

  
  function PrefixNode(tag, token, attached_node) {
    this.tag = tag;
    this.token = token;
    this.attached_node = attached_node;
    this.parent = null;
  }

  
  
  // tokenize

  function tokenize(code) {
    var tokens = [];
    var tn = 0;
    
    var zero = "0".charCodeAt(0);
    var nine = "9".charCodeAt(0); 
    var lower_a = "a".charCodeAt(0);
    var lower_f = "f".charCodeAt(0);    
    var upper_a = "A".charCodeAt(0);
    var upper_f = "F".charCodeAt(0);
    
    var dispatch = false; // have we just seen a # character?
    
    // i tracks the start of the current window
    // extent is the window for slicing
    
    for (var i = 0, 
             extent = i, 
             j = code.length; 
             i < j && extent <= j;) {          
                
      var c = code[i];
      
      // we care about capturing the whole token when dispatch is used, so back up the
      // starting index by 1
      if (dispatch) i--; 
      
      switch (c) {
        // dispatch alters the value of the next thing read
        case "#":
          dispatch = true;
          i++;
          extent++;
          continue;
          
        case " ":    // ignore whitespace
        case "\t":
        case "\n":
        case "\r":
        case ",":   
          extent++
          break; 
          
        // simple terms
        case "^":
        case "`":
        case ")":
        case "[":
        case "]":
        case "}":
        case "@":
          tokens[tn++] = new Token(c, i, c, ++extent - i);
          break;
        
        case "'":
          tokens[tn++] = new Token(code.slice(i, ++extent), i, dispatch ? "#'" : "'", extent - i);
          break
        
        case "(":
          tokens[tn++] = new Token(code.slice(i, ++extent), i, "(", extent - i);
          break;          
          
        case "{":
          tokens[tn++] = new Token(code.slice(i, ++extent), i, dispatch ? "#{" : "{", extent - i);
          break;  
        
        case "\\":
          if (code.slice(i + 1, i + 8) === "newline") {
            tokens[tn++] = new Token("\\newline", i, "value", 8);
            extent = i + 9; 
          }
          else if (code.slice(i + 1, i + 6) === "space") {
            tokens[tn++] = new Token("\\space", i, "value", 6);
            extent = i + 6;
          }
          else if (code.slice(i + 1, i + 4) === "tab") {
            tokens[tn++] = new Token("\\tab", i, "value", 4);
            extent = i + 5;
          } // work around fun bug with &,>,< in character literals
          else if (code.slice(i + 1, i + 6) === "&amp;") {
            tokens[tn++] = new Token("\\&amp;", i, "value", 6);
            extent = i + 6; 
          }
          else if (code.slice(i + 1, i + 5) === "&lt;") {
            tokens[tn++] = new Token("\\&lt;", i, "value", 5);
            extent = i + 5;
          }
          else if (code.slice(i + 1, i + 5) === "&gt;") {
            tokens[tn++] = new Token("\\&gt;", i, "value", 5);
            extent = i + 5;
          }
          
          else {
            extent += 2;
            tokens[tn++] = new Token(code.slice(i, extent), i, "value", 2);
          }
          break;
        
        case "~": // slice
          if (code[i + 1] === "@") {
            extent += 2;
            tokens[tn++] = new Token(code.slice(i, extent), i, "splice", 2);
          }
          else {
            tokens[tn++] = new Token(code.slice(i, ++extent), i, "unquote", 2);
          }
          break;
        
        // complicated terms
        case "\"": // strings and regexps
          for (extent++; extent <= j; extent++) {
            if (code[extent] === "\\") extent++;
            else if (code[extent] === "\"") break;
          }
          tokens[tn++] = new Token(code.slice(i, ++extent), i, dispatch ? "regexp" : "string", extent - i);       
          break;
          
        case ";":
          for (; extent <= j && code[extent] !== "\n" && code[extent] !== "\r"; extent++);
          tokens[tn++] = new Token(code.slice(i, ++extent), i, "comments", extent - i);   
          break;
        
        case "+": // numbers; fall through to symbol for + and - not prefixing a number
        case "-":
        case "0":
        case "1":
        case "2":
        case "3":
        case "4":
        case "5":
        case "6":
        case "7":
        case "8":
        case "9":
        // todo: exponents, hex
        // http://my.safaribooksonline.com/9781449310387/14?reader=pf&readerfullscreen=&readerleftmenu=1
          var c2 = code.charCodeAt(i + 1);
          if (((c === "+" || c === "-") && (c2 >= zero && c2 <= nine)) // prefixes
              || (c !== "+" && c !== "-")) {
            if (c === "+" || c === "-") extent++; 
            for (; extent <= j; extent++) {
              var charCode = code.charCodeAt(extent);
              if (charCode < zero || charCode > nine) break;
            }
            
            c = code[extent];
            c2 = code.charCodeAt(extent + 1);
            if ((c === "r" || c === "R" || c === "/" || c === ".") // interstitial characters
                && (c2 >= zero && c2 <= nine)) {
              for (extent++; extent <= j; extent++) {
                var charCode = code.charCodeAt(extent);
                if (charCode < zero || charCode > nine) break;
              }
            }
            
            c = code[extent];
            c2 = code.charCodeAt(extent + 1);
            if ((c === "x" || c === "X") && 
                ((c2 >= zero && c2 <= nine) 
                 || (c2 >= lower_a && c2 <= lower_f)
                 || (c2 >= upper_a && c2 <= upper_f))) {
              for (extent++; extent <= j; extent++) {
                var charCode = code.charCodeAt(extent);
                if (((charCode >= zero && charCode <= nine) 
                    || (charCode >= lower_a && charCode <= lower_f)
                    || (charCode >= upper_a && charCode <= upper_f))) continue;
                break;
              }
            }
            
            c = code[extent];
            c2 = code.charCodeAt(extent + 1);
            if ((c === "e" || c === "E") 
                && (c2 >= zero && c2 <= nine)) {
              for (extent++; extent <= j; extent++) {
                var charCode = code.charCodeAt(extent);
                if (charCode < zero || charCode > nine) break;
              }
            }
            
            c = code[extent];
            if (c === "N" || c === "M") extent++;

            tokens[tn++] = new Token(code.slice(i, extent), i, "value", extent - i);
            break;
          }

        case "_":
          if (dispatch && c === "_") {
            tokens[tn++] = new Token(code.slice(i, ++extent), i, "skip", extent - i);
            break;
          } // if not a skip, fall through to symbols
        
        // Allow just about any other symbol as a symbol. This is far more permissive than 
        // clojure actually allows, but should catch any weirdo crap that accidentally gets
        // into the code.
        default: 
          for (extent++; extent <= j; extent++) {
            switch (code[extent]) {
              case " ":
              case "\t":
              case "\n":
              case "\r":
              case "\\":
              case ",":
              case "{":
              case "}":
              case "(":
              case ")":
              case "[":
              case "]":
              case "^":
              case "`":
              case "@":   
                break;
              case ";":   
                // theres a weird bug via syntax highligher that gives us escaped entities.
                // need to watch out for these
                if (code.slice(extent-3, extent+1) === "&lt;"
                    ||code.slice(extent-3, extent+1) === "&gt;"
                    ||code.slice(extent-4, extent+1) === "&amp;") {
                  continue;
                }
                break;
              default:
                continue;
            }
            break;
          }
          
          var value = code.slice(i, extent);
          var tag = "symbol";
          if (value[0] == ":") {
            tag = "keyword";
          }
          else if (value === "true" || value === "false" || value === "nil") {
            tag = "value";
          }
          tokens[tn++] = new Token(value, i, tag, extent - i);
      }
      
      dispatch = false;
      i = extent;
    } 

    return tokens;
  }


  function build_tree(tokens) {
    var toplevel = {
      list: [], 
      tag: "toplevel", 
      parent: null, 
      opening: null,
      closing: null,
      depth: -1
    };
    
    // loop variables hoisted out as semi globals to track position in token stream
    var i = -1;
    var j = tokens.length;
    
    function parse_one(t) {
      // ignore special tokens and forms that dont belong in the tree
      for (; t && (t.tag === "comments" || t.tag === "invalid" || t.tag == "skip") && i < j; ) {
        if (t.tag === "skip") {
          t.tag = "preprocessor";
          annotate_comment(parse_one(tokens[++i]));
        }
        t = tokens[++i];
      }
      
      if (!t) return {}; // hackity hack
      
      switch (t.tag) {
        case "{":
          return build_aggregate(new LispNode("map", [], t), "}");
        case "(":
          return build_aggregate(new LispNode("list", [], t), ")");
        case "#{":
          return build_aggregate(new LispNode("set", [], t), "}");
        case "[":
          return build_aggregate(new LispNode("vector", [], t), "]");
        case "'":
          return new PrefixNode("quote", t, parse_one(tokens[++i]));
        case "#'":
          return new PrefixNode("varquote", t, parse_one(tokens[++i]));  
        case "@":
          return new PrefixNode("deref", t, parse_one(tokens[++i]));  
        case "`":
          return new PrefixNode("quasiquote", t, parse_one(tokens[++i]));  
        case "unquote":
          return new PrefixNode("unquote", t, parse_one(tokens[++i]));
        case "splice":
          return new PrefixNode("splice", t, parse_one(tokens[++i]));  
        case "^":
          t.tag = "meta";
          var meta = parse_one(tokens[++i]);
          var next = parse_one(tokens[++i]);
          next.meta = meta;
          return next;
      }
      
      return t;
    }
    
    // build_aggregate collects to ether sub forms for one aggregate for. 
    function build_aggregate(current, expected_closing) {
      for (i++; i < j; i++) {
        var t = tokens[i];

        if (t.tag === "}" || t.tag === ")" || t.tag === "]") {
          if (t.tag !== expected_closing) t.tag = "invalid";
          current.closing = t;
          if (expected_closing) return current;
        }
        var node = parse_one(t);

        node.parent = current;
        current.list[current.list.length] = node;
      }
      
      return current;
    }
    
    build_aggregate(toplevel, null);
    
    return toplevel;
  }

  // annotation rules to apply to a form based on its head

  var show_locals = true;  // HACK. would rather not use a (semi)-global.

  /* annotate_comment is a special case annotation. 
   * in addition to its role in styling specific forms, it is called by parse_one to
   * ignore any forms skipped with #_
   */ 
  function annotate_comment(exp) {
    exp.tag = "comments";

    if (exp.list) {
      exp.opening.tag = "comments";
      exp.closing.tag = "comments";
    
      for (var i = 0; i < exp.list.length; i++) {
        var child = exp.list[i];
        if (child.list) {
          annotate_comment(child);
        }
        if (child.attached_node) {
          annotate_comment(child.attached_node);
        }
        else {
          child.tag = "comments";
        }
      }
    }
  }

  /* custom annotation rules are stored here */
  var annotation_rules = {};
  
  // this function is exposed to allow ad hoc extension of the customisation rules
  function register_annotation_rule(names, rule) {
    for (var i = 0; i < names.length; i++) {
      annotation_rules[names[i]] = rule;
    }
  }


  function annotate_destructuring (exp, scope) {
    if (exp.list) {
      if (exp.tag === "vector") {
        for (var i = 0; i < exp.list.length; i++) {
          annotate_destructuring(exp.list[i], scope);
        }
      } 
      else if (exp.tag === "map") {
        for (var i = 0; i < exp.list.length; i += 2) {
          var key = exp.list[i];
          var val = exp.list[i + 1];
          
          if (key.tag === "keyword" && val.tag === "vector") {
            for (var ii = 0, jj = val.list.length; ii < jj; ii++) {
              if (val.list[ii].tag !== "symbol") continue;
              val.list[ii].tag = "variable";
              scope[val.list[ii].value] = true;
            }
          }
          else {
            annotate_destructuring(key, scope);
            annotate_expressions(val, scope);
          }
        } 
      }
    } 
    else if (exp.tag === "symbol" && (exp.value !== "&" && exp.value !== "&amp;")){
      exp.tag = "variable";
      scope[exp.value] = true;
    }
  }

  function _annotate_binding_vector (exp, scope) {
    if (exp.tag !== "vector") return;
  
    var bindings = exp.list;

    if (bindings.length % 2 === 1) return;
    
    for (var i = 0; i < bindings.length; i += 2) {
      annotate_destructuring(bindings[i], scope);
      annotate_expressions(bindings[i + 1], scope);
    }    
  }

  function annotate_binding (exp, scope) {
    var bindings = exp.list[1];
    if (!show_locals) return; // HACK

    if (bindings) {
      scope = Object.create(scope);
      _annotate_binding_vector(bindings, scope);
    }
    for (var i = 2; i < exp.list.length; i++) {
      annotate_expressions(exp.list[i], scope);
    }
  }
  
  function _annotate_function_body (exp, scope, start_idx) {
    var argvec = exp.list[start_idx];
    if (argvec.tag !== "vector") return;

    scope = Object.create(scope);

    for (var i = 0, j = argvec.list.length; i < j; i++) {
      annotate_destructuring(argvec.list[i], scope);
    }
    
    for (var i = start_idx, j = exp.list.length; i < j; i++) {
      annotate_expressions(exp.list[i], scope);
    }
  }
  
  function annotate_function (exp, scope) {
    for (var i = 1, j = exp.list.length; i < j; i++) {
      var child = exp.list[i];
      
      if (child.tag === "vector") {
        _annotate_function_body (exp, scope, i);
        return;
      }
      else if (child.tag === "list") {
        _annotate_function_body(child, scope, 0)
      }
    }
  }
  
  function annotate_letfn (exp, scope) {
    scope = Object.create(scope);
    var bindings = exp.list[1];
    
    var fn;
    for (var i = 0, j = bindings.list.length; i < j; i++) {
      fn = bindings.list[i];
      if (!fn.list[0]) continue;
      fn.list[0].tag = "variable";
      scope[fn.list[0].value] = true;
    }
    
    for (i = 0, j = bindings.list.length; i < j; i++) {
      var fn = bindings.list[i];
      annotate_function(fn, scope);
    }
    
    for (i = 2, j = exp.list.length; i < j; i++) {
      annotate_expressions(exp.list[i], scope);
    }
  }

  register_annotation_rule(
    ["comment"],
    annotate_comment
  );
  
  register_annotation_rule(
    ["let", "when-let", "if-let", "binding", "doseq", "for", "dotimes", "let*"],
    annotate_binding
  );
  
  register_annotation_rule(
    ["defn", "defn-", "fn", "bound-fn", "defmacro", "fn*", "defmethod"],
    annotate_function
  );
  
  register_annotation_rule(
    ["letfn"],
    annotate_letfn
  );

  // standard annotations

  function _annotate_metadata_recursive(meta, scope) {
    if (!meta) return;

    if (meta.list !== undefined && meta.list !== null) {
      for (var i = 0, j = meta.list.length; i < j; i++) {
        meta.opening.secondary_tags.meta = true
        meta.closing.secondary_tags.meta = true
        _annotate_metadata_recursive(meta.list[i], scope);
      }
    }
    else if (meta.attached_node) {
      meta.token.secondary_tags.meta = true;
      _annotate_metadata_recursive(meta.attached_node, scope);
    }
    else {
      meta.secondary_tags.meta = true;
    }
  }
  
  function annotate_metadata(exp) {
    if (!(exp && exp.meta)) return;
    var meta = exp.meta;
    
     annotate_expressions(meta, {});    
    _annotate_metadata_recursive(meta, {});
  }


  function annotate_quoted(exp, scope) {
    if (!exp) return;

    if (exp.list !== undefined && exp.list !== null) {
      for (var i = 0, j = exp.list.length; i < j; i++) {
        exp.opening.secondary_tags.quoted = true
        exp.closing.secondary_tags.quoted = true
        annotate_quoted(exp.list[i], scope);
      }
    }
    else if (exp.attached_node) {
      if (exp.tag === "unquote" || exp.tag === "splice") return;
      exp.token.secondary_tags.quoted = true;
      annotate_quoted(exp.attached_node, scope);
    }
    else {
      exp.secondary_tags.quoted = true;
    }
  }


  function annotate_expressions(exp, scope) {
    annotate_metadata(exp);
    
    switch (exp.tag) {
      case "toplevel": 
        for (var i = 0; i < exp.list.length; i++) {
          annotate_expressions(exp.list[i], scope);
        }
        break;
      
      case "list": // functions, macros, special forms, comments
        var head = exp.list[0];
      
        if (head) {
          if (head.tag === "list" || head.tag === "vector" 
           || head.tag === "map" || head.tag === "set") {
            annotate_expressions(head, scope);
          }
          else if (head.attached_node) {
            annotate_expressions(head.attached_node, scope);
          }
          else {
            head.tag = (head.value.match(/(^\.)|(\.$)|[A-Z].*\//)
                        ? "method"
                        : "function");
          }

          // apply specific rules
          if (annotation_rules.hasOwnProperty(head.value)) {
            annotation_rules[head.value](exp, scope);
          } 
          else {
            for (var i = 1; i < exp.list.length; i++) {
              annotate_expressions(exp.list[i], scope);
            }
          } 
        }
        else { // empty list
          exp.opening.tag = "value";
          exp.closing.tag = "value";
        }
      
        break;
      
      case "vector": // data
      case "map":
      case "set":
        for (var i = 0; i < exp.list.length; i++) {
          annotate_expressions(exp.list[i], scope);
        }
        break;
      
      case "symbol":
        if (exp.value.match(/[A-Z].*\/[A-Z_]+/)) {
          exp.tag = "constant";
        }
        else if (show_locals && scope[exp.value]) {
          exp.tag = "variable";
        }
        else if (exp.tag === "symbol" && exp.value.match(/([A-Z].*\/)?[A-Z_]+/)) {
          exp.tag = "type";
        }
        break;
      
      case "quote":
      case "quasiquote":
        annotate_quoted(exp.attached_node, scope);
        
      default:
        if (exp.attached_node) annotate_expressions(exp.attached_node, scope);
    }
  }

  // translation of tag to css:
  var css_translation = {
    "constant":     "constants",
    "keyword":      "constants",
    "method":       "color1",
    "type":         "color3", 
    "function":     "functions",
    "string":       "string",
    "regexp":       "string",
    "value":        "value",
    "comments":     "comments",
    "symbol":       "symbol",
    "variable":     "variable",
    "splice":       "preprocessor", 
    "unquote":      "preprocessor",     
    "preprocessor": "preprocessor",
    "meta":         "preprocessor", 
    "'":            "preprocessor", 
    "#'":           "preprocessor",    
    "(":            "plain",
    ")":            "plain",
    "{":            "keyword",
    "}":            "keyword",
    "#{":           "keyword",   
    "[":            "keyword",
    "]":            "keyword",
    "invalid":      "invalid",
    "@":            "plain" 
  };
  
  function translate_tags_to_css(tokens) {
    for (var i = 0, j = tokens.length; i < j; i++) {
      var token = tokens[i];
      token.css = css_translation[token.tag];
      for (var k in token.secondary_tags) if (token.secondary_tags.hasOwnProperty(k))
        token.css += " " + k ;
    };
  }
  
  
  // create the new brush

  SH.brushes.Clojure = function () {};
  SH.brushes.Clojure.prototype = new SyntaxHighlighter.Highlighter();
  
  SH.brushes.Clojure.prototype.findMatches = function find_matches (regexpList, code) {
    // this is a nasty global hack. need to resolve this
    if (this.params && this.params.locals) {
      show_locals = this.params.locals === true || this.params.locals === "true"; 
    }
    else {
      show_locals = true;
    }
    
    var tokens = tokenize(code);
    annotate_expressions(build_tree(tokens), {});
    translate_tags_to_css(tokens);

    return tokens;
  };
  
  SH.brushes.Clojure.aliases = ['clojure', 'Clojure', 'clj'];
  SH.brushes.Clojure.register_annotation_rule = register_annotation_rule;

  return {
    tokenize: tokenize,
    build_tree: build_tree
  };
})(SyntaxHighlighter);
</script><title>bcbio.variation -- Marginalia</title></head><body><table><tr><td class="docs"><div class="header"><h1 class="project-name">bcbio.variation</h1><h2 class="project-version">0.0.9-SNAPSHOT</h2><br /><p>Toolkit to analyze genomic variation data, built on the GATK with Clojure</p>
</div><div class="dependencies"><h3>dependencies</h3><table><tr><td class="dep-name">org.clojure/clojure</td><td class="dotted"><hr /></td><td class="dep-version">1.5.1</td></tr><tr><td class="dep-name">org.clojure/math.combinatorics</td><td class="dotted"><hr /></td><td class="dep-version">0.0.2</td></tr><tr><td class="dep-name">org.clojure/data.csv</td><td class="dotted"><hr /></td><td class="dep-version">0.1.2</td></tr><tr><td class="dep-name">org.clojure/core.match</td><td class="dotted"><hr /></td><td class="dep-version">0.2.0-alpha9</td></tr><tr><td class="dep-name">org.clojure/tools.cli</td><td class="dotted"><hr /></td><td class="dep-version">0.2.2</td></tr><tr><td class="dep-name">clj-stacktrace</td><td class="dotted"><hr /></td><td class="dep-version">0.2.5</td></tr><tr><td class="dep-name">org.clojars.chapmanb/gatk-lite</td><td class="dotted"><hr /></td><td class="dep-version">2.3.4</td></tr><tr><td class="dep-name">org.clojars.chapmanb/picard</td><td class="dotted"><hr /></td><td class="dep-version">1.73</td></tr><tr><td class="dep-name">org.clojars.chapmanb/sam</td><td class="dotted"><hr /></td><td class="dep-version">1.73</td></tr><tr><td class="dep-name">org.clojars.chapmanb/tribble</td><td class="dotted"><hr /></td><td class="dep-version">119</td></tr><tr><td class="dep-name">org.clojars.chapmanb/jama</td><td class="dotted"><hr /></td><td class="dep-version">1.0.2</td></tr><tr><td class="dep-name">org.apache.commons/commons-jexl</td><td class="dotted"><hr /></td><td class="dep-version">2.1.1</td></tr><tr><td class="dep-name">org.apache.commons/commons-math</td><td class="dotted"><hr /></td><td class="dep-version">2.2</td></tr><tr><td class="dep-name">org.reflections/reflections</td><td class="dotted"><hr /></td><td class="dep-version">0.9.8</td></tr><tr><td class="dep-name">org.simpleframework/simple-xml</td><td class="dotted"><hr /></td><td class="dep-version">2.0.4</td></tr><tr><td class="dep-name">colt/colt</td><td class="dotted"><hr /></td><td class="dep-version">1.2.0</td></tr><tr><td class="dep-name">org.clojars.chapmanb/snpeff</td><td class="dotted"><hr /></td><td class="dep-version">3.1</td></tr><tr><td class="dep-name">org.biojava/biojava3-core</td><td class="dotted"><hr /></td><td class="dep-version">3.0.4</td></tr><tr><td class="dep-name">org.biojava/biojava3-alignment</td><td class="dotted"><hr /></td><td class="dep-version">3.0.4</td></tr><tr><td class="dep-name">org.clojars.chapmanb/circdesigna</td><td class="dotted"><hr /></td><td class="dep-version">0.0.2</td></tr><tr><td class="dep-name">clj-genomespace</td><td class="dotted"><hr /></td><td class="dep-version">0.1.3</td></tr><tr><td class="dep-name">clj-blend</td><td class="dotted"><hr /></td><td class="dep-version">0.1.1-SNAPSHOT</td></tr><tr><td class="dep-name">incanter/incanter-core</td><td class="dotted"><hr /></td><td class="dep-version">1.4.0</td></tr><tr><td class="dep-name">incanter/incanter-charts</td><td class="dotted"><hr /></td><td class="dep-version">1.4.0</td></tr><tr><td class="dep-name">incanter/incanter-excel</td><td class="dotted"><hr /></td><td class="dep-version">1.4.0</td></tr><tr><td class="dep-name">nz.ac.waikato.cms.weka/weka-stable</td><td class="dotted"><hr /></td><td class="dep-version">3.6.6</td></tr><tr><td class="dep-name">org.clojars.chapmanb/fast-random-forest</td><td class="dotted"><hr /></td><td class="dep-version">0.98</td></tr><tr><td class="dep-name">com.leadtune/clj-ml</td><td class="dotted"><hr /></td><td class="dep-version">0.2.4</td></tr><tr><td class="dep-name">fs</td><td class="dotted"><hr /></td><td class="dep-version">1.1.2</td></tr><tr><td class="dep-name">clj-yaml</td><td class="dotted"><hr /></td><td class="dep-version">0.3.1</td></tr><tr><td class="dep-name">doric</td><td class="dotted"><hr /></td><td class="dep-version">0.8.0</td></tr><tr><td class="dep-name">ordered</td><td class="dotted"><hr /></td><td class="dep-version">1.3.2</td></tr><tr><td class="dep-name">de.kotka/lazymap</td><td class="dotted"><hr /></td><td class="dep-version">3.1.0</td></tr><tr><td class="dep-name">lonocloud/synthread</td><td class="dotted"><hr /></td><td class="dep-version">1.0.3</td></tr><tr><td class="dep-name">pallet-fsm</td><td class="dotted"><hr /></td><td class="dep-version">0.1.0</td></tr><tr><td class="dep-name">clj-time</td><td class="dotted"><hr /></td><td class="dep-version">0.4.3</td></tr><tr><td class="dep-name">clj-aws-s3</td><td class="dotted"><hr /></td><td class="dep-version">0.3.1</td></tr><tr><td class="dep-name">org.clojure/java.jdbc</td><td class="dotted"><hr /></td><td class="dep-version">0.2.2</td></tr><tr><td class="dep-name">org.xerial/sqlite-jdbc</td><td class="dotted"><hr /></td><td class="dep-version">3.7.2</td></tr><tr><td class="dep-name">c3p0/c3p0</td><td class="dotted"><hr /></td><td class="dep-version">0.9.1.2</td></tr><tr><td class="dep-name">hiccup</td><td class="dotted"><hr /></td><td class="dep-version">1.0.1</td></tr><tr><td class="dep-name">enlive</td><td class="dotted"><hr /></td><td class="dep-version">1.0.1</td></tr></table></div></td><td class="codes" style="text-align: center; vertical-align: middle;color: #666;padding-right:20px"><br /><br /><br />(this space intentionally left almost blank)</td></tr><tr><td class="docs"><div class="toc"><a name="toc"><h3>namespaces</h3></a><ul><li><a href="#bcbio.align.interval">bcbio.align.interval</a></li><li><a href="#bcbio.align.ref">bcbio.align.ref</a></li><li><a href="#bcbio.align.reorder">bcbio.align.reorder</a></li><li><a href="#bcbio.run.broad">bcbio.run.broad</a></li><li><a href="#bcbio.run.itx">bcbio.run.itx</a></li><li><a href="#bcbio.variation.annotate.effects">bcbio.variation.annotate.effects</a></li><li><a href="#bcbio.variation.annotate.entropy">bcbio.variation.annotate.entropy</a></li><li><a href="#bcbio.variation.annotate.mfe">bcbio.variation.annotate.mfe</a></li><li><a href="#bcbio.variation.annotate.nbq">bcbio.variation.annotate.nbq</a></li><li><a href="#bcbio.variation.annotation">bcbio.variation.annotation</a></li><li><a href="#bcbio.variation.api.file">bcbio.variation.api.file</a></li><li><a href="#bcbio.variation.api.metrics">bcbio.variation.api.metrics</a></li><li><a href="#bcbio.variation.api.run">bcbio.variation.api.run</a></li><li><a href="#bcbio.variation.api.shared">bcbio.variation.api.shared</a></li><li><a href="#bcbio.variation.callable">bcbio.variation.callable</a></li><li><a href="#bcbio.variation.combine">bcbio.variation.combine</a></li><li><a href="#bcbio.variation.compare">bcbio.variation.compare</a></li><li><a href="#bcbio.variation.complex">bcbio.variation.complex</a></li><li><a href="#bcbio.variation.config">bcbio.variation.config</a></li><li><a href="#bcbio.variation.core">bcbio.variation.core</a></li><li><a href="#bcbio.variation.custom.core">bcbio.variation.custom.core</a></li><li><a href="#bcbio.variation.custom.nist">bcbio.variation.custom.nist</a></li><li><a href="#bcbio.variation.evaluate">bcbio.variation.evaluate</a></li><li><a href="#bcbio.variation.filter">bcbio.variation.filter</a></li><li><a href="#bcbio.variation.filter.attr">bcbio.variation.filter.attr</a></li><li><a href="#bcbio.variation.filter.classify">bcbio.variation.filter.classify</a></li><li><a href="#bcbio.variation.filter.intervals">bcbio.variation.filter.intervals</a></li><li><a href="#bcbio.variation.filter.rules">bcbio.variation.filter.rules</a></li><li><a href="#bcbio.variation.filter.specific">bcbio.variation.filter.specific</a></li><li><a href="#bcbio.variation.filter.train">bcbio.variation.filter.train</a></li><li><a href="#bcbio.variation.filter.trusted">bcbio.variation.filter.trusted</a></li><li><a href="#bcbio.variation.filter.util">bcbio.variation.filter.util</a></li><li><a href="#bcbio.variation.grade">bcbio.variation.grade</a></li><li><a href="#bcbio.variation.haploid">bcbio.variation.haploid</a></li><li><a href="#bcbio.variation.index.gemini">bcbio.variation.index.gemini</a></li><li><a href="#bcbio.variation.index.metrics">bcbio.variation.index.metrics</a></li><li><a href="#bcbio.variation.index.subsample">bcbio.variation.index.subsample</a></li><li><a href="#bcbio.variation.metrics">bcbio.variation.metrics</a></li><li><a href="#bcbio.variation.multiple">bcbio.variation.multiple</a></li><li><a href="#bcbio.variation.multisample">bcbio.variation.multisample</a></li><li><a href="#bcbio.variation.normalize">bcbio.variation.normalize</a></li><li><a href="#bcbio.variation.phasing">bcbio.variation.phasing</a></li><li><a href="#bcbio.variation.recall">bcbio.variation.recall</a></li><li><a href="#bcbio.variation.remote.client">bcbio.variation.remote.client</a></li><li><a href="#bcbio.variation.remote.core">bcbio.variation.remote.core</a></li><li><a href="#bcbio.variation.remote.file">bcbio.variation.remote.file</a></li><li><a href="#bcbio.variation.report">bcbio.variation.report</a></li><li><a href="#bcbio.variation.structural">bcbio.variation.structural</a></li><li><a href="#bcbio.variation.utils.background">bcbio.variation.utils.background</a></li><li><a href="#bcbio.variation.utils.callsummary">bcbio.variation.utils.callsummary</a></li><li><a href="#bcbio.variation.utils.cgmetrics">bcbio.variation.utils.cgmetrics</a></li><li><a href="#bcbio.variation.utils.core">bcbio.variation.utils.core</a></li><li><a href="#bcbio.variation.utils.gms">bcbio.variation.utils.gms</a></li><li><a href="#bcbio.variation.utils.illumina">bcbio.variation.utils.illumina</a></li><li><a href="#bcbio.variation.utils.popfreq">bcbio.variation.utils.popfreq</a></li><li><a href="#bcbio.variation.utils.sanger">bcbio.variation.utils.sanger</a></li><li><a href="#bcbio.variation.utils.summarize">bcbio.variation.utils.summarize</a></li><li><a href="#bcbio.variation.utils.svmerge">bcbio.variation.utils.svmerge</a></li><li><a href="#bcbio.variation.validate">bcbio.variation.validate</a></li><li><a href="#bcbio.variation.variantcontext">bcbio.variation.variantcontext</a></li><li><a href="#bcbio.variation.vcfwalker">bcbio.variation.vcfwalker</a></li><li><a href="#bcbio.variation.web.db">bcbio.variation.web.db</a></li><li><a href="#bcbio.variation.workflow.xprize">bcbio.variation.workflow.xprize</a></li></ul></div></td><td class="codes">&nbsp;</td></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.align.interval" name="bcbio.align.interval"><h1 class="project-name">bcbio.align.interval</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Convert BED interval contig names between compatible assemblies
  Handles Human hg19 to GRCh37 naming conversions.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.align.interval
  (:use [clojure.java.io]
        [bcbio.align.ref :only [get-seq-name-map]]
        [bcbio.variation.normalize :only [prep-rename-map]])
  (:require [clojure.string :as string]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><p>Remap the input contig into GRCh37 contig name.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- update-contig-name
  [name-map line]
  (let [parts (string/split line #&quot;\t&quot;)
        remap-contig (get name-map (first parts))]
    (when remap-contig
      (cons remap-contig (rest parts)))))</pre></td></tr><tr><td class="docs"><p>Rename BED coordinates to match supplied reference file</p>
</td><td class="codes"><pre class="brush: clojure">(defn rename-bed
  [bed-file ref-file &amp; {:keys [out-dir]}]
  (let [out-file (itx/add-file-part bed-file &quot;remap&quot; out-dir)]
    (when (itx/needs-run? out-file)
      (let [name-map (prep-rename-map :GRCh37 ref-file)]
        (with-open [rdr (reader bed-file)
                    wtr (writer out-file)]
          (doall
           (map #(.write wtr (str (string/join &quot;\t&quot; %) &quot;\n&quot;))
                (-&gt;&gt; (line-seq rdr)
                     (map (partial update-contig-name name-map))
                     (remove nil?)))))))
    out-file))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.align.ref" name="bcbio.align.ref"><h1 class="project-name">bcbio.align.ref</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Deal with reference sequences for alignment and variant calling.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.align.ref
  (:import [org.broadinstitute.sting.gatk.datasources.reference ReferenceDataSource]
           [net.sf.picard.reference ReferenceSequenceFileFactory]
           [net.sf.picard.sam CreateSequenceDictionary])
  (:use [clojure.java.io]
        [ordered.map :only [ordered-map]])
  (:require [clojure.string :as string]
            [fs.core :as fs]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn create-ref-dict
  [ref-file]
  (let [dict-file (str (itx/file-root ref-file) &quot;.dict&quot;)]
    (when (itx/needs-run? dict-file)
      (.instanceMain (CreateSequenceDictionary.)
                     (into-array [(str &quot;r=&quot; ref-file) (str &quot;o=&quot; dict-file)])))
    dict-file))</pre></td></tr><tr><td class="docs"><p>Retrieve Picard sequence dictionary from FASTA reference file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-seq-dict*
  [ref-file]
  (create-ref-dict ref-file)
  (ReferenceDataSource. (file ref-file))
  (-&gt; (file ref-file)
      ReferenceSequenceFileFactory/getReferenceSequenceFile
      .getSequenceDictionary))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(def get-seq-dict (memoize get-seq-dict*))</pre></td></tr><tr><td class="docs"><p>Retrieve Picard sequence dictionary and reference from FASTA file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-seq-dict-and-ref*
  [ref-file]
  (create-ref-dict ref-file)
  (ReferenceDataSource. (file ref-file))
  (let [seq-ref (ReferenceSequenceFileFactory/getReferenceSequenceFile (file ref-file))
        seq-dict (-&gt; seq-ref .getSequenceDictionary)]
    [seq-dict seq-ref]))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(def get-seq-dict-and-ref (memoize get-seq-dict-and-ref*))</pre></td></tr><tr><td class="docs"><p>Retrieve map of sequence names to index positions in the input reference.
   This is useful for sorting by position.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-seq-name-map
  [ref-file]
  (reduce (fn [coll [i x]] (assoc coll x i))
          (ordered-map)
          (map-indexed vector
                       (map #(.getSequenceName %) (.getSequences (get-seq-dict ref-file))))))</pre></td></tr><tr><td class="docs"><p>Retrieve sequence in the provided region from input reference file.
   start and end are 1-based inclusive coordinates (VCF style)</p>
</td><td class="codes"><pre class="brush: clojure">(defn extract-sequence
  [ref-file contig start end]
  (let [[seq-dict seq-ref] (get-seq-dict-and-ref ref-file)]
    (when (and (contains? (set (map #(.getSequenceName %) (.getSequences seq-dict))) contig)
               (&lt;= end (.getSequenceLength (.getSequence seq-dict contig))))
      (-&gt; seq-ref
          (.getSubsequenceAt contig start end)
          .getBases
          (#(map char %))
          (#(apply str %))))))</pre></td></tr><tr><td class="docs"><p>Sort a BED file relative to the input reference.
   Takes a IO intensive approach over memory intensive by sorting in blocks
   of chromosomes. <code>same-time-chrs</code> handles the tradeoff between speed and
   memory by determining how many chromosomes to process simultaneously.</p>
</td><td class="codes"><pre class="brush: clojure">(defn sort-bed-file
  [bed-file ref-file]
  (letfn [(process-line [cur-chrs line]
            (let [tab-parts (string/split line #&quot;\t&quot;)
                  parts (if (&gt; (count tab-parts) 1)
                          tab-parts
                          (string/split line #&quot; &quot;))]
              (let [[chr start end] (take 3 parts)]
                (when (or (nil? cur-chrs) (contains? cur-chrs chr))
                  [[chr (Integer/parseInt start) (Integer/parseInt end)] line]))))
          (get-input-chrs [bed-file]
            (with-open [rdr (reader bed-file)]
              (-&gt;&gt; (line-seq rdr)
                   (map (partial process-line nil))
                   (map ffirst)
                   set)))]
    (let [out-file (itx/add-file-part bed-file &quot;sorted&quot;)
          input-chrs (get-input-chrs bed-file)
          same-time-chrs 5]
      (when (or (itx/needs-run? out-file)
                (&gt; (fs/mod-time bed-file) (fs/mod-time out-file)))
        (itx/with-tx-file [tx-out out-file]
          (with-open [wtr (writer tx-out)]
            (doseq [cur-chrs (-&gt;&gt; (get-seq-dict ref-file)
                                  .getSequences
                                  (map #(.getSequenceName %))
                                  (filter input-chrs)
                                  (partition-all same-time-chrs)
                                  (map set))]
              (with-open [rdr (reader bed-file)]
                (doseq [[_ line] (-&gt;&gt; (line-seq rdr)
                                      (map (partial process-line cur-chrs))
                                      (remove nil?)
                                      (sort-by first))]
                  (.write wtr (str line &quot;\n&quot;))))))))
      out-file)))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.align.reorder" name="bcbio.align.reorder"><h1 class="project-name">bcbio.align.reorder</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Reorder BAM alignment files to a reference dictionary, potentially swapping naming.
  Handles Human hg19 to GRCh37 naming conversions.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.align.reorder
  (:import [net.sf.samtools SAMFileReader SAMFileWriterFactory SAMReadGroupRecord
            SAMTag SAMFileReader$ValidationStringency])
  (:use [clojure.java.io]
        [bcbio.align.ref :only [get-seq-dict]]
        [bcbio.run.broad :only [index-bam]]
        [bcbio.variation.normalize :only [prep-rename-map]])
  (:require [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><p>Add updated sequence dictionary and run group information to header.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- updated-bam-header
  [in-bam ref-file call exp]
  (letfn [(update-rgs [rgs]
            (if-not (empty? rgs) rgs
                    [(doto (SAMReadGroupRecord. &quot;1&quot;)
                       (.setLibrary (:sample exp))
                       (.setPlatform (get call :platform &quot;illumina&quot;))
                       (.setSample (:sample exp))
                       (.setPlatformUnit (:sample exp)))]))]
    (let [read-groups (update-rgs (-&gt; in-bam .getFileHeader .getReadGroups))]
      (doto (-&gt; in-bam .getFileHeader .clone)
        (.setSequenceDictionary (-&gt; ref-file get-seq-dict))
        (.setReadGroups read-groups)))))</pre></td></tr><tr><td class="docs"><p>Retrieve order of chromosomes to fetch and mapping to new index.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-new-chr-order
  [bam-names ref-names ref-file]
  (letfn [(get-bam-name-map [bam-names orig-ref-names]
            (let [ref-names (set orig-ref-names)
                  name-remap (prep-rename-map :GRCh37 ref-file)]
              (reduce (fn [coll x]
                        (assoc coll (cond
                                     (contains? ref-names x) x
                                     (contains? name-remap x) (get name-remap x)
                                     :else (throw (Exception. (str &quot;Could not map &quot; x))))
                               x))
                      {} bam-names)))
          (get-index-map [name-map]
            (let [bam-name-map (reduce (fn [coll [x y]] (assoc coll y x))
                                       {} name-map)]
              (reduce (fn [coll [i x]]
                        (assoc coll i (.indexOf ref-names (get bam-name-map x))))
                      {} (map-indexed vector bam-names))))]
    (when-not (every? #(apply = %) (partition 2 (interleave ref-names bam-names)))
      (let [name-map (get-bam-name-map bam-names ref-names)]
        {:names (remove nil? (map #(get name-map %) ref-names))
         :indexes (get-index-map name-map)}))))</pre></td></tr><tr><td class="docs"><p>Lazy sequence for BAM reads from a Picard iterator.</p>
</td><td class="codes"><pre class="brush: clojure">(defn bam-read-seq
  [iter]
  (lazy-seq
   (when (.hasNext iter)
     (cons (.next iter) (bam-read-seq iter)))))</pre></td></tr><tr><td class="docs"><p>Write reordered BAM file in specified chromosome order.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- write-reorder-bam
  [in-bam out-bam chr-order header]
  (let [default-rg-id (-&gt; header .getReadGroups first .getId)]
    (letfn [(update-read [read]
              (let [new-rg-id (if-let [x (.getAttribute read (.name SAMTag/RG))] x
                                      default-rg-id)]
                (doto read
                  (.setHeader header)
                  (.setReferenceIndex (get (:indexes chr-order)
                                           (.getReferenceIndex read) -1))
                  (.setMateReferenceIndex (get (:indexes chr-order)
                                               (.getMateReferenceIndex read) -1))
                  (.setAttribute (.name SAMTag/RG) new-rg-id))))]
      (doseq [cur-chr (:names chr-order)]
        (with-open [iter (.query in-bam cur-chr 0 0 false)]
          (doseq [read (bam-read-seq iter)]
            (.addAlignment out-bam (update-read read)))))
      (with-open [iter (.queryUnmapped in-bam)]
        (doseq [read (bam-read-seq iter)]
          (.addAlignment out-bam (update-read read)))))))</pre></td></tr><tr><td class="docs"><p>Reorder and remap BAM file to match supplied reference file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn reorder-bam
  [bam-file ref-file call exp &amp; {:keys [out-dir]}]
  (let [out-file (itx/add-file-part bam-file &quot;reorder&quot; out-dir)]
    (when (itx/needs-run? out-file)
      (index-bam bam-file)
      (SAMFileReader/setDefaultValidationStringency SAMFileReader$ValidationStringency/LENIENT)
      (with-open [in-bam (SAMFileReader. (file bam-file))]
        (let [ref-names (map #(.getSequenceName %) (-&gt; ref-file get-seq-dict .getSequences))
              bam-names (map #(.getSequenceName %) (-&gt; in-bam .getFileHeader .getSequenceDictionary
                                                       .getSequences))
              header (updated-bam-header in-bam ref-file call exp)]
          (if-let [chr-order (get-new-chr-order bam-names ref-names ref-file)]
            (do
              (with-open [out-bam (.makeSAMOrBAMWriter (SAMFileWriterFactory.)
                                                       header true (file out-file))]
                (write-reorder-bam in-bam out-bam chr-order header))
              out-file)
            bam-file))))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -main [bam-file ref-file sample-name]
  (reorder-bam bam-file ref-file {} {:sample sample-name}))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.run.broad" name="bcbio.run.broad"><h1 class="project-name">bcbio.run.broad</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>High level functions to run software from Broad: GATK, Picard</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.run.broad
  (:import [org.broadinstitute.sting.gatk CommandLineGATK]
           [net.sf.samtools SAMFileReader SAMFileReader$ValidationStringency]
           [net.sf.picard.sam BuildBamIndex])
  (:use [clojure.java.io]
        [bcbio.align.ref :only [sort-bed-file create-ref-dict]])
  (:require [fs.core :as fs]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><p>Ensure reference dictionary </p>
</td><td class="codes"><pre class="brush: clojure">(defn- create-ref-dict-gatk
  [args]
  (when-let [ref-file (second (drop-while
                               #(not (contains? #{&quot;-R&quot; &quot;--reference_sequence&quot;} %))
                               args))]
    (create-ref-dict ref-file)))</pre></td></tr><tr><td class="docs"><p>Run a GATK commandline in an idempotent file-safe transaction.
   Contains a workaround to not die on errors while generating GATKReports,
   which occur when calling this externally as a library function.</p>
</td><td class="codes"><pre class="brush: clojure">(defn run-gatk
  [program args file-info map-info]
  (when (itx/needs-run? (map #(% file-info) (get map-info :out [])))
    (create-ref-dict-gatk args)
    (let [std-args (concat [&quot;-T&quot; program]
                           (when-not (contains? (set args) &quot;--unsafe&quot;)
                             [&quot;--unsafe&quot; &quot;LENIENT_VCF_PROCESSING&quot;])
                           [&quot;--read_filter&quot; &quot;BadCigar&quot; &quot;--read_filter&quot; &quot;NotPrimaryAlignment&quot;])]
      (itx/with-tx-files [tx-file-info file-info (get map-info :out []) [&quot;.idx&quot;]]
        (try
          (CommandLineGATK/start (CommandLineGATK.)
                                 (into-array (map str (itx/subs-kw-files
                                                       (concat std-args args)
                                                       tx-file-info))))
          (catch java.lang.VerifyError e
            (when-not (.contains (.getMessage e) &quot;GATKRunReport&quot;)
              (throw e))))))))</pre></td></tr><tr><td class="docs"><p>Generate BAM index, skipping if already present.</p>
</td><td class="codes"><pre class="brush: clojure">(defn index-bam
  [in-bam]
  (let [index-file (str in-bam &quot;.bai&quot;)]
    (when (itx/needs-run? index-file)
      (SAMFileReader/setDefaultValidationStringency SAMFileReader$ValidationStringency/LENIENT)
      (BuildBamIndex/createIndex (SAMFileReader. (file in-bam)) (file index-file)))
    index-file))</pre></td></tr><tr><td class="docs"><p>Supply GATK commandline arguments for interval files, merging via intersection.</p>
</td><td class="codes"><pre class="brush: clojure">(defn gatk-cl-intersect-intervals
  [intervals ref-file &amp; {:keys [vcf]}]
  (cond
   (or (nil? intervals)
       (empty? intervals)) (if vcf [&quot;-L&quot; vcf] [])
   (coll? intervals) (concat (flatten (map #(list &quot;-L&quot; %)
                                           (map #(sort-bed-file % ref-file) intervals)))
                             [&quot;--interval_set_rule&quot; &quot;INTERSECTION&quot;])
   :else [&quot;-L&quot; (sort-bed-file intervals ref-file)]))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.run.itx" name="bcbio.run.itx"><h1 class="project-name">bcbio.run.itx</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Functionality for running idempotent, transactional processes.
   Provides an API for long running processes in computational
   pipelines. Avoids re-running a process if it has produced the
   output file on a previous run, and leaving partially finished
   files in the case of premature termination.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.run.itx
  (:import (java.io File))
  (:use [clojure.java.io])
  (:require [clojure.string :as string]
            [fs.core :as fs]))</pre></td></tr><tr><td class="docs"><h2>Idempotent processing</h2>

<p>avoid re-running when output files exist</p>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Check if an output files need a run: any do not exist or empty file</p>
</td><td class="codes"><pre class="brush: clojure">(defn needs-run?
  [&amp; fnames]
  (letfn [(file-non-empty? [f]
            (and (fs/exists? f)
                 (&gt; (fs/size f) 0)))]
    (not-every? true?
                (map file-non-empty? (flatten fnames)))))</pre></td></tr><tr><td class="docs"><p>Substitute any keywords in the arguments from file information map.</p>
</td><td class="codes"><pre class="brush: clojure">(defn subs-kw-files
  [args file-info]
  (letfn [(maybe-sub-kw [x]
            (if (and (keyword? x)
                     (contains? file-info x))
              (get file-info x)
              x))]
    (map maybe-sub-kw args)))</pre></td></tr><tr><td class="docs"><h2>Transactions</h2>

<p>Handle output files in a separate transaction directory to avoid
partially finished output files if long-running processes fail.</p>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn temp-dir-w-prefix [root prefix]
  (let [dir (File/createTempFile prefix  (file root))]
    (fs/delete dir)
    (fs/mkdir dir)
    dir))</pre></td></tr><tr><td class="docs"><p>Provide a temporary directory, removed when exiting the body.</p>
</td><td class="codes"><pre class="brush: clojure">(defmacro with-temp-dir
  [[tmp-dir base-dir] &amp; body]
  `(let [~tmp-dir (temp-dir-w-prefix ~base-dir &quot;tmp&quot;)]
     (try
       ~@body
       (finally
        (fs/delete-dir ~tmp-dir)))))</pre></td></tr><tr><td class="docs"><p>Update file-info with need-tx files in a safe transaction directory.</p>
</td><td class="codes"><pre class="brush: clojure">(defn safe-tx-files
  [file-info need-tx]
  (let [tx-files (map #(get file-info %) need-tx)
        tx-dir (temp-dir-w-prefix (fs/parent (first tx-files)) &quot;txtmp&quot;)]
    (reduce (fn [m [k v]]
              (assoc m k v))
            file-info
            (zipmap need-tx
                    (map #(str (fs/file tx-dir (fs/base-name %))) tx-files)))))</pre></td></tr><tr><td class="docs"><p>Rename generated transaction files into expected file location.</p>
</td><td class="codes"><pre class="brush: clojure">(defn rename-tx-files
  [tx-file-info file-info need-tx exts]
  (doseq [tx-key need-tx]
    (let [tx-safe (get tx-file-info tx-key) 
          tx-final (get file-info tx-key)]
      (fs/rename tx-safe tx-final)
      (doseq [ext exts]
        (when (fs/exists? (str tx-safe ext))
          (fs/rename (str tx-safe ext) (str tx-final ext)))))))</pre></td></tr><tr><td class="docs"><p>Perform action with files, keeping need-tx files in a transaction.</p>
</td><td class="codes"><pre class="brush: clojure">(defmacro with-tx-files
  [[tx-file-info file-info need-tx exts] &amp; body]
  (if (= (count need-tx) 0)
    `(do ~@body)
    `(let [~tx-file-info (safe-tx-files ~file-info ~need-tx)]
       (try
         ~@body
         (rename-tx-files ~tx-file-info ~file-info ~need-tx ~exts)
         (finally
          (fs/delete-dir (fs/parent (get ~tx-file-info (first ~need-tx)))))))))</pre></td></tr><tr><td class="docs"><p>Handle a single file in a transaction directory.</p>
</td><td class="codes"><pre class="brush: clojure">(defmacro with-tx-file
  [[tx-file orig-file] &amp; body]
  `(let [~tx-file (:out (safe-tx-files {:out ~orig-file} [:out]))]
     (try
       ~@body
       (rename-tx-files {:out ~tx-file} {:out ~orig-file} [:out] [])
       (finally
        (fs/delete-dir (fs/parent ~tx-file))))))</pre></td></tr><tr><td class="docs"><h2>Naming</h2>

<p>Generate new file names from existing ones</p>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Retrieve file name without extension: /path/to/fname.txt -> /path/to/fname</p>
</td><td class="codes"><pre class="brush: clojure">(defn file-root
  [fname]
  (let [i (.lastIndexOf fname &quot;.&quot;)]
    (if (pos? i)
      (subs fname 0 i)
      fname)))</pre></td></tr><tr><td class="docs"><p>Add file extender: base.txt -> base-part.txt</p>
</td><td class="codes"><pre class="brush: clojure">(defn add-file-part
  ([fname part]
     (add-file-part fname part nil))
  ([fname part out-dir]
     (let [out-fname (format &quot;%s-%s%s&quot; (file-root fname) part (fs/extension fname))]
       (if-not (nil? out-dir)
         (str (fs/file out-dir (fs/base-name out-fname)))
         out-fname))))</pre></td></tr><tr><td class="docs"><p>Remove file specialization extender: base-part.txt -> base.txt</p>
</td><td class="codes"><pre class="brush: clojure">(defn remove-file-part
  [fname part]
  (string/replace (str fname) (str &quot;-&quot; part) &quot;&quot;))</pre></td></tr><tr><td class="docs"><p>Remove any zip extensions from the input filename</p>
</td><td class="codes"><pre class="brush: clojure">(defn remove-zip-ext
  [fname]
  (letfn [(maybe-remove-ext [fname ext]
            (if (.endsWith fname ext)
              (subs fname 0 (- (.length fname) (.length ext)))
              fname))]
    (let [exts [&quot;.tar.gz&quot; &quot;tar.bz2&quot; &quot;.gz&quot; &quot;.bz2&quot; &quot;.zip&quot;]]
      (reduce maybe-remove-ext fname exts))))</pre></td></tr><tr><td class="docs"><h2>File and directory manipulation</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Remove file or directory only if it exists.</p>
</td><td class="codes"><pre class="brush: clojure">(defn remove-path
  [x]
  (if (fs/exists? x)
    (if (fs/directory? x)
      (fs/delete-dir x)
      (fs/delete x))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.annotate.effects" name="bcbio.variation.annotate.effects"><h1 class="project-name">bcbio.variation.annotate.effects</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Predict functional consequences of variant changes leveraging snpEff.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.annotate.effects
  (:import [ca.mcgill.mcb.pcingola.snpEffect.commandLine
            SnpEffCmdEff SnpEffCmdDownload]
           [bcbio.variation.util ThreadLocalPrintStream])
  (:require [clojure.java.io :as io]
            [clojure.java.shell :as shell]
            [fs.core :as fs]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><h2>snpEff</h2>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- get-snpeff-config
  [base-dir]
  (let [data-dir (str (fs/file base-dir &quot;snpeff&quot; &quot;data&quot;))
        orig-config (-&gt; (ClassLoader/getSystemClassLoader)
                        (.getResourceAsStream &quot;snpEff.config&quot;))
        config-file (str (fs/file base-dir &quot;snpeff&quot; &quot;snpEff.config&quot;))]
    (when-not (fs/exists? data-dir)
      (fs/mkdirs data-dir))
    (when (itx/needs-run? config-file)
      (with-open [rdr (io/reader orig-config)
                  wtr (io/writer config-file)]
        (doseq [line (line-seq rdr)]
          (.write wtr (str
                       (if (.startsWith line &quot;data_dir&quot;)
                         (str &quot;data_dir = &quot; data-dir)
                         line)
                       &quot;\n&quot;)))))
    {:data-dir data-dir
     :config-file config-file}))</pre></td></tr><tr><td class="docs"><p>Check for a snpEff genome index and download if not present.</p>
</td><td class="codes"><pre class="brush: clojure">(defn download-genome
  [genome base-dir]
  (let [{:keys [data-dir config-file]} (get-snpeff-config base-dir)
        genome-dir (str (fs/file data-dir genome))]
    (when-not (fs/exists? genome-dir)
      (fs/mkdirs genome-dir)
      (doto (SnpEffCmdDownload.)
        (.parseArgs (into-array [&quot;-c&quot; config-file genome]))
        .run)
      (doseq [x (fs/glob (str &quot;*&quot; genome &quot;.zip&quot;))]
        (fs/delete x)))
    config-file))</pre></td></tr><tr><td class="docs"><p>Annotate the input file with snpEff, providing predictions of variant effects. </p>
</td><td class="codes"><pre class="brush: clojure">(defn snpeff-annotate
  [in-file genome base-dir &amp; {:keys [out-dir]}]
  (let [config-file (download-genome genome base-dir)
        out-file (itx/add-file-part in-file &quot;effects&quot; out-dir)]
    (when (itx/needs-run? out-file)
      ;; snpEff prints to standard out so we need to safely redirect that to a file.
      (itx/with-tx-file [tx-out out-file]
        (let [orig-out System/out]
          (try
            (with-open [wtr (java.io.PrintStream. tx-out)]
              (System/setOut (ThreadLocalPrintStream. wtr))
              (doto (SnpEffCmdEff.)
                (.parseArgs (into-array [&quot;-noStats&quot; &quot;-c&quot; config-file genome in-file]))
                .run))
            (finally
              (System/setOut orig-out))))))
    out-file))</pre></td></tr><tr><td class="docs"><h2>VEP</h2>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- get-vep-cmd [vep-dir]
  (let [vep-file (when vep-dir (str (fs/file (fs/expand-home vep-dir)
                                             &quot;variant_effect_predictor.pl&quot;)))]
    (when (and vep-file (fs/exists? vep-file))
      vep-file)))</pre></td></tr><tr><td class="docs"><p>Run Ensembl Variant Effects Predictor on input variant file.
   Re-annotates the input file with CSQ field compatible with Gemini.</p>
</td><td class="codes"><pre class="brush: clojure">(defn run-vep
  [in-file vep-dir &amp; {:keys [re-run?]}]
  (when-let [vep-cmd (get-vep-cmd vep-dir)]
    (let [out-file (itx/add-file-part in-file &quot;vep&quot;)]
      (when (or (itx/needs-run? out-file) re-run?)
        (itx/with-tx-file [tx-out out-file]
          (shell/sh &quot;perl&quot; vep-cmd &quot;-i&quot; in-file &quot;-o&quot; tx-out &quot;--vcf&quot; &quot;--cache&quot;
                    &quot;--terms&quot; &quot;so&quot; &quot;--sift&quot; &quot;b&quot; &quot;--polyphen&quot; &quot;b&quot; &quot;--hgnc&quot; &quot;--numbers&quot;
                    &quot;--fields&quot; &quot;Consequence,Codons,Amino_acids,Gene,HGNC,Feature,EXON,PolyPhen,SIFT&quot;)))
      out-file)))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.annotate.entropy" name="bcbio.variation.annotate.entropy"><h1 class="project-name">bcbio.variation.annotate.entropy</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Calculate Shannon entropy for flanking sequence surrounding variants.
   Used to identify low-complexity repeat regions in variants.
   Based on 'vcfentropy' from Erik Garrison's vcflib:
   https://github.com/ekg/vcflib</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.annotate.entropy
  (:import [org.broadinstitute.sting.gatk.walkers.annotator.interfaces.InfoFieldAnnotation]
           [org.broadinstitute.sting.utils.codecs.vcf VCFInfoHeaderLine VCFHeaderLineType])
  (:gen-class
   :name bcbio.variation.annotate.entropy.ShannonEntropy
   :extends org.broadinstitute.sting.gatk.walkers.annotator.interfaces.InfoFieldAnnotation))</pre></td></tr><tr><td class="docs"><h2>Shannon entropy</h2>

<p>From John Lawrence Aspden's information theory posts
https://github.com/johnlawrenceaspden/hobby-code/blob/master/averygentleintroduction-part5.clj</p>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn bits [n]
  &quot;How many bits to represent n alternatives? Fractions allowed! Also know as log2.&quot;
  (/ (Math/log n) (Math/log 2)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn shannon-entropy [P]
  (let [odds (map second P)
        total (reduce + odds)
        bits-aliased (/ (reduce + (map * odds (map bits odds))) total)]
    (- (bits total) bits-aliased)))</pre></td></tr><tr><td class="docs"><p>Calculate entropy of a sequence based on distribution of dimers.
   Splits sequence into all dimer 2bp windows, calculates frequency
   of each dimer and then feeds distribution to shannon calculation.</p>
</td><td class="codes"><pre class="brush: clojure">(defn seq-entropy
  [seq]
  (-&gt;&gt; seq
       (partition 2 1)
       frequencies
       shannon-entropy))</pre></td></tr><tr><td class="docs"><h2>Helper function</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Retrieve sequence surrounding the current variant, with nbp flanking sequence.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-flank-seq
  [ref-context nbp]
  (letfn [(subset-region [x]
            (let [want-size (inc (* 2 nbp))
                  end-subtract (/ (- (count x) want-size) 2)]
              (subs x end-subtract (- (count x) end-subtract))))]
    (-&gt;&gt; ref-context
         .getBases
         (map char)
         (apply str)
         subset-region)))</pre></td></tr><tr><td class="docs"><h2>GATK walker</h2>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(def flank-bp 12)</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -getKeyNames [_]
  [&quot;Entropy&quot;])</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -getDescriptions [_]
  [(VCFInfoHeaderLine. &quot;Entropy&quot; 1 VCFHeaderLineType/Float
                       (format &quot;Shannon entropy of variant flanking regions, %sbp on both sides&quot;
                               flank-bp))])</pre></td></tr><tr><td class="docs"><p>Retrieve flanking region surrounding variant and calculate entropy.</p>
</td><td class="codes"><pre class="brush: clojure">(defn -annotate
  [_ _ _ ref _ _ _]
  {&quot;Entropy&quot; (-&gt;&gt; (get-flank-seq ref flank-bp)
                  seq-entropy
                  (format &quot;%.2f&quot;))})</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.annotate.mfe" name="bcbio.variation.annotate.mfe"><h1 class="project-name">bcbio.variation.annotate.mfe</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Calculate delta G Minimum Free Energy for sequence secondary structures.
   Extracts regions surrounding variants and identifies the free energy
   of the most problematic secondary structures. Larger negative free energy
   values are especially stable and problematic.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.annotate.mfe
  (:import [org.broadinstitute.sting.gatk.walkers.annotator.interfaces.InfoFieldAnnotation]
           [org.broadinstitute.sting.utils.codecs.vcf VCFInfoHeaderLine VCFHeaderLineType])
  (:use [circdesigna.core :only [min-free-energy]]
        [bcbio.variation.annotate.entropy :only [get-flank-seq]])
  (:gen-class
   :name bcbio.variation.annotate.entropy.MinFreeEnergy
   :extends org.broadinstitute.sting.gatk.walkers.annotator.interfaces.InfoFieldAnnotation))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(def flank-bp 15)</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -getKeyNames [_]
  [&quot;MFE&quot;])</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -getDescriptions [_]
  [(VCFInfoHeaderLine. &quot;MFE&quot; 1 VCFHeaderLineType/Float
                       (format (str &quot;delta G minimum free energy of the most problematic &quot;
                                    &quot;secondary structure +/- %sbp around variant&quot;)
                               flank-bp))])</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- safe-min-free-energy
  [seq]
  (try
    (min-free-energy seq)
    (catch java.lang.ArrayIndexOutOfBoundsException e
      0.0)))</pre></td></tr><tr><td class="docs"><p>Retrieve flanking region surrounding variant and calculate MFE.</p>
</td><td class="codes"><pre class="brush: clojure">(defn -annotate
  [_ _ _ ref _ _ _]
  {&quot;MFE&quot; (-&gt;&gt; (get-flank-seq ref flank-bp)
              safe-min-free-energy
              (format &quot;%.2f&quot;))})</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.annotate.nbq" name="bcbio.variation.annotate.nbq"><h1 class="project-name">bcbio.variation.annotate.nbq</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>GATK annotator that calculates Mean Neighboring Base Quality (NBQ) for variants.</p>

<p>  The motivation for this annotation is that regional base quality influences whether
  a call is correct. The Atlas2 paper describes the metric in more detail:</p>

<p>  http://www.biomedcentral.com/1471-2105/13/8/abstract</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.annotate.nbq
  (:import [org.broadinstitute.sting.gatk.walkers.annotator.interfaces.InfoFieldAnnotation]
           [org.broadinstitute.sting.utils.codecs.vcf VCFInfoHeaderLine VCFHeaderLineType]
           [org.broadinstitute.sting.utils BaseUtils])
  (:require [incanter.stats :as istats])
  (:gen-class
   :name bcbio.variation.annotate.nbq.MeanNeighboringBaseQuality
   :extends org.broadinstitute.sting.gatk.walkers.annotator.interfaces.InfoFieldAnnotation))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(def flank-bp 5)</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -getKeyNames
  [_]
  [&quot;NBQ&quot;])</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -getDescriptions
  [_]
  [(VCFInfoHeaderLine. &quot;NBQ&quot; 1 VCFHeaderLineType/Float
                       (format &quot;Mean Neighboring Base Quality, includes %sbp on both sides&quot;
                               flank-bp))])</pre></td></tr><tr><td class="docs"><p>Provide Mean Neighboring Base Quality calculations at a position.</p>

<pre><code>- Get a pileup for each sample context.
- Use pileup to retrieve reads and current offsets.
- Filter reads to those that match an alternative base
- Get quality from reads and pull out qualities in surrounding region
- Calculate mean and return.
</code></pre>
</td><td class="codes"><pre class="brush: clojure">(defn -annotate
  [_ _ _ _ contexts vc _]
  (letfn [(orient-reads [[offset read]]
            (if (.getReadNegativeStrandFlag read)
              {:offset offset
               :bases (BaseUtils/simpleReverseComplement (.getReadBases read))
               :quals (-&gt; read .getBaseQualities vec reverse)}
              {:offset offset
               :bases (.getReadString read)
               :quals (-&gt; read .getBaseQualities vec)}))
          (neighbor-qualities [{:keys [offset quals]}]
            (map #(nth quals % nil) (range (- offset flank-bp) (+ offset flank-bp))))
          (supports-alt? [alt-bases {:keys [offset bases]}]
            (let [base (char (nth bases offset))]
              (contains? alt-bases base)))
          (pileup-qualities [alt-bases pileup]
            (-&gt;&gt; (map vector (.getOffsets pileup) (.getReads pileup))
                 (map orient-reads)
                 (filter (partial supports-alt? alt-bases))
                 (map neighbor-qualities)))]
    (let [alt-bases (-&gt;&gt; (.getAlternateAlleles vc)
                              (map #(.getBaseString %))
                              (map first)
                              set)]
      (when (seq alt-bases)
        {&quot;NBQ&quot; (-&gt;&gt; contexts
                    vals
                    (map #(.getBasePileup %))
                    (map (partial pileup-qualities alt-bases))
                    flatten
                    (remove nil?)
                    istats/mean
                    (format &quot;%.2f&quot;))}))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.annotation" name="bcbio.variation.annotation"><h1 class="project-name">bcbio.variation.annotation</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Annotate variant calls with metrics for assessing false positives
  http://www.broadinstitute.org/gsa/wiki/index.php/VariantAnnotator</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.annotation
  (:use [bcbio.variation.utils.cgmetrics :only [add-cgmetrics]])
  (:require [fs.core :as fs]
            [bcbio.run.itx :as itx]
            [bcbio.run.broad :as broad]))</pre></td></tr><tr><td class="docs"><p>Standard annotations applied to variants</p>
</td><td class="codes"><pre class="brush: clojure">(def  std-annotations
  [&quot;AlleleBalance&quot; &quot;BaseQualityRankSumTest&quot; &quot;DepthOfCoverage&quot;
   &quot;FisherStrand&quot; &quot;GCContent&quot; &quot;HaplotypeScore&quot; &quot;HomopolymerRun&quot;
   &quot;MappingQualityRankSumTest&quot; &quot;MappingQualityZero&quot;
   &quot;MeanNeighboringBaseQuality&quot; &quot;QualByDepth&quot;
   &quot;ReadPosRankSumTest&quot; &quot;RMSMappingQuality&quot;
   &quot;DepthPerAlleleBySample&quot; &quot;AlleleBalanceConfidenceInterval&quot;
   &quot;MostProbableGenotype&quot; &quot;ReadMeanLen&quot; &quot;ReadMeanPos&quot;
   &quot;ReadPosEndDist&quot; &quot;MinFreeEnergy&quot; &quot;ShannonEntropy&quot;])</pre></td></tr><tr><td class="docs"><p>Add GATK annotation metrics to variant calls.</p>
</td><td class="codes"><pre class="brush: clojure">(defn add-gatk-annotations
  [in-vcf align-bam ref &amp; {:keys [out-dir intervals annos]}]
  {:pre [(not (nil? align-bam))]}
  (let [file-info {:out-vcf (itx/add-file-part in-vcf &quot;annotated&quot; out-dir)}
        ready-annos (if annos annos std-annotations)
        args (concat [&quot;-R&quot; ref
                      &quot;-I&quot; align-bam
                      &quot;--variant&quot; in-vcf
                      &quot;--allow_potentially_misencoded_quality_scores&quot;
                      &quot;-o&quot; :out-vcf]
                     (reduce #(concat %1 [&quot;-A&quot; %2]) [] ready-annos)
                     (broad/gatk-cl-intersect-intervals intervals ref :vcf in-vcf))]
    (broad/index-bam align-bam)
    (broad/run-gatk &quot;VariantAnnotator&quot; args file-info {:out [:out-vcf]})
    (:out-vcf file-info)))</pre></td></tr><tr><td class="docs"><p>Flexible addition of additions to a variant file.
  Handles GATK annotations and Complete Genomics metrics.</p>
</td><td class="codes"><pre class="brush: clojure">(defn add-variant-annotations
  [vcf-file bam-file ref-file call &amp; {:keys [out-dir intervals]}]
  (let [x (get call :annotate &quot;&quot;)
        ann (cond
             (true? x) &quot;gatk&quot;
             (false? x) &quot;&quot;
             :else x)]
    (cond
     (and (= ann &quot;gatk&quot;) (not (nil? bam-file)))
     (add-gatk-annotations vcf-file bam-file ref-file :out-dir out-dir :intervals intervals)
     (.contains ann &quot;masterVar&quot;)
     (add-cgmetrics vcf-file ann ref-file :out-dir out-dir)
     :else vcf-file)))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.api.file" name="bcbio.variation.api.file"><h1 class="project-name">bcbio.variation.api.file</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Provide top level API for retrieving available files for a user.
  Encapsulates distributed storage in GenomeSpace as well as locally
  produced files.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.api.file
  (:use [clojure.java.io]
        [bcbio.variation.api.shared :only [web-config remote-file-cache]])
  (:require [clojure.java.shell :as shell]
            [clojure.string :as string]
            [clj-stacktrace.repl :as stacktrace]
            [fs.core :as fs]
            [bcbio.run.itx :as itx]
            [bcbio.variation.annotate.effects :as effects]
            [bcbio.variation.index.metrics :as metrics]
            [bcbio.variation.index.gemini :as gemini]
            [bcbio.variation.normalize :as normalize]
            [bcbio.variation.remote.core :as remote]))</pre></td></tr><tr><td class="docs"><h2>File retrieval, with caching</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Retrieve default + public directories for specific remote instances.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-default-public
  [rclient]
  (case (:type rclient)
    :gs (map (fn [x] {:id x})
             (cons &quot;.&quot; (remove #(.contains % (:username rclient))
                               (get-in @web-config [:remote :public]))))
    :galaxy (remote/list-dirs rclient nil)
    []))</pre></td></tr><tr><td class="docs"><p>Update file cache for our current user and filetype</p>
</td><td class="codes"><pre class="brush: clojure">(defn- update-user-files
  [rclient ftype]
   (let [dirnames (get-default-public rclient)
         file-info (mapcat #(remote/list-files rclient % ftype) dirnames)]
     (swap! remote-file-cache assoc [(:username rclient) ftype] file-info)
     file-info))</pre></td></tr><tr><td class="docs"><p>Retrieve file information for files of the specified type, with caching.</p>
</td><td class="codes"><pre class="brush: clojure">(defn list-files-w-cache
  [rclient ftype]
  (let [cache-info (get @remote-file-cache [(:username rclient) ftype])]
    (if (seq cache-info)
      (do
        (future (update-user-files rclient ftype))
        cache-info)
      (update-user-files rclient ftype))))</pre></td></tr><tr><td class="docs"><h2>Pre-fetching of data for front end interactivity</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Prepare biodata directory, synchronizing with GenomeSpace client.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- prep-biodata-dir
  [rclient biodata-dir]
  (letfn [(download-and-unpack [gs-id]
            (let [zip-file (remote/get-file gs-id rclient)]
              (when (and (fs/exists? zip-file)
                         (itx/needs-run? (itx/remove-zip-ext zip-file)))
                (shell/sh &quot;gunzip&quot; zip-file)
                (spit zip-file (str &quot;unzipped to &quot; (itx/remove-zip-ext zip-file))))))]
    (doall (map #(download-and-unpack (:id %))
                (remote/list-files rclient biodata-dir :gz)))))</pre></td></tr><tr><td class="docs"><p>Set of files currently under preparation, preventing double work.</p>
</td><td class="codes"><pre class="brush: clojure">(def ^{:doc 
       :private true}
  prep-queue (atom #{}))</pre></td></tr><tr><td class="docs"><p>Do actual work of preparing input file: resort and annotate for effects.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- prep-file*
  [in-file ref-info out-dir cache-dir]
  (let [current-ref (normalize/pick-best-ref in-file (cons (:genome ref-info) (:genome-alts ref-info)))]
    (-&gt; in-file
        (normalize/prep-vcf (:genome ref-info) nil :out-dir out-dir :orig-ref-file current-ref
                            :config {:remove-refcalls false})
        (effects/snpeff-annotate (:effects ref-info) cache-dir :out-dir out-dir))))</pre></td></tr><tr><td class="docs"><p>Provide knob to avoid doing labor intensive prep for testing environments.</p>
</td><td class="codes"><pre class="brush: clojure">(def ^{:doc 
       :dynamic true}
  *skip-prep* false)</pre></td></tr><tr><td class="docs"><p>Setup preparation for preparing downloading input files.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- prep-file
  [in-file ref-info is-new?]
  (let [out-file (if *skip-prep* in-file (itx/add-file-part in-file &quot;prep&quot;))
        cache-dir (get-in @web-config [:dir :cache])]
    (when (or (itx/needs-run? out-file) is-new?)
      (when-not (contains? @prep-queue in-file)
        (try
          (swap! prep-queue conj in-file)
          (itx/with-temp-dir [out-dir (fs/parent in-file)]
            (fs/rename (prep-file* in-file ref-info out-dir cache-dir)
                       out-file))
          (catch Exception ex
            (stacktrace/pst ex)
            (throw ex))
          (finally
           (swap! prep-queue disj in-file)))))
    out-file))</pre></td></tr><tr><td class="docs"><p>Provide list of files currently indexing.</p>
</td><td class="codes"><pre class="brush: clojure">(def 
  index-queue (atom #{}))</pre></td></tr><tr><td class="docs"><p>Check if a file is newly created, or out of date with server.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- is-file-new?
  [local-file finfo]
  (if (or (nil? (:created-on finfo)) (nil? (:size finfo)))
    false
    (or (not= (fs/size local-file) (:size finfo))
        (&lt; (fs/mod-time local-file) (.getTime (:created-on finfo))))))</pre></td></tr><tr><td class="docs"><p>Retrieve a file from remote server and prepare for analysis:
   - Checks for remote updates
   - Downloads the file if necessary
   - Preps the file for analysis, including resorting to reference genome
     and annotating.
   - Indexes for metric retrieval.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-prep-and-index
  [finfo rclient]
  (let [ref-info (first (:ref @web-config))
        test-local-file (remote/get-file (:id finfo) rclient)
        is-new? (is-file-new? test-local-file finfo)
        local-file (if is-new?
                     (do
                       (fs/delete test-local-file)
                       (remote/get-file (:id finfo) rclient))
                     test-local-file)
        ready-file (prep-file local-file ref-info is-new?)]
    (when ready-file
      (when-not (contains? @index-queue ready-file)
        (try
          (swap! index-queue conj ready-file)
          (metrics/index-variant-file ready-file (:genome ref-info) :re-index? is-new?
                                      :subsample-params (:params @web-config))
          (gemini/index-variant-file ready-file (:genome ref-info) :re-index? is-new?
                                     :subsample-params (:params @web-config))
          (catch Exception ex
            (stacktrace/pst ex))
          (finally
           (swap! index-queue disj ready-file)))))
    ready-file))</pre></td></tr><tr><td class="docs"><p>Retrieve and pre-index files for analysis from the remote client.</p>
</td><td class="codes"><pre class="brush: clojure">(defn pre-fetch-remotes
  [rclient]
  (doall (map (partial update-user-files rclient) [:vcf]))
  (when-let [cache-dir (get-in @web-config [:dir :cache])]
    (when-let [biodata-dir (get-in @web-config [:remote :biodata])]
      (prep-biodata-dir rclient biodata-dir))
    (doseq [x (list-files-w-cache rclient :vcf)]
      (get-prep-and-index x rclient))))</pre></td></tr><tr><td class="docs"><h2>Client API, with pre-fetching</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Top level retrieval of a client from username/password to pre-connected client.
   As a side effect, pre-retrieve and caches files and associated information.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-client
  [creds &amp; {:keys [pre-fetch? allow-offline?]
            :or {pre-fetch? true}}]
  (let [rclient (remote/get-client (-&gt; creds
                                       (assoc :allow-offline? allow-offline?)
                                       (assoc :type (get creds :type :gs))))]
    (when (and pre-fetch? (:conn rclient))
      (future (pre-fetch-remotes rclient)))
    rclient))</pre></td></tr><tr><td class="docs"><p>Retrieve local cached files supporting offline processing
   XXX Needs updating to hook back in for full offline analysis reboot.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-local-dl-files
  [ftype &amp; {:keys [dirnames]}]
  {:pre [(nil? dirnames)]}
  (letfn [(check-dir-for-type [root _ files]
            (-&gt;&gt; files
                 (filter #(.endsWith % (str &quot;.&quot; (name ftype))))
                 (map #(str (file root %)))))
          (convert-to-api [cache-dir fname]
            {:id fname
             :tags []
             :filename (str (fs/base-name fname))
             :folder (string/replace (str (fs/parent fname)) (str (fs/file cache-dir)) &quot;&quot;)
             :size (fs/size fname)
             :created-on (java.util.Date. (fs/mod-time fname))})]
    (let [cache-dir (get-in @web-config [:dir :cache])]
      (-&gt;&gt; (fs/walk check-dir-for-type cache-dir)
           flatten
           (map (partial convert-to-api cache-dir))))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.api.metrics" name="bcbio.variation.api.metrics"><h1 class="project-name">bcbio.variation.api.metrics</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Provide high level API for accessing variant associated metrics.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.api.metrics
  (:import [org.jfree.data.statistics HistogramDataset HistogramType])
  (:use [bcbio.variation.api.shared :only [web-config]]
        [bcbio.variation.variantcontext :only [get-vcf-iterator parse-vcf]])
  (:require [clojure.set :as set]
            [bcbio.variation.api.file :as fileapi]
            [bcbio.variation.index.metrics :as im]
            [bcbio.variation.index.gemini :as gemini]))</pre></td></tr><tr><td class="docs"><h2>Helper functions</h2>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(declare available-metrics)</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- get-histogram-bins
  [items n bin-min bin-max]
  &quot;Retrieve values binned into a histogram using JFree Chart.&quot;
  (let [ds (doto (HistogramDataset.)
             (.setType HistogramType/RELATIVE_FREQUENCY)
             (.addSeries 0 (double-array items) n bin-min bin-max))]
    {:x (map #(.getXValue ds 0 %) (range (.getItemCount ds 0)))
     :y (map #(.getYValue ds 0 %) (range (.getItemCount ds 0)))}))</pre></td></tr><tr><td class="docs"><p>Remove nil values and empty input metrics.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- clean-raw-metrics
  [raw metrics]
  (reduce (fn [coll [k vs]]
            (let [clean-vs (remove nil? vs)]
              (if (empty? clean-vs)
                coll
                (assoc coll k clean-vs))))
          {}
          (zipmap metrics (map (fn [x] (map #(get % x) raw)) metrics))))</pre></td></tr><tr><td class="docs"><p>Retrieve the configured range of a metric</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-metric-range
  [metric]
  (-&gt; (filter #(= (:id %) metric) (available-metrics nil))
      first
      :range))</pre></td></tr><tr><td class="docs"><p>Bin metrics in preparation for histogram display using predefined min-max boundaries.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- prepare-plot-metrics
  [metric raw]
  (let [bins 100
        [bin-min bin-max] (get-metric-range metric)
        data (get-histogram-bins raw bins bin-min bin-max)]
    {:vals (:y data)
     :bin-width (- (second (:x data)) (first (:x data)))
     :x-scale {:type :linear
               :domain [bin-min bin-max]}
     :y-scale {:type :linear}}))</pre></td></tr><tr><td class="docs"><p>Retrieve raw metrics from multiple sources, combining on IDs.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- combined-raw-metrics
  [vcf-file ref-file metrics use-subsample?]
  (letfn [(metrics-by-id [metrics-fn]
            (reduce (fn [coll x]
                      (assoc coll (:id x) x))
                    {}
                    (metrics-fn vcf-file ref-file :metrics (when metrics (map :id metrics))
                                :use-subsample? use-subsample?)))
          (present-metrics-by-id [base metrics-fn]
            (-&gt; (metrics-by-id metrics-fn)
                (select-keys (keys base))))]
    (let [base-metrics (metrics-by-id im/get-raw-metrics)]
      (-&gt;&gt; (merge-with merge
                       base-metrics
                       (present-metrics-by-id base-metrics gemini/get-raw-metrics))
           vals
           (sort-by :id)))))</pre></td></tr><tr><td class="docs"><h2>API functions</h2>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn available-metrics
  [file-id &amp; {:keys [rclient]}]
  (let [vcf-file (when file-id (fileapi/get-prep-and-index {:id file-id} rclient))]
    (concat (im/available-metrics vcf-file)
            (gemini/available-metrics vcf-file))))</pre></td></tr><tr><td class="docs"><p>Provide metrics for a VCF file ready for plotting and visualization.</p>
</td><td class="codes"><pre class="brush: clojure">(defn plot-ready-metrics
  [in-vcf-file &amp; {:keys [metrics rclient]}]
  (let [vcf-file (fileapi/get-prep-and-index {:id in-vcf-file} rclient)
        ref-file (-&gt; @web-config :ref first :genome)
        plot-metrics (or metrics (available-metrics in-vcf-file :rclient rclient))
        raw-metrics (clean-raw-metrics
                     (combined-raw-metrics vcf-file ref-file plot-metrics false)
                     (map :id plot-metrics))]
    {:filename in-vcf-file
     :created-on (java.util.Date.)
     :metrics (map #(merge % (prepare-plot-metrics (:id %) (get raw-metrics (:id %))))
                   (remove #(nil? (get raw-metrics (:id %))) plot-metrics))}))</pre></td></tr><tr><td class="docs"><p>Retrieve available choices for categorical variables from raw data.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- collect-category-choices
  [raw to-collect]
  (reduce (fn [coll [data cur-id]]
            (if-let [v (get data cur-id)]
              (let [vs (if (set? v) v #{v})]
                (assoc coll cur-id (set/union vs (get coll cur-id))))
              coll))
          (into {} (for [y to-collect] [y #{}]))
          (for [x raw, y to-collect]
            [x y])))</pre></td></tr><tr><td class="docs"><p>Finalize metrics information providing high level choices for categorical variables.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- finalize-metrics
  [metrics raw]
  (let [choices (-&gt;&gt; metrics
                     (filter #(= :category (get-in % [:x-scale :type])))
                     (map :id)
                     (collect-category-choices raw))]
    (letfn [(add-choices [m]
              (if-let [c (get choices (:id m))]
                (assoc m :choices c)
                m))
            (finalize-metric [m]
              (-&gt; m
                  add-choices
                  (dissoc :rows)))]
      (map finalize-metric metrics))))</pre></td></tr><tr><td class="docs"><p>Retrieve raw metrics values from input VCF.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-raw-metrics
  [variant-id &amp; {:keys [metrics rclient use-subsample?]}]
  (let [vcf-file (fileapi/get-prep-and-index {:id variant-id} rclient)
        ref-file (-&gt; @web-config :ref first :genome)
        metrics (or metrics (available-metrics variant-id :rclient rclient))
        raw (combined-raw-metrics vcf-file ref-file metrics use-subsample?)]
    {:raw raw
     :metrics (finalize-metrics metrics raw)}))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.api.run" name="bcbio.variation.api.run"><h1 class="project-name">bcbio.variation.api.run</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>High level API to run analyses.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.api.run
  (:use [bcbio.variation.filter :only [category-variant-filter]]
        [bcbio.variation.api.shared :only [web-config]])
  (:require [clojure.string :as string]
            [fs.core :as fs]
            [bcbio.run.itx :as itx]
            [bcbio.variation.api.file :as file-api]
            [bcbio.variation.remote.core :as remote]
            [bcbio.variation.workflow.xprize :as xprize]))</pre></td></tr><tr><td class="docs"><p>Run analysis on provided inputs, dispatching on analysis type</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti do-analysis
  (fn [atype params rclient] (keyword atype)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- to-prep-file [x]
  (itx/add-file-part x &quot;prep&quot;))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- from-prep-file [x]
  (itx/remove-file-part x &quot;prep&quot;))</pre></td></tr><tr><td class="docs"><p>Run filtering, pushing results to remote file store.
   Returns list of output files following pushing the filter.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- run-filter
  [atype params rclient]
  (let [ref-file (-&gt; @web-config :ref first :genome)
        in-file (to-prep-file (remote/get-file (:filename params) rclient))
        filter-file (category-variant-filter in-file (:metrics params) ref-file :remove? true)
        local-out-dir (fs/file (fs/parent in-file) (name atype))
        final-filter-file (str (fs/file local-out-dir (from-prep-file (fs/base-name filter-file))))]
    (when-not (fs/exists? local-out-dir)
      (fs/mkdirs local-out-dir))
    (doseq [ext [&quot;&quot; &quot;.idx&quot;]]
      (fs/rename (str filter-file ext) (str final-filter-file ext)))
    (doseq [ext [&quot;-prep-gemini.db&quot; &quot;-prep-metrics.db&quot; &quot;-prep.vcf&quot;]]
      (let [idx-name (str (fs/file local-out-dir (fs/name final-filter-file)) ext)]
        (when (fs/exists? idx-name)
          (fs/delete idx-name))))
    (remote/put-file rclient final-filter-file
                     {:input-file (:filename params)
                      :expose-fn (:expose-fn params)
                      :tag (name atype)
                      :file-type :vcf})
    ;; Do not need to re-prep this file since it's a subset of a prep
    (fs/touch final-filter-file)
    (fs/copy final-filter-file (to-prep-file final-filter-file))
    (future (file-api/pre-fetch-remotes rclient))
    final-filter-file))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod do-analysis :filter
  ^{:doc &quot;Filter an input file according to specified metrics.
          params:
            - filename: The file to process
            - metrics: A map of filters, with metrics names as keys
              and either ranges ([min max]) or categories as values.&quot;}
  [atype params rclient]
  {:runner (future (to-prep-file
                    (if (empty? (:metrics params))
                      (remote/get-file (:filename params) rclient)
                      (run-filter atype params rclient))))})</pre></td></tr><tr><td class="docs"><p>Prepare X prize input files, potentially pulling from remote directories.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- prep-xprize-files
  [work-info rclient]
  (letfn [(get-remote-files [work-info]
            (reduce (fn [coll kw]
                      (assoc coll kw (when-let [f (get coll kw)]
                                       (remote/get-file f rclient :out-dir (:dir work-info)))))
                    work-info [:variant-file :region-file]))]
    (-&gt; work-info
        (assoc :orig-variant-file (:variant-file work-info))
        get-remote-files)))</pre></td></tr><tr><td class="docs"><p>Upload X Prize results files back to remote directories.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- upload-xprize-files
  [{:keys [work-info comparison]} rclient params]
  (when-not (nil? (:conn rclient))
    (when-let [remote-input (:orig-variant-file work-info)]
      (doseq [x (map #(get-in comparison [:c-files %])
                     [:concordant :discordant :discordant-missing :phasing-error :summary])]
        (let [ftype (cond
                     (.endsWith x &quot;.vcf&quot;) :vcf
                     :else :tabular)]
          (remote/put-file rclient x {:dbkey :hg19
                                      :file-type ftype
                                      :input-file remote-input
                                      :expose-fn (:expose-fn params)
                                      :tag &quot;xprize&quot;})))))
   comparison)</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod do-analysis :xprize
  ^{:doc &quot;Run X Prize comparison and scoring analysis on provided input files.
          params:
            - variant-file: Input variant file, in VCF format, to compare.
            - region-file: Optional BED file of regions to score on.
            - comparison-genome: Name of genome to compare against. Used
              to look up comparison details in configuration file.
            - host-info: Host information for providing callbacks to a local server.&quot;}
  [atype params rclient]
  (let [work-info (xprize/prep-scoring params @web-config)]
    {:runner (future (-&gt; work-info
                         (prep-xprize-files rclient)
                         (xprize/run-scoring-analysis rclient @web-config)
                         (upload-xprize-files rclient params)))
     :work-info work-info}))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.api.shared" name="bcbio.variation.api.shared"><h1 class="project-name">bcbio.variation.api.shared</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Shared functionality useful across multiple API calls.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.api.shared
  (:use [clojure.java.io]
        [bcbio.variation.remote.client :only [gs-default-server]]
        [bcbio.variation.web.db :only [prepare-web-db]])
  (:require [clojure.string :as string]
            [clj-yaml.core :as yaml]))</pre></td></tr><tr><td class="docs"><p>Web configuration, loaded from input YAML file</p>
</td><td class="codes"><pre class="brush: clojure">(def 
  web-config (atom nil))</pre></td></tr><tr><td class="docs"><p>Hold directory of remote files by user and filetype.</p>
</td><td class="codes"><pre class="brush: clojure">(def 
  remote-file-cache (atom {}))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn url-&gt;dir
  [url]
  (string/replace (.getHost (as-url url)) &quot;.&quot; &quot;_&quot;))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn load-web-config
  [config-file]
  (let [config (-&gt; config-file slurp yaml/parse-string)]
    (letfn [(maybe-fix-biodata [x]
              (if (.startsWith x &quot;biodata:&quot;)
                (str (get-in config [:dir :cache])
                     &quot;/&quot; (url-&gt;dir gs-default-server)
                     (get-in config [:remote :biodata])
                     (string/replace-first x &quot;biodata:&quot; ))
                x))
            (fix-gs-ref [ref]
              (reduce (fn [coll k]
                        (let [val (get coll k)]
                          (assoc coll k
                                 (cond
                                  (string? val) (maybe-fix-biodata val)
                                  (seq? val) (map maybe-fix-biodata val)
                                  :else val))))
                      ref (keys ref)))]
      (assoc config :ref (map fix-gs-ref (:ref config))))))</pre></td></tr><tr><td class="docs"><p>Set configuration and database information from input YAML file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn set-config-from-file!
  [config-file]
  (let [config (load-web-config config-file)]
    (reset! web-config (assoc config :db
                              (prepare-web-db (str (file (get-in config [:dir :work])
                                                         &quot;analyses.db&quot;)))))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.callable" name="bcbio.variation.callable"><h1 class="project-name">bcbio.variation.callable</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Identify callable bases from a BAM alignment file.
  Help differentiate positions where we can not assess variation</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.callable
  (:import [org.broad.tribble.bed BEDCodec]
           [org.broad.tribble.index IndexFactory]
           [org.broad.tribble AbstractFeatureReader])
  (:use [clojure.java.io]
        [bcbio.align.ref :only [sort-bed-file]]
        [bcbio.variation.variantcontext :only [get-vcf-source]])
  (:require [clojure.string :as string]
            [fs.core :as fs]
            [bcbio.run.itx :as itx]
            [bcbio.run.broad :as broad]))</pre></td></tr><tr><td class="docs"><p>Identify callable bases from the provided alignment file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn identify-callable
  [align-bam ref &amp; {:keys [out-dir intervals]}]
  (let [base-dir (if (or (nil? out-dir)
                         (fs/writeable? (fs/parent align-bam)))
                   (fs/parent align-bam)
                   out-dir)
        base-fname (str (file base-dir (-&gt; align-bam fs/base-name itx/file-root)))
        file-info {:out-bed (format &quot;%s-callable.bed&quot; base-fname)
                   :out-summary (format &quot;%s-callable-summary.txt&quot; base-fname)}
        args (concat [&quot;-R&quot; ref
                      &quot;-I&quot; align-bam
                      &quot;--out&quot; :out-bed
                      &quot;--summary&quot; :out-summary]
                     (broad/gatk-cl-intersect-intervals intervals ref))]
    (if-not (fs/exists? base-dir)
      (fs/mkdirs base-dir))
    (broad/index-bam align-bam)
    (broad/run-gatk &quot;CallableLoci&quot; args file-info {:out [:out-bed :out-summary]})
    (:out-bed file-info)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn features-in-region [source space start end]
  (with-open [bed-iter (.query source space start end)]
    (vec (for [f bed-iter]
           {:chr (.getChr f)
            :start (.getStart f)
            :end (.getEnd f)
            :name (.getName f)
            :score (.getScore f)
            :strand (.getStrand f)}))))</pre></td></tr><tr><td class="docs"><p>Provide tribble feature source for a BED formatted file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-bed-source
  [bed-file ref-file]
  (let [batch-size 500
        work-bed (sort-bed-file bed-file ref-file)
        idx (IndexFactory/createIntervalIndex (file work-bed) (BEDCodec.) batch-size)]
    (AbstractFeatureReader/getFeatureReader work-bed (BEDCodec.) idx)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn get-bed-iterator
  [bed-file ref-file]
  (.iterator (get-bed-source bed-file ref-file)))</pre></td></tr><tr><td class="docs"><p>Create BED file of callable regions from the BAM alignment file.
  Pass the callable BED to GATK for subsetting based on callable intervals.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-callable-bed
  [align-bam ref &amp; {:keys [out-dir intervals]}]
  (let [orig-bed-file (identify-callable align-bam ref :out-dir out-dir
                                         :intervals intervals)
        out-file (itx/add-file-part orig-bed-file &quot;intervals&quot;)]
    (with-open [bed-iter (get-bed-iterator orig-bed-file ref)
                wtr (writer out-file)]
      (doseq [f bed-iter]
        (when (= (.getName f) &quot;CALLABLE&quot;)
          (.write wtr (format &quot;%s\t%s\t%s\n&quot; (.getChr f)
                              (dec (.getStart f)) (.getEnd f))))))
    out-file))</pre></td></tr><tr><td class="docs"><p>Limit input BED intervals to only chromosomes found in a VCF file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn limit-bed-intervals
  [intervals call exp config]
  (let [out-file (itx/add-file-part intervals (:name call) (get-in config [:dir :prep]))]
    (when (or (itx/needs-run? out-file)
              (&gt; (fs/mod-time intervals) (fs/mod-time out-file)))
      (with-open [rdr (reader intervals)
                  wtr (writer out-file)
                  call-vcf-s (get-vcf-source (:file call) (:ref exp))]
        (let [seq-names (set (.getSequenceNames call-vcf-s))]
          (doseq [x (filter #(contains? seq-names (first (string/split % #&quot;\t&quot;)))
                            (line-seq rdr))]
            (.write wtr (str x &quot;\n&quot;))))))
    out-file))</pre></td></tr><tr><td class="docs"><h2>Multiple callables</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Provide callable checker for potentially multiple inputs</p>
</td><td class="codes"><pre class="brush: clojure">(defprotocol CallableChecker
  (has-callers? [this])
  (is-callable? [this space start end]))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defrecord BamCallable [sources check-fn]
  CallableChecker
  (has-callers? [_]
    (not (empty? sources)))
  (is-callable? [_ space start end]
    (letfn [(source-is-callable? [source space start end]
              (if (&lt;= start end)
                (&gt; (count (features-in-region source space start end)) 0)
                false))]
      (if (empty? sources)
        true
        (check-fn #(source-is-callable? % space start end) sources))))
  java.io.Closeable
  (close [_]
    (doseq [x sources]
      (.close x))))</pre></td></tr><tr><td class="docs"><p>Retrieve generalized callabilitu checkers that handles multiple file inputs.
  Checks if a chromosome start end region is callable based on reads in input BAM files.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-callable-checker
  [bam-files ref &amp; {:keys [out-dir intervals check-fn]
                 :or {check-fn some}}]
  (let [work-bam-files (remove nil? (if (coll? bam-files) bam-files [bam-files]))
        sources (map #(-&gt; (get-callable-bed % ref :out-dir out-dir :intervals intervals)
                          (get-bed-source ref))
                     work-bam-files)]
    (BamCallable. sources check-fn)))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.combine" name="bcbio.variation.combine"><h1 class="project-name">bcbio.variation.combine</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Combine variant files, handling no-calls versus reference calls</p>

<ol>
<li>Combine the variants to create a merged set of positions to call at</li>
<li>For each variant file:
  a. Generate callability at each position
  b. Combine original calls with merged positions
  c. Walk through each no-call and set as reference if callable</li>
</ol>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.combine
  (:import [org.broadinstitute.sting.utils.variantcontext 
            VariantContextBuilder])
  (:use [clojure.tools.cli :only [cli]]
        [bcbio.variation.complex :only [normalize-variants]]
        [bcbio.variation.filter.intervals :only [vcf-sample-name select-by-sample]]
        [bcbio.variation.haploid :only [diploid-calls-to-haploid]]
        [bcbio.variation.multisample :only [get-out-basename multiple-samples?]]
        [bcbio.variation.normalize :only [prep-vcf clean-problem-vcf]]
        [bcbio.variation.phasing :only [is-haploid?]]
        [bcbio.variation.structural :only [write-non-svs]]
        [bcbio.variation.variantcontext :only [get-vcf-header write-vcf-w-template
                                               get-vcf-iterator parse-vcf
                                               get-vcf-retriever variants-in-region]])
  (:require [fs.core :as fs]
            [clojure.string :as string]
            [bcbio.run.itx :as itx]
            [bcbio.run.broad :as broad]))</pre></td></tr><tr><td class="docs"><p>Combine multiple variant files with GATK CombineVariants.
   Only correctly handles all-by-all comparisons with the same ploidy level.</p>
</td><td class="codes"><pre class="brush: clojure">(defn combine-variants
  [vcfs ref &amp; {:keys [merge-type out-dir intervals unsafe name-map base-ext check-ploidy? quiet-out?]
               :or {merge-type :unique
                    unsafe false
                    name-map {}
                    check-ploidy? true}}]
  (when (and check-ploidy?
             (&gt; (count (set (remove nil? (map #(is-haploid? % ref) vcfs)))) 1))
    (throw (Exception. (format &quot;Haploid and non-haploid combinations not supported: %s %s&quot;
                               (vec vcfs) (vec (map #(is-haploid? % ref) vcfs))))))
  (letfn [(unique-name [i f]
            (if quiet-out?
              (str &quot;v&quot; i)
              (string/replace (get name-map f
                                   (-&gt; f fs/base-name itx/file-root))
                              &quot;-&quot; &quot;_&quot;)))]
    (let [base-dir (if (nil? out-dir) (fs/parent (first vcfs)) out-dir)
          full-base-name (-&gt; vcfs first fs/base-name itx/remove-zip-ext)
          base-name (if (nil? base-ext) full-base-name
                        (format &quot;%s-%s.vcf&quot; (first (string/split full-base-name #&quot;-&quot;))
                                base-ext))
          file-info {:out-vcf (str (fs/file base-dir
                                            (itx/add-file-part base-name
                                                               (case merge-type
                                                                 :minimal &quot;mincombine&quot;
                                                                 :full &quot;fullcombine&quot;
                                                                 &quot;combine&quot;))))}
          args (concat [&quot;-R&quot; ref
                        &quot;-o&quot; :out-vcf
                        &quot;--rod_priority_list&quot; (string/join &quot;,&quot; (map-indexed unique-name vcfs))]
                       ;(if unsafe [&quot;--unsafe&quot; &quot;ALLOW_SEQ_DICT_INCOMPATIBILITY&quot;] [])
                       (if unsafe [&quot;--unsafe&quot; &quot;ALL&quot;] [])
                       (if quiet-out? [&quot;--suppressCommandLineHeader&quot; &quot;--setKey&quot; &quot;null&quot;] [])
                       (flatten (map-indexed #(list (str &quot;--variant:&quot; (unique-name %1 %2)) %2) vcfs))
                       (broad/gatk-cl-intersect-intervals intervals ref)
                       (case merge-type
                         :full [&quot;--genotypemergeoption&quot; &quot;PRIORITIZE&quot;]
                         :unique [&quot;--genotypemergeoption&quot; &quot;UNIQUIFY&quot;]
                         :minimal [&quot;--sites_only&quot; &quot;--minimalVCF&quot;]))]
      (if-not (fs/exists? base-dir)
        (fs/mkdirs base-dir))
      (broad/run-gatk &quot;CombineVariants&quot; args file-info {:out [:out-vcf]})
      (:out-vcf file-info))))</pre></td></tr><tr><td class="docs"><h2>Clean multi-alleles</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Clean up variant contexts with multi-allele, consolidating calls and removing unused alleles.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- clean-multialleles
  [retriever vcs]
  (letfn [(others-at-pos [vcs retriever]
            (filter #(apply = (map (juxt :chr :start) [% (first vcs)]))
                    (apply variants-in-region
                           (cons retriever ((juxt :chr :start :end) (first vcs))))))
          (get-ref-alt-alleles [vc]
            (let [ref (.getDisplayString (:ref-allele vc))]
              (map (fn [x] [ref (.getDisplayString x)]) (:alt-alleles vc))))
          (sort-by-allele-count [xs]
            (let [count-groups (group-by val xs)
                  topcount-alleles (keys (get count-groups (apply max (keys count-groups))))]
              (first (sort-by #(count (first %)) topcount-alleles))))]
    (let [alleles (reduce (fn [coll x]
                            (assoc coll x (inc (get coll x 0))))
                          {} (mapcat get-ref-alt-alleles (others-at-pos vcs retriever)))
          final-alleles (if (empty? alleles)
                          (-&gt; vcs first get-ref-alt-alleles first)
                          (sort-by-allele-count alleles))]
      (-&gt; (VariantContextBuilder. (:vc (first vcs)))
          (.alleles final-alleles)
          (.stop (+ (:start (first vcs)) (if (= 0 (count (second final-alleles)))
                                           (count (first final-alleles))
                                           (max 0 (dec (count (first final-alleles)))))))
          .make))))</pre></td></tr><tr><td class="docs"><p>Fix multiple alleles in a VCF produced by combining multiple inputs.
   This combines calls present at multiple positions and removes multi-alleles
   not present in input calls.</p>
</td><td class="codes"><pre class="brush: clojure">(defn fix-minimal-combined
  [combined-vcf vcfs ref]
  (let [out-file (itx/add-file-part combined-vcf &quot;fix&quot;)]
    (when (itx/needs-run? out-file)
      (with-open [vcf-iter (get-vcf-iterator combined-vcf ref)]
        (write-vcf-w-template combined-vcf {:out out-file}
                              (map (partial clean-multialleles (apply get-vcf-retriever (cons ref vcfs)))
                                   (partition-by (juxt :chr :start)
                                                 (parse-vcf vcf-iter)))
                              ref)))
    out-file))</pre></td></tr><tr><td class="docs"><p>Check if interval BED files overlap with current analysis genome build.
  This is useful when an input VCF is from an alternate genome and needs
  conversion. In this case we shouldn't yet be using interval selection.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- genome-safe-intervals
  [intervals ref-file exp]
  (if (or (nil? ref-file) (= ref-file (:ref exp)))
    intervals
    []))</pre></td></tr><tr><td class="docs"><p>Prepare input file for comparisons based on configuration:
    - Selecting a single sample from multi-sample files
    - Resorting and fixing chromosome naming
    - Removing reference call genotypes
   This organizes the logic which get convoluted for different cases.
   The approach is to select a single sample and remove refcalls if we have
   a multiple sample file, so the sample name will be correct.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- dirty-prep-work
  [in-file call exp intervals out-dir out-fname]
  (letfn [(run-sample-select [in-file ref-file ext]
            (select-by-sample (:sample exp) in-file (str (:name call) ext)
                              ref-file :out-dir out-dir
                              :intervals (genome-safe-intervals intervals ref-file exp)
                              :remove-refcalls (get call :remove-refcalls false)))]
    (let [sample-file (if (and (multiple-samples? in-file) (:sample exp))
                        (run-sample-select in-file (get call :ref (:ref exp)) &quot;&quot;)
                        in-file)
          prep-file (if (and (true? (:prep call))
                             (not= (:ref exp) (:ref call)))
                      (prep-vcf sample-file (:ref exp) (:sample exp) :out-dir out-dir
                                :out-fname out-fname :orig-ref-file (:ref call)
                                :config call)
                      sample-file)
          hap-file (if (true? (:make-haploid call))
                     (diploid-calls-to-haploid prep-file (:ref exp) :out-dir out-dir)
                     prep-file)
          noref-file (if (or (and (not (multiple-samples? in-file)) (:remove-refcalls call))
                             (and (not (nil? (:ref call))) (not (empty? intervals))))
                       (run-sample-select hap-file (:ref exp) &quot;-noref&quot;)
                       hap-file)]
      noref-file)))</pre></td></tr><tr><td class="docs"><p>Prepare call information for VCF comparisons by normalizing through GATK.
  Handles:</p>

<ol>
<li>Combining multiple input files</li>
<li>Fixing reference and sample information.</li>
<li>Splitting combined MNPs into phased SNPs</li>
</ol>
</td><td class="codes"><pre class="brush: clojure">(defn gatk-normalize
  [call exp intervals out-dir transition]
  (if-not (fs/exists? out-dir)
    (fs/mkdirs out-dir))
  (letfn [(merge-call-files [call in-files]
            (let [ref (get call :ref (:ref exp))]
              (combine-variants in-files ref
                                :merge-type :full :out-dir out-dir
                                :intervals (genome-safe-intervals intervals ref exp)
                                :check-ploidy? false
                                :unsafe true)))]
    (let [in-files (if (coll? (:file call)) (:file call) [(:file call)])
          out-fname (str (get-out-basename exp call in-files) &quot;.vcf&quot;)
          _ (transition :clean (str &quot;Cleaning input VCF: &quot; (:name call)))
          clean-files (vec (map #(if-not (:preclean call) %
                                         (clean-problem-vcf % (:ref exp) (:sample exp) :out-dir out-dir))
                                in-files))
          _ (transition :merge (str &quot;Merging multiple input files: &quot; (:name call)))
          merge-file (if (&gt; (count clean-files) 1)
                       (merge-call-files call clean-files)
                       (first clean-files))
          _ (transition :prep (str &quot;Prepare VCF, resorting to genome build: &quot; (:name call)))
          prep-file (dirty-prep-work merge-file call exp intervals out-dir out-fname)]
      (transition :normalize (str &quot;Normalize MNP and indel variants: &quot; (:name call)))
      (assoc call :file (if (true? (get call :normalize true))
                          (normalize-variants prep-file (:ref exp) out-dir
                                              :out-fname out-fname)
                          prep-file)))))</pre></td></tr><tr><td class="docs"><h2>Top-level entry points</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Provide convenient entry to fully normalize a variant file for comparisons.</p>
</td><td class="codes"><pre class="brush: clojure">(defn full-prep-vcf
  [vcf-file ref-file &amp; {:keys [max-indel resort keep-ref]}]
  (let [out-file (itx/add-file-part vcf-file &quot;fullprep&quot;)]
    (when (itx/needs-run? out-file)
      (itx/with-temp-dir [out-dir (fs/parent vcf-file)]
        (let [exp {:sample (-&gt; vcf-file get-vcf-header .getGenotypeSamples first)
                   :ref ref-file :params {:max-indel max-indel}}
              call {:name &quot;fullprep&quot; :file vcf-file :preclean true
                    :prep true :normalize true :prep-sv-genotype false
                    :fix-sample-header true
                    :prep-sort-pos resort
                    :remove-refcalls (not keep-ref)}
              out-info (gatk-normalize call exp [] out-dir
                                       (fn [_ x] (println x)))
              nosv-file (if max-indel
                          (write-non-svs (:file out-info) (:ref exp) (:params exp))
                          (:file out-info))]
          (fs/rename nosv-file out-file))))
    out-file))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -main [&amp; args]
  (let [[options [vcf-file ref-file] banner]
        (cli args
             [&quot;-i&quot; &quot;--max-indel&quot; &quot;Maximum indel size to include&quot; :default nil
              :parse-fn #(Integer. %)]
             [&quot;-s&quot; &quot;--resort&quot; &quot;Resort input file by coordinate position&quot; :default false :flag true]
             [&quot;-r&quot; &quot;--keep-ref&quot; &quot;Keep reference (0/0) calls&quot; :default false :flag true])]
    (when (or (:help options) (nil? vcf-file) (nil? ref-file))
      (println &quot;Required arguments:&quot;)
      (println &quot;    &lt;vcf-file&gt; VCF input file to prepare.&quot;)
      (println &quot;    &lt;ref-file&gt; Genome reference file (GRCh37/b37 coordinates)&quot;)
      (println)
      (println banner)
      (System/exit 0))
    (let [out-file (full-prep-vcf vcf-file ref-file :max-indel (:max-indel options)
                                  :resort (:resort options) :keep-ref (:keep-ref options))]
      (println out-file)
      (System/exit 0))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.compare" name="bcbio.variation.compare"><h1 class="project-name">bcbio.variation.compare</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Generate comparisons between two sets of variant calls.
   Utilizes GATK walkers to generate detailed and summary statistics
   about two sets of calls:</p>

<ul>
<li>Identify non-callable regions with CallableLociWalker</li>
<li>Combine variants from two samples</li>
<li>Use VariantEval to calculate overall concordance statistics</li>
<li>Provide output for concordant and discordant regions for
 detailed investigation</li>
</ul>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.compare
  (:use [clojure.java.io]
        [clojure.math.combinatorics :only [combinations]]
        [ordered.map :only [ordered-map]]
        [bcbio.align.reorder :only [reorder-bam]]
        [bcbio.variation.annotation :only [add-variant-annotations]]
        [bcbio.variation.callable :only [get-callable-bed]]
        [bcbio.variation.combine :only [combine-variants gatk-normalize]]
        [bcbio.variation.config :only [load-config do-transition]]
        [bcbio.variation.evaluate :only [calc-variant-eval-metrics]]
        [bcbio.variation.filter :only [variant-filter variant-format-filter
                                       pipeline-recalibration]]
        [bcbio.variation.filter.intervals :only [combine-multiple-intervals]]
        [bcbio.variation.multiple :only [prep-cmp-name-lookup pipeline-compare-multiple]]
        [bcbio.variation.multisample :only [compare-two-vcf-flexible
                                            multiple-samples?]]
        [bcbio.variation.recall :only [create-merged]]
        [bcbio.variation.structural :only [compare-sv-pipeline]]
        [bcbio.variation.validate :only [pipeline-validate]]
        [bcbio.variation.variantcontext :only [parse-vcf write-vcf-w-template
                                               get-vcf-iterator]])
  (:require [clojure.string :as string]
            [clj-yaml.core :as yaml]
            [fs.core :as fs]
            [lonocloud.synthread :as -&gt;]
            [bcbio.run.itx :as itx]
            [bcbio.run.broad :as broad]
            [bcbio.variation.grade :as grade]
            [bcbio.variation.phasing :as phasing]
            [bcbio.variation.report :as report]))</pre></td></tr><tr><td class="docs"><h2>Variance assessment</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Variant comparison producing 3 files: concordant and both directions discordant</p>
</td><td class="codes"><pre class="brush: clojure">(defn select-by-concordance
  [sample call1 call2 ref &amp; {:keys [out-dir intervals]}]
  (let [base-dir (if (nil? out-dir) (fs/parent (:file call1)) out-dir)
        ready-intervals (remove nil? (flatten [intervals (:intervals call1)
                                               (:intervals call2)]))]
    (if-not (fs/exists? base-dir)
      (fs/mkdirs base-dir))
    (doall
     (for [[c1 c2 cmp-type] [[call1 call2 &quot;concordance&quot;]
                             [call1 call2 &quot;discordance&quot;]
                             [call2 call1 &quot;discordance&quot;]]]
       (let [file-info {:out-vcf (str (fs/file base-dir
                                               (format &quot;%s-%s-%s-%s.vcf&quot;
                                                       sample (:name c1) (:name c2) cmp-type)))}
             args (concat
                   [&quot;-R&quot; ref
                    &quot;--sample_name&quot; sample
                    &quot;--variant&quot; (:file c1)
                    (str &quot;--&quot; cmp-type) (:file c2)
                    &quot;--out&quot; :out-vcf]
                   (broad/gatk-cl-intersect-intervals ready-intervals ref))]
         (broad/run-gatk &quot;SelectVariants&quot; args file-info {:out [:out-vcf]})
         (:out-vcf file-info))))))</pre></td></tr><tr><td class="docs"><h2>Custom parsing and combinations</h2>

<p>Utilizes GATK VariantContexts</p>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Lazy stream of VariantContexts categorized by concordant/discordant matching.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- vc-by-match-category
  [vcf-iter]
  (letfn [(genotype-alleles [g]
            (vec (map #(.toString %) (:alleles g))))
          (is-concordant? [vc]
            (= (-&gt; (map genotype-alleles (:genotypes vc))
                   set
                   count)
               1))]
    (for [vc (parse-vcf vcf-iter)]
      [(if (is-concordant? vc) :concordant :discordant)
       (:vc vc)])))</pre></td></tr><tr><td class="docs"><p>Provide concordant and discordant variants for two variant files.</p>
</td><td class="codes"><pre class="brush: clojure">(defn split-variants-by-match
  [vcf1 vcf2 ref]
  (let [combo-file (combine-variants [vcf1 vcf2] ref)
        out-map {:concordant (itx/add-file-part combo-file &quot;concordant&quot;)
                 :discordant (itx/add-file-part combo-file &quot;discordant&quot;)}]
    (if-not (fs/exists? (:concordant out-map))
      (with-open [combo-vcf-iter (get-vcf-iterator combo-file ref)]
        (write-vcf-w-template combo-file out-map (vc-by-match-category combo-vcf-iter)
                              ref)))
    out-map))</pre></td></tr><tr><td class="docs"><h2>Pipeline</h2>

<p>Process a directory of variant calls from multiple
sources, generating a summary of concordance plus detailed metrics
differences for tweaking filters.</p>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Retrieve BAM files associated with alignments, normalizing if needed.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- prepare-input-bams
  [exp out-dir]
  (let [call-bams (map (fn [c] [(get c :align (:align exp)) c]) (:calls exp))]
    (map (fn [[b c]] (when-not (nil? b)
                     (reorder-bam b (:ref exp) c exp :out-dir out-dir)))
         call-bams)))</pre></td></tr><tr><td class="docs"><p>Prepare merged and annotated VCF files for an experiment.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- prepare-vcf-calls
  [exp config]
  (let [out-dir (get-in config [:dir :prep] (get-in config [:dir :out]))
        transition (partial do-transition config)
        align-bams (prepare-input-bams exp out-dir)
        all-intervals (remove nil? (map :intervals (cons exp (:calls exp))))
        start-vcfs (vec (map #(gatk-normalize % exp all-intervals out-dir transition)
                             (:calls exp)))
        _ (transition :combine &quot;Creating merged VCF files for all comparisons&quot;)
        merged-vcfs (create-merged (map :file start-vcfs) align-bams exp
                                   :out-dir out-dir
                                   :intervals all-intervals)
        _ (transition :annotate &quot;Annotate VCFs with metrics&quot;)
        ann-vcfs (map (fn [[v b c]]
                        (add-variant-annotations v b (:ref exp) c :out-dir out-dir
                                                 :intervals all-intervals))
                      (map vector merged-vcfs align-bams (:calls exp)))
        _ (transition :filter &quot;Post annotation filtering&quot;)
        filter-vcfs (map (fn [[v c]]
                           (cond
                            (:filters c) (variant-filter v (:filters c) (:ref exp))
                            (:format-filters c) (variant-format-filter v (:format-filters c)
                                                                       (:ref exp))
                            :else v))
                         (map vector ann-vcfs (:calls exp)))]
    (map (fn [[c v b]] (-&gt; c
                           (assoc :file v)
                           (assoc :align b)))
         (map vector (:calls exp) filter-vcfs align-bams))))</pre></td></tr><tr><td class="docs"><p>Compare two standard VCF files based on the supplied configuration.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- compare-two-vcf-standard
  [c1 c2 exp config]
  (letfn [(callable-intervals [exp c1 c2]
            (let [out-dir (get-in config [:dir :prep] (get-in config [:dir :out]))
                  align-bams (remove nil? (map :align [c1 c2]))]
              (when (and (:intervals exp) (seq align-bams))
                (combine-multiple-intervals (:intervals exp) align-bams (:ref exp)
                                            :out-dir out-dir :name (:sample exp)))))
          (discordant-name [x]
            (format &quot;%s-discordant&quot; (:name x)))
          (zipmap-ordered [xs1 xs2]
            (apply ordered-map (interleave xs1 xs2)))]
    (let [c-files (select-by-concordance (:sample exp) c1 c2 (:ref exp)
                                         :out-dir (get-in config [:dir :out])
                                         :intervals (:intervals exp))
          eval (calc-variant-eval-metrics (:sample exp) (:file c1) (:file c2) (:ref exp)
                                          :out-base (first c-files)
                                          :intervals (:intervals exp))
          c-eval (calc-variant-eval-metrics (:sample exp) (:file c1) (:file c2) (:ref exp)
                                            :out-base (itx/add-file-part (first c-files) &quot;callable&quot;)
                                            :intervals (callable-intervals exp c1 c2))]
      {:c-files (zipmap-ordered (map keyword
                                     [&quot;concordant&quot; (discordant-name c1) (discordant-name c2)])
                                c-files)
       :c1 c1 :c2 c2 :exp exp :dir (config :dir)
       :metrics (report/concordance-report-metrics (:sample exp) eval)
       :callable-metrics (report/concordance-report-metrics (:sample exp) c-eval)})))</pre></td></tr><tr><td class="docs"><p>Compare two VCF files, handling standard and haploid specific comparisons.</p>
</td><td class="codes"><pre class="brush: clojure">(defn compare-two-vcf
  [c1 c2 exp config]
  (do-transition config :compare (format &quot;Comparing VCFs: %s vs %s&quot; (:name c1) (:name c2)))
  (let [[c1 c2 sv-cmp] (if-not (:mod c1)
                         (compare-sv-pipeline c1 c2 exp config)
                         [c1 c2 {}])
        phased-vcfs (group-by #(-&gt; % :file (phasing/is-haploid? (:ref exp))) [c1 c2])
        out-cmp (cond
                 (get phased-vcfs true) (phasing/compare-two-vcf-phased phased-vcfs exp config)
                 (multiple-samples? (:file c1)) (compare-two-vcf-flexible c1 c2 exp config)
                 :else (compare-two-vcf-standard c1 c2 exp config))
        grade-cmp (if (grade/is-grade-cmp? exp)
                    (grade/annotate-discordant out-cmp)
                    out-cmp)]
    (assoc grade-cmp :c-files (reduce (fn [coll [k v]] (assoc coll k v))
                                      (:c-files grade-cmp) sv-cmp))))</pre></td></tr><tr><td class="docs"><h2>Customizable finalizer comparisons</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Run a post-pairwise comparison function, returning updated comparison details,</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti run-finalizer
  (fn [cmps finalizer exp config] (-&gt; finalizer :method keyword)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod run-finalizer :recal-filter
  [&amp; args]
  (apply pipeline-recalibration args))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod run-finalizer :multiple
  [&amp; args]
  (apply pipeline-compare-multiple args))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod run-finalizer :validate
  [&amp; args]
  (apply pipeline-validate args))</pre></td></tr><tr><td class="docs"><p>Finalize all comparisons with finished initial pass data.</p>
</td><td class="codes"><pre class="brush: clojure">(defn finalize-comparisons
  [cmps exp config]
  (letfn [(add-summary [x]
            (-&gt; x
                (assoc :exp exp)
                (-&gt;/as cur-cmp
                  (assoc :summary (report/top-level-metrics cur-cmp)))
                (-&gt;/when (grade/is-grade-cmp? exp)
                  (-&gt;/as cmp-w-summary
                    (assoc :grade-breakdown (grade/prep-grade-breakdown cmp-w-summary))))))
          (update-w-finalizer [cur-cmps finalizer]
            &quot;Update the current comparisons with a defined finalizer.&quot;
            (do-transition config :finalize
                           (format &quot;Finalize %s: %s&quot; (:method finalizer)
                                   (let [t (:target finalizer)]
                                     (if (coll? t) (string/join &quot;, &quot; t) t))))
            (let [updated-cmp (run-finalizer cur-cmps finalizer exp config)]
              (assoc cur-cmps (map #(get-in updated-cmp [% :name]) [:c1 :c2])
                     (if-not (:re-compare updated-cmp) updated-cmp
                             (compare-two-vcf (:c1 updated-cmp) (:c2 updated-cmp) exp config)))))]
    (-&gt;&gt; (reduce update-w-finalizer
                 (prep-cmp-name-lookup cmps) (:finalize exp))
         vals
         (map add-summary))))</pre></td></tr><tr><td class="docs"><h2>Top-level</h2>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- get-summary-writer [config config-file ext]
  (if-not (nil? (get-in config [:dir :out]))
    (do
      (if-not (fs/exists? (get-in config [:dir :out]))
        (fs/mkdirs (get-in config :dir :out)))
      (writer (str (fs/file (get-in config [:dir :out])
                            (format &quot;%s-%s&quot;
                                    (itx/file-root (fs/base-name config-file)) ext)))))
    (writer System/out)))</pre></td></tr><tr><td class="docs"><p>Perform comparison between variant calls using inputs from YAML config.</p>
</td><td class="codes"><pre class="brush: clojure">(defn variant-comparison-from-config
  [config-file]
  (let [config (load-config config-file)
        comparisons (flatten
                     (for [exp (:experiments config)]
                       (let [cmps (for [[c1 c2] (combinations (prepare-vcf-calls exp config) 2)]
                                    (compare-two-vcf c1 c2 exp config))]
                         (finalize-comparisons cmps exp config))))
        grading-file (str (fs/file (get-in config [:dir :out])
                                   (format &quot;%s-grading.yaml&quot; (itx/file-root (fs/base-name config-file)))))]
    (do-transition config :summary &quot;Summarize comparisons&quot;)
    (with-open [w (get-summary-writer config config-file &quot;summary.txt&quot;)]
      (report/write-summary-txt w comparisons))
    (with-open [w (get-summary-writer config config-file &quot;files.csv&quot;)]
      (report/write-files-csv w comparisons config))
    (with-open [w (get-summary-writer config config-file &quot;summary.csv&quot;)]
      (report/write-summary-csv w comparisons))
    (when-let [bdowns (seq (remove nil? (map :grade-breakdown comparisons)))]
      (spit grading-file (yaml/generate-string bdowns)))
    (do-transition config :finished &quot;Finished&quot;)
    comparisons))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -main [config-file]
  (try
    (variant-comparison-from-config config-file)
    (catch Throwable t
      (.printStackTrace t)
      (shutdown-agents)
      (System/exit -1))
    (finally
      (shutdown-agents)
      (System/exit 0))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.complex" name="bcbio.variation.complex"><h1 class="project-name">bcbio.variation.complex</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Handle complex variations representations: multi-nucleotide
   polymorphisms and indels.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.complex
  (:import [org.broadinstitute.sting.utils.variantcontext Allele
            VariantContextBuilder GenotypesContext GenotypeBuilder
            VariantContextUtils]
           [org.biojava3.core.sequence DNASequence]
           [org.biojava3.alignment Alignments SimpleGapPenalty
            Alignments$PairwiseSequenceScorerType])
  (:use [clojure.java.io]
        [clojure.set :only [union]]
        [ordered.set :only [ordered-set]]
        [bcbio.align.ref :only [extract-sequence]]
        [bcbio.variation.variantcontext :only [parse-vcf write-vcf-w-template
                                               get-vcf-iterator]])
  (:require [clojure.string :as string]
            [bcbio.run.broad :as broad]
            [bcbio.run.itx :as itx]
            [fs.core :as fs]))</pre></td></tr><tr><td class="docs"><h2>Multi-nucleotide polymorphisms (MNPs)</h2>

<p>Split into single variant primitives.</p>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Do a set of alleles have any variants at a position.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- has-variant-base?
  [alleles i]
  (&gt; (count (set (map #(nth % i nil) alleles)))
     1))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- get-vc-alleles [vc]
  (vec (map #(.getDisplayString %) (cons (:ref-allele vc) (:alt-alleles vc)))))</pre></td></tr><tr><td class="docs"><p>Identify complex indels that can be split into multiple calls.</p>
</td><td class="codes"><pre class="brush: clojure">(defn is-multi-indel?
  [vc]
  (letfn [(monomorphic-alleles? [vc]
            (= 1 (-&gt;&gt; (get-vc-alleles vc)
                      (map set)
                      (apply union)
                      count)))
          (has-multiple-nonref-alleles? [vc]
            (and (&gt; (.length (:ref-allele vc)) 1)
                 (&gt; (apply min (map #(.length %) (:alt-alleles vc))) 1)
                 (not (monomorphic-alleles? vc))))
          (has-ref-padding-mismatch? [vc]
            (let [alleles (get-vc-alleles vc)]
              (not= (nth (first alleles) 0) (nth (second alleles) 0))))]
    (and (= &quot;INDEL&quot; (:type vc))
         (or (has-multiple-nonref-alleles? vc)
             (has-ref-padding-mismatch? vc)))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- contains-indel? [alleles i]
  (when (&lt; i (count (first alleles)))
    (contains? (set (map #(str (nth % i)) alleles)) &quot;-&quot;)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- starts-an-indel? [alleles i]
  (contains-indel? alleles (inc i)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- gap-end? [alleles i]
  (and (pos? i)
       (not (contains-indel? alleles i))
       (contains-indel? alleles (dec i))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- is-match? [alleles i]
  (= 1 (count (set (map #(str (nth % i)) alleles)))))</pre></td></tr><tr><td class="docs"><p>Detect single call SNP variants within a MNP genotype.
  Handles reference no-variant padding bases on the 5' end of
  the sequence, writing only variants at the adjusted positions.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- split-alleles
  [vc alleles &amp; {:keys [prev-pad]}]
  (letfn [(is-internal-indel? [alleles i]
            (and (pos? i)
                 (contains-indel? alleles i)
                 (is-match? alleles (dec i))))
          (is-anchor-mismatch? [alleles i]
            (and (= 1 i)
                 (not (is-match? alleles i))
                 (is-match? alleles 0)))
          (is-fiveprime-indel? [alleles i]
            (and (zero? i)
                 (or
                  (starts-an-indel? alleles i)
                  (contains-indel? alleles i))))
          (needs-padding? [alleles i]
            (or (pos? i)
                (and (is-fiveprime-indel? alleles i)
                     (is-match? alleles i))
                (and (not (is-fiveprime-indel? alleles i))
                     (not (is-match? alleles i)))))
          (has-nopad-five-indel? [alleles i]
            (and (is-fiveprime-indel? alleles i)
                 (contains-indel? alleles i)))
          (extend-indels [alleles i]
            {:start (if (or (is-internal-indel? alleles i)
                            (is-fiveprime-indel? alleles i))
                      (max (dec i) 0)
                      i)
             :end (inc (or (last (take-while #(or (contains-indel? alleles %)
                                                  (starts-an-indel? alleles %))
                                             (range i (count (first alleles)))))
                           i))})
          (ref-and-alt-alleles [cur-alleles]
            (let [refa (first cur-alleles)
                  alts (map (fn [x]
                              (if (= (.getDisplayString x) (.getDisplayString refa))
                                refa x))
                            (rest cur-alleles))]
              {:ref refa :alts alts}))
          (extract-variants [alleles pos]
            (let [{:keys [start end]} (extend-indels alleles pos)
                  str-alleles (map #(-&gt; (str (if (has-nopad-five-indel? alleles start) prev-pad &quot;&quot;)
                                             (subs % start end))
                                        (string/replace &quot;-&quot; &quot;&quot;))
                                   alleles)
                  cur-alleles (map-indexed (fn [i x] (Allele/create x (= 0 i)))
                                           str-alleles)
                  size (let [base (.length (first cur-alleles))]
                         (if (some empty? str-alleles) base (dec base)))
                  w-gap-start (-&gt; (first alleles) (subs 0 start) (string/replace &quot;-&quot; &quot;&quot;) count)
                  ready-alleles (ref-and-alt-alleles cur-alleles)]
              {:offset (+ w-gap-start (if (has-nopad-five-indel? alleles start) -1 0))
               :end (+ w-gap-start size)
               :next-start end
               :size size
               :orig-alleles alleles
               :ref-allele (:ref ready-alleles)
               :alleles (:alts ready-alleles)}))]
    (remove nil?
            (loop [i 0 final []]
              (cond
               (&gt;= i (-&gt; alleles first count)) final
               (has-variant-base? alleles i)
               (let [next-var (extract-variants alleles i)]
                 (recur (:next-start next-var) (conj final next-var)))
               :else (recur (inc i) final))))))</pre></td></tr><tr><td class="docs"><p>Retrieve a new set of genotypes with the given alleles.
   Update genotypes from the VariantContext, copying the existing
   genotype and substituting in the provided alleles and phasing information.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- genotype-w-alleles
  [vc alleles orig-alleles is-phased]
  (letfn [(get-new-allele [new-alleles orig-alleles]
            (let [old-map (into {} (map-indexed
                                    (fn [i x]
                                      [(string/replace x &quot;-&quot; &quot;&quot;) i])
                                    orig-alleles))]
              (fn [old-allele]
                (nth new-alleles (get old-map (.getDisplayString old-allele))))))
          (add-new-genotype [allele-mapper context genotype]
            (doto context
              (.replace (-&gt; (GenotypeBuilder. genotype)
                            (.alleles (map allele-mapper (.getAlleles genotype)))
                            (.phased (or (.isPhased genotype) is-phased))
                            .make))))]
    (reduce (partial add-new-genotype (get-new-allele alleles orig-alleles))
            (-&gt; vc .getGenotypes GenotypesContext/copy)
            (.getGenotypes vc))))</pre></td></tr><tr><td class="docs"><p>Create a new VariantContext as a subset of an existing variant.
   <code>allele-info</code> specifies the location size and alleles for the new variant:
   <code>{:offset :size :ref-allele :alleles}</code></p>
</td><td class="codes"><pre class="brush: clojure">(defn- new-split-vc
  [vc i allele-info]
  (let [pos (+ (:offset allele-info) (.getStart vc))
        all-alleles (cons (:ref-allele allele-info) (:alleles allele-info))]
    (-&gt; (VariantContextBuilder. vc)
        (.start pos)
        (.stop (+ pos (get allele-info :size 0)))
        (.genotypes (genotype-w-alleles vc all-alleles (:orig-alleles allele-info)
                                        (&gt; i 0)))
        (.alleles (set all-alleles))
        (.make))))</pre></td></tr><tr><td class="docs"><p>Split a MNP into individual alleles</p>
</td><td class="codes"><pre class="brush: clojure">(defn- split-mnp
  [vc]
  (let [alleles (split-alleles vc (get-vc-alleles vc))]
    (map (fn [[i x]] (new-split-vc (:vc vc) i x)) (map-indexed vector alleles))))</pre></td></tr><tr><td class="docs"><h2>Indels</h2>

<p>Create a normalized representation for comparison.</p>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Perform alignment of input sequences using BioJava.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- multiple-alignment
  [seqs]
  (letfn [(original-seq-position [seqs]
            (let [orig-order (into {} (map-indexed (fn [i x] [x i])
                                                   (into (ordered-set) seqs)))]
              (fn [x]
                (get orig-order (string/replace x &quot;-&quot; &quot;&quot;)))))
          (unique-aligns [xs]
            (vals (reduce (fn [coll x]
                            (assoc coll (string/replace x &quot;-&quot; &quot;&quot;) x))
                          {} xs)))
          (all-gap? [xs]
            (= (set (map str xs)) #{&quot;-&quot;}))
          (finalize-alignment [seqs]
            (let [n (count seqs)
                  gap-free (remove all-gap? (partition n (apply interleave (take n seqs))))]
              (map (fn [i]
                     (string/join &quot;&quot; (map #(nth % i) gap-free)))
                   (range n))))]
    (let [align-args (to-array [(SimpleGapPenalty. 20 1)])
          base-align (map #(.getSequenceAsString %)
                          (-&gt; (map #(DNASequence. %) seqs)
                              (Alignments/getMultipleSequenceAlignment align-args)
                              .getAlignedSequences))
          orig-align (sort-by (original-seq-position seqs) (unique-aligns base-align))]
      (finalize-alignment orig-align))))</pre></td></tr><tr><td class="docs"><p>Left align variants that start with a gap mismatch.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- fix-gap-start-mismatch
  [alleles]
  (letfn [(make-5-gap-wref [x]
            (let [anchor (subs x 0 1)
                  nogap-x (string/replace (subs x 1) &quot;-&quot; &quot;&quot;)]
              (string/join &quot;&quot; (conj (vec (cons anchor
                                               (repeat (dec (- (count x) (count nogap-x))) &quot;-&quot;)))
                                    nogap-x))))]
    (if (.contains (second alleles) &quot;-&quot;)
      [(first alleles) (make-5-gap-wref (second alleles))]
      [(make-5-gap-wref (first alleles)) (second alleles)])))</pre></td></tr><tr><td class="docs"><p>Ensure reference alignment gaps next to variants are consistently left aligned.
   Adjacent SNP and indels can have the SNP placed anywhere within the indel. This left
   aligns them to maintain anchoring via the 5' reference.
    ATCT  => ATCT
    AC--     A--C</p>
</td><td class="codes"><pre class="brush: clojure">(defn- left-align-complex
  [alleles]
  {:pre [(= 2 (count alleles))]
   :post [(= (count (first alleles))
             (count (first %)))]}
  (letfn [(gap-start-mismatch? [alleles i]
            (or (and (starts-an-indel? alleles i)
                     (not (is-match? alleles i))
                     (not (contains-indel? alleles i)))
                false))
          (gap-allele-type [alleles i]
            (cond
             (gap-start-mismatch? alleles i) :gs-mismatch
             (contains-indel? alleles i) :gap
             (gap-end? alleles i) :gap-end
             (is-match? alleles i) :match
             :else :mismatch))
          (split-at-match-gaps [[ann _]]
            (if (= :gap-end ann) ann :match))
          (get-region-allele [xs allele]
            (apply str (map #(nth allele (second %)) xs)))
          (get-region-alleles [alleles xs]
            (let [orig-alleles (map (partial get-region-allele xs) alleles)]
              (if (contains? (set (map first xs)) :gs-mismatch) 
                (fix-gap-start-mismatch orig-alleles)
                orig-alleles)))
          (concat-results [allele-parts]
            (vec (map #(apply str (map % allele-parts)) [first second])))]
    (concat-results
     (-&gt;&gt; (map (fn [x] [(gap-allele-type alleles x) x]) (range (count (first alleles))))
          (partition-by split-at-match-gaps)
          (map (partial get-region-alleles alleles))))))</pre></td></tr><tr><td class="docs"><p>Confirm that new variants match correctly back to original.
   Catch any potential errors in splitting by ensuring reference coordinates
   and sequences match original.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- sanity-check-split-vcs
  [vc new-vcs]
  (letfn [(get-vc-info [vc]
            (let [alleles (map #(.getDisplayString %) (.getAlleles vc))]
              {:start (.getStart vc)
               :alleles alleles}))
          (get-check-ref [orig new]
            (let [int-pos (- (:start new) (:start orig))
                  check-ref (first (:alleles new))]
              (if (neg? int-pos)
                [0 (subs check-ref (Math/abs int-pos))]
                [int-pos check-ref])))
          (check-split-vc [orig new]
            (let [[int-pos check-ref] (get-check-ref orig new)]
              (when (or (&gt;= int-pos (count (first (:alleles orig))))
                        (neg? int-pos)
                        (not= (subs (first (:alleles orig)) int-pos (+ int-pos (count check-ref)))
                           check-ref))
                (throw (Exception. (format &quot;Matching problem with split alleles: %s %s %s %s&quot;
                                           (:chr vc) (:start vc) orig new))))))]
    (doall (map (partial check-split-vc (get-vc-info (:vc vc)))
                (map get-vc-info new-vcs)))))</pre></td></tr><tr><td class="docs"><p>Split complex indels into individual variant components.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- split-complex-indel
  [vc ref]
  (let [prev-pad (or (extract-sequence ref (:chr vc) (dec (:start vc)) (dec (:start vc))) &quot;N&quot;)
        ; Do not use reference sequence. Causes more trouble than aligning ref/alt directly.
        ref-seq nil ;(extract-sequence ref (:chr vc) (:start vc) (:end vc))
        alleles (split-alleles vc (-&gt;&gt; (conj (get-vc-alleles vc) ref-seq)
                                       (remove empty?)
                                       (remove nil?)
                                       multiple-alignment
                                       (#(if (&gt; (count %) 2) % (left-align-complex %))))
                               :prev-pad prev-pad)]
    (when-not (= (count alleles) (count (set (map :offset alleles))))
      (throw (Exception. (format &quot;Mutiple alleles at same position: %s %s %s&quot;
                                 (:chr vc) (:start vc) (vec alleles)))))
    (let [split-vcs (map (fn [[i x]] (new-split-vc (:vc vc) i x))
                         (map-indexed vector alleles))]
      (sanity-check-split-vcs vc split-vcs)
      split-vcs)))</pre></td></tr><tr><td class="docs"><p>Remove extra variant bases, if necessary, from 5' end of indels.
  Checks both called alleles and potential alleles for extra 5' padding
  removing this if not needed to distinguish any potential alleles.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- maybe-strip-indel
  [vc]
  (letfn [(strip-indel [vc i alleles]
            (let [start-pos (dec i)
                  ref-allele (subs (first alleles) start-pos)
                  cur-alleles (map #(Allele/create (subs % start-pos)
                                                   (= ref-allele (subs % start-pos)))
                                   alleles)]
              (new-split-vc vc 0 {:offset start-pos
                                  :size (dec (count ref-allele))
                                  :orig-alleles alleles
                                  :ref-allele (first cur-alleles)
                                  :alleles (rest cur-alleles)})))
          (variant-allele-pos [input-alleles]
            (let [str-alleles (map #(.getDisplayString %) input-alleles)
                  first-var-i (first (filter #(has-variant-base? str-alleles %)
                                             (range (apply max (map count str-alleles)))))]
              [str-alleles first-var-i]))
          (used-alt-alleles [vc]
            (let [genotype-alleles (set (mapcat :alleles (:genotypes vc)))]
              (filter #(contains? genotype-alleles %) (:alt-alleles vc))))]
    (let [alt-alleles (used-alt-alleles vc)
          [orig-alleles first-var-i] (variant-allele-pos (cons (:ref-allele vc)
                                                               alt-alleles))
          [_ nocall-i] (variant-allele-pos (cons (:ref-allele vc) alt-alleles))]
      (if (or (nil? first-var-i) (&lt;= first-var-i 1)
              (nil? nocall-i) (&lt;= nocall-i 1))
        (:vc vc)
        (strip-indel (:vc vc) first-var-i orig-alleles)))))</pre></td></tr><tr><td class="docs"><h2>VCF file conversion</h2>

<p>Process entire files, normalizing complex variations</p>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Round the start value of a VC to the nearest ten million.
   This heuristic will cause problems with out of order variant
   contexts that span this split junction (9999999 and 10000000) but
   saves having to work with overlapping groups allowing streaming.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- round-vc-start
  [vc]
  (let [rounder 10000000.0]
    {:chr (.getChr vc)
     :pos (-&gt; (.getStart vc)
              (/ rounder)
              Math/floor
              (* rounder)
              int)}))</pre></td></tr><tr><td class="docs"><p>Sort a group of variant contexts by start position.
   Ensures that post-normalized variant contexts
   sort correctly within the blocks defined by round-vc-start.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- sort-vc-group
  [vcs]
  (sort-by #(.getStart %) vcs))</pre></td></tr><tr><td class="docs"><p>Lazy list of variant context with MNPs split into single genotypes and indels stripped.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-normalized-vcs
  [vc-iter ref]
  (letfn [(process-vc [vc]
            (condp = (:type vc)
              &quot;MNP&quot; (split-mnp vc)
              &quot;INDEL&quot; (if (is-multi-indel? vc)
                        (split-complex-indel vc ref)
                        [(maybe-strip-indel vc)])
              [(:vc vc)]))]
    (-&gt;&gt; (mapcat process-vc vc-iter)
         (partition-by round-vc-start)
         (mapcat sort-vc-group))))</pre></td></tr><tr><td class="docs"><p>Left align variants in an input VCF file for a standard representation.
  Checks final line count of prepared file, returning left-aligned files
  only when converting every variant in the input.</p>
</td><td class="codes"><pre class="brush: clojure">(defn left-align-variants
  [in-file ref &amp; {:keys [out-dir rerun?]}]
  (letfn [(line-count [f]
            (with-open [rdr (reader f)]
              (count (remove #(.startsWith % &quot;#&quot;) (line-seq rdr)))))]
    (let [file-info {:out-vcf (itx/add-file-part in-file &quot;leftalign&quot; out-dir)}
          args [&quot;-R&quot; ref &quot;-o&quot; :out-vcf &quot;--variant&quot; in-file]]
      (when (and rerun? (fs/exists? (:out-vcf file-info)))
        (fs/delete (:out-vcf file-info)))
      (broad/run-gatk &quot;LeftAlignVariants&quot; args file-info {:out [:out-vcf]})
      (if (= (line-count in-file) (line-count (:out-vcf file-info)))
        (:out-vcf file-info)
        in-file))))</pre></td></tr><tr><td class="docs"><p>Convert MNPs and indels into normalized representation.</p>
</td><td class="codes"><pre class="brush: clojure">(defn normalize-variants
  ([in-file ref]
     (normalize-variants in-file ref nil))
  ([in-file ref out-dir &amp; {:keys [out-fname]}]
     (let [base-name (if (nil? out-fname) (itx/remove-zip-ext in-file) out-fname)
           out-file (itx/add-file-part base-name &quot;nomnp&quot; out-dir)
           out-pre-file (itx/add-file-part base-name &quot;worknomnp&quot; out-dir)]
       (when (itx/needs-run? out-file)
         (when (fs/exists? out-pre-file)
           (fs/delete out-pre-file))
         (let [la-file (left-align-variants in-file ref :out-dir out-dir :rerun? true)]
           (with-open [vcf-iter (get-vcf-iterator la-file ref)]
             (write-vcf-w-template in-file {:out out-pre-file}
                                   (get-normalized-vcs (parse-vcf vcf-iter) ref)
                                   ref))
           (fs/rename (left-align-variants out-pre-file ref :out-dir out-dir :rerun? true)
                      out-file)))
       out-file)))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.config" name="bcbio.variation.config"><h1 class="project-name">bcbio.variation.config</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Load and prepare inputs from YAML configuration files.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.config
  (:use [clojure.java.io]
        [clj-time.local :only [format-local-time local-now]])
  (:require [clojure.string :as string]
            [clojure.tools.logging :as log]
            [clj-stacktrace.repl :as stacktrace]
            [clj-yaml.core :as yaml]
            [fs.core :as fs]
            [pallet.algo.fsm.fsm :as fsm-base]
            [pallet.algo.fsm.fsm-dsl :as fsm]
            [pallet.algo.fsm.event-machine :as event-machine]))</pre></td></tr><tr><td class="docs"><h2>Logging</h2>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- get-log-file [config]
  (let [out-dir (get-in config [:dir :out])]
    (when-not (nil? out-dir)
      (when-not (fs/exists? out-dir)
        (fs/mkdirs out-dir))
      (file out-dir &quot;processing-status.log&quot;))))</pre></td></tr><tr><td class="docs"><p>Retrieve current processing status information from state machine log file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-log-status
  [config]
  (when-let [log-file (get-log-file config)]
    (when (fs/exists? log-file)
      (with-open [rdr (reader log-file)]
        (let [[_ state-str info-str] (string/split (last (line-seq rdr)) #&quot; :: &quot;)]
          (-&gt; (read-string info-str)
              (assoc :state (read-string (last (string/split state-str #&quot; &quot;))))))))))</pre></td></tr><tr><td class="docs"><p>Write an error exception to the processing log file</p>
</td><td class="codes"><pre class="brush: clojure">(defn traceback-to-log
  [e config]
  (with-open [wtr (writer (get-log-file config) :append true)]
    (binding [*out* wtr]
      (stacktrace/pst e)
      (println (str (format-local-time (local-now) :date-hour-minute-second)
                    &quot; :: State :error :: {:desc \&quot;Exception during processing: &quot;
                    e &quot;\&quot;}&quot;)))))</pre></td></tr><tr><td class="docs"><p>Define a finite state machine of transitions during comparison processes.</p>
</td><td class="codes"><pre class="brush: clojure">(defn prep-comparison-fsm
  [config]
  (let [out-file (get-log-file config)]
    (letfn [(log-transition [_ new-state]
              (let [out (format &quot;State %s :: %s&quot; (:state-kw new-state)
                                (:state-data new-state))]
                (log/log :info out)
                (when out-file
                  (spit out-file (str (format-local-time (local-now) :date-hour-minute-second)
                                      &quot; :: &quot; out &quot;\n&quot;) :append true))))]
      (log-transition nil {:state-kw :begin :state-data {:desc &quot;Starting variation analysis&quot;}})
      (event-machine/event-machine
       (fsm/event-machine-config
        (fsm/using-fsm-features (fsm-base/with-transition-observer log-transition))
        (fsm/initial-state :begin)
        (fsm/initial-state-data {})
        (fsm/state :begin
                   (fsm/valid-transitions :clean))
        (fsm/state :clean
                   (fsm/valid-transitions :merge))
        (fsm/state :merge
                   (fsm/valid-transitions :prep))
        (fsm/state :prep
                   (fsm/valid-transitions :normalize))
        (fsm/state :normalize
                   (fsm/valid-transitions :combine :clean))
        (fsm/state :combine
                   (fsm/valid-transitions :annotate))
        (fsm/state :annotate
                   (fsm/valid-transitions :filter))
        (fsm/state :filter
                   (fsm/valid-transitions :compare))
        (fsm/state :compare
                   (fsm/valid-transitions :compare :finalize :summary :clean :finished))
        (fsm/state :finalize
                   (fsm/valid-transitions :finalize :compare :summary :clean))
        (fsm/state :summary
                   (fsm/valid-transitions :finished :clean))
        (fsm/state :finished))))))</pre></td></tr><tr><td class="docs"><p>Perform a transition on configured finite state machine moving to the provided state</p>
</td><td class="codes"><pre class="brush: clojure">(defn do-transition
  [config state desc]
  (if-let [do-trans (get-in config [:fsm :transition])]
    (do-trans #(assoc % :state-kw state :state-data {:desc desc}))
    (println state desc)))</pre></td></tr><tr><td class="docs"><h2>Configuration</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Add files of interest in a directory with the given extension.
  This allows batch processing of directories.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- add-dir-files
  [config exts]
  (letfn [(files-from-dir [dir]
            (-&gt;&gt; (fs/list-dir dir)
                 (filter #(contains? exts (fs/extension %)))
                 (map #(str (fs/file dir %)))))
          (process-call [call]
            (if-let [dir (:dir call)]
              (assoc call :file (files-from-dir dir))
              call))
          (process-exp [exp]
            (assoc exp :calls (map process-call (:calls exp))))]
    (assoc config :experiments
           (map process-exp (:experiments config)))))</pre></td></tr><tr><td class="docs"><p>Do not allow duplicate names in experiments.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- no-duplicate-names?
  [config]
  (letfn [(exp-no-duplicate? [exp]
            (every? (fn [[_ x]] (= 1 x)) (frequencies (map :name (:calls exp)))))]
    (every? exp-no-duplicate? (:experiments config))))</pre></td></tr><tr><td class="docs"><p>Load configuration file, handling conversion of relative to absolute paths.</p>
</td><td class="codes"><pre class="brush: clojure">(defn load-config
  [config-file]
  {:post [(no-duplicate-names? %)]}
  (let [config (-&gt; config-file slurp yaml/parse-string)
        base-dir (fs/file (get-in config [:dir :base] &quot;.&quot;))
        to-process #{[:dir :out] [:dir :prep]
                     [:experiments :ref] [:experiments :intervals]
                     [:experiments :align] [:experiments :calls :file]
                     [:experiments :calls :align] [:experiments :calls :annotate]
                     [:experiments :calls :dir]}]
    (letfn [(make-absolute [x]
              (if (.isAbsolute (file x))
                x
                (str (fs/file base-dir x))))
            (maybe-process [val path]
              (if (contains? to-process path)
                (cond
                 (seq? val) (map make-absolute val)
                 (string? val) (make-absolute val)
                 :else val)
                val))
            (update-tree [config path]
              (cond (map? config)
                    (reduce (fn [item [k v]]
                              (assoc item k (cond
                                             (map? v) (update-tree v (conj path k))
                                             (seq? v) (map #(update-tree % (conj path k)) v)
                                             :else (maybe-process v (conj path k)))))
                            config
                            (vec config))
                    (contains? to-process path) (maybe-process config path)
                    :else config))]
      (-&gt; config
          (update-tree [])
          (add-dir-files #{&quot;.vcf&quot;})
          (#(assoc % :fsm (prep-comparison-fsm %)))))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.core" name="bcbio.variation.core"><h1 class="project-name">bcbio.variation.core</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.core
  (:import [org.broadinstitute.sting.gatk CommandLineGATK])
  (:require [clojure.string :as string]
            [bcbio.variation.compare]
            [bcbio.variation.combine]
            [bcbio.variation.haploid]
            [bcbio.align.reorder]
            [bcbio.variation.utils.core])
  (:gen-class))</pre></td></tr><tr><td class="docs"><p>Mapping of special command line arguments to main functions</p>
</td><td class="codes"><pre class="brush: clojure">(def ^{:doc 
       :private true}
  altmain-map
  {:compare bcbio.variation.compare/-main
   :prep bcbio.variation.combine/-main
   :haploid bcbio.variation.haploid/-main
   :reorder bcbio.align.reorder/-main
   :utils bcbio.variation.utils.core/-main})</pre></td></tr><tr><td class="docs"><p>Retrieve alternative main functions based on first argument.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-altmain-fn
  [arg]
  (when (and (not (nil? arg))
             (.startsWith arg &quot;variant-&quot;))
    (get altmain-map
         (keyword (string/replace-first arg &quot;variant-&quot; &quot;&quot;)))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -main [&amp; args]
  (if-let [alt-fn (get-altmain-fn (first args))]
    (do
      (apply alt-fn (rest args))
      (System/exit 0))
    (CommandLineGATK/main (into-array (if-not (nil? args) args [&quot;-h&quot;])))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.custom.core" name="bcbio.variation.custom.core"><h1 class="project-name">bcbio.variation.custom.core</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Commandline dispatch for custom one-off exploratory code</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.custom.core
  (:require [bcbio.variation.custom.nist :as nist]))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -main [prog &amp; args]
  (apply (case (keyword prog)
           :nist nist/summarize-discordants)
         args))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.custom.nist" name="bcbio.variation.custom.nist"><h1 class="project-name">bcbio.variation.custom.nist</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Explore variant calling from fosmid data against NIST whole genome datasets</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.custom.nist
  (:use [bcbio.variation.filter.attr :only [prep-vc-attr-retriever]])
  (:require [clojure.string :as string]
            [incanter.stats :as istats]
            [bcbio.variation.variantcontext :as gvc]))</pre></td></tr><tr><td class="docs"><p>Retrieve filter information associated with NIST variant calls</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-nist-filter
  [retriever vc]
  (if-let [nist-vc (first (gvc/variants-in-region retriever vc))]
    (if (empty? (:filters nist-vc))
      :ref-call
      (first (:filters nist-vc)))
    :no-call))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- get-gms-score
  [attr-get vc]
  (let [attr &quot;gms_illumina&quot;]
    (-&gt; (attr-get [attr] vc)
        (get attr))))</pre></td></tr><tr><td class="docs"><p>Provide high level statistics on discordant calls.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- collect-stats-for-discordant
  [fosmid-file nist-file ref-file]
  (let [attr-get (prep-vc-attr-retriever fosmid-file ref-file)]
    (with-open [vrn-iter (gvc/get-vcf-iterator fosmid-file ref-file)
                nist-retriever (gvc/get-vcf-retriever ref-file nist-file)]
      (reduce (fn [coll vc]
                {:filters (let [filt (get-nist-filter nist-retriever vc)]
                            ;; (when (= :ref-call filt)
                            ;;   (println ((juxt :chr :start) vc) (get-gms-score attr-get vc)))
                            (assoc (:filters coll) filt (inc (get-in coll [:filters filt] 0))))
                 :gms (cons (get-gms-score attr-get vc) (:gms coll))})
              {:filters {} :gms []}
              (filter #(= &quot;SNP&quot; (:type %)) (gvc/parse-vcf vrn-iter))))))</pre></td></tr><tr><td class="docs"><p>Split NIST filter names into individual components to summarize.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- split-filter-name
  [x]
  (-&gt; x
      (string/replace &quot;filtered&quot; &quot;&quot;)
      (string/split #&quot;Tranche&quot;)
      (#(remove empty? %))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- counts-to-individual-filters
  [xs]
  (letfn [(split-by-filter [[k v]]
            (when-not (keyword? k)
              (partition 2 (interleave (split-filter-name k) (repeat v)))))]
    (reduce (fn [coll [k v]]
              (assoc coll k (+ v (get coll k 0))))
            {}
            (mapcat split-by-filter xs))))</pre></td></tr><tr><td class="docs"><p>Summarize discordant calls between fosmid and NIST calls.</p>
</td><td class="codes"><pre class="brush: clojure">(defn summarize-discordants
  [fosmid-file nist-file ref-file]
  (let [stats (collect-stats-for-discordant fosmid-file nist-file ref-file)
        ready-gms (filter #(&lt; % 100.0) (:gms stats))
        special-filters [:ref-call :no-call]]
    (doseq [k special-filters]
      (println k (get-in stats [:filters k])))
    (doseq [[k v] (counts-to-individual-filters (:filters stats))]
      (println k v))
    (println &quot;GMS&quot; (count (:gms stats)) (count ready-gms) (istats/quantile ready-gms))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.evaluate" name="bcbio.variation.evaluate"><h1 class="project-name">bcbio.variation.evaluate</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Provide high level summary evaluation of variant results, building off GATK VariantEval.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.evaluate
  (:import [org.broadinstitute.sting.gatk.report GATKReport])
  (:use [clojure.java.io]
        [ordered.map :only [ordered-map]])
  (:require [clojure.string :as string]
            [doric.core :as doric]
            [bcbio.run.itx :as itx]
            [bcbio.run.broad :as broad]))</pre></td></tr><tr><td class="docs"><p>Compare two variant files with GenotypeConcordance in VariantEval</p>
</td><td class="codes"><pre class="brush: clojure">(defn calc-variant-eval-metrics
  [sample vcf1 vcf2 ref &amp; {:keys [out-base intervals]}]
  (let [file-info {:out-eval (str (itx/file-root (if (nil? out-base) vcf1 out-base)) &quot;.eval&quot;)}
        args (concat
              [&quot;-R&quot; ref
               &quot;--out&quot; :out-eval
               &quot;--eval&quot; vcf1
               &quot;--comp&quot; vcf2
               &quot;--sample&quot; sample
               &quot;--doNotUseAllStandardModules&quot;
               &quot;--evalModule&quot; &quot;CompOverlap&quot;
               &quot;--evalModule&quot; &quot;CountVariants&quot;
               &quot;--evalModule&quot; &quot;GenotypeConcordance&quot;
               &quot;--evalModule&quot; &quot;TiTvVariantEvaluator&quot;
               &quot;--evalModule&quot; &quot;ValidationReport&quot;
               &quot;--stratificationModule&quot; &quot;Sample&quot;
               &quot;--stratificationModule&quot; &quot;Filter&quot;]
              (broad/gatk-cl-intersect-intervals intervals ref))]
    (broad/run-gatk &quot;VariantEval&quot; args file-info {:out [:out-eval]})
    (:out-eval file-info)))</pre></td></tr><tr><td class="docs"><p>Run VariantEval providing summary information for a VCF file</p>
</td><td class="codes"><pre class="brush: clojure">(defn- calc-summary-eval-metrics
  [vcf ref dbsnp intervals cmp-interval-file]
  (let [file-info {:out-eval (str (itx/file-root vcf) &quot;-summary.eval&quot;)}
        args (concat
              [&quot;-R&quot; ref
               &quot;--out&quot; :out-eval
               &quot;--eval&quot; vcf
               &quot;--doNotUseAllStandardModules&quot;
               &quot;--evalModule&quot; &quot;CompOverlap&quot;
               &quot;--evalModule&quot; &quot;CountVariants&quot;
               &quot;--evalModule&quot; &quot;ThetaVariantEvaluator&quot;
               &quot;--evalModule&quot; &quot;TiTvVariantEvaluator&quot;
               &quot;--evalModule&quot; &quot;ValidationReport&quot;
               &quot;--evalModule&quot; &quot;VariantSummary&quot;
               &quot;--stratificationModule&quot; &quot;Filter&quot;]
              (broad/gatk-cl-intersect-intervals intervals ref)
              (if (nil? dbsnp) [] [&quot;--dbsnp&quot; dbsnp])
              (if (nil? cmp-interval-file)
                []
                [&quot;--stratificationModule&quot; &quot;IntervalStratification&quot;
                 &quot;--stratIntervals&quot; cmp-interval-file]))]
    (broad/run-gatk &quot;VariantEval&quot; args file-info {:out [:out-eval]})
    (:out-eval file-info)))</pre></td></tr><tr><td class="docs"><p>Parses a GATK output table and filters based on supplied input function.</p>
</td><td class="codes"><pre class="brush: clojure">(defn organize-gatk-report-table
  [eval-file table-name filter-fn]
  (let [table (-&gt; (GATKReport. (file eval-file))
                  (.getTable table-name))
        cols (rest (.getColumnInfo table))
        headers (map #(keyword (.getColumnName %)) cols)]
    (-&gt;&gt; (for [i (range (.getNumRows table))]
           (zipmap headers
                   (map #(.get table i (inc %)) (range (count headers)))))
         (filter filter-fn))))</pre></td></tr><tr><td class="docs"><p>Provide high level summary metrics of a single variant file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn summary-eval-metrics
  [vcf ref &amp; {:keys [intervals cmp-intervals dbsnp]}]
  (let [group-metrics (concat [:Novelty] (if intervals [:IntervalStratification] []))
        val-metrics [:nSamples :nProcessedLoci :nSNPs :TiTvRatio :TiTvRatioPerSample
                     :nSNPsPerSample :SNPNoveltyRate]
        count-metrics [:nSNPs :nInsertions :nDeletions :nHets :nHomVar :hetHomRatio]]
    (letfn [(all-called? [x]
              (and (= (:Filter x) &quot;called&quot;)
                   (contains? #{nil &quot;all&quot;} (:Sample x))))
            (select-keys-ordered [metrics coll]
              (ordered-map (map (fn [x] [x (get coll x)]) metrics)))
            (get-table-info [eval-file table metrics]
              (-&gt;&gt; (organize-gatk-report-table eval-file table all-called?)
                   (map (partial select-keys-ordered metrics))))
            (merge-line [vals]
              (reduce (fn [outer tbl-vals]
                        (reduce (fn [inner [k v]]
                                  (assoc inner k v))
                                outer (remove #(contains? (set group-metrics) %1) tbl-vals)))
                      (first vals) (rest vals)))
            (merge-tables [&amp; tbls]
              (map merge-line
                   (partition (count tbls) (apply interleave tbls))))]
      (let [eval-file (calc-summary-eval-metrics vcf ref dbsnp
                                                 intervals cmp-intervals)]
        (merge-tables
         (get-table-info eval-file &quot;CountVariants&quot; (concat group-metrics count-metrics))
         (get-table-info eval-file &quot;VariantSummary&quot; (concat group-metrics val-metrics)))))))</pre></td></tr><tr><td class="docs"><p>Write high level summary metrics to CSV file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn write-summary-eval-metrics
  [vcf ref &amp; {:keys [intervals cmp-intervals dbsnp]}]
  (let [out-file (str (itx/file-root vcf) &quot;-summary.csv&quot;)]
    (let [metrics (summary-eval-metrics vcf ref :intervals intervals :cmp-intervals cmp-intervals
                                        :dbsnp dbsnp)]
      (with-open [wtr (writer out-file)]
        (.write wtr (str (string/join &quot;,&quot; (map name (-&gt; metrics first keys))) &quot;\n&quot;))
        (doseq [xs metrics]
          (.write wtr (str (string/join &quot;,&quot; (vals xs)) &quot;\n&quot;)))))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -main
  ([vcf ref dbsnp intervals cmp-intervals]
     (write-summary-eval-metrics vcf ref :intervals intervals :cmp-intervals cmp-intervals
                                 :dbsnp dbsnp))
  ([vcf ref dbsnp cmp-intervals]
     (write-summary-eval-metrics vcf ref :cmp-intervals cmp-intervals
                                 :dbsnp dbsnp))
  ([vcf ref dbsnp]
     (write-summary-eval-metrics vcf ref :dbsnp dbsnp)))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.filter" name="bcbio.variation.filter"><h1 class="project-name">bcbio.variation.filter</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Filter variant calls according to supplied criteria.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.filter
  (:use [clojure.string :only [split]]
        [bcbio.variation.filter.attr :only [get-vc-attr prep-vc-attr-retriever]]
        [bcbio.variation.filter.classify :only [pipeline-classify-filter]]
        [bcbio.variation.filter.specific :only [get-x-specific-variants]]
        [bcbio.variation.filter.trusted :only [get-support-vcfs get-trusted-variants]]
        [bcbio.variation.filter.util :only [remove-cur-filters]]
        [bcbio.variation.metrics :only [to-float passes-filter?]]
        [bcbio.variation.variantcontext :only [parse-vcf write-vcf-w-template
                                               get-vcf-iterator write-vcf-from-filter
                                               select-variants]])
  (:require [clojure.set :as set]
            [clojure.string :as string]
            [bcbio.run.broad :as broad]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn jexl-from-config [jexl-filters]
  &quot;Retrieve GATK JEXL commandline expressions from filters.&quot;
  (letfn [(jexl-args [x]
            [&quot;--filterName&quot; (str (first (split x #&quot;\s+&quot;)) &quot;Filter&quot;)
             &quot;--filterExpression&quot; x])]
    (flatten (map jexl-args jexl-filters))))</pre></td></tr><tr><td class="docs"><p>Perform hard variant filtering with supplied JEXL expression criteria.</p>
</td><td class="codes"><pre class="brush: clojure">(defn variant-filter
  [in-vcf jexl-filters ref]
  (let [file-info {:out-vcf (itx/add-file-part in-vcf &quot;filter&quot;)}
        args (concat [&quot;-R&quot; ref
                      &quot;--variant&quot; in-vcf
                      &quot;-o&quot; :out-vcf
                      &quot;-l&quot; &quot;ERROR&quot;
                      &quot;--unsafe&quot; &quot;ALL&quot; ;&quot;ALLOW_SEQ_DICT_INCOMPATIBILITY&quot;
                      ]
                      (jexl-from-config jexl-filters))]
    (broad/run-gatk &quot;VariantFiltration&quot; args file-info {:out [:out-vcf]})
    (:out-vcf file-info)))</pre></td></tr><tr><td class="docs"><p>Perform hard variant filtration handling both range and category metrics</p>
</td><td class="codes"><pre class="brush: clojure">(defn category-variant-filter
  [in-vcf metrics ref &amp; {:keys [remove?]}]
  (let [attr-getter (prep-vc-attr-retriever in-vcf ref)]
    (letfn [(infinity-flag? [x]
              (.contains (str x) &quot;Infinity&quot;))
            (in-range? [[orig-min orig-max] x]
              (let [min (if (infinity-flag? orig-min) (- Integer/MAX_VALUE) orig-min)
                    max (if (infinity-flag? orig-max) Integer/MAX_VALUE orig-max)]
                (and (&gt;= x min) (&lt;= x max))))
            (attr-passes? [got want]
              (cond
               (set? want) (or (empty? want)
                               (not (empty? (set/intersection got want)))) 
               (or (vector? want) (list? want)) (in-range? want got)))
            (passes-metrics? [vc]
              (let [attrs (attr-getter (keys metrics) vc)]
                (and (passes-filter? vc) 
                     (every? (fn [[k v]]
                               (attr-passes? (get attrs k) v)) metrics))))
            (range-to-str [k [min max]]
              (cond
               (infinity-flag? min) (format &quot;%s &gt; %.1f&quot; k max)
               (infinity-flag? max) (format &quot;%s &lt; %.1f&quot; k min)
               :else (format &quot;%s not [%.1f %.1f]&quot; k min max)))
            (metric-to-str [[k v]]
              (cond
               (set? v) (format &quot;%s not [%s]&quot; k (string/join &quot;,&quot; v))
               (or (vector? v) (list? v)) (range-to-str k v)))]
      (if remove?
        (select-variants in-vcf passes-metrics? &quot;filter&quot; ref)
        (write-vcf-from-filter in-vcf ref &quot;filter&quot;
                               &quot;ManualRanges&quot; (string/join &quot;; &quot; (map metric-to-str metrics))
                               passes-metrics?)))))</pre></td></tr><tr><td class="docs"><p>Perform hard filtering base on JEXL expressions on metrics in the Genotype FORMAT field.</p>
</td><td class="codes"><pre class="brush: clojure">(defn variant-format-filter
  [in-vcf exps ref]
  (letfn [(format-filter [exp]
            (let [[attr op-str str-val] (string/split exp #&quot; &quot;)
                  val (to-float str-val)
                  op (eval (read-string op-str))]
              (fn [vc]
                (when-let [vc-val (get-vc-attr vc [:format attr] {})]
                  (not (op vc-val val))))))
          (format-filter-multi [exps]
            (let [int-filters (map format-filter exps)]
              (fn [vc]
                (every? true? (map #(% vc) int-filters)))))]
    (write-vcf-from-filter in-vcf ref &quot;ffilter&quot;
                           &quot;FormatRanges&quot; (string/join &quot;; &quot; exps)
                           (format-filter-multi exps))))</pre></td></tr><tr><td class="docs"><p>Perform the variant recalibration step with input training VCF files.
  training-vcfs is a list of <code>{:file vcf-file :name name-to-use :prior probability}</code></p>
</td><td class="codes"><pre class="brush: clojure">(defn- variant-recalibration
  [in-vcf training-vcfs annotations ref &amp; {:keys [lenient]}]
  (let [base-out (itx/file-root in-vcf)
        file-info {:out-recal (str base-out &quot;.recal&quot;)
                   :out-tranch (str base-out &quot;.tranches&quot;)
                   :out-r (str base-out &quot;-recalplots.R&quot;)}
        args (concat [&quot;-R&quot; ref
                      &quot;-input&quot; in-vcf
                      &quot;-recalFile&quot; :out-recal
                      &quot;-tranchesFile&quot; :out-tranch
                      &quot;-rscriptFile&quot; :out-r
                      &quot;--mode&quot; &quot;BOTH&quot;]
                     (if lenient
                       [&quot;--percentBadVariants&quot; &quot;0.05&quot;
                        &quot;--maxGaussians&quot; &quot;4&quot;]
                       [&quot;--percentBadVariants&quot; &quot;0.03&quot;
                        &quot;--maxGaussians&quot; &quot;10&quot;])
                     (flatten (map (fn [x] [&quot;-an&quot; x]) annotations))
                     (flatten (map (fn [x] [(str &quot;-resource:&quot; (:name x)
                                                 &quot;,known=true&quot;
                                                 &quot;,training=true&quot;
                                                 &quot;,truth=&quot; (:truth x)
                                                 &quot;,prior=&quot; (:prior x)
                                                 &quot;,bad=&quot; (:bad x))
                                            (:file x)])
                                   training-vcfs)))]
    (broad/run-gatk &quot;VariantRecalibrator&quot; args file-info {:out [:out-recal :out-tranch]})
    file-info))</pre></td></tr><tr><td class="docs"><p>Apply variant recalibration to input VCF.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- apply-recalibration
  [in-vcf recal-files ref]
  (let [file-info {:out-vcf (itx/add-file-part in-vcf &quot;recalfilter&quot;)}
        args [&quot;-R&quot; ref
              &quot;-input&quot; in-vcf
              &quot;--ts_filter_level&quot; &quot;99.0&quot;
              &quot;--mode&quot; &quot;BOTH&quot;
              &quot;-tranchesFile&quot; (:out-tranch recal-files)
              &quot;-recalFile&quot; (:out-recal recal-files)
              &quot;-o&quot; :out-vcf]]
    (broad/run-gatk &quot;ApplyRecalibration&quot; args file-info {:out [:out-vcf]})
    (:out-vcf file-info)))</pre></td></tr><tr><td class="docs"><p>Perform filtration using variant recalibration based on known variations.
  Training-vcfs is a list of true training sites along with associated
  probability and name.</p>
</td><td class="codes"><pre class="brush: clojure">(defn variant-recal-filter
  [in-vcf training-vcfs annotations ref &amp; {:keys [lenient]}]
  (let [recal-files (variant-recalibration in-vcf training-vcfs annotations ref :lenient lenient)]
    (apply-recalibration in-vcf recal-files ref)))</pre></td></tr><tr><td class="docs"><p>Retrieve training information for GATK recalibration:
   - No support specified: use the target comparison
   - Support specified and a specific comparison pair
   - Support specified as a single target: use target versus all comparison</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-train-info
  [cmps-by-name support config]
  (let [support-vcfs (get-support-vcfs cmps-by-name support config)]
      [{:file (:true-positives support-vcfs)
        :name &quot;concordant&quot;
        :truth &quot;true&quot;
        :bad &quot;false&quot;
        :prior 10.0}
       {:file (:false-positives support-vcfs)
        :name &quot;discordant&quot;
        :truth &quot;false&quot;
        :bad &quot;true&quot;
        :prior 10.0}]))</pre></td></tr><tr><td class="docs"><p>Perform variant recalibration and filtration as part of processing pipeline.</p>
</td><td class="codes"><pre class="brush: clojure">(defn pipeline-recalibration
  [cmps-by-name finalizer exp config]
  (let [init-target (get cmps-by-name (:target finalizer)
                         (get cmps-by-name (reverse (:target finalizer))))
        all-params (let [x (:params finalizer)] (if (map? x) [x] x))]
    (reduce (fn [target [params fkey]]
              (let [in-vcf (remove-cur-filters (-&gt; target fkey :file) (:ref exp))
                    support (get params :support (:target finalizer))
                    train-info (get-train-info cmps-by-name support config)
                    trusted-info [{:name &quot;trusted&quot;
                                   :file (when-let [trusted (:trusted params)]
                                           (get-trusted-variants cmps-by-name support trusted
                                                                 exp config))}
                                  {:name &quot;xspecific&quot;
                                   :file (when (:xspecific params)
                                           (get-x-specific-variants cmps-by-name support exp config))}]]
                (-&gt; target
                    (assoc-in [fkey :file]
                              (-&gt; in-vcf
                                  (#(if-let [anns (:annotations params)]
                                      (variant-recal-filter % train-info
                                                            anns (:ref exp)
                                                            :lenient (:lenient params))
                                      %))
                                  (#(if-let [hard-filters (:filters params)]
                                      (variant-filter % hard-filters (:ref exp))
                                      %))
                                  (#(if-not (:classifiers params)
                                      %
                                      (pipeline-classify-filter % (concat trusted-info train-info)
                                                                (get target fkey)
                                                                exp params config)))))
                    (#(assoc-in % [fkey :name] (format &quot;%s-%s&quot; (get-in % [fkey :name]) &quot;recal&quot;)))
                    (assoc-in [fkey :mod] &quot;recal&quot;)
                    (assoc :re-compare true))))
            init-target (map vector all-params [:c1 :c2]))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.filter.attr" name="bcbio.variation.filter.attr"><h1 class="project-name">bcbio.variation.filter.attr</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Provide generalized access to variant attributes, handling retrieval
   from multiple sources (VCF INFO file, VCF FORMAT field, Gemini).</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.filter.attr
  (:use [bcbio.variation.haploid :only [get-likelihoods]]
        [bcbio.variation.metrics :only [to-float]])
  (:require [clojure.string :as string]
            [incanter.stats :as stats]
            [lonocloud.synthread :as -&gt;]
            [bcbio.variation.variantcontext :as gvc]
            [bcbio.variation.index.gemini :as gemini]))</pre></td></tr><tr><td class="docs"><p>Generalized retrieval of attributes from variant with a single genotype.</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti get-vc-attr
  (let [gemini-ids (set (map :id (gemini/available-metrics nil :include-noviz? true)))]
    (fn [vc attr retrievers]
      (if (contains? gemini-ids attr)
        :gemini
        attr))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-vc-attr &quot;AD&quot;
  ^{:doc &quot;AD: Allelic depth for ref and alt alleles. Converted to percent
          deviation from expected for haploid/diploid calls.
          Also calculates allele depth from AO and DP used by FreeBayes.
          AO is the count of the alternative allele.&quot;}
  [vc attr _]
  {:pre [(= 1 (:num-samples vc))
         (contains? #{1 2} (-&gt; vc :genotypes first :alleles count))]}
  (letfn [(calc-expected [g ref-count allele-count]
            {:pre [(not (neg? ref-count))]}
            (when (or (pos? ref-count) (pos? allele-count))
              (when-let [e-pct (get {&quot;HOM_VAR&quot; 1.0 &quot;HET&quot; 0.5 &quot;HOM_REF&quot; 0.0} (:type g))]
                (Math/abs (- e-pct (/ allele-count (+ allele-count ref-count)))))))
          (from-ad [g]
            (let [ads (map float (get-in g [:attributes attr]))
                  ref-count (first ads)
                  allele-count (apply + (rest ads))]
              (calc-expected g ref-count allele-count)))
          (from-ao [g]
            (let [alt-count (apply + (map #(Float/parseFloat %)
                                          (string/split (get-in g [:attributes &quot;AO&quot;]) #&quot;,&quot;)))
                  total-count (float (get-in g [:attributes &quot;DP&quot;]))]
              (calc-expected g (- total-count alt-count) alt-count)))]
    (let [g (-&gt; vc :genotypes first)]
      (cond
       (get-in g [:attributes &quot;AO&quot;]) (from-ao g)
       (seq (get-in g [:attributes attr])) (from-ad g)
       :else nil
       ;; (println (format &quot;AD not found in attributes %s %s %s&quot;
       ;;                  (:attributes g) (:chr vc) (:start vc)))
       ))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-vc-attr [:format &quot;AD&quot;]
  [vc attr retrievers]
  (get-vc-attr vc &quot;AD&quot; retrievers))</pre></td></tr><tr><td class="docs"><p>Convert p-value into Phred scores compatible with bayesian likelihoods</p>
</td><td class="codes"><pre class="brush: clojure">(defn convert-pval-to-phred
  [pval]
  (max (* 10.0 (Math/log10 (to-float pval)))
       -255.0))</pre></td></tr><tr><td class="docs"><p>Retrieve PLs, handling non-Bayesian callers by conversion of p-values to phred scores.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-pls
  [vc]
  {:pre [(= 1 (:num-samples vc))
         (contains? #{1 2} (-&gt; vc :genotypes first :alleles count))]}
  (let [g (-&gt; vc :genotypes first)
        pls (dissoc (get-likelihoods (:genotype g) :no-convert true)
                    (:type g))
        pval (when-let [pval (get-in g [:attributes &quot;PVAL&quot;])]
               (convert-pval-to-phred pval))]
    (-&gt; (:genotype g)
        (get-likelihoods :no-convert true)
        (dissoc (:type g))
        (-&gt;/when pval
          (assoc &quot;HOM_REF&quot; pval)))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-vc-attr &quot;PL&quot;
  ^{:doc &quot;Provide likelihood confidence for the called genotype.
          For reference calls, retrieve the likelihood of the most likely
          variant (least negative). For variant calls, retrieve
          the reference likelihood.
          Handles non-Bayesian callers by conversion of p-values for phred scores.&quot;}
  [vc attr _]
  (let [g (-&gt; vc :genotypes first)
        pls (get-pls vc)]
    (when-not (empty? pls)
      (if (= (:type g) &quot;HOM_REF&quot;)
        (apply max (vals pls))
        (get pls &quot;HOM_REF&quot;)))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-vc-attr &quot;PLratio&quot;
  ^{:doc &quot;Calculate ratio of reference likelihood call to alternative variant calls.
          This helps measure whether a call is increasingly likely to be reference
          compared with variant choices.&quot;}
  [vc attr _]
  {:pre [(= 1 (:num-samples vc))]}
  (let [g (-&gt; vc :genotypes first)
        pls (dissoc (get-likelihoods (:genotype g) :no-convert true)
                    (:type g))]
    (when-not (zero? (count pls))
      (/ (get pls &quot;HOM_REF&quot;)
         (apply min (cons -1.0 (-&gt; pls (dissoc &quot;HOM_REF&quot;) vals)))))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-vc-attr &quot;QUAL&quot;
  [vc attr _]
  (:qual vc))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-vc-attr [:format &quot;DP&quot;]
  ^{:doc &quot;Retrieve depth from Genotype FORMAT metrics.
          Handles custom cases like cortex_var with alternative
          depth attributes, and Illumina with (DPU and DPI).&quot;}
  [vc attr _]
  {:pre [(= 1 (:num-samples vc))]}
  (letfn [(contains-good? [xs x]
            (and (contains? xs x)
                 (not= (get xs x) -1)
                 (not= (get xs x) [])))]
    (let [g-attrs (-&gt; vc :genotypes first :attributes)]
      (cond
       (contains-good? g-attrs &quot;DP&quot;) (to-float (get g-attrs &quot;DP&quot;))
       (contains-good? g-attrs &quot;AD&quot;) (to-float (apply + (get g-attrs &quot;AD&quot;)))
       (contains-good? g-attrs &quot;COV&quot;) (int (apply + (map to-float (string/split (get g-attrs &quot;COV&quot;) #&quot;,&quot;))))
       (contains-good? g-attrs &quot;DPU&quot;) (to-float (get g-attrs &quot;DPU&quot;))
       (contains-good? g-attrs &quot;DPI&quot;) (to-float (get g-attrs &quot;DPI&quot;))
       :else nil))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-vc-attr &quot;DP&quot;
  ^{:doc &quot;Retrieve depth for an allele, first trying genotype information
          then falling back on information in INFO column.&quot;}
  [vc attr rets]
  (if-let [gt-dp (when (= 1 (:num-samples vc))
                   (get-vc-attr vc [:format attr] rets))]
    gt-dp
    (to-float (get-in vc [:attributes attr]))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-vc-attr &quot;Context&quot;
  ^{:doc &quot;Retrieve cytosine context, relative to standard CG sites&quot;}
  [vc attr _]
  (let [ctxt (get-in vc [:attributes attr])]
    (if (string? ctxt) ctxt (first ctxt))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-vc-attr &quot;CM&quot;
  ^{:doc &quot;Retrieve number of methylated cytosines, requires a single sample&quot;}
  [vc _ _]
  (let [g-attrs (when (= 1 (:num-samples vc))
                  (select-keys (-&gt; vc :genotypes first :attributes)
                               [&quot;CM&quot;]))]
    (when (seq g-attrs)
      (get g-attrs &quot;CM&quot;))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-vc-attr &quot;CU&quot;
  ^{:doc &quot;Retrieve percentage of methylated cytosines, requires a single sample&quot;}
  [vc _ _]
  (let [g-attrs (when (= 1 (:num-samples vc))
                  (reduce (fn [coll [k v]]
                            (assoc coll k (to-float v)))
                          {}
                          (select-keys (-&gt; vc :genotypes first :attributes)
                                       [&quot;CM&quot; &quot;CU&quot;])))]
    (when (= 2 (count g-attrs))
      (let [total (apply + (vals g-attrs))]
        (if (zero? total) 0.0 (/ (get g-attrs &quot;CM&quot;) total))))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-vc-attr :gemini
  ^{:doc &quot;Retrieve attribute information from associated Gemini index.&quot;}
  [vc attr retrievers]
  (when-let [getter (:gemini retrievers)]
    (getter vc attr)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-vc-attr :default
  [vc attr _]
  (let [x (get-in vc [:attributes attr])]
    (when-not (nil? x)
      (try (Float/parseFloat x)
           (catch java.lang.NumberFormatException _ x)))))</pre></td></tr><tr><td class="docs"><p>Retrieve attributes from variants independent of location.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-vc-attrs
  [vc attrs retrievers]
  (zipmap attrs (map #(get-vc-attr vc % retrievers) attrs)))</pre></td></tr><tr><td class="docs"><p>Retrieve quantile ranges of attributes for min/max normalization.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-vc-attr-ranges
  [attrs in-vcf ref retrievers]
  (letfn [(get-quartiles [[k v]]
            [k (stats/quantile (remove nil? v) :probs [0.05 0.95])])]
    (with-open [vcf-iter (gvc/get-vcf-iterator in-vcf ref)]
      (-&gt;&gt; (reduce (fn [coll vc]
                    (reduce (fn [icoll [k v]]
                              (assoc icoll k (cons v (get icoll k))))
                            coll (get-vc-attrs vc attrs retrievers)))
                  (zipmap attrs (repeat [])) (gvc/parse-vcf vcf-iter))
           (map get-quartiles)
           (into {})))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- get-external-retrievers
  [in-file ref-file]
  {:gemini (gemini/vc-attr-retriever in-file ref-file)})</pre></td></tr><tr><td class="docs"><p>Normalized attributes for each variant context in an input file.
   Passed two input VCFs:
    - in-vcf -- provides full range of inputs for classification and
      used for building normalization ranges.
    - work-vcf -- file for attribute retrieval, used to setup variable
      retrieval from external sources like Gemini</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti get-vc-attrs-normalized
  (fn [_ _ _ config] (keyword (get config :normalize &quot;default&quot;))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-vc-attrs-normalized :minmax
  ^{:doc &quot;Minimum/maximum normalization to a 0-1 scale using quartiles.&quot;}
  [attrs in-vcf ref config]
  (letfn [(min-max-norm [x [minv maxv]]
            (let [safe-maxv (if (= minv maxv) (inc maxv) maxv)
                  trunc-score-max (if (&lt; x safe-maxv) x safe-maxv)
                  trunc-score (if (&gt; trunc-score-max minv) trunc-score-max minv)]
              (/ (- trunc-score minv) (- safe-maxv minv))))
          (min-max-norm-ranges [mm-ranges [k v]]
            [k (when-not (nil? v)
                 (min-max-norm v (get mm-ranges k)))])]
    (let [retrievers (get-external-retrievers in-vcf ref)
          mm-ranges (get-vc-attr-ranges attrs in-vcf ref retrievers)]
      (fn [work-vcf]
        (let [work-retrievers (get-external-retrievers work-vcf ref)]
          (fn [vc]
            (-&gt;&gt; (get-vc-attrs vc attrs work-retrievers)
                 (map (partial min-max-norm-ranges mm-ranges))
                 (into {}))))))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-vc-attrs-normalized :log
  ^{:doc &quot;Log normalization of specified input variables.&quot;}
  [attrs in-vcf ref config]
  (let [base-fn (get-vc-attrs-normalized attrs in-vcf ref (assoc config :normalize :default))
        need-log-vars (set (:log-attrs config))]
    (fn [work-vcf]
      (let [inner-fn (base-fn work-vcf)]
        (fn [vc]
          (reduce (fn [coll [k v]]
                    (assoc coll k
                           (if (contains? need-log-vars k) (Math/log v) v)))
                  {} (inner-fn vc)))))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-vc-attrs-normalized :default
  ^{:doc &quot;Attribute access without normalization.&quot;}
  [attrs _ ref config]
  (fn [work-vcf]
    (let [retrievers (get-external-retrievers work-vcf ref)]
      (fn [vc]
        (into {} (get-vc-attrs vc attrs retrievers))))))</pre></td></tr><tr><td class="docs"><p>Provide easy lookup of attributes from multiple input sources</p>
</td><td class="codes"><pre class="brush: clojure">(defn prep-vc-attr-retriever
  [in-file ref-file]
  (let [retrievers (get-external-retrievers in-file ref-file)]
    (fn [attrs vc]
      (into {} (get-vc-attrs vc attrs retrievers)))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.filter.classify" name="bcbio.variation.filter.classify"><h1 class="project-name">bcbio.variation.filter.classify</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Provide classification based filtering for variants.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.filter.classify
  (:import [org.broadinstitute.sting.utils.variantcontext VariantContextBuilder]
           [org.broadinstitute.sting.utils.codecs.vcf VCFHeader VCFInfoHeaderLine
            VCFHeaderLineType VCFFilterHeaderLine VCFHeaderLineCount])
  (:use [ordered.set :only [ordered-set]]
        [clojure.math.combinatorics :only [cartesian-product]]
        [clj-ml.utils :only [serialize-to-file deserialize-from-file]]
        [clj-ml.data :only [make-dataset dataset-set-class make-instance]]
        [clj-ml.classifiers :only [make-classifier classifier-train
                                   classifier-evaluate classifier-classify]]
        [bcbio.variation.filter.util :only [remove-cur-filters]]
        [bcbio.variation.filter.attr :only [get-vc-attrs-normalized prep-vc-attr-retriever]]
        [bcbio.variation.filter.intervals :only [pipeline-combine-intervals]]
        [bcbio.variation.variantcontext :only [parse-vcf write-vcf-w-template
                                               get-vcf-iterator has-variants?
                                               get-vcf-retriever variants-in-region]])
  (:require [clojure.string :as string]
            [fs.core :as fs]
            [bcbio.run.itx :as itx]
            [bcbio.variation.filter.trusted :as trusted]
            [bcbio.variation.filter.rules :as rules]
            [bcbio.variation.variantcontext :as gvc]))</pre></td></tr><tr><td class="docs"><h2>Split variants for classification</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Define splitting of classifiers based on variant characteristics.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- classifier-types
  [attr-key]
  (let [variant-types [:snp :complex]
        zygosity [:hom :het]]
    (map (fn [[vtype z]] {:variant-type vtype
                          :attr-key attr-key
                          :zygosity z})
         (cartesian-product variant-types zygosity))))</pre></td></tr><tr><td class="docs"><p>Convert a classifier types into a string name for output files.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- ctype-to-str
  [x]
  (str (name (:attr-key x)) &quot;-&quot;
       (name (:variant-type x)) &quot;_&quot;
       (name (:zygosity x))))</pre></td></tr><tr><td class="docs"><p>Map variant types to specialized classifiers.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-classifier-type
  [vc attr-key attr-get]
  {:variant-type (case (:type vc)
                   &quot;SNP&quot; :snp
                   :complex)
   :attr-key attr-key
   :zygosity (rules/vc-zygosity vc)})</pre></td></tr><tr><td class="docs"><h2>Linear classifier</h2>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- get-vc-inputs
  [attrs normalizer group vc]
  (let [n-vals (normalizer vc)]
    (conj (vec (map #(get n-vals %) attrs)) group)))</pre></td></tr><tr><td class="docs"><p>Retrieve normalized training inputs from VCF file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-train-inputs
  [group in-vcf ctype attrs normalizer ref]
  (let [attr-get (prep-vc-attr-retriever in-vcf ref)]
    (with-open [vcf-iter (get-vcf-iterator in-vcf ref)]
      (-&gt;&gt; (parse-vcf vcf-iter)
           (filter #(= ctype (get-classifier-type % (:attr-key ctype) attr-get)))
           (map (partial get-vc-inputs attrs normalizer group))
           doall))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- get-dataset
  [attrs inputs]
  (make-dataset &quot;ds&quot; (conj (vec attrs) {:c [:pass :fail]}) inputs {:class :c}))</pre></td></tr><tr><td class="docs"><p>Do the work of training a variant classifier.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- train-vcf-classifier
  [ctype attrs pre-normalizer true-vcf false-vcf ref config]
  (let [config (merge {:normalize :default} config)
        inputs (concat (get-train-inputs :pass true-vcf ctype attrs
                                         (pre-normalizer true-vcf)
                                         ref)
                       (get-train-inputs :fail false-vcf ctype attrs
                                         (pre-normalizer false-vcf)
                                         ref))
        classifier (case (keyword (get config :classifier-type :svm))
                     :svm (make-classifier :support-vector-machine :smo
                                           {:complexity-constant 100.0})
                     :svm-rbf (make-classifier :support-vector-machine :smo
                                               {:kernel-function {:radial-basis {:gamma 0.01}}
                                                :complexity-constant 100000.0})
                     :random-forest (make-classifier :decision-tree :random-forest
                                                     {:num-trees-in-forest 50
                                                      :num-features-to-consider
                                                      (-&gt; attrs count Math/sqrt Math/ceil int)}))]
    (when (seq inputs)
      (-&gt;&gt; (get-dataset attrs inputs)
           (classifier-train classifier)))))</pre></td></tr><tr><td class="docs"><p>Provide a variant classifier based on provided attributes and true/false examples.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- build-vcf-classifiers
  [attr-map pre-normalizer base-vcf true-vcf false-vcf ref config out-dir]
  (letfn [(build-vcf-classifier [ctype attrs]
            (let [out-dir (if (nil? out-dir) (str (fs/parent base-vcf)) out-dir)
                  out-file (format &quot;%s/%s-%s-classifier.bin&quot; out-dir
                                   (fs/name base-vcf) (ctype-to-str ctype))]
              (if-not (itx/needs-run? out-file)
                (deserialize-from-file out-file)
                (when-let [classifier (train-vcf-classifier ctype attrs pre-normalizer true-vcf false-vcf
                                                            ref config)]
                  (serialize-to-file classifier out-file)
                  classifier))))]
    (let [ctypes (mapcat classifier-types (keys attr-map))]
      (zipmap ctypes (map #(build-vcf-classifier % (get attr-map (:attr-key %))) ctypes)))))</pre></td></tr><tr><td class="docs"><p>Add details on the filtering to the VCF file header.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- add-cfilter-header
  [attrs]
  (fn [_ header]
    (let [str-attrs (map (fn [[k v]] (str (name k) &quot;: &quot; (string/join &quot;,&quot; v))) attrs)
          desc (str &quot;Classification filters based on true/false positives for: &quot;
                    (string/join &quot;; &quot; str-attrs))
          new #{(VCFInfoHeaderLine. &quot;CFILTERS&quot; VCFHeaderLineCount/UNBOUNDED
                                    VCFHeaderLineType/String desc)
                (VCFFilterHeaderLine. &quot;CScoreFilter&quot; &quot;Based on classifcation CFILTERS&quot;)}]
      (VCFHeader. (apply ordered-set (concat (.getMetaDataInInputOrder header) new))
                  (.getGenotypeSamples header)))))</pre></td></tr><tr><td class="docs"><p>Check if a variant passes, including external metadata annotations.
   - trusted: pass variants that overlap in the trusted set
   - xspecific: exclude variants specific to a technology or caller
   - otherwise check the variant filters that failed, passing those that are clean</p>
</td><td class="codes"><pre class="brush: clojure">(defn- vc-passes-w-meta?
  [vc c-filters meta-getters config]
  (letfn [(meta-has-variants? [kw]
            (has-variants? (get meta-getters kw)
                           (:chr vc) (:start vc) (:end vc)
                           (:ref-allele vc) (:alt-alleles vc)))]
    (cond
     (meta-has-variants? :trusted) true
     (meta-has-variants? :xspecific) false
     (empty? c-filters) true
     :else false)))</pre></td></tr><tr><td class="docs"><p>Update a variant context with filter information from classifier.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- filter-vc
  [cs normalizer attr-get meta-getters config vc]
  (letfn [(check-attrgroup-classifier [[attr-key attrs]]
            (let [c (get cs (get-classifier-type vc attr-key attr-get))
                  val (get-vc-inputs attrs normalizer :fail vc)
                  score (classifier-classify c (-&gt; (get-dataset attrs 1)
                                                   (make-instance val)))]
              (when (pos? score) attr-key)))]
    (let [c-filters (-&gt;&gt; (:classifiers config)
                         (map check-attrgroup-classifier)
                         (remove nil?))]
      (-&gt; (VariantContextBuilder. (:vc vc))
          (.attributes (assoc (:attributes vc) &quot;CFILTERS&quot; (if (empty? c-filters)
                                                            &quot;None&quot;
                                                            (string/join &quot;,&quot; (map name c-filters)))))
          (.filters (when-not (vc-passes-w-meta? vc c-filters meta-getters config)
                      #{&quot;CScoreFilter&quot;}))
          .make))))</pre></td></tr><tr><td class="docs"><p>Retrieve variants to use for true/false positive training.
   Dispatches based on approach used. For recalling, we can pull directly
   from input files</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti get-train-variants
  (fn [orig-file train-files call exp config call-type out-dir]
    (let [is-recall (get call :recall false)
          recall-approach (keyword (get-in exp [:params :compare-approach] :consensus))]
      (if is-recall
        (if (= :consensus recall-approach)
          [:recall (keyword call-type) (if (:round train-files) :iterate :final)]
          [:recall :rewrite])
        :default))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-train-variants [:recall :rewrite]
  ^{:doc &quot;Retrieve variants from original file based on variants in target file.&quot;}
  [orig-file target-files _ exp _ ext out-dir]
  (letfn [(get-orig-variants [retriever vc]
            (-&gt;&gt; (variants-in-region retriever (:chr vc) (:start vc) (:end vc))
                 (filter #(= (:start %) (:start vc)))
                 (map :vc)))]
    (let [out-file (itx/add-file-part orig-file ext out-dir)
          target-file (get target-files (keyword ext))]
      (when (itx/needs-run? out-file)
        (with-open [vcf-iter (get-vcf-iterator target-file (:ref exp))
                    retriever (get-vcf-retriever (:ref exp) orig-file)]
          (write-vcf-w-template orig-file {:out out-file}
                                (mapcat (partial get-orig-variants retriever)
                                        (parse-vcf vcf-iter))
                                (:ref exp))))
      out-file)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-train-variants [:recall :fps :iterate]
  ^{:doc &quot;Identify false positive variants directly from recalled consensus calls.
          These contain the `set` key value pair with information about supporting
          calls. We filter variants that have low support from multiple callers, then
          compare based on novelty in dbSNP. Novel and know have different inclusion
          parameters derived from examining real true/false calls in replicate
          experiments. The logic for inclusion is:
          - Variants with support from less than `fp-freq` percentage of callers.
            This defaults to less than 25% of callers used.
          - We exclude low mapping quality reads, which end up being non-representative
            of more general cases since they are poorly represented in true positives.
            This is worth looking at more for generalizing the approach to these regions.
          - Include indels in low entropy regions which are often problematic.
          - Include novel variants not found in dbSNP that have low read support.
          - Include known variants, in dbSNP, depending on type:
             - SNP: include SNPs with high likelihood of being ref&quot;}
  [orig-file _ call exp _ ext out-dir]
  (let [passes-rules? (rules/vc-checker orig-file call exp)]
    (letfn [(is-potential-fp? [vc]
              (or (passes-rules? vc
                                 :yes [:below-call-support :high-map-quality :het-snp :low-confidence])
                  (passes-rules? vc
                                 :yes [:below-call-support :high-map-quality :novel])
                  (passes-rules? vc
                                 :yes [:below-call-support :high-map-quality :low-confidence]
                                 :no [:novel])))]
    (gvc/select-variants orig-file is-potential-fp? ext (:ref exp)
                         :out-dir out-dir))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-train-variants [:recall :tps :iterate]
  ^{:doc &quot;Identify true positive training variants directly from recalled consensus.
          Use variants found in all input callers, then restrict similarly to false
          positives to maintain representative sets. We restrict by lower depth and
          problematic reference likelihoods. We also include high confidence calls
          with lower supporting calls to keep a wider range: these include SNPs with
          a low likelihood of being reference and known indels.&quot;}
  [orig-file _ call exp _ ext out-dir]
  (let [passes-rules? (rules/vc-checker orig-file call exp)]
    (letfn [(is-tp? [vc]
              (passes-rules? vc :yes [:all-callers :flex-low-confidence]))]
      (gvc/select-variants orig-file is-tp? ext (:ref exp)
                           :out-dir out-dir))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-train-variants [:recall :trusted :iterate]
  ^{:doc &quot;Retrieve set of trusted variants based on input parameters and recalled consensus.&quot;}
  [orig-file _ call exp params ext out-dir]
  (let [calls (remove #(= (:name %) (:name call)) (:calls exp))]
    (letfn [(is-trusted? [vc]
              (when-let [trusted (:trusted params)]
                (trusted/is-trusted-variant? vc trusted calls)))]
      (gvc/select-variants orig-file is-trusted? ext (:ref exp)
                           :out-dir out-dir))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-train-variants [:recall :trusted :final]
  [orig-file train-files call exp params ext out-dir]
  (get-train-variants orig-file (assoc train-files :round 1) call exp params ext out-dir))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-train-variants [:recall :xspecific :final]
  ^{:doc &quot;Retrieve specific variants to exclude, handling variants falling below untrusted thresh.
          The `untrusted` keyword in the configuration parameters specifies the threshold to use.&quot;}
  [orig-file train-files call exp params ext out-dir]
  (with-open [xspecific-get (gvc/get-vcf-retriever (:ref exp) (:xspecific train-files))]
    (let [calls (remove #(= (:name %) (:name call)) (:calls exp))]
      (letfn [(xspecific? [vc]
                (has-variants? xspecific-get
                               (:chr vc) (:start vc) (:end vc)
                               (:ref-allele vc) (:alt-alleles vc)))
              (untrusted? [vc]
                (when-let [untrusted (:untrusted params)]
                      (not (trusted/is-trusted-variant? vc untrusted calls))))
              (is-untrusted? [vc]
                (or (untrusted? vc) (xspecific? vc)))]
        (gvc/select-variants orig-file is-untrusted? ext (:ref exp)
                             :out-dir out-dir)))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-train-variants [:recall :tps :final]
  ^{:doc &quot;Iteratively identify true positive variants: low support variants
          that pass the previous round of filtering.&quot;}
  [orig-file train-files call exp params ext out-dir]
  (let [passes-rules? (rules/vc-checker orig-file call exp)
        out-file (itx/add-file-part orig-file &quot;tps&quot; out-dir)]
    (letfn [(low-support-novel? [vc]
              (passes-rules? vc
                             :yes [:below-call-support :het-snp :novel :low-depth]))
            (is-previous-tp? [vc]
              (when-not (low-support-novel? vc)
                (or
                 (passes-rules? vc
                                :yes [:below-call-support :passes-filter]
                                :no [:problem-allele-balance
                                     :low-confidence-novel-het-snp])
                 (passes-rules? vc
                                :yes [:below-call-support :het-snp :good-pl]
                                :no [:problem-allele-balance :novel]))))]
      (when (itx/needs-run? out-file)
        (-&gt; (:prev train-files)
            (gvc/select-variants is-previous-tp? ext (:ref exp)
                                 :out-dir out-dir)
            (remove-cur-filters (:ref exp))
            (fs/rename out-file))))
    out-file))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-train-variants [:recall :fps :final]
  ^{:doc &quot;Iteratively identify false positive variants: low support variants
          that fail the previous round of filtering.&quot;}
  [orig-file train-files call exp params ext out-dir]
  (let [passes-rules? (rules/vc-checker orig-file call exp)
        out-file (itx/add-file-part orig-file &quot;fps&quot; out-dir)]
    (letfn [(well-supported-known? [vc]
              (passes-rules? vc
                             :yes [:below-call-support :het-snp]
                             :no [:novel :low-depth]))
            (is-previous-fp? [vc]
              (when-not (well-supported-known? vc)
                (or (passes-rules? vc
                                   :yes [:below-call-support :high-map-quality]
                                   :no [:passes-filter])
                    (passes-rules? vc
                                   :yes [:below-call-support :high-map-quality
                                         :het-snp :low-confidence :novel]))))]
      (when (itx/needs-run? out-file)
        (-&gt; (:prev train-files)
            (gvc/select-variants is-previous-fp? ext (:ref exp)
                                 :out-dir out-dir)
            (remove-cur-filters (:ref exp))
            (fs/rename out-file))))
    out-file))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-train-variants :default
  ^{:doc &quot;By default, return the prepped training file with no changes.&quot;}
  [_ train-files _ _ _ ext _]
  (get train-files (keyword ext)))</pre></td></tr><tr><td class="docs"><p>Filter an input VCF file using a trained classifier on true/false variants.</p>
</td><td class="codes"><pre class="brush: clojure">(defn filter-vcf-w-classifier
  [base-vcf train-files call exp config]
  (let [out-dir (when-let [tround (:round train-files)]
                  (str (fs/file (fs/parent base-vcf) &quot;trainround&quot;) tround))
        out-file (itx/add-file-part base-vcf &quot;cfilter&quot; out-dir)]
    (when (and out-dir (not (fs/exists? out-dir)))
      (fs/mkdirs out-dir))
    (when (itx/needs-run? out-file)
      (let [true-vcf (get-train-variants base-vcf train-files call exp config
                                         &quot;tps&quot; out-dir)
            false-vcf (get-train-variants base-vcf train-files call exp config
                                          &quot;fps&quot; out-dir)
            trusted-vcf (get-train-variants base-vcf train-files call exp
                                            config &quot;trusted&quot; out-dir)
            xspecific-vcf (get-train-variants base-vcf train-files call exp config
                                              &quot;xspecific&quot; out-dir)
            ref (:ref exp)
            pre-normalizer (get-vc-attrs-normalized (apply concat (vals (:classifiers config)))
                                                    base-vcf ref config)
            cs (build-vcf-classifiers (:classifiers config) pre-normalizer base-vcf
                                      true-vcf false-vcf ref config out-dir)
            config (merge {:normalize :default} config)
            attr-get (prep-vc-attr-retriever base-vcf ref)]
        (println &quot;Filter VCF with&quot; (str cs))
        (with-open [vcf-iter (get-vcf-iterator base-vcf ref)
                    trusted-get (get-vcf-retriever ref trusted-vcf)
                    xspecific-get (get-vcf-retriever ref xspecific-vcf)]
          (write-vcf-w-template base-vcf {:out out-file}
                                (map (partial filter-vc cs (pre-normalizer base-vcf) attr-get
                                              {:trusted trusted-get :xspecific xspecific-get}
                                              config)
                                     (parse-vcf vcf-iter))
                                ref :header-update-fn (add-cfilter-header (:classifiers config))))))
    out-file))</pre></td></tr><tr><td class="docs"><p>Fit VCF classification-based filtering into analysis pipeline.</p>
</td><td class="codes"><pre class="brush: clojure">(defn pipeline-classify-filter
  [in-vcf train-info call exp params config]
  (letfn [(get-train-vcf [type]
            (-&gt; (filter #(= type (:name %)) train-info)
                first
                :file))
          (fix-param-classifiers [params]
            (if (map? (:classifiers params))
              params
              (assoc params :classifiers {:all (:classifiers params)})))
          (flatten-param-classifiers [params]
            (assoc params :classifiers
                   {:all (-&gt;&gt; (:classifiers params) vals (apply concat) set vec)}))]
    (pipeline-combine-intervals exp config)
    (let [orig-trains {:tps (get-train-vcf &quot;concordant&quot;)
                       :fps (get-train-vcf &quot;discordant&quot;)
                       :trusted (get-train-vcf &quot;trusted&quot;)
                       :xspecific (get-train-vcf &quot;xspecific&quot;)}
          params (fix-param-classifiers params)
          x1 (filter-vcf-w-classifier in-vcf (assoc orig-trains :round 1)
                                      call exp (flatten-param-classifiers params))]
      (filter-vcf-w-classifier in-vcf (assoc orig-trains :prev x1) call exp params))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.filter.intervals" name="bcbio.variation.filter.intervals"><h1 class="project-name">bcbio.variation.filter.intervals</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Combined interval lists from filtered variants prepared via multiple calls.
  Multiple call approaches and technologies result in reduced call regions due
  to coverage. These functions manage creation of reduced BED files.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.filter.intervals
  (:import [org.broadinstitute.sting.utils.interval IntervalUtils
            IntervalMergingRule IntervalSetRule]
           [org.broadinstitute.sting.utils GenomeLocParser
            GenomeLocSortedSet]
           [org.broadinstitute.sting.utils.exceptions UserException$BadInput])
  (:use [clojure.java.io]
        [clojure.set :only [intersection]]
        [bcbio.align.ref :only [get-seq-dict]]
        [bcbio.variation.callable :only [get-callable-bed get-bed-iterator]]
        [bcbio.variation.variantcontext :only [get-vcf-header]])
  (:require [fs.core :as fs]
            [bcbio.run.itx :as itx]
            [bcbio.run.broad :as broad]))</pre></td></tr><tr><td class="docs"><h2>interval VCF subsetting by BED</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Retrieve samples identified in the input VCF file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-sample-names
  [in-vcf]
  (-&gt; in-vcf get-vcf-header .getGenotypeSamples vec))</pre></td></tr><tr><td class="docs"><p>Retrieve the sample name in a provided VCF file, allowing for partial matches.</p>
</td><td class="codes"><pre class="brush: clojure">(defn vcf-sample-name
  [sample in-vcf ref-file]
  (letfn [(sample-match [x choices]
            (let [do-match (filter #(when (.contains % x) %) choices)]
              (when (= 1 (count do-match))
                (first do-match))))]
    (let [vcf-samples (-&gt; in-vcf get-vcf-header .getGenotypeSamples set)]
      (cond
       (contains? vcf-samples sample) sample
       (= 1 (count vcf-samples)) (first vcf-samples)
       :else (sample-match sample vcf-samples)))))</pre></td></tr><tr><td class="docs"><p>Select only the sample of interest from input VCF files.</p>
</td><td class="codes"><pre class="brush: clojure">(defn select-by-sample
  [sample in-file name ref &amp; {:keys [out-dir intervals remove-refcalls ext
                                     exclude-intervals]
                              :or {remove-refcalls false}}]
  (let [base-dir (if (nil? out-dir) (fs/parent in-file) out-dir)
        file-info {:out-vcf (if ext (itx/add-file-part in-file ext out-dir)
                                (str (fs/file base-dir
                                              (format &quot;%s-%s.vcf&quot; sample name))))}
        args (concat [&quot;-R&quot; ref
                      &quot;--sample_name&quot; (vcf-sample-name sample in-file ref)
                      &quot;--variant&quot; in-file
                      &quot;--unsafe&quot; &quot;ALL&quot; ; &quot;ALLOW_SEQ_DICT_INCOMPATIBILITY&quot;
                      &quot;--out&quot; :out-vcf]
                     (when remove-refcalls [&quot;--excludeNonVariants&quot; &quot;--excludeFiltered&quot;])
                     (when exclude-intervals [&quot;--excludeIntervals&quot; exclude-intervals])
                     (broad/gatk-cl-intersect-intervals intervals ref))]
    (if-not (fs/exists? base-dir)
      (fs/mkdirs base-dir))
    (broad/run-gatk &quot;SelectVariants&quot; args file-info {:out [:out-vcf]})
    (:out-vcf file-info)))</pre></td></tr><tr><td class="docs"><h2>BED manipulation</h2>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- bed-to-intervals
  [bed-file ref-file loc-parser]
  (with-open [bed-iter (get-bed-iterator bed-file ref-file)]
    (doall (map #(.createGenomeLoc loc-parser %) bed-iter))))</pre></td></tr><tr><td class="docs"><p>Intersect a group of intervals present on a contig.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- intersect-by-contig
  [start-intervals combine-rule]
  (loop [final []
         intervals start-intervals]
    (if (empty? intervals)
      final
      (recur (try (IntervalUtils/mergeListsBySetOperator final (first intervals)
                                                         (if (= :union combine-rule)
                                                           IntervalSetRule/UNION
                                                           IntervalSetRule/INTERSECTION))
                  (catch UserException$BadInput e []))
             (rest intervals)))))</pre></td></tr><tr><td class="docs"><p>Intersect and exclude intervals on a contig.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- prep-intervals-by-contig
  [start-intervals exclude-intervals loc-parser combine-rule]
  (let [overlaps (intersect-by-contig start-intervals combine-rule)]
    (if (empty? exclude-intervals)
      overlaps
      (let [clean-intervals (-&gt;&gt; (group-by #(.getStart %) exclude-intervals)
                                 vals
                                 (map (fn [xs] (sort-by #(.size %) &gt; xs)))
                                 (map first))]
        (-&gt; (GenomeLocSortedSet/createSetFromList loc-parser overlaps)
            (.subtractRegions (GenomeLocSortedSet/createSetFromList loc-parser clean-intervals))
            .toList)))))</pre></td></tr><tr><td class="docs"><p>Generate list of intervals that intersect in all provided BED files.</p>
</td><td class="codes"><pre class="brush: clojure">(defn intersection-of-bed-files
  [all-beds ref loc-parser &amp; {:keys [exclude-bed combine-rule]}]
  (letfn [(intervals-by-chrom [bed-file]
            (group-by #(.getContig %) (bed-to-intervals bed-file ref loc-parser)))
          (get-by-contig [interval-groups contig]
            (map #(get % contig []) interval-groups))]
    (let [interval-groups (map intervals-by-chrom all-beds)
          exclude-by-contig (if exclude-bed (intervals-by-chrom exclude-bed) {})
          contigs (vec (apply intersection (map #(set (keys %)) interval-groups)))]
      (mapcat #(prep-intervals-by-contig (get-by-contig interval-groups %)
                                         (get exclude-by-contig % []) loc-parser
                                         combine-rule)
              contigs))))</pre></td></tr><tr><td class="docs"><p>Combine intervals from an initial BED and coverage BAM files.</p>
</td><td class="codes"><pre class="brush: clojure">(defn combine-multiple-intervals
  [initial-bed align-bams ref &amp; {:keys [out-dir name exclude-intervals combine-rule
                                        more-beds]}]
  (let [all-beds (concat [initial-bed] more-beds
                         (map #(get-callable-bed % ref :out-dir out-dir
                                                 :intervals initial-bed)
                              align-bams))
        loc-parser (GenomeLocParser. (get-seq-dict ref))
        out-file (itx/add-file-part initial-bed
                                    (str (if name (str name &quot;-&quot;) &quot;&quot;) &quot;multicombine&quot;)
                                    out-dir)]
    (when (itx/needs-run? out-file)
      (with-open [wtr (writer out-file)]
        (doseq [x (IntervalUtils/sortAndMergeIntervals
                   loc-parser (intersection-of-bed-files all-beds ref loc-parser
                                                         :exclude-bed exclude-intervals
                                                         :combine-rule combine-rule)
                   IntervalMergingRule/ALL)]
          (.write wtr (format &quot;%s\t%s\t%s\n&quot; (.getContig x) (dec (.getStart x)) (.getStop x))))))
    out-file))</pre></td></tr><tr><td class="docs"><p>Combine multiple intervals as part of processing and filtering pipeline.</p>
</td><td class="codes"><pre class="brush: clojure">(defn pipeline-combine-intervals
  [exp config]
  (let [base-intervals (:intervals exp)
        all-aligns (set (remove nil? (map :align (cons exp (:calls exp)))))]
    (when (and base-intervals (seq all-aligns))
      (combine-multiple-intervals base-intervals all-aligns
                                  (:ref exp)
                                  :exclude-intervals (:exclude-intervals exp)
                                  :name (:sample exp)
                                  :out-dir (get-in config [:dir :prep] (get-in config [:dir :out]))))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.filter.rules" name="bcbio.variation.filter.rules"><h1 class="project-name">bcbio.variation.filter.rules</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Define filtration rules used to help identify true/false positives for variant classification.
   Helps organize the logic of selecting variants.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.filter.rules
  (:require [bcbio.variation.filter.attr :as attr]
            [bcbio.variation.metrics :as metrics]
            [bcbio.variation.multiple :as multiple]))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn vc-zygosity [vc]
  (if (some #(.startsWith (:type %) &quot;HET&quot;) (:genotypes vc)) :het :hom))</pre></td></tr><tr><td class="docs"><p>Check if a variant context has a low amount of supporting variant calls.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- below-support-thresh?
  [vc _ call exp]
  (let [freq (get call :fp-freq 0.25)
        thresh (Math/ceil (* freq (dec (count (:calls exp)))))]
    (-&gt; (multiple/get-vc-set-calls vc (:calls exp))
        (disj (:name call))
        count
        (&lt;= thresh))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- is-intersection? [vc _ _ _]
  (when-let [set-val (get-in vc [:attributes &quot;set&quot;])]
    (= set-val &quot;Intersection&quot;)))</pre></td></tr><tr><td class="docs"><p>Is a variant novel, or is it represented in dbSNP?</p>
</td><td class="codes"><pre class="brush: clojure">(defn- novel-variant?
  [vc _ _ _]
  (contains? #{nil &quot;.&quot;} (:id vc)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- het-snp? [vc _ _ _]
  (and (= &quot;SNP&quot; (:type vc))
       (= :het (vc-zygosity vc))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- het-indel? [vc _ _ _]
  (and (not= &quot;SNP&quot; (:type vc))
       (= :het (vc-zygosity vc))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn novel-het-indel? [vc g c e]
  (and (het-indel? vc g c e) (novel-variant? vc g c e)))</pre></td></tr><tr><td class="docs"><p>Define low confidence calls.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- low-call-confidence?
  [vc attr-get _ _]
  (let [attrs (attr-get [&quot;PL&quot; &quot;PLratio&quot;] vc)]
    (when (not (nil? (get attrs &quot;PL&quot;)))
      (or (&gt; (get attrs &quot;PL&quot;) -7.5)
          (&lt; (or (get attrs &quot;PLratio&quot;) Float/MAX_VALUE) 0.25)))))</pre></td></tr><tr><td class="docs"><p>Identify PL ratios with reasonable support for being a variant.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- good-pl-support?
  [vc attr-get _ _]
  (let [attrs (attr-get [&quot;PLratio&quot;] vc)]
    (when (not-any? nil? (vals attrs))
      (&gt; (get attrs &quot;PLratio&quot;) 0.4))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- low-confidence-novel-het-snp?
  [vc attr-get c e]
  (and (low-call-confidence? vc attr-get c e)
       (novel-variant? vc attr-get c e)
       (het-snp? vc attr-get c e)))</pre></td></tr><tr><td class="docs"><p>Define calls with a more flexible low confidence call</p>
</td><td class="codes"><pre class="brush: clojure">(defn- flex-low-call-confidence?
  [vc attr-get _ _]
   (let [attrs (attr-get [&quot;PL&quot;] vc)]
    (when (not-any? nil? (vals attrs))
      (&gt; (get attrs &quot;PL&quot;) -20.0))))</pre></td></tr><tr><td class="docs"><p>Calls with low supporting depth</p>
</td><td class="codes"><pre class="brush: clojure">(defn- low-depth?
  [vc attr-get _ _]
  (let [attrs (attr-get [&quot;DP&quot;] vc)]
    (when (not-any? nil? (vals attrs))
      (&lt; (get attrs &quot;DP&quot;) 25.0))))</pre></td></tr><tr><td class="docs"><p>Avoid feeding low quality mapping into true/false positives.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- passes-mapping-quality?
  [vc attr-get _ _]
  (let [attrs (attr-get [&quot;MQ&quot;] vc)]
    (when (not-any? nil? (vals attrs))
      (&gt; (get attrs &quot;MQ&quot;) 50.0))))</pre></td></tr><tr><td class="docs"><p>Identify skewed allele balances indicative of artifacts.
   This is a signature of problem heterozygote calls from GATK Haplotype caller.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- artifact-allele-balance?
  [vc attr-get _ _]
  (let [attrs (attr-get [&quot;AD&quot;] vc)]
    (when (not-any? nil? (vals attrs))
      (&gt; (get attrs &quot;AD&quot;) 0.35))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- passes-filter?
  [vc _ _ _]
  (metrics/passes-filter? vc))</pre></td></tr><tr><td class="docs"><p>Define keyword mappings to function definitions</p>
</td><td class="codes"><pre class="brush: clojure">(def ^{:private true
       :doc }
  rules {:below-call-support below-support-thresh?
         :all-callers is-intersection? 
         :novel novel-variant?
         :het-snp het-snp?
         :het-indel het-indel?
         :novel-het-indel novel-het-indel?
         :low-confidence-novel-het-snp low-confidence-novel-het-snp?
         :low-confidence low-call-confidence?
         :good-pl good-pl-support?
         :flex-low-confidence flex-low-call-confidence?
         :low-depth low-depth?
         :passes-filter passes-filter?
         :high-map-quality passes-mapping-quality?
         :problem-allele-balance artifact-allele-balance?})</pre></td></tr><tr><td class="docs"><p>Identify variants conforming to supplied rules.</p>
</td><td class="codes"><pre class="brush: clojure">(defn vc-checker
  [orig-file call exp]
  (let [attr-get (attr/prep-vc-attr-retriever orig-file (:ref exp))]
    (letfn [(call-rule [vc rulekw]
              ((get rules rulekw) vc attr-get call exp))]
      (fn [vc &amp; {:keys [yes no]}]
        (and (every? (partial call-rule vc) yes)
             (not-any? (partial call-rule vc) no))))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.filter.specific" name="bcbio.variation.filter.specific"><h1 class="project-name">bcbio.variation.filter.specific</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Identify technology or caller specific variants from multiple combined callsets.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.filter.specific
  (:import [org.broadinstitute.sting.utils.variantcontext VariantContextBuilder]
           [org.broadinstitute.sting.utils.codecs.vcf VCFHeader VCFInfoHeaderLine
            VCFHeaderLineCount VCFHeaderLineType])
  (:use [ordered.set :only [ordered-set]]
        [bcbio.variation.filter.attr :only [get-vc-attrs]]
        [bcbio.variation.filter.trusted :only [variant-set-metadata
                                               get-comparison-fullcombine]])
  (:require [bcbio.variation.variantcontext :as gvc])
  (:require [clojure.string :as string]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- get-specific
  [data kw-want kw-cmp]
  (when (and (= 1 (count (kw-want data)))
             (&gt; (count (kw-cmp data)) 1))
    (first (kw-want data))))</pre></td></tr><tr><td class="docs"><p>Check if a variant is specific to a caller or method.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-x-specific-designation
  [vc calls]
  (let [data (variant-set-metadata vc calls)]
    (reduce (fn [coll [kw-want kw-cmp]]
              (if-let [x (get-specific data kw-want kw-cmp)]
                (assoc coll kw-want x)
                coll))
            {} [[:caller :technology] [:technology :caller]])))</pre></td></tr><tr><td class="docs"><p>Add specificity information to a VariantContext if present.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- add-x-specific
  [vc calls]
  (letfn [(xspec-to-string [[k v]]
            (str (name k) &quot;:&quot; v))]
    (let [xspec (get-x-specific-designation vc calls)]
      (when (seq xspec)
        (-&gt; (VariantContextBuilder. (:vc vc))
            (.attributes (assoc (:attributes vc)
                           &quot;xspecific&quot; (-&gt;&gt; xspec
                                            (map xspec-to-string)
                                            (string/join &quot;,&quot;))))
            .make)))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- add-x-specific-header
  [_ header]
  (let [new #{(VCFInfoHeaderLine.
               &quot;xspecific&quot; VCFHeaderLineCount/UNBOUNDED VCFHeaderLineType/String
               &quot;Identify variant call as specific to a technology or calling method.&quot;)}]
    (VCFHeader. (apply ordered-set (concat (.getMetaDataInInputOrder header) new))
                (.getGenotypeSamples header))))</pre></td></tr><tr><td class="docs"><p>Simple measure to evaluate call support based on depth and allele balance.
   This identifies poorly supported items, which primarily make up false
   positive examples.</p>
</td><td class="codes"><pre class="brush: clojure">(defn poor-call-support?
  [vc &amp; {:keys [thresh]
         :or {thresh {:dp 100 :ad 0.05}}}]
  (let [attrs (get-vc-attrs vc [[:format &quot;AD&quot;] [:format &quot;DP&quot;]] {})]
    (and (when-let [dp (get attrs [:format &quot;DP&quot;])]
           (&lt; dp (:dp thresh)))
         (when-let [ad (get attrs [:format &quot;AD&quot;])]
           (&gt; ad (:ad thresh))))))</pre></td></tr><tr><td class="docs"><p>Filter VCF file generating output only variants specific to a technology or caller.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-x-specific-variants
  [cmps support exp config]
  (when-let [base-vcf (get-comparison-fullcombine cmps support config)]
    (let [out-file (itx/add-file-part base-vcf &quot;xspecific&quot;)]
      (when (itx/needs-run? out-file)
        (with-open [base-vcf-iter (gvc/get-vcf-iterator base-vcf (:ref exp))]
          (gvc/write-vcf-w-template base-vcf {:out out-file}
                                    (-&gt;&gt; (gvc/parse-vcf base-vcf-iter)
                                         (filter poor-call-support?)
                                         (map #(add-x-specific % (:calls exp)))
                                         (remove nil?))
                                    (:ref exp) :header-update-fn add-x-specific-header)))
      out-file)))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.filter.train" name="bcbio.variation.filter.train"><h1 class="project-name">bcbio.variation.filter.train</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Extract training cases from comparisons for machine learning approaches.
  Based on a comparison, identified potential true positives, false positives
  and false negatives to further tweak classifiers.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.filter.train
  (:use [clojure.java.io]
        [bcbio.variation.multiple :only [prep-cmp-name-lookup]])
  (:require [fs.core :as fs]
            [bcbio.run.broad :as broad]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><p>Retrieve output file of concordant calls between two sets of variant calls</p>
</td><td class="codes"><pre class="brush: clojure">(defn- select-concordant
  [fname1 fname2 ref out-file]
  (let [args [&quot;-R&quot; ref
              &quot;--variant&quot; fname1
              &quot;--concordance&quot; fname2
              &quot;--out&quot; :out-vcf]]
    (broad/run-gatk &quot;SelectVariants&quot; args {:out-vcf out-file} {:out [:out-vcf]}))
  out-file)</pre></td></tr><tr><td class="docs"><p>Common infrastructure for generating training values</p>
</td><td class="codes"><pre class="brush: clojure">(defn- prep-common
  [case-kw file-ext cases out-base ref-file]
  (letfn [(get-discordant-by-kw [x]
            (get-in x [:c-files (keyword (str (get x case-kw) &quot;-discordant&quot;))]))]
    (let [out-file (str out-base file-ext)]
      (when (itx/needs-run? out-file)
        (apply select-concordant
               (concat (map get-discordant-by-kw cases) [ref-file out-file])))
      out-file)))</pre></td></tr><tr><td class="docs"><p>Retrieve potential false negatives, discordant calls found in all of the
   comparison cases but not in the target.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- prep-false-negatives
  [cases out-base ref-file]
  (prep-common :cmp &quot;-potential-fns.vcf&quot;
               cases out-base ref-file))</pre></td></tr><tr><td class="docs"><p>Retrieve potential false positives, discordant calls from the target not
   found in any of the comparison cases.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- prep-false-positives
  [cases out-base ref-file]
  (prep-common :target &quot;-potential-fps.vcf&quot;
               cases out-base ref-file))</pre></td></tr><tr><td class="docs"><p>Retrieve cases to use for preparing training sets from supplied inputs.
   Prepares list of maps with :target :cmp :c-files, where the latter contains
   all original comparison files.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-train-cases
  [cmps-orig train-info]
  (letfn [(get-train-case [cmps target cmp]
            {:target target :cmp cmp
             :c-files (:c-files (get cmps [target cmp] (get cmps [cmp target])))})]
    (let [cmps (prep-cmp-name-lookup cmps-orig)]
      (map (partial get-train-case cmps (:target train-info)) (:cmps train-info)))))</pre></td></tr><tr><td class="docs"><p>Prepare exploratory training cases based on specified inputs</p>
</td><td class="codes"><pre class="brush: clojure">(defn extract-train-cases
  [cmps train-info exp config]
  (let [out-dir (str (file (get-in config [:dir :prep] (get-in config [:dir :out])) &quot;train&quot;))
        cases (get-train-cases cmps train-info)
        out-base (str (file out-dir (format &quot;%s-%s&quot; (:sample exp) (:target train-info))))]
    (when (not (fs/exists? out-dir))
      (fs/mkdirs out-dir))
    {:fns (prep-false-negatives cases out-base (:ref exp))
     :fps (prep-false-positives cases out-base (:ref exp))}))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.filter.trusted" name="bcbio.variation.filter.trusted"><h1 class="project-name">bcbio.variation.filter.trusted</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Retrieve trusted variants from comparisons based on configured thresholds.
  Allows specification of cases where we should trust variants to pass, such
  as: found in more than two sequencing technologies, or called in 3 aligners,
  or called in 7 out of 8 inputs.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.filter.trusted
  (:use [bcbio.variation.multiple :only [multiple-overlap-analysis remove-mod-name
                                         prep-cmp-name-lookup get-vc-set-calls]]
        [bcbio.variation.variantcontext :only [parse-vcf write-vcf-w-template
                                               get-vcf-iterator]])
  (:require [clojure.string :as string]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><p>Check if a comparison set is only pairwise and not multiple.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- pairwise-only?
  [cmp-names]
  (= 1 (count (set (map (fn [xs] (vec (map remove-mod-name xs))) cmp-names)))))</pre></td></tr><tr><td class="docs"><p>Retrieve supporting VCFs for a set of comparisons and specified support.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-support-vcfs
  [cmps support config &amp; {:keys [remove-mods?]}]
  (let [cmps-by-name (if (map? cmps) cmps (prep-cmp-name-lookup cmps :remove-mods? remove-mods?))
        support (if (and (not (coll? support)) (pairwise-only? (keys cmps-by-name)))
                  (first (keys cmps-by-name))
                  support)]
    (if (coll? support)
      (zipmap [:true-positives :false-positives]
              (take 2 (-&gt; cmps-by-name (get support) :c-files vals)))
      (let [x (multiple-overlap-analysis cmps-by-name config support)]
        (into {} (map (juxt identity x)
                      [:true-positives :false-positives :target-overlaps]))))))</pre></td></tr><tr><td class="docs"><p>Retrieve metadata associated with overlapping variants from combined set attribute.</p>
</td><td class="codes"><pre class="brush: clojure">(defn variant-set-metadata
  [vc calls]
  (when-let [set-calls (get-vc-set-calls vc calls)]
    (reduce (fn [coll x]
              (let [cur-name (string/replace (:name x) &quot;-&quot; &quot;_&quot;)]
                (if-not (contains? set-calls cur-name)
                  coll
                  (reduce (fn [inner [k v]]
                            (assoc inner k (conj (get inner k #{}) v)))
                          coll (assoc (get x :metadata {}) :total cur-name)))))
            {} calls)))</pre></td></tr><tr><td class="docs"><p>Determine if we trust a variant based on specified trust parameters.
  The params specify required counts for inclusion. For instance:
  {:total 4 :technology 3 :caller 2} includes variants located in 4 total calls
  or in three different technologies or in 2 different callers.
  It can also handle percentages for required inputs:
  {:total 1.0 :technology 0.75}</p>
</td><td class="codes"><pre class="brush: clojure">(defn is-trusted-variant?
  [vc params calls]
  (letfn [(collapse-md-by-type [calls]
            (reduce (fn [coll [k v]]
                      (assoc coll k (conj (get coll k #{}) v)))
                    {:total (set (map :name calls))}
                    (mapcat :metadata calls)))
          (calc-md-counts [calls]
            (reduce (fn [coll [k v]]
                      (assoc coll k (count v)))
                    {}
                    (collapse-md-by-type calls)))
          (param-passes? [metadata md-counts [k v]]
            (let [n (count (get metadata k []))]
              (if (&gt; v 1)
                (&gt;= n v)
                (&gt;= (/ n (get md-counts k)) v))))]
    (let [use-calls (remove :recall calls)]
      (some (partial param-passes? (variant-set-metadata vc use-calls)
                     (calc-md-counts use-calls))
            params))))</pre></td></tr><tr><td class="docs"><p>Retrieve the all variant fullcombine VCF for a set of comparisons.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-comparison-fullcombine
  [cmps support config]
  (:target-overlaps
   (get-support-vcfs cmps (if (coll? support) (first support) support)
                     config :remove-mods? true)))</pre></td></tr><tr><td class="docs"><p>Retrieve VCF file of trusted variants based on specific parameters.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-trusted-variants
  [cmps support params exp config]
  (when-let [base-vcf (get-comparison-fullcombine cmps support config)]
    (let [out-file (itx/add-file-part base-vcf &quot;trusted&quot;)]
      (when (itx/needs-run? out-file)
        (with-open [base-vcf-iter (get-vcf-iterator base-vcf (:ref exp))]
          (write-vcf-w-template base-vcf {:out out-file}
                                (-&gt;&gt; (parse-vcf base-vcf-iter)
                                     (filter #(is-trusted-variant? % params (:calls exp)))
                                     (map :vc))
                                (:ref exp))))
      out-file)))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.filter.util" name="bcbio.variation.filter.util"><h1 class="project-name">bcbio.variation.filter.util</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Provide useful utilities dealing with filtering of variants</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.filter.util
  (:import [org.broadinstitute.sting.utils.variantcontext
            VariantContextBuilder])
(:require [bcbio.run.itx :as itx]
          [bcbio.variation.variantcontext :as gvc]))</pre></td></tr><tr><td class="docs"><p>Remove any filter information in the supplied file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn remove-cur-filters
  [in-vcf ref]
  (letfn [(remove-vc-filter [vc]
            [:out (-&gt; (VariantContextBuilder. (:vc vc))
                      (.passFilters)
                      (.make))])]
    (let [out-file (itx/add-file-part in-vcf &quot;nofilter&quot;)]
      (when (itx/needs-run? out-file)
        (with-open [vcf-iter (gvc/get-vcf-iterator in-vcf ref)]
          (gvc/write-vcf-w-template in-vcf {:out out-file}
                                    (map remove-vc-filter (gvc/parse-vcf vcf-iter))
                                    ref)))
      out-file)))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.grade" name="bcbio.variation.grade"><h1 class="project-name">bcbio.variation.grade</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Support comparisons of variant calls to reference call sets, providing
   detailed metrics about problematic discordant calls.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.grade
  (:import [org.broadinstitute.sting.utils.codecs.vcf
            VCFInfoHeaderLine VCFHeaderLineType]
           [org.broadinstitute.sting.utils.variantcontext VariantContextBuilder])
  (:require [clojure.set :refer [intersection]]
            [clojure.string :as string]
            [clojure.math.combinatorics :as combo]
            [lonocloud.synthread :as -&gt;]
            [bcbio.run.itx :as itx]
            [bcbio.variation.annotation :as annotation]
            [bcbio.variation.combine :as combine]
            [bcbio.variation.filter.attr :as attr]
            [bcbio.variation.phasing :as phasing]
            [bcbio.variation.variantcontext :as gvc]))</pre></td></tr><tr><td class="docs"><h2>Utility functions</h2>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn is-grade-cmp?
  [exp]
  (= :grade (keyword (get exp :approach &quot;compare&quot;))))</pre></td></tr><tr><td class="docs"><p>Grading references are either haploid or identified with grading-ref type.</p>
</td><td class="codes"><pre class="brush: clojure">(defn is-grading-ref?
  [exp c]
  (or (= :grading-ref (keyword (:type c)))
      (-&gt; c :file (phasing/is-haploid? (:ref exp)))))</pre></td></tr><tr><td class="docs"><p>Separate grading reference and evaluation genome based on <code>type</code> parameter.
   Defaults to the first being reference and second evaluation if not defined.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- find-grading-and-eval-kws
  [exp c1 c2 c-files]
  (let [grade-groups (group-by (partial is-grading-ref? exp) [c1 c2])
        marked-ref (first (get grade-groups true))
        marked-eval (first (get grade-groups false))
        [truth-c eval-c] (if (and marked-ref marked-eval)
                           [marked-ref marked-eval]
                           [c1 c2])
        eval-kw (keyword (str (:name eval-c) &quot;-discordant&quot;))
        truth-kw (keyword (str (:name truth-c) &quot;-discordant&quot;))]
    {:eval (if (contains? c-files eval-kw) eval-kw :discordant)
     :truth (if (contains? c-files truth-kw) truth-kw :discordant-missing)}))</pre></td></tr><tr><td class="docs"><h2>Summarize grading results</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Decide on a likely reason for a discordant variant call</p>
</td><td class="codes"><pre class="brush: clojure">(defn- pick-discordant-reason
  [vc attr-getter]
  (letfn [(is-repeat-region? [attrs]
            (or (&lt; (or (get attrs &quot;gms_illumina&quot;) 100.0) 50.0)
                (contains? (or (get attrs &quot;rmsk&quot;) #{}) &quot;repeat&quot;)))
          (is-error-prone? [attrs]
            (contains? (or (get attrs &quot;in_cse&quot;) #{}) &quot;error-prone&quot;))]
    (let [attrs (attr-getter [&quot;DP&quot; &quot;rmsk&quot; &quot;gms_illumina&quot; &quot;in_cse&quot;] vc)]
      (cond
       (&lt; (or (get attrs &quot;DP&quot;) 500) 10) :low-coverage
       (is-error-prone? attrs) :error-prone
       (is-repeat-region? attrs) :repeat
       :else :other))))</pre></td></tr><tr><td class="docs"><p>Identify the variant type and discordant category.
   - variant types -- :snp :indel
   - discordant types -- :shared :missing :extra
   - reason types -- :hethom :vardiff :low-coverage :repeat :error-prone :other</p>
</td><td class="codes"><pre class="brush: clojure">(defn- identify-discordant-cat
  [vc attr-getter]
  (let [vtype (keyword (string/lower-case (:type vc)))
        cat (-&gt; (get-in vc [:attributes &quot;GradeCat&quot;])
                (string/replace &quot;discordant-&quot; &quot;&quot;)
                keyword)
        [dtype rtype] (case cat
                        (:missing :extra) [cat (pick-discordant-reason vc attr-getter)]
                        [:shared cat])]
    [vtype dtype rtype]))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- count-discordant-categories
  [vcf-file ref-file]
  (let [attr-getter (attr/prep-vc-attr-retriever vcf-file ref-file)]
    (with-open [in-vcf-iter (gvc/get-vcf-iterator vcf-file ref-file)]
      (reduce (fn [coll vc]
                (let [cat (identify-discordant-cat vc attr-getter)]
                  (assoc-in coll cat (inc (get-in coll cat 0)))))
              {} (gvc/parse-vcf in-vcf-iter)))))</pre></td></tr><tr><td class="docs"><p>Prepare detailed grading breakdown of concordant and discordant variants.
   The goal is to help identify common causes of discordance.</p>
</td><td class="codes"><pre class="brush: clojure">(defn prep-grade-breakdown
  [cmp]
  (let [kws (find-grading-and-eval-kws (:exp cmp) (:c1 cmp) (:c2 cmp)
                                       (:c-files cmp))
        vcf-file (get-in cmp [:c-files (:eval kws)])
        ref-file (get-in cmp [:exp :ref])
        summary (:summary cmp)]
    {:sample (:sample summary)
     :concordant (select-keys summary [:genotype_concordance :callable_concordance
                                       :concordant])
     :discordant (count-discordant-categories vcf-file ref-file)}))</pre></td></tr><tr><td class="docs"><h2>Identify grading references</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Convert truth discordants into reference calls </p>
</td><td class="codes"><pre class="brush: clojure">(defn- to-refcalls
  [f ref-file]
  (let [out-file (itx/add-file-part f &quot;asref&quot;)]
    (when (itx/needs-run? out-file)
      (with-open [in-vcf-iter (gvc/get-vcf-iterator f ref-file)]
        (gvc/write-vcf-w-template f {:out out-file}
                                  (map #(gvc/genotypes-&gt;refcall %)
                                       (gvc/parse-vcf in-vcf-iter))
                                  ref-file)))
    out-file))</pre></td></tr><tr><td class="docs"><p>Merge extra and missing discordant calls into single VCF.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- merge-discordants
  [eval-vcf truth-vcf align-bam ref-file]
  (let [truth-dis-vcf (-&gt; truth-vcf
                          (to-refcalls ref-file)
                          (-&gt;/when align-bam
                            (annotation/add-gatk-annotations align-bam ref-file :annos [&quot;DepthOfCoverage&quot;])))]
    (combine/combine-variants [eval-vcf truth-dis-vcf]
                              ref-file :merge-type :full :quiet-out? true :check-ploidy? false)))</pre></td></tr><tr><td class="docs"><h2>Add grading info to VCF</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Identify variants that are variant calls but discordant based on het/hom calls.</p>
</td><td class="codes"><pre class="brush: clojure">(defn hethom-discordant?
  [vc other-vcs]
  (letfn [(get-alleles [x]
            (-&gt;&gt; (:genotypes x)
                 (map :alleles)
                 flatten
                 (remove #(.isReference %))
                 set))]
    (let [vc2 (first (filter #(and (= (:start vc) (:start %))
                                   (= (:ref-allele vc) (:ref-allele %)))
                             other-vcs))]
      (seq (intersection (get-alleles vc) (get-alleles vc2))))))</pre></td></tr><tr><td class="docs"><p>Is a variant context a no-variant (reference) call.</p>
</td><td class="codes"><pre class="brush: clojure">(defn is-novar-call?
  [vc]
  (-&gt;&gt; (:genotypes vc)
       (map :alleles)
       flatten
       (every? #(.isReference %))))</pre></td></tr><tr><td class="docs"><p>Assign a discordance category to variants that do not match grading reference.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- assign-grade-cat
  [vc ref-vcs]
  (cond
   (empty? ref-vcs) :discordant-extra
   (is-novar-call? vc) :discordant-missing
   (hethom-discordant? vc ref-vcs) :discordant-hethom
   :else :discordant-vardiff))</pre></td></tr><tr><td class="docs"><p>Determine likelihood of grading reference based on grading category.
   :discordant-missing -- probability that grading standard is actually reference.
   :discordant-hethom  -- probability that grading standard is alternative variant.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-grade-score
  [ref-vc cat]
  (let [pls (when ref-vc
              (attr/get-pls ref-vc))]
    (case cat
      :discordant-missing (get pls &quot;HOM_REF&quot;)
      :discordant-hethom (first (vals (dissoc pls &quot;HOM_REF&quot;)))
      nil)))</pre></td></tr><tr><td class="docs"><p>Add grading category and score, providing additional details on discordant variants.</p>
</td><td class="codes"><pre class="brush: clojure">(defn add-grade-cat
  [ref-get vc]
  (let [ref-vcs (gvc/variants-in-region ref-get vc)
        grade-cat (assign-grade-cat vc ref-vcs)]
    (-&gt; (VariantContextBuilder. (:vc vc))
        (.attributes (-&gt; (:attributes vc)
                         (assoc &quot;GradeCat&quot; (name grade-cat))
                         (-&gt;/when-let [score (get-grade-score (first ref-vcs) grade-cat)]
                           (assoc &quot;GradeScore&quot; (float score)))))
        .make)))</pre></td></tr><tr><td class="docs"><p>Add grading INFO fields to VCF output header</p>
</td><td class="codes"><pre class="brush: clojure">(defn add-grade-header
  [_ header]
  (gvc/header-w-md
   header
   #{(VCFInfoHeaderLine. &quot;GradeCat&quot; 1 VCFHeaderLineType/String
                         &quot;Grading category based on comparison with reference call set.&quot;)
     (VCFInfoHeaderLine. &quot;GradeScore&quot; 1 VCFHeaderLineType/Float
                         &quot;Grading score: phred score of correct probability reference call.&quot;)}))</pre></td></tr><tr><td class="docs"><p>Update a comparison with annotated information on discordant grading</p>
</td><td class="codes"><pre class="brush: clojure">(defn annotate-discordant
  [cmp]
  (let [kws (find-grading-and-eval-kws (:exp cmp) (:c1 cmp) (:c2 cmp)
                                       (:c-files cmp))
        eval-vcf (get-in cmp [:c-files (:eval kws)])
        truth-vcf (get-in cmp [:c-files (:truth kws)])
        ref-file (get-in cmp [:exp :ref])
        align-bam (get-in cmp [:exp :align])
        base-eval-vcf (merge-discordants eval-vcf truth-vcf align-bam ref-file)
        out-vcf (itx/add-file-part eval-vcf &quot;annotate&quot;)]
    (when (itx/needs-run? out-vcf)
      (with-open [ref-get (gvc/get-vcf-retriever ref-file truth-vcf)
                  eval-iter (gvc/get-vcf-iterator base-eval-vcf ref-file)]
        (gvc/write-vcf-w-template base-eval-vcf {:out out-vcf}
                                  (map (partial add-grade-cat ref-get)
                                       (gvc/parse-vcf eval-iter))
                                  ref-file :header-update-fn add-grade-header)))
    (assoc-in cmp [:c-files (:eval kws)] out-vcf)))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.haploid" name="bcbio.variation.haploid"><h1 class="project-name">bcbio.variation.haploid</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Convert diploid variants from GATK into haploid calls based on genotype likelihoods.
  We assess diploid GATK calls based on the phred-normalized likelihood (PL). Lower variant
  PLs are likely to be true and included. The GATK documentation contains a detailed example
  of the format and interpretation:
  http://gatkforums.broadinstitute.org/discussion/1268/how-should-i-interpret-vcf-files-produced-by-the-gatk</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.haploid
  (:import [org.broadinstitute.sting.utils.variantcontext 
            VariantContextBuilder GenotypesContext GenotypeBuilder Allele])
  (:use [clojure.java.io]
        [bcbio.variation.variantcontext :only [parse-vcf get-vcf-iterator write-vcf-w-template]])
  (:require [clojure.string :as string]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><h2>Convert diploid -> haploid</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Threshold to include a heterozygous allele as a haploid homozygote variant.
  Based on type of variant: SNPs have lower threshold of inclusion.
  Includes two thresholds: for possibly being homozygous variant and
  for not being homozygous reference.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-haploid-thresh
  [vc]
  (case (:type vc)
    &quot;SNP&quot; {&quot;HOM_VAR&quot; 1e-5
           &quot;HOM_REF&quot; 1e-20}
    {&quot;HOM_VAR&quot; 1e-50
     &quot;HOM_REF&quot; 1e-200}))</pre></td></tr><tr><td class="docs"><p>Retrieve all likelihoods (PL) for genotype.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-likelihoods
  [g &amp; {:keys [no-convert]}]
  (when (and (.hasLikelihoods g)
             (&gt; (count (vec (.getAsVector (.getLikelihoods g)))) 1))
    (let [pl-vec (vec (.getAsVector (.getLikelihoods g)))]
      (if (= (count pl-vec) 2)
        (zipmap [&quot;HOM_REF&quot; &quot;HOM_VAR&quot;] pl-vec)
        (let [in-map (-&gt; (.getLikelihoods g) (.getAsMap (nil? no-convert)))]
          (zipmap (map #(.name %) (keys in-map)) (vals in-map)))))))</pre></td></tr><tr><td class="docs"><p>Can we reasonably convert a heterozygote call to haploid based on likelihoods?
   We allow a het to pass when the homozygous variant prob is less than
   our defined thresholds, or our homozygous reference prob is greater.</p>
</td><td class="codes"><pre class="brush: clojure">(defn het-can-be-haploid?
  [g vc]
  (let [probs (get-likelihoods g)
        thresh (get-haploid-thresh vc)]
    (letfn [(passes-var? []
              (when-let [p (get probs &quot;HOM_VAR&quot;)]
                (&gt; p (get thresh &quot;HOM_VAR&quot;))))
            (passes-ref? []
              (when-let [p (get probs &quot;HOM_REF&quot;)]
                (&lt; p (get thresh &quot;HOM_REF&quot;))))]
      (or (passes-var?) (passes-ref?)))))</pre></td></tr><tr><td class="docs"><p>Retrieve updated genotype with haploid allele.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-haploid-genotype
  [vc]
  (letfn [(maybe-variant-haploid [g vc]
            (when (het-can-be-haploid? g vc)
              (first (filter #(and (.isNonReference %) (.isCalled %))
                               (.getAlleles g)))))
          (extract-mixed-allele [alleles]
            (let [ready (remove #(.isNoCall %) alleles)]
              (when (= 1 (count ready))
                (first ready))))
          (get-haploid-allele [g vc]
            (case (:type g)
              &quot;HOM_VAR&quot; (first (:alleles g))
              &quot;MIXED&quot; (extract-mixed-allele (:alleles g))
              &quot;HET&quot; (maybe-variant-haploid (:genotype g) vc)
              nil))
          (add-haploid-genotype [context g]
            (let [allele (or (get-haploid-allele g vc) Allele/NO_CALL)]
              (doto context
                (.replace (-&gt; (GenotypeBuilder. (:genotype g))
                              (.alleles [allele])
                              .make)))))]
    (reduce add-haploid-genotype
            (-&gt; vc :vc .getGenotypes GenotypesContext/copy)
            (:genotypes vc))))</pre></td></tr><tr><td class="docs"><p>Check for at least one called Allele in a list of Genotypes.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- has-called-allele?
  [genotypes]
  (not-every? #(.isNoCall %) (mapcat #(.getAlleles %) genotypes)))</pre></td></tr><tr><td class="docs"><p>Convert diploid allele to haploid variant.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- convert-to-haploid
  [vc]
  (let [new-genotype (get-haploid-genotype vc)]
    (if (has-called-allele? new-genotype)
      [:haploid (-&gt; (VariantContextBuilder. (:vc vc))
                    (.genotypes new-genotype)
                    (.make))]
      [:unchanged (:vc vc)])))</pre></td></tr><tr><td class="docs"><p>Convert set of diploid GATK calls on a haploid genome based on likelihoods.</p>
</td><td class="codes"><pre class="brush: clojure">(defn diploid-calls-to-haploid
  [vcf ref &amp; {:keys [out-dir]}]
  (let [out-files {:haploid (itx/add-file-part vcf &quot;haploid&quot; out-dir)
                   :unchanged (itx/add-file-part vcf &quot;nonhaploid&quot; out-dir)}]
    (when (itx/needs-run? (vals out-files))
      (with-open [vcf-iter (get-vcf-iterator vcf ref)]
        (write-vcf-w-template vcf out-files
                              (map convert-to-haploid (parse-vcf vcf-iter))
                              ref)))
    (:haploid out-files)))</pre></td></tr><tr><td class="docs"><h2>Examine diploid metrics</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Write phred likelihoods for het calls to be haploid variants.</p>
</td><td class="codes"><pre class="brush: clojure">(defn write-het-variant-pls
  [vcf-file ref-file &amp; attrs]
  (letfn [(get-pl [vc]
            (let [g (-&gt; vc :genotypes first :genotype)]
              (when (.hasLikelihoods g)
                (let [in-map (-&gt; (.getLikelihoods g) (.getAsMap true))]
                  (get (zipmap (map #(.name %) (keys in-map)) (vals in-map))
                       &quot;HOM_VAR&quot;)))))]
  (let [out-file (str (itx/file-root vcf-file) &quot;-het-pls.csv&quot;)]
    (with-open [vcf-iter (get-vcf-iterator vcf-file ref-file)
                wtr (writer out-file)]
      (doseq [val (-&gt;&gt; (parse-vcf vcf-iter)
                       (filter #(= &quot;HET&quot; (-&gt; % :genotypes first :type)))
                       (map get-pl)
                       (remove nil?))]
        (.write wtr (str (string/join &quot;,&quot; (cons val attrs)) &quot;\n&quot;))))
    out-file)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -main
  [vcf ref]
  (diploid-calls-to-haploid vcf ref))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.index.gemini" name="bcbio.variation.index.gemini"><h1 class="project-name">bcbio.variation.index.gemini</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Index and retrieve variant associated population genetic and disease data.
   Built on the Gemini framework: https://github.com/arq5x/gemini</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.index.gemini
  (:use [clojure.java.io]
        [ordered.map :only [ordered-map]]
        [bcbio.variation.api.shared :only [web-config]]
        [bcbio.variation.web.db :only [get-sqlite-db get-sqlite-db-pool]])
  (:require [clojure.java.jdbc :as sql]
            [clojure.java.shell :as shell]
            [clojure.string :as string]
            [fs.core :as fs]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><h2>Gemini</h2>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn get-gemini-cmd []
  (let [cmd (get-in @web-config [:program :gemini] &quot;gemini&quot;)
        info (try (shell/sh cmd &quot;-h&quot;)
                  (catch java.io.IOException _
                    {:exit -1}))]
    (when (zero? (:exit info))
      cmd)))</pre></td></tr><tr><td class="docs"><p>Check if the input file contains snpEff annotations.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- has-snpeff-anns?
  [in-file]
  (with-open [rdr (reader in-file)]
    (-&gt;&gt; (line-seq rdr)
         (take-while #(.startsWith % &quot;##&quot;))
         (filter #(.startsWith % &quot;##SnpEff&quot;))
         count
         pos?)))</pre></td></tr><tr><td class="docs"><p>Pre-index a variant file with gemini, handling snpEff annotations.</p>
</td><td class="codes"><pre class="brush: clojure">(defn index-variant-file
  [in-file _ &amp; {:keys [re-index?]}]
  (when-let [gemini-cmd (get-gemini-cmd)]
    (when in-file
      (let [index-file (str (itx/file-root in-file) &quot;-gemini.db&quot;)]
        (when (or (itx/needs-run? index-file) re-index?)
          (itx/with-tx-file [tx-index index-file]
            (apply shell/sh
                   (concat [gemini-cmd &quot;load&quot; &quot;-v&quot; in-file]
                           (when (has-snpeff-anns? in-file)
                             [&quot;-t&quot; &quot;snpEff&quot;])
                           [tx-index]))))
        index-file))))</pre></td></tr><tr><td class="docs"><p>Gemini metrics to expose for query and visualization.</p>
</td><td class="codes"><pre class="brush: clojure">(def ^{:doc 
       :private true}
  gemini-metrics
  (ordered-map
   &quot;aaf_1kg_all&quot; {:range [0.0 1.0]
                  :desc &quot;1000 genomes allele frequency, all populations&quot;}
   &quot;gms_illumina&quot; {:range [0.0 100.0]
                   :y-scale {:type :log}
                   :desc &quot;Genome Mappability Score with an Illumina error model&quot;}
   &quot;in_cse&quot; {:x-scale {:type :category}
             :desc &quot;Presence of variant in an error prone genomic position&quot;}
   &quot;rmsk&quot; {:x-scale {:type :category}
           :desc &quot;Repeat status: is the variant in a known repeat region&quot;}
   &quot;type&quot; {:x-scale {:type :category}
           :rows {:type &quot;&quot; :sub_type &quot;&quot;}
           :desc &quot;Type of variant change&quot;}
   &quot;zygosity&quot; {:x-scale {:type :category}
               :rows {:num_hom_ref &quot;homozygous ref&quot;
                      :num_het &quot;heterozygous&quot;
                      :num_hom_alt &quot;homozygous&quot;}
               :desc &quot;Allele types present in individuals&quot;}
   &quot;encode_consensus_gm12878&quot; {:x-scale {:type :category}
                               :desc &quot;Chromatin status: consensus from ENCODE for NA12878&quot;}
   &quot;in_public&quot; {:x-scale {:type :category}
                :rows {:in_dbsnp &quot;dbSNP&quot;
                       :in_hm3 &quot;HapMap3&quot;
                       :in_esp &quot;ESP&quot;
                       :in_1kg &quot;1000genomes&quot;}
                :desc &quot;Presence in large variant projects like dbSNP and 1000 genomes&quot;}
   &quot;is_coding&quot; {:x-scale {:type :category}
                :desc &quot;Type of coding transcript influenced by variant&quot;}
   &quot;impact_severity&quot; {:x-scale {:type :category}
                      :desc &quot;Severity of variant impact on coding region&quot;}))</pre></td></tr><tr><td class="docs"><p>Convert a gemini attribute into potentially multiple gemini column names.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- attr-&gt;colnames
  [attr]
  (-&gt;&gt; (if-let [rows (get-in gemini-metrics [(name attr) :rows])]
         (keys rows)
         [attr])
       (map name)))</pre></td></tr><tr><td class="docs"><p>Retrieve metrics available from Gemini.</p>
</td><td class="codes"><pre class="brush: clojure">(defn available-metrics
  [in-file &amp; {:keys [noviz?]}]
  (let [all-metrics (-&gt;&gt; gemini-metrics
                         (map (fn [[k v]] (assoc v :id k)))
                         (filter #(or noviz? (get % :viz true))))]
    (if-let [index-db (index-variant-file in-file nil)]
      (sql/with-connection (get-sqlite-db index-db)
        (letfn [(db-has-metric? [x]
                  (sql/with-query-results rows
                    [(str &quot;SELECT chrom, start FROM variants WHERE &quot;
                          (-&gt;&gt; (attr-&gt;colnames (:id x))
                               (map #(str % &quot; IS NOT NULL&quot;))
                               (string/join &quot; OR &quot;))
                           &quot; LIMIT 1&quot;)]
                    (seq rows)))]
          (doall (filter db-has-metric? all-metrics))))
      all-metrics)))</pre></td></tr><tr><td class="docs"><p>Provide additional post-processing of gemini supplied attributes.</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti finalize-gemini-attr
  (fn [attr row] (keyword (string/lower-case attr))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod finalize-gemini-attr :sift_score
  [_ row]
  (let [val (first (vals row))]
    (if (nil? val) 1.0 val)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod finalize-gemini-attr :polyphen_score
  [_ row]
  (let [val (first (vals row))]
    (if (nil? val) 0.0 val)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod finalize-gemini-attr :gms_illumina
  [_ row]
  (let [val (first (vals row))]
    (if (nil? val) 100.0 val)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod finalize-gemini-attr :gms_solid
  [_ row]
  (let [val (first (vals row))]
    (if (nil? val) 100.0 val)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod finalize-gemini-attr :gms_iontorrent
  [_ row]
  (let [val (first (vals row))]
    (if (nil? val) 100.0 val)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod finalize-gemini-attr :in_cse
  [_ row]
  (let [val (first (vals row))]
    (if (and (not (nil? val)) (pos? val)) #{&quot;error-prone&quot;} #{&quot;standard&quot;})))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod finalize-gemini-attr :rmsk
  [_ row]
  (let [val (first (vals row))]
    #{(if (nil? val) &quot;non-repeat&quot; &quot;repeat&quot;)}))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod finalize-gemini-attr :type
  [_ row]
  (set (map #(case %
               &quot;ts&quot; &quot;transition&quot;
               &quot;tv&quot; &quot;transversion&quot;
               &quot;ins&quot; &quot;insertion&quot;
               &quot;del&quot; &quot;deletion&quot;
               %)
            (vals row))))</pre></td></tr><tr><td class="docs"><p>Convert a row into pre-configured names based on gemini-metrics :rows</p>
</td><td class="codes"><pre class="brush: clojure">(defn- row-&gt;names
  [attr row]
  (let [row-names (get-in gemini-metrics [attr :rows])]
    (reduce (fn [coll [k v]]
              (if (and (not (nil? v))
                       (pos? v))
                (conj coll (get row-names (keyword k)))
                coll))
            #{} row)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod finalize-gemini-attr :zygosity
  [attr row]
  (row-&gt;names attr row))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod finalize-gemini-attr :encode_consensus_gm12878
  ^{:doc &quot;ENCODE chromatin segment predictions, from Table 3 of doi:10.1038/nature11247&quot;}
  [_ row]
  (let [val (first (vals row))]
    #{(case val
        &quot;CTCF&quot; &quot;CTCF-enriched&quot;
        &quot;E&quot; &quot;Enhancer&quot;
        &quot;PF&quot; &quot;Promoter flanking&quot;
        &quot;R&quot; &quot;Repressed&quot;
        &quot;TSS&quot; &quot;Promoter with TSS&quot;
        &quot;T&quot; &quot;Transcribed&quot;
        &quot;WE&quot; &quot;Weak enchancer&quot;
        &quot;Unknown&quot;)}))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod finalize-gemini-attr :in_public
  [attr row]
  (let [publics (row-&gt;names attr row)]
    (if (seq publics)
      publics
      #{&quot;unique&quot;})))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod finalize-gemini-attr :is_coding
  [_ row]
  (let [val (first (vals row))]
    (if (and (not (nil? val)) (pos? val)) #{&quot;coding&quot;} #{&quot;noncoding&quot;})))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod finalize-gemini-attr :impact_severity
  [_ row]
  (let [val (first (vals row))]
    #{val}))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod finalize-gemini-attr :default
  [_ row]
  (let [val (first (vals row))]
    val))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- gemini-metric-from-row
  [row attr]
  (let [colnames (attr-&gt;colnames attr)]
    (finalize-gemini-attr attr
                          (zipmap colnames
                                  (map #(get row (keyword (string/lower-case %))) colnames)))))</pre></td></tr><tr><td class="docs"><p>Retrieve metrics by name from a gemini index for provided VariantContexts.</p>
</td><td class="codes"><pre class="brush: clojure">(defn vc-attr-retriever
  [in-file ref-file]
  (if-let [index-db (index-variant-file in-file ref-file)]
    (let [pool (get-sqlite-db-pool index-db)]
      (fn [vc attr]
        (sql/with-connection pool
          (sql/with-query-results rows
            [(str &quot;SELECT &quot; (string/join &quot;,&quot; (attr-&gt;colnames attr))
                  &quot; FROM variants WHERE chrom = ? AND start = ? and ref = ?&quot;)
             (str &quot;chr&quot; (:chr vc)) (dec (:start vc)) (.getBaseString (:ref-allele vc))]
            (gemini-metric-from-row (first rows) attr)))))
    (fn [vc attr] nil)))</pre></td></tr><tr><td class="docs"><p>Retrieve table of Gemini metrics keyed on variant names.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-raw-metrics
  [in-file ref-file &amp; {:keys [metrics noviz?]}]
  (when-let [index-db (index-variant-file in-file ref-file)]
    (let [plot-metrics (filter (partial contains? gemini-metrics)
                               (or metrics (map :id (available-metrics in-file
                                                                       :noviz? noviz?))))]
      (when (seq plot-metrics)
        (sql/with-connection (get-sqlite-db index-db)
          (sql/with-query-results rows
            [(str &quot;SELECT chrom, start, ref, &quot;
                  (string/join &quot;, &quot; (mapcat attr-&gt;colnames plot-metrics))
                  &quot; FROM variants WHERE (filter is NULL or filter = 'PASS')&quot;
                  &quot; ORDER BY chrom, start&quot;)]
            (doall (map (fn [orig]
                          (reduce (fn [coll x]
                                    (assoc coll x (gemini-metric-from-row orig x)))
                                  {:id [(string/replace (:chrom orig) &quot;chr&quot; &quot;&quot;) (inc (:start orig)) (:ref orig)]}
                                  plot-metrics))
                        rows))))))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.index.metrics" name="bcbio.variation.index.metrics"><h1 class="project-name">bcbio.variation.index.metrics</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Pre-index a variant file for quick retrieval of associated metrics.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.index.metrics
  (:use [ordered.map :only [ordered-map]]
        [bcbio.variation.metrics :only [passes-filter?]]
        [bcbio.variation.filter.attr :only [get-vc-attrs]]
        [bcbio.variation.index.subsample :only [subsample-by-cluster]]
        [bcbio.variation.variantcontext :only [get-vcf-header get-vcf-iterator parse-vcf]]
        [bcbio.variation.web.db :only [get-sqlite-db]])
  (:require [clojure.string :as string]
            [clojure.java.jdbc :as sql]
            [fs.core :as fs]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><p>Metrics to expose, ranked in order of priority with default min/max values.</p>
</td><td class="codes"><pre class="brush: clojure">(def 
  expose-metrics
  (ordered-map &quot;QUAL&quot; {:range [0.0 2000.0]
                       :desc &quot;Variant quality score, phred-scaled&quot;}
               &quot;DP&quot; {:range [0.0 250.0]
                     :desc &quot;Read depth after filtering of low quality reads&quot;}
               &quot;MQ&quot; {:range [25.0 75.0]
                     :desc &quot;Mapping quality&quot;}
               &quot;QD&quot; {:range [0.0 50.0]
                     :desc &quot;Variant confidence by depth&quot;}
               &quot;FS&quot; {:range [0.0 100.0]
                     :y-scale {:type :log}
                     :desc &quot;Phred-scaled p-value using Fisher's exact test to detect strand bias&quot;}
               &quot;ReadPosEndDist&quot; {:range [0.0 50.0]
                                 :desc &quot;Mean distance from either end of read&quot;}
               &quot;MFE&quot; {:range [-10.0 0.0]
                      :y-scale {:type :log}
                      :desc (str &quot;Minimum Free Energy of secondary structure near variant. &quot;
                                 &quot;Larger negative values are more problematic.&quot;)}
               &quot;Entropy&quot; {:range [1.0 4.0]
                          :desc (str &quot;Shannon entropy of variant flanking regions. &quot;
                                     &quot;Low values indicate repetitive sequence.&quot;)}
               &quot;AD&quot; {:range [0.0 1.0]
                     :y-scale {:type :log}
                     :desc &quot;Deviation from expected allele balance for ref/alt alleles&quot;}
               &quot;PL&quot; {:range [-100.0 0]
                     :desc &quot;Normalized, phred-scaled likelihoods for alternative genotype&quot;}
               &quot;HaplotypeScore&quot; {:range [0.0 50.0]
                                 :desc &quot;Consistency of the site with at most two segregating haplotypes&quot;}
               ;; Validation
               &quot;GradeCat&quot; {:x-scale {:type :category}
                           :desc &quot;Validation category, differentiating discordant types&quot;}
               ;; Methylation metrics from BisSNP
               &quot;CS&quot; {:x-scale {:type :category}
                     :desc &quot;Strand of cytosine relative to reference genome&quot;}
               &quot;Context&quot; {:x-scale {:type :category}
                          :desc &quot;Cytosine context: homozygous or heterozygous CG sites&quot;}
               &quot;CM&quot; {:range [0.0 50.0]
                     :y-scale {:type :log}
                     :desc &quot;Number of unconverted, methylated, cytosines&quot;}
               &quot;CU&quot; {:range [0.0 1.0]
                     :y-scale {:type :log}
                     :desc &quot;Percentage of methylated bases at a position.&quot;}))</pre></td></tr><tr><td class="docs"><p>Default metrics that are always available.</p>
</td><td class="codes"><pre class="brush: clojure">(def ^{:doc  :private true}
  default-metrics
  [{:id &quot;QUAL&quot; :type :float}])</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmulti available-metrics
  (fn [in-file] in-file))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod available-metrics nil
  ^{:doc &quot;Retrieve all available default metrics without file information&quot;}
  [_]
  (map (fn [[k v]] (assoc v :id k)) expose-metrics))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod available-metrics :default
  ^{:doc &quot;Retrieve metrics available for variant input file.&quot;}
  [vcf-file]
  (letfn [(convert-header [line]
            {:id (.getID line)
             :type (case (.name (.getType line))
                     &quot;Integer&quot; :float
                     &quot;Float&quot; :float
                     &quot;String&quot; :text
                     &quot;Character&quot; :text
                     :else nil)})
          (add-base-info [x]
            (merge x (get expose-metrics (:id x))))]
    (let [metrics-order (reduce (fn [coll [i x]] (assoc coll x i))
                                {} (map-indexed vector (keys expose-metrics)))]
      (-&gt;&gt; (get-vcf-header vcf-file)
           .getMetaDataInInputOrder
           (filter #(contains? #{&quot;INFO&quot; &quot;FORMAT&quot;} (.getKey %)))
           (filter #(contains? expose-metrics (.getID %)))
           (group-by #(.getID %))
           vals
           (map first)
           (map convert-header)
           (concat default-metrics)
           (map add-base-info)
           (sort-by #(get metrics-order (:id %)))))))</pre></td></tr><tr><td class="docs"><p>Common columns for variant metrics table.</p>
</td><td class="codes"><pre class="brush: clojure">(def ^{:doc 
       :private true}
  shared-metrics-cols [[:contig :text]
                       [:start :integer]
                       [:refallele :text]
                       [:issubsample :integer]])</pre></td></tr><tr><td class="docs"><p>Create table to represent variant metrics</p>
</td><td class="codes"><pre class="brush: clojure">(defn- create-metrics-tables
  [metrics]
  (apply sql/create-table (concat [:metrics] shared-metrics-cols
                                  (map (fn [x] [(:id x) (:type x)]) metrics))))</pre></td></tr><tr><td class="docs"><p>Check if an index file has up to date columns</p>
</td><td class="codes"><pre class="brush: clojure">(defn- index-needs-update?
  [index-file metrics]
  (let [want-cols (set (concat (map first shared-metrics-cols)
                               (map #(keyword (string/lower-case (:id %))) metrics)))]
    (sql/with-connection (get-sqlite-db index-file)
      (sql/with-query-results rows
        [&quot;SELECT * from metrics LIMIT 1&quot;]
        (not= want-cols (-&gt; rows first keys set))))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- num-variants
  [index-file]
  (sql/with-connection (get-sqlite-db index-file)
    (sql/with-query-results rows
      [&quot;SELECT count(*) from metrics&quot;]
      (-&gt; rows first vals first))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- all-metrics-as-subsample
  [index-file]
  (sql/with-connection (get-sqlite-db index-file)
    (sql/update-values :metrics [&quot;start &gt; -1&quot;] {:issubsample 1})))</pre></td></tr><tr><td class="docs"><p>Retrieve numerical raw metrics for filtering</p>
</td><td class="codes"><pre class="brush: clojure">(declare get-raw-metrics)
(defn get-raw-metrics-linear
  [in-file ref-file]
  (let [metrics (-&gt;&gt; (available-metrics in-file)
                     (filter #(= :linear (get-in % [:x-scale :type] :linear)))
                     (map :id))]
    (get-raw-metrics in-file ref-file :metrics metrics)))</pre></td></tr><tr><td class="docs"><p>Identify a subsample of records to use in visualization</p>
</td><td class="codes"><pre class="brush: clojure">(defn- subsample-metrics
  [index-file in-file ref-file params]
  (let [sub-ids (subsample-by-cluster (get-raw-metrics-linear in-file ref-file) params)]
    (sql/with-connection (get-sqlite-db index-file)
      (sql/transaction
       (doseq [xid sub-ids]
         (sql/update-values :metrics
                            (cons &quot;contig=? AND start=? and refallele=?&quot; (vec xid))
                            {:issubsample 1}))))))</pre></td></tr><tr><td class="docs"><p>Pre-index a variant file with associated metrics.</p>
</td><td class="codes"><pre class="brush: clojure">(defn index-variant-file
  [in-file ref-file &amp; {:keys [re-index? subsample-params]}]
  (let [batch-size 10000
        metrics (available-metrics in-file)
        index-file (str (itx/file-root in-file) &quot;-metrics.db&quot;)]
    (when (or re-index?
              (itx/needs-run? index-file)
              (index-needs-update? index-file metrics))
      (itx/with-tx-file [tx-index index-file]
        (sql/with-connection (get-sqlite-db tx-index :create true)
          (sql/transaction
           (create-metrics-tables metrics))
          (with-open [vcf-iter (get-vcf-iterator in-file ref-file)]
            (doseq [vcs (partition-all batch-size (filter passes-filter? (parse-vcf vcf-iter)))]
              (sql/transaction
               (doseq [vc vcs]
                 (sql/insert-record :metrics
                                    (-&gt; (get-vc-attrs vc (map :id metrics) {})
                                        (assoc :contig (:chr vc))
                                        (assoc :start (:start vc))
                                        (assoc :refallele (.getBaseString (:ref-allele vc)))
                                        (assoc :issubsample 0)))))))))
      (if (and subsample-params
               (&gt; (num-variants index-file) (get-in subsample-params [:subsample :count])))
        (subsample-metrics index-file in-file ref-file subsample-params)
        (all-metrics-as-subsample index-file)))
    index-file))</pre></td></tr><tr><td class="docs"><p>Provide category metrics as expected sets to match gemini usage.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- maybe-fix-category
  [val attr]
  (if (= :category (get-in expose-metrics [attr :x-scale :type]))
    #{val}
    val))</pre></td></tr><tr><td class="docs"><p>Retrieve table of raw metrics using indexed variant file</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-raw-metrics
  [in-file ref-file &amp; {:keys [metrics use-subsample?]}]
  (let [index-db (index-variant-file in-file ref-file)
        plot-metrics (filter (partial contains? expose-metrics)
                             (or metrics (map :id (available-metrics in-file))))]
    (sql/with-connection (get-sqlite-db index-db)
      (sql/with-query-results rows
        [(str &quot;SELECT contig, start, refallele, &quot; (string/join &quot;, &quot; plot-metrics)
              &quot; FROM metrics&quot;
              (if use-subsample? &quot; WHERE issubsample=1 &quot; &quot; &quot;))]
              &quot;ORDER BY contig, start&quot;
        (doall (map (fn [orig]
                      (reduce (fn [coll x]
                                (assoc coll x (-&gt; orig
                                                  (get (keyword (string/lower-case x)))
                                                  (maybe-fix-category x))))
                              {:id [(:contig orig) (:start orig) (:refallele orig)]}
                              plot-metrics))
                    rows))))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.index.subsample" name="bcbio.variation.index.subsample"><h1 class="project-name">bcbio.variation.index.subsample</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Provide rapid subsampling capabilities for indexed retrieval of metrics.
  Used on index preparation to provide a representative subset of large
  datasets based on assessment metrics. Sub-sampled metrics allow
  interactive visualizations of large data.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.index.subsample
  (:require [clj-ml.data :as mldata]
            [clj-ml.clusterers :as mlclust]))</pre></td></tr><tr><td class="docs"><p>Return ids of subsampled metrics with a single representative from each cluster.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- final-subsample-ids
  [xs clusters]
  (let [final-is (-&gt; (reduce (fn [coll [i cluster]]
                               {:seen (conj (:seen coll) cluster)
                                :want (if (contains? (:seen coll) cluster)
                                        (:want coll)
                                        (conj (:want coll) i))})
                             {:seen #{} :want []} (map-indexed vector clusters))
                     :want
                     set)]
    (remove nil?
            (map-indexed (fn [i x] (when (contains? final-is i) x)) xs))))</pre></td></tr><tr><td class="docs"><p>Subsample a set of metrics using clustering. Returns ids of
  representative items from each cluster.</p>
</td><td class="codes"><pre class="brush: clojure">(defn subsample-by-cluster
  [metrics params]
  (letfn [(get-attrs [attrs x] (map #(get x %) attrs))]
    (let [clusterer (mlclust/make-clusterer (keyword (get-in params [:subsample :method]))
                                            {:number-clusters (get-in params [:subsample :count])})
          attrs (-&gt; metrics first (dissoc :id) keys)
          ds (mldata/make-dataset &quot;ds&quot; attrs
                                  (map (partial get-attrs attrs) metrics))]
      (mlclust/clusterer-build clusterer ds)
      (-&gt;&gt; (mlclust/clusterer-cluster clusterer ds)
           mldata/dataset-seq
           (map mldata/instance-get-class)
           (final-subsample-ids (map :id metrics))))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.metrics" name="bcbio.variation.metrics"><h1 class="project-name">bcbio.variation.metrics</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Accumulate and analyze metrics associated with each variant.
   This provides summaries intended to identify characteristic
   metrics to use for filtering.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.metrics
  (:use [clojure.java.io]
        [clojure.set]
        [bcbio.variation.variantcontext :only [parse-vcf get-vcf-iterator]]
        [clojure.string :only [split-lines]]
        [clj-ml.data :only [make-dataset]]
        [clj-ml.classifiers :only [make-classifier classifier-train]]
        [ordered.set :only [ordered-set]])
  (:require [incanter.stats :as istats]
            [doric.core :as doric]))</pre></td></tr><tr><td class="docs"><h2>Convenience functions</h2>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn to-float [x]
  (if (number? x)
    (float x)
    (try
      (Float/parseFloat x)
      (catch Exception e nil))))</pre></td></tr><tr><td class="docs"><p>Check if a VariantContext is not filtered.</p>
</td><td class="codes"><pre class="brush: clojure">(defn passes-filter?
  [vc]
  (= (count (:filters vc)) 0))</pre></td></tr><tr><td class="docs"><p>Check if a variant context is not filter and is not a reference call.</p>
</td><td class="codes"><pre class="brush: clojure">(defn nonref-passes-filter?
  [vc]
  (and (passes-filter? vc)
       (every? #(contains? #{&quot;HET&quot; &quot;HOM_VAR&quot;} (:type %)) (:genotypes vc))))</pre></td></tr><tr><td class="docs"><p>Retrieve numeric metrics associated with VariantContext.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-vc-metrics
  [vc]
  (reduce (fn [coll [k v]]
            (if-let [num-v (to-float v)]
              (assoc coll k num-v)
              coll))
   {}
   (assoc (:attributes vc) &quot;QUAL&quot; (:qual vc))))</pre></td></tr><tr><td class="docs"><h2>Summary metrics</h2>

<p>Provide a summary-style presentation of distribution of metrics values.</p>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(def header [{:name :metric}
             {:name :count}
             {:name :min :format #(format &quot;%.2f&quot; %)}
             {:name :pct25 :format #(format &quot;%.2f&quot; %)}
             {:name :median :format #(format &quot;%.2f&quot; %)}
             {:name :pct75 :format #(format &quot;%.2f&quot; %)}
             {:name :max :format #(format &quot;%.2f&quot; %)}])</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn summary-stats [key vals]
  &quot;Provide summary statistics on a list of values.&quot;
  (zipmap (map :name header)
          (concat [key (count vals)]
                  (istats/quantile vals))))</pre></td></tr><tr><td class="docs"><p>Accumulate raw statistics associated with variant calls from input VCF.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- raw-vcf-stats
  [vcf-file ref-file]
  (letfn [(collect-attributes [collect [k v]]
            (if-not (nil? (to-float v))
              (assoc collect k (cons (to-float v) (get collect k [])))
              collect))
          (collect-vc [collect vc]
            (assoc (reduce collect-attributes collect (:attributes vc))
              &quot;QUAL&quot; (cons (:qual vc)
                           (get collect &quot;QUAL&quot; []))))]
    (with-open [vcf-iter (get-vcf-iterator vcf-file ref-file)]
      (reduce collect-vc {} (filter passes-filter? (parse-vcf vcf-iter))))))</pre></td></tr><tr><td class="docs"><h2>Classify</h2>

<p>Provide metrics for files in preparation for automated
classification.</p>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Collect classification metrics from a single VCF file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-file-metrics
  [ref-file vcf-file]
  (letfn [(has-nil-names [metrics all-metrics all-names]
            (let [test-names (union (-&gt; metrics keys set) all-names)]
              (apply union
                     (map (fn [xs] (set (keep #(when (nil? (get xs %)) %) test-names)))
                          (cons metrics (take-last 10 all-metrics))))))
          (classifier-metrics [coll vc]
            (let [cur-metrics (get-vc-metrics vc)]
              (-&gt; coll
                  (assoc :rows (cons cur-metrics (:rows coll)))
                  (assoc :names (union (-&gt; cur-metrics keys set) (:names coll)))
                  (assoc :nil-names (union (has-nil-names cur-metrics (:rows coll) (:names coll))
                                           (:nil-names coll))))))
          (prep-table [{rows :rows names :names nil-names :nil-names}]
            (let [sort-names (sort (vec names))]
              {:cols sort-names
               :with-nil-cols nil-names
               :rows (map (fn [x]
                            (map #(get x %) sort-names))
                          rows)}))]
    (with-open [vcf-iter (get-vcf-iterator vcf-file ref-file)]
      (prep-table
       (reduce classifier-metrics {:rows [] :names #{} :nil-names #{}}
               (filter passes-filter? (parse-vcf vcf-iter)))))))</pre></td></tr><tr><td class="docs"><p>Collect metrics from multiple vcf files into tables suitable for
  classification algorithms.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-vcf-classifier-metrics
  [ref-file vcf-files &amp; {:keys [remove-nil-cols]
                         :or {remove-nil-cols true}}]
  (letfn [(get-shared-cols [xs]
            (-&gt; (apply intersection (map #(set (:cols %)) xs))
                sort
                vec))
          (filter-by-cols [orig-cols want-cols]
            (let [check-cols (set want-cols)
                  want (set (keep-indexed #(if (contains? check-cols %2) %1) orig-cols))]
              (fn [xs]
                (keep-indexed #(when (contains? want %1) %2) xs))))
          (subset-file-metrics [shared-cols nil-cols {cols :cols rows :rows}]
            (let [ready-cols (if-not remove-nil-cols shared-cols
                                     (remove #(contains? nil-cols %) shared-cols))
                  row-filter (filter-by-cols cols ready-cols)]
              {:cols ready-cols
               :rows (remove #(not= (count %) (count ready-cols)) (map row-filter rows))}))]
    (let [file-metrics (map (partial get-file-metrics ref-file) vcf-files)
          shared-cols (get-shared-cols file-metrics)
          nil-cols (apply union (map #(set (:with-nil-cols %)) file-metrics))]
      (map (partial subset-file-metrics shared-cols nil-cols) file-metrics))))</pre></td></tr><tr><td class="docs"><p>Retrieve classification metrics from a tree based classifier.
  Metric ordering is relative to the usefulness in classifying.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- parse-classifier-nodes
  [classifier metrics]
  (-&gt;&gt; classifier
       .graph
       split-lines
       (map #(re-find #&quot;label=\&quot;(\w+)\&quot;&quot; %))
       (map second)
       flatten
       (remove nil?)
       (filter #(contains? (set metrics) %))
       (apply ordered-set)))</pre></td></tr><tr><td class="docs"><p>Classify VCF files with INFO metrics using a decision tree classifier.</p>
</td><td class="codes"><pre class="brush: clojure">(defn classify-decision-tree
  [metrics]
  (letfn [(prep-one-dataset [rows i]
            (map #(conj (vec %) (str i)) rows))
          (prep-dataset [metrics]
            (make-dataset &quot;ds&quot; (conj (-&gt; metrics first :cols vec)
                                     {:c (map str (range (count metrics)))})
                          (apply concat (map-indexed #(prep-one-dataset (:rows %2) %1) metrics))
                          {:class :c}))]
    (let [ds (prep-dataset metrics)
          c (-&gt; (make-classifier :decision-tree :c45)
                (classifier-train ds))]
      (vec (parse-classifier-nodes c (-&gt; metrics first :cols))))))</pre></td></tr><tr><td class="docs"><p>Merge multiple classification approaches into a set of final metrics.
  <code>in-metrics</code> contains ordered best metric classifiers from the different
  approaches. Returns interleaved metrics ranked by present in these
  classifiers. </p>
</td><td class="codes"><pre class="brush: clojure">(defn merge-classified-metrics
  [in-metrics]
  (loop [cur in-metrics
         final (ordered-set)]
    (if (every? empty? cur)
      {:top-metrics (vec final)}
      (recur (map rest cur)
             (reduce #(conj %1 %2) final (remove nil? (map first cur)))))))</pre></td></tr><tr><td class="docs"><p>Apply machine learning/classification approaches to distinguish useful
  metrics distinguishing VCF files.</p>
</td><td class="codes"><pre class="brush: clojure">(defn ml-on-vcf-metrics
  [ref-file vcf-files]
  (letfn [(run-classifier [remove-nil-cols]
            (-&gt; (get-vcf-classifier-metrics ref-file vcf-files :remove-nil-cols remove-nil-cols)
                classify-decision-tree))]
    (merge-classified-metrics (map run-classifier [true false]))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.multiple" name="bcbio.variation.multiple"><h1 class="project-name">bcbio.variation.multiple</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Handle useful comparisons from multiple variation calling approaches.
  High level API to consolidate pairwise variant comparisons.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.multiple
  (:use [clojure.set :only [union]]
        [ordered.map :only [ordered-map]]
        [bcbio.variation.annotation :only [add-variant-annotations]]
        [bcbio.variation.callable :only [get-callable-checker is-callable? has-callers?]]
        [bcbio.variation.combine :only [combine-variants]]
        [bcbio.variation.metrics :only [nonref-passes-filter?]]
        [bcbio.variation.variantcontext :only [parse-vcf get-vcf-retriever
                                               variants-in-region
                                               get-vcf-iterator write-vcf-w-template]])
  (:require [clojure.string :as string]
            [fs.core :as fs]
            [bcbio.run.itx :as itx]
            [bcbio.run.broad :as broad]))</pre></td></tr><tr><td class="docs"><h2>Utility functions</h2>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn remove-mod-name [x &amp; {:keys [mods] :or {mods [&quot;recal&quot;]}}]
  &quot;Removes modification names from an approach name.&quot;
  (reduce (fn [final mod]
            (string/replace final (str &quot;-&quot; mod) ))
          x mods))</pre></td></tr><tr><td class="docs"><p>Lookup map of comparisons by method names.
   - ignore: a list of method names to ignore when creating the lookup map.
   - remove-mods?: Flag to remove naming modifications. This
                   will replace original comparisons with recalibrated.</p>
</td><td class="codes"><pre class="brush: clojure">(defn prep-cmp-name-lookup
  [cmps &amp; {:keys [ignore remove-mods?] :or {ignore #{}}}]
  (reduce (fn [m x]
            (let [names (map #(let [n (get-in x [% :name])]
                                (if-not remove-mods? n
                                        (remove-mod-name n :mods [(get-in x [% :mod])])))
                             [:c1 :c2])]
              (if (some #(contains? ignore %) names) m
                  (assoc m names x))))
          (ordered-map)
          cmps))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- not-target? [target-name xs]
  (not (contains? (set (map remove-mod-name xs)) target-name)))</pre></td></tr><tr><td class="docs"><h2>Prepare multi-overlap sets</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Retrieve all called items from a variant context 'set' attribute.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-vc-set-calls
  [vc calls]
  (when-let [set-val (get-in vc [:attributes &quot;set&quot;])]
    (if (= set-val &quot;Intersection&quot;)
      (set (map :name calls))
      (-&gt;&gt; (string/split set-val #&quot;-&quot;)
           (remove #(.startsWith % &quot;filter&quot;))
           (map #(string/split % #&quot;AND&quot;))
           (apply concat)
           set))))</pre></td></tr><tr><td class="docs"><p>Select samples based on name of a 'set' from CombineVariants.</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti select-variant-by-set
  (fn [_ _ set-name] (keyword set-name)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod select-variant-by-set :Intersection
  [vcf-in ref set-name]
  (let [file-info {:out-vcf (itx/add-file-part vcf-in set-name nil)}
        args [&quot;-R&quot; ref
              &quot;-o&quot; :out-vcf
              &quot;--variant&quot; vcf-in
              &quot;-select&quot; (format &quot;set == '%s'&quot; set-name)]]
    (broad/run-gatk &quot;SelectVariants&quot; args file-info {:out [:out-vcf]})
    (:out-vcf file-info)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod select-variant-by-set :default
  ^{:doc &quot;Select non-intersection names, handling GATK special cases like intersection
          and filtered.&quot;}
  [vcf-in ref set-name]
  (letfn [(in-set? [vc]
            (contains? (get-vc-set-calls vc [{:name set-name}])
                       set-name))]
    (let [out-file (itx/add-file-part vcf-in set-name nil)]
      (when (itx/needs-run? out-file)
        (with-open [in-iter (get-vcf-iterator vcf-in ref)]
          (write-vcf-w-template vcf-in {:out out-file}
                                (map :vc (filter in-set? (parse-vcf in-iter)))
                                ref)))
      out-file)))</pre></td></tr><tr><td class="docs"><p>Create VCF of the intersection of all concordant calls.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- gen-all-concordant
  [cmps-by-name ref out-dir config &amp; {:keys [do-include? base-ext]
                                      :or {base-ext &quot;multiall&quot;}}]
  (let [concordant-map (reduce (fn [m [k v]]
                                 (if (or (nil? do-include?) (do-include? k))
                                   (assoc m (get-in v [:c-files :concordant]) (string/join &quot;AND&quot; k))
                                   m))
                               (ordered-map) cmps-by-name)
        union-vcf (combine-variants (keys concordant-map) ref :merge-type :full :out-dir out-dir
                                    :name-map concordant-map :base-ext base-ext)]
    {:union union-vcf
     :intersection (select-variant-by-set union-vcf ref &quot;Intersection&quot;)}))</pre></td></tr><tr><td class="docs"><p>Generate false positives, dispatching differently when the target is from recalling.</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti gen-target-fps
  (fn [_ _ _ _ call _ _]
    (if (get call :recall false) :recall :default)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod gen-target-fps :recall
  ^{:doc &quot;False positive generation for combine call sets resulting from recalling.
          Report calls with low support across inputs callsets.&quot;}
  [target-cmps target-name _ target-overlap-vcf call ref out-dir]
  (let [calls (vec (set (mapcat (juxt :c1 :c2) (vals target-cmps))))
        out-file (itx/add-file-part target-overlap-vcf &quot;lowcounts&quot; out-dir)
        freq (get call :fp-freq 0.25)
        thresh (Math/ceil (* freq (dec (count calls))))]
    (letfn [(is-lowcount-fp? [vc]
              (-&gt; (get-vc-set-calls vc calls)
                  (disj target-name)
                  count
                  (&lt;= thresh)))]
      (when (itx/needs-run? out-file)
        (with-open [in-iter (get-vcf-iterator target-overlap-vcf ref)]
          (write-vcf-w-template target-overlap-vcf {:out out-file}
                                (map :vc (filter is-lowcount-fp? (parse-vcf in-iter)))
                                ref))))
    out-file))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod gen-target-fps :default
  ^{:doc &quot;False positive generation for single call sets: report discordant variants
          callable in other samples.&quot;}
  [target-cmps target-name other-conc-vcf _ _ ref out-dir]
  (letfn [(check-shared [fetch any-callable]
            (fn [x]
              (and (nonref-passes-filter? x)
                   (if (has-callers? any-callable)
                     (is-callable? any-callable (:chr x) (:start x) (:end x))
                     (not (empty? (variants-in-region fetch (:chr x)
                                                      (:start x) (:end x))))))))
          (get-shared-discordant [xs fetch any-callable]
            (let [pass-and-shared? (check-shared fetch any-callable)]
              (map :vc (filter pass-and-shared? xs))))]
    (let [disc-vcfs (remove nil? (map (fn [v]
                                        (get-in v [:c-files
                                                   (keyword (format &quot;%s-discordant&quot; target-name))]))
                                      (vals target-cmps)))
          disc-vcf (-&gt; (combine-variants disc-vcfs ref :merge-type :full :out-dir out-dir
                                         :base-ext (format &quot;dis%s&quot; target-name))
                       (select-variant-by-set ref &quot;Intersection&quot;))
          out-file (itx/add-file-part disc-vcf &quot;shared&quot;)
          align-bams (-&gt;&gt; (vals target-cmps)
                          (map (juxt :c1 :c2))
                          flatten
                          (map :align)
                          (remove nil?))]
      (with-open [disc-iter (get-vcf-iterator disc-vcf ref)
                  other-retriever (get-vcf-retriever ref other-conc-vcf)
                  call-source (get-callable-checker align-bams ref
                                                    :out-dir (str (fs/parent out-dir)))]
        (when (itx/needs-run? out-file)
          (write-vcf-w-template disc-vcf {:out out-file}
                                (get-shared-discordant (parse-vcf disc-iter)
                                                       other-retriever call-source)
                                ref)))
      out-file)))</pre></td></tr><tr><td class="docs"><p>Create files of false negatives and positives from target-name.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- gen-target-problems
  [target-name target-call cmps-by-name true-p-vcf target-overlap-vcf ref out-dir config]
  (let [notarget-concordant (gen-all-concordant cmps-by-name ref out-dir config
                                                :do-include? (partial not-target? target-name)
                                                :base-ext (format &quot;multino%s&quot; target-name))]
    {:false-negatives
     (-&gt; (combine-variants [true-p-vcf (:intersection notarget-concordant)]
                           ref :merge-type :full :out-dir out-dir
                           :name-map {true-p-vcf &quot;truep&quot;
                                      (:intersection notarget-concordant) target-name}
                           :base-ext (format &quot;multiall-no%s&quot; target-name))
         (select-variant-by-set ref target-name))
     :false-positives (gen-target-fps (remove #(not-target? target-name (first %))
                                              cmps-by-name)
                                      target-name (:union notarget-concordant)
                                      target-overlap-vcf target-call
                                      ref out-dir)}))</pre></td></tr><tr><td class="docs"><p>Provide high level concordance overlap comparisons for multiple call approaches.
  Organizes relative to the given target name generating:
   - VCF of calls concordant in all methods: intersection of all concordant calls.
     These are true positives.
   - VCF of calls discordant in the target method, but concordant in the remainder:
     the intersection of all concordant pairs not including target-name minus the
     overall intersection of concordants. These are false negatives.
   - VCF of non-ref calls discordant in the target method and called in any of the other
     methods. We restrict to shared calls to avoid penalizing unique calls.
     These are false positives.</p>
</td><td class="codes"><pre class="brush: clojure">(defn multiple-overlap-analysis
  [cmps config target-name &amp; {:keys [dirname ignore] :or {dirname &quot;multiple&quot;
                                                          ignore #{}}}]
  (let [cmps-by-name (prep-cmp-name-lookup (if (map? cmps) (vals cmps) cmps)
                                           :ignore (union ignore #{&quot;all&quot; &quot;validate&quot;}))
        out-dir (str (fs/file (get-in config [:dir :prep] (get-in config [:dir :out]))
                              dirname))
        ref (-&gt; cmps-by-name vals first :exp :ref)
        target-call (-&gt;&gt; cmps-by-name
                         (remove #(not-target? target-name (first %)))
                         first
                         second
                         ((juxt :c1 :c2))
                         (filter #(= (remove-mod-name (:name %)) target-name))
                         first)]
    (when-not (fs/exists? out-dir)
      (fs/mkdirs out-dir))
    (let [all-overlap (gen-all-concordant cmps-by-name ref out-dir config)
          true-p-vcf (:intersection all-overlap)
          target-overlaps (-&gt; all-overlap
                              :union
                              (select-variant-by-set ref target-name))
          target-problems (gen-target-problems target-name target-call cmps-by-name
                                               true-p-vcf target-overlaps ref out-dir config)]
      (ordered-map :true-positives true-p-vcf
                   :false-negatives (:false-negatives target-problems)
                   :false-positives (:false-positives target-problems)
                   :target-overlaps target-overlaps))))</pre></td></tr><tr><td class="docs"><p>Perform high level pipeline comparison of a target with multiple experiments.</p>
</td><td class="codes"><pre class="brush: clojure">(defn pipeline-compare-multiple
  [cmps finalizer exp config]
  (let [analysis (multiple-overlap-analysis cmps config (:target finalizer)
                                            :ignore (set (get finalizer :ignore #{})))]
    {:c-files analysis
     :c1 {:name (:target finalizer)}
     :c2 {:name &quot;all&quot;}
     :exp exp :dir (config :dir)}))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.multisample" name="bcbio.variation.multisample"><h1 class="project-name">bcbio.variation.multisample</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Compare multiple sample input files, allowing flexible configuration
  of concordance/discordance logic for comparison two sets of calls.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.multisample
  (:use [clojure.java.io]
        [clojure.set :only [intersection]]
        [ordered.map :only [ordered-map]])
  (:require [clojure.string :as string]
            [bcbio.run.itx :as itx]
            [bcbio.variation.variantcontext :as gvc]))</pre></td></tr><tr><td class="docs"><p>Check if the input VCF file has multiple genotyped samples.</p>
</td><td class="codes"><pre class="brush: clojure">(defn multiple-samples?
  [in-file &amp; {:keys [sample]}]
  (let [samples (-&gt; in-file gvc/get-vcf-header .getGenotypeSamples)]
    (or (&gt; (count samples) 1)
        (and (not (nil? sample))
             (not (contains? (set samples) sample))))))</pre></td></tr><tr><td class="docs"><p>Retrieve basename for output display, handling multiple sample inputs.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-out-basename
  [exp call in-files]
  (let [sample-name (or (:sample exp)
                        (-&gt; in-files first gvc/get-vcf-header .getGenotypeSamples first
                            (str &quot;multi&quot;)))]
    (format &quot;%s-%s&quot; sample-name (:name call))))</pre></td></tr><tr><td class="docs"><p>Retrieve output files for a variant to variant comparison</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-cmp-outfiles
  [c1 c2 exp config]
  (let [out-dir (get-in config [:dir :out])
        base-out (str (file out-dir (format &quot;%s-%s.vcf&quot;
                                            (get-out-basename exp c1 [(:file c1)])
                                            (:name c2))))
        out-files (into (ordered-map :concordant (itx/add-file-part base-out &quot;concordant&quot;))
                        (map (fn [c]
                               [(keyword (str (:name c) &quot;-discordant&quot;))
                                (itx/add-file-part base-out (str (:name c) &quot;-discordant&quot;))])
                             [c1 c2]))]
    out-files))</pre></td></tr><tr><td class="docs"><p>Compare two genotyping calls for a single sample, returning details about match:
   - concordant: 100% match between alleles
   - phasing-mismatch: Alleles match but phasing information does not.
   - nocall-mismatch: Alleles mismatch due to a no-call in one of the genotypes.
   - partial-mismatch: Alleles match in at least one position but mismatch elsewhere. 
   - discordant: No recoverable match characteristics</p>
</td><td class="codes"><pre class="brush: clojure">(defn compare-genotypes
  [g1 g2]
  (letfn [(has-nocall? [g]
            (some #(.isNoCall %) (:alleles g)))
          (phase-mismatch? [g1 g2]
            (and (or (:phased? g1) (:phased? g2))
                 (= (:alleles g1) (reverse (:alleles g2)))))
          (atleast-one-match? [g1 g2]
            (seq (intersection (set (:alleles g1)) (set (:alleles g2)))))
          (nocall-mismatch? [g1 g2]
            (and (or (has-nocall? g1) (has-nocall? g2))
                 (atleast-one-match? g1 g2)))
          (num-matches [g1 g2]
            (count (intersection
                    (set (map #(.getDisplayString %) (:alleles g1)))
                    (set (map #(.getDisplayString %) (:alleles g2))))))]
    (cond
     (= (:alleles g1) (:alleles g2)) :concordant
     (phase-mismatch? g1 g2) :phasing-mismatch
     (nocall-mismatch? g1 g2) :phasing-nocall
     (atleast-one-match? g1 g2) :partial-mismatch
     :else :discordant)))</pre></td></tr><tr><td class="docs"><p>Check if variants have the same position and reference allele.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- same-vc-coords?
  [&amp; xs]
  (apply = (map (juxt :chr :start :end :ref-allele) xs)))</pre></td></tr><tr><td class="docs"><p>Flexible comparison of variants, assuming pre-checking of
   vc1 and vc2 to overlap in the same genomic region.</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti compare-vcs
  (fn [vc1 vc2 params]
    (cond
     (not (nil? (:compare-approach params))) (keyword (:compare-approach params))
     (or (&gt; (:num-samples vc1) 1)
         (&gt; (:num-samples vc2) 1)) :multiple
     :else :default)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod compare-vcs :multiple
  ^{:doc &quot;Compare variant contexts handling multiple sample comparisons.&quot;}
  [vc1 vc2 params]
  (letfn [(calc-genotype-score [g1 g2]
            (case (compare-genotypes g1 g2)
              :concordant 1.0
              :phasing-mismatch 1.0
              :nocall-mismatch 0.5
              :partial-mismatch 0.5
              0.0))]
    (when (same-vc-coords? vc1 vc2)
      (let [score-thresh (get params :multiple-thresh 1.0)
            vc2-cmps (into {} (map (juxt :sample-name identity) (:genotypes vc2)))
            score (/ (apply + (map #(calc-genotype-score % (get vc2-cmps (:sample-name %)))
                                   (:genotypes vc1)))
                     (:num-samples vc1))]
        (&gt;= score score-thresh)))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod compare-vcs :approximate
  ^{:doc &quot;Provide approximate comparisons between variants, handling cases
          like het versus homozygous variant calls and indels with
          different overlapping calls. The goal is to identify almost-match
          cases which are useful for variant evidence.&quot;}
  [vc1 vc2 params]
  (when (= (:type vc1) (:type vc2))
    (compare-vcs vc1 vc2 (assoc params :compare-approach
                                (str &quot;approximate-&quot; (-&gt; vc1 :type string/lower-case))))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod compare-vcs :approximate-indel
  ^{:doc &quot;Approximate comparisons for indels, allowing overlapping
          indels to count as concordant.&quot;}
  [vc1 vc2 params]
  {:pre [(every? #(= 1 (:num-samples %)) [vc1 vc2])]}
  (letfn [(all-alleles [x]
            (map #(.getBaseString %) (cons (:ref-allele x) (-&gt; x :genotypes first :alleles))))]
    (let [vc1-alleles (all-alleles vc1)
          vc2-alleles (all-alleles vc2)]
      (and (contains? (set (range (dec (:start vc1)) (:end vc1))) (dec (:start vc2)))
           (or (every? #(= 1 (count (first %))) [vc1-alleles vc2-alleles])
               (every? #(&gt; (count (first %)) 1) [vc1-alleles vc2-alleles]))))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod compare-vcs :approximate-snp
  ^{:doc &quot;Approximate comparisons for SNPs, allowing matching het/hom calls.&quot;}
  [vc1 vc2 params]
  {:pre [(every? #(= 1 (:num-samples %)) [vc1 vc2])]}
  (when (same-vc-coords? vc1 vc2)
    (not (empty?
          (-&gt;&gt; [vc1 vc2]
               (map #(-&gt; % :genotypes first :alleles set))
               (apply intersection))))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod compare-vcs :default
  ^{:doc &quot;Provide exact comparisons for variants, requiring identical
          base coordinates and reference and identical allele calls.&quot;}
  [vc1 vc2 params]
  {:pre [(every? #(= 1 (:num-samples %)) [vc1 vc2])]}
  (when (same-vc-coords? vc1 vc2) 
    (apply = (map #(-&gt; % :genotypes first :alleles) [vc1 vc2]))))</pre></td></tr><tr><td class="docs"><p>Top level comparison of variant contexts: check if any vc2s match vc1.
   Flexible handles different comparisons with <code>compare-vcs</code></p>
</td><td class="codes"><pre class="brush: clojure">(defn find-concordant-vcs
  [vc1 vc2-checks params]
  (letfn [(are-concordant? [vc1 vc2]
            (when (compare-vcs vc1 vc2 params)
              true))]
    (let [vc2-groups (group-by (partial are-concordant? vc1) vc2-checks)]
      [(get vc2-groups true [])
       (get vc2-groups nil [])])))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- add-cmp-kw
  [xs kw]
  (partition 2 (interleave (repeat kw) xs)))</pre></td></tr><tr><td class="docs"><p>Compare variant context with second list of variants.
  Assumes sorted vc2-iter by position, returning any variants in the region
  that don't match.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- compare-vc-w-iter
  [vc1 vc2-iter cmp-kws params]
  {:pre [(= 3 (count cmp-kws))]}
  (letfn [(less-than-vc? [vc1 vc2]
            (and (= (:chr vc2) (:chr vc1))
                 (&lt;= (:start vc2) (:end vc1))))]
    (let [[cur-vc2-iter rest-vc2-iter] (split-with (partial less-than-vc? vc1) vc2-iter)
          [vc2-extras vc2-checks] (split-with #(&lt; (:start %) (:start vc1)) cur-vc2-iter)
          [vc2-matches vc2-continues] (find-concordant-vcs vc1 vc2-checks params)]
      {:cur-cmps (concat (add-cmp-kw vc2-extras (last cmp-kws))
                         [(if (seq vc2-matches)
                            [(first cmp-kws) vc1]
                            [(second cmp-kws) vc1])])
       :cur-vc2-iter (concat vc2-continues rest-vc2-iter)})))</pre></td></tr><tr><td class="docs"><p>Lazy comparison of two sets of variants. Assumes identical ordering.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- compare-two-vc-iters
  [vc1-iter vc2-iter cmp-kws params]
  (lazy-seq
   (if-let [vc1 (first vc1-iter)]
     (let [{:keys [cur-cmps cur-vc2-iter]} (compare-vc-w-iter vc1 vc2-iter cmp-kws params)]
       (concat cur-cmps (compare-two-vc-iters (rest vc1-iter) cur-vc2-iter cmp-kws params)))
     (add-cmp-kw vc2-iter (last cmp-kws)))))</pre></td></tr><tr><td class="docs"><p>Compare two variant input files, with flexible matching conditions.
   TODO: restrict comparison by intervals.</p>
</td><td class="codes"><pre class="brush: clojure">(defn compare-two-vcf-flexible
  [c1 c2 exp config]
  (let [out-files (get-cmp-outfiles c1 c2 exp config)]
    (when (itx/needs-run? (vals out-files))
      (with-open [c1-iter (gvc/get-vcf-iterator (:file c1) (:ref exp))
                  c2-iter (gvc/get-vcf-iterator (:file c2) (:ref exp))]
        (gvc/write-vcf-w-template (:file c1) out-files
                                  (compare-two-vc-iters (gvc/parse-vcf c1-iter)
                                                        (gvc/parse-vcf c2-iter)
                                                        (keys out-files)
                                                        (get exp :params {}))
                                  (:ref exp))))
    {:c-files out-files :c1 c1 :c2 c2 :exp exp :dir (:dir config)}))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.normalize" name="bcbio.variation.normalize"><h1 class="project-name">bcbio.variation.normalize</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Prepare a VCF file for comparison by normalizing chromosome names,
  sort order, sample name, and genotype representation.
  This handles the work of making slightly different representations
  match, enabling VCF comparisons.
  Currently implemented for human only, with hooks to generalize for other
  organisms.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.normalize
  (:import [org.broadinstitute.sting.utils.variantcontext VariantContextBuilder GenotypeBuilder]
           [org.broadinstitute.sting.utils.codecs.vcf VCFHeader]
           [org.broad.tribble.readers AsciiLineReader])
  (:use [clojure.java.io]
        [bcbio.variation.variantcontext :only [write-vcf-w-template
                                               get-vcf-iterator parse-vcf
                                               get-vcf-line-parser
                                               from-genotype]]
        [bcbio.align.ref :only [get-seq-dict get-seq-name-map extract-sequence]]
        [ordered.map :only (ordered-map)]
        [ordered.set :only (ordered-set)])
  (:require [clojure.string :as string]
            [fs.core :as fs]
            [lonocloud.synthread :as -&gt;]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><h2>Chromosome name remapping</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Provide mapping from variant chromosome names to reference
keyed on the organism name. Currently only a human GRCh37 remap.</p>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmulti chr-name-remap (fn [type &amp; args] type))</pre></td></tr><tr><td class="docs"><p>Function to retrieve hg19 information. Requires korma and
  mysql connector.</p>
</td><td class="codes"><pre class="brush: clojure">(comment
(defn- get-hg19-map
  []
  (defdb db (mysql {:db &quot;hg19&quot;
                    :user &quot;genome&quot;
                    :host &quot;genome-mysql.cse.ucsc.edu&quot;}))
  (defentity ucscToEnsembl)
  (-&gt;&gt; (select ucscToEnsembl)
       (map (juxt :ucsc :ensembl))
       (into {}))))</pre></td></tr><tr><td class="docs"><p>Cached version of hg19 map to avoid having to make database connections</p>
</td><td class="codes"><pre class="brush: clojure">(def hg19-map
  {&quot;chrM&quot; &quot;MT&quot; &quot;chrMT&quot; &quot;MT&quot; &quot;chrUn_gl000211&quot; &quot;GL000211&quot;, &quot;chrUn_gl000222&quot; &quot;GL000222&quot;,
   &quot;chrUn_gl000233&quot; &quot;GL000233&quot;, &quot;chrUn_gl000244&quot; &quot;GL000244&quot;, &quot;chrUn_gl000212&quot; &quot;GL000212&quot;,
   &quot;chrUn_gl000223&quot; &quot;GL000223&quot;, &quot;chrUn_gl000234&quot; &quot;GL000234&quot;, &quot;chrUn_gl000245&quot; &quot;GL000245&quot;,
   &quot;chrUn_gl000213&quot; &quot;GL000213&quot;, &quot;chrUn_gl000224&quot; &quot;GL000224&quot;, &quot;chrUn_gl000235&quot; &quot;GL000235&quot;,
   &quot;chrUn_gl000246&quot; &quot;GL000246&quot;, &quot;chr6_mcf_hap5&quot; &quot;HSCHR6_MHC_MCF&quot;, &quot;chrUn_gl000214&quot; &quot;GL000214&quot;,
   &quot;chrUn_gl000225&quot; &quot;GL000225&quot;, &quot;chrUn_gl000236&quot; &quot;GL000236&quot;, &quot;chrUn_gl000247&quot; &quot;GL000247&quot;,
   &quot;chr1&quot; &quot;1&quot;, &quot;chr6_cox_hap2&quot; &quot;HSCHR6_MHC_COX&quot;, &quot;chrUn_gl000215&quot; &quot;GL000215&quot;,
   &quot;chrUn_gl000226&quot; &quot;GL000226&quot;, &quot;chrUn_gl000237&quot; &quot;GL000237&quot;, &quot;chrUn_gl000248&quot; &quot;GL000248&quot;,
   &quot;chr2&quot; &quot;2&quot;, &quot;chrUn_gl000216&quot; &quot;GL000216&quot;, &quot;chrUn_gl000227&quot; &quot;GL000227&quot;,
   &quot;chrUn_gl000238&quot; &quot;GL000238&quot;, &quot;chrUn_gl000249&quot; &quot;GL000249&quot;, &quot;chr3&quot; &quot;3&quot;,
   &quot;chrUn_gl000217&quot; &quot;GL000217&quot;, &quot;chrUn_gl000228&quot; &quot;GL000228&quot;, &quot;chrUn_gl000239&quot; &quot;GL000239&quot;,
   &quot;chr9_gl000201_random&quot; &quot;GL000201&quot;, &quot;chr4&quot; &quot;4&quot;, &quot;chr11_gl000202_random&quot; &quot;GL000202&quot;,
   &quot;chrUn_gl000218&quot; &quot;GL000218&quot;, &quot;chrUn_gl000229&quot; &quot;GL000229&quot;, &quot;chr9_gl000200_random&quot; &quot;GL000200&quot;,
   &quot;chr19_gl000209_random&quot; &quot;GL000209&quot;, &quot;chr5&quot; &quot;5&quot;, &quot;chrUn_gl000219&quot; &quot;GL000219&quot;,
   &quot;chr1_gl000192_random&quot; &quot;GL000192&quot;, &quot;chr18_gl000207_random&quot; &quot;GL000207&quot;, &quot;chr6&quot; &quot;6&quot;,
   &quot;chr21_gl000210_random&quot; &quot;GL000210&quot;, &quot;chr17_gl000206_random&quot; &quot;GL000206&quot;,
   &quot;chr9_gl000199_random&quot; &quot;GL000199&quot;, &quot;chr1_gl000191_random&quot; &quot;GL000191&quot;,
   &quot;chr4_gl000194_random&quot; &quot;GL000194&quot;, &quot;chr19_gl000208_random&quot; &quot;GL000208&quot;,
   &quot;chr17_gl000205_random&quot; &quot;GL000205&quot;, &quot;chr7&quot; &quot;7&quot;, &quot;chr9_gl000198_random&quot; &quot;GL000198&quot;,
   &quot;chr8_gl000197_random&quot; &quot;GL000197&quot;, &quot;chr4_gl000193_random&quot; &quot;GL000193&quot;,
   &quot;chr17_gl000204_random&quot; &quot;GL000204&quot;, &quot;chr8&quot; &quot;8&quot;, &quot;chrX&quot; &quot;X&quot;, &quot;chr8_gl000196_random&quot; &quot;GL000196&quot;,
   &quot;chr7_gl000195_random&quot; &quot;GL000195&quot;, &quot;chr20&quot; &quot;20&quot;, &quot;chr9&quot; &quot;9&quot;, &quot;chrY&quot; &quot;Y&quot;,
   &quot;chr17_gl000203_random&quot; &quot;GL000203&quot;, &quot;chr10&quot; &quot;10&quot;, &quot;chr21&quot; &quot;21&quot;, &quot;chr6_dbb_hap3&quot; &quot;HSCHR6_MHC_DBB&quot;,
   &quot;chr11&quot; &quot;11&quot;, &quot;chr22&quot; &quot;22&quot;, &quot;chr6_ssto_hap7&quot; &quot;HSCHR6_MHC_SSTO&quot;, &quot;chr17_ctg5_hap1&quot; &quot;HSCHR17_1&quot;,
   &quot;chr12&quot; &quot;12&quot;, &quot;chr13&quot; &quot;13&quot;, &quot;chr14&quot; &quot;14&quot;, &quot;chr15&quot; &quot;15&quot;, &quot;chr16&quot; &quot;16&quot;,
   &quot;chr6_mann_hap4&quot; &quot;HSCHR6_MHC_MANN&quot;, &quot;chr17&quot; &quot;17&quot;, &quot;chr18&quot; &quot;18&quot;, &quot;chr19&quot; &quot;19&quot;,
   &quot;chr6_qbl_hap6&quot; &quot;HSCHR6_MHC_QBL&quot;, &quot;chr6_apd_hap1&quot; &quot;HSCHR6_MHC_APD&quot;,
   &quot;chrUn_gl000240&quot; &quot;GL000240&quot;, &quot;chrUn_gl000230&quot; &quot;GL000230&quot;, &quot;chrUn_gl000241&quot; &quot;GL000241&quot;,
   &quot;chr4_ctg9_hap1&quot; &quot;HSCHR4_1&quot;, &quot;chrUn_gl000220&quot; &quot;GL000220&quot;, &quot;chrUn_gl000231&quot; &quot;GL000231&quot;,
   &quot;chrUn_gl000242&quot; &quot;GL000242&quot;, &quot;chrUn_gl000221&quot; &quot;GL000221&quot;, &quot;chrUn_gl000232&quot; &quot;GL000232&quot;,
   &quot;chrUn_gl000243&quot; &quot;GL000243&quot;})</pre></td></tr><tr><td class="docs"><p>Convert any non-versioned names into the representative version in ref-dict.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- fix-non-version-names
  [base-map ref-dict]
  (letfn [(find-best-match [x check]
            (first (filter #(.startsWith % x) check)))]
    (reduce (fn [coll [k v]]
              (assoc coll k
                     (if (contains? ref-dict v)
                       v
                       (find-best-match v (keys ref-dict)))))
            {} base-map)))</pre></td></tr><tr><td class="docs"><p>Add alternative key variations:
    - underscore to dash in hg19 names
    - chr added to all GRCh37 names instead of hg19 names</p>
</td><td class="codes"><pre class="brush: clojure">(defn- add-alt-keys
  [base-map modtype]
  {:pre [(= modtype :underscore)]}
  (reduce (fn [coll [k v]]
            (-&gt; coll
                (assoc k v)
                (assoc (string/replace k &quot;_&quot; &quot;-&quot;) v)
                (assoc (str &quot;chr&quot; v) v)))
          {} base-map))</pre></td></tr><tr><td class="docs"><p>Fix GRCh37/hg19 name mappings to handle common problem cases.</p>
</td><td class="codes"><pre class="brush: clojure">(defn prep-rename-map
  [map-key ref-file]
  (let [remappers {:GRCh37 hg19-map}]
    (-&gt; (get remappers map-key)
        (fix-non-version-names (get-seq-name-map ref-file))
        (add-alt-keys :underscore))))</pre></td></tr><tr><td class="docs"><p>Retrieve a list of all chromosome names from a reference FASTA file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- chrs-from-fasta-file
  [ref-file]
  (map #(.getSequenceName %) (-&gt; ref-file get-seq-dict .getSequences)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod chr-name-remap :GRCh37
  [map-key ref-file orig-ref-file]
  (let [rename-map (prep-rename-map map-key ref-file)
        ref-chrs (set (chrs-from-fasta-file ref-file))
        vcf-chrs (when (and orig-ref-file (not= orig-ref-file ref-file))
                   (chrs-from-fasta-file orig-ref-file))]
    (letfn [(maybe-remap-name [x]
              (let [remap-x (get rename-map x)]
                (if (and remap-x (contains? ref-chrs remap-x))
                  remap-x x)))]
      (if vcf-chrs
        (zipmap vcf-chrs
                (map maybe-remap-name vcf-chrs))
        rename-map))))</pre></td></tr><tr><td class="docs"><h2>Resort and normalize variants</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Build a new variant context with updated sample name and normalized alleles.
  Based on :prep-allele-count in the configuration updates haploid allele calls. This
  normalizes the representation in Mitochondrial and Y chromosomes which are
  haploid but are often represented as diploid with a single call.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- fix-vc
  [sample config orig]
  (letfn [(update-genotype-sample [vc sample]
            (if (and (not (nil? sample))
                     (= 1 (count (.getGenotypes vc))))
              (let [g (first (.getGenotypes vc))]
                [(-&gt; (GenotypeBuilder. g)
                     (.name sample)
                     .make)])
              (.getGenotypes vc)))
          (normalize-allele-calls [g]
            {:pre [(or (nil? (:prep-allele-count config))
                       (contains? (set [1 (:prep-allele-count config)]) (count (.getAlleles g))))]}
            (if (or (nil? (:prep-allele-count config))
                    (= (count (.getAlleles g)) (:prep-allele-count config)))
              g
              (-&gt; (GenotypeBuilder. g)
                  (.alleles (repeat (:prep-allele-count config)
                                    (first (.getAlleles g))))
                  .make)))]
    (-&gt; orig
        (assoc :vc
          (-&gt; (VariantContextBuilder. (:vc orig))
              (.genotypes (map normalize-allele-calls (update-genotype-sample (:vc orig) sample)))
              .make)))))</pre></td></tr><tr><td class="docs"><p>Check if a variant has a non-informative no-call genotype.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- no-call-genotype?
  [vc config]
  (let [to-remove (cond
                   (:prep-sv-genotype config) #{}
                   (:remove-refcalls config) #{&quot;NO_CALL&quot; &quot;MIXED&quot; &quot;HOM_REF&quot;}
                   :else #{&quot;NO_CALL&quot; &quot;MIXED&quot;})]
    (if-not (= 1 (:num-samples vc)) false
            (try
              (contains? to-remove (-&gt; vc :genotypes first :type))
              (catch Exception e
                (println (:chr vc) (:start vc))
                (throw e))))))</pre></td></tr><tr><td class="docs"><p>Check a VCF input line for identical REF and ALT calls</p>
</td><td class="codes"><pre class="brush: clojure">(defn nochange-alt?
  [line]
  (let [parts (string/split line #&quot;\t&quot;)]
    (= (nth parts 3) (nth parts 4))))</pre></td></tr><tr><td class="docs"><p>Sort stream of line inputs by position.
  Requires loading the entire file into memory during the sort-by phase
  so will not work on massive files. Should be feasible with files
  split by chromosome.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- sort-by-position
  [line-seq]
  (letfn [(add-position [line]
            (let [[chrom start] (take 2 (string/split line #&quot;\t&quot;))]
              [[chrom (Integer/parseInt start)] line]))]
    (-&gt;&gt; line-seq
         (map add-position)
         (sort-by first)
         (map second))))</pre></td></tr><tr><td class="docs"><p>Provide genotype calls for structural variants to a single ref call.
  Structural variants often don't have proper genotype references since
  individual haplotypes are not called. This makes them a single reference
  if not specified or mixed.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- normalize-sv-genotype
  [config sample orig]
  (letfn [(maybe-fix-vc [g alt-allele]
            (case (:type g)
              &quot;MIXED&quot; (-&gt; (GenotypeBuilder. (:genotype g))
                          (.alleles) (remove #(.isNoCall %) (:alleles g))
                          .make)
              (&quot;UNAVAILABLE&quot; &quot;NO_CALL&quot;) (-&gt; (GenotypeBuilder. (:genotype g))
                                            (.alleles [alt-allele])
                                            .make)
              (:genotype g)))
          (ref-vc-genotype [gs alt-allele]
            (case (count gs)
              0 [(-&gt; (GenotypeBuilder.)
                     (.name sample)
                     (.alleles [alt-allele])
                     .make)]
              1 [(maybe-fix-vc (first gs) alt-allele)]
              (map :genotype gs)))]
    (if (:prep-sv-genotype config)
      (let [new-gs (ref-vc-genotype (:genotypes orig)
                                    (first (:alt-alleles orig)))]
        (-&gt; orig
            (assoc :vc
              (-&gt; (VariantContextBuilder. (:vc orig))
                  (.genotypes new-gs)
                  .make))
            (assoc :genotypes (map from-genotype new-gs))))
      orig)))</pre></td></tr><tr><td class="docs"><p>Provide VariantContexts ordered by chromosome and normalized.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- ordered-vc-iter
  [rdr vcf-decoder sample config]
  (-&gt;&gt; rdr
       line-seq
       (#(if (:prep-sort-pos config) (sort-by-position %) %))
       (remove nochange-alt?)
       (map vcf-decoder)
       (remove #(no-call-genotype? % config))
       (map (partial normalize-sv-genotype config sample))
       (map (partial fix-vc sample config))
       (map :vc)))</pre></td></tr><tr><td class="docs"><p>Provide fixes to VCF input lines that do not require VariantContext parsing.
  Fixes:
    - INFO lines with empty attributes (starting with ';'), found in
      Complete Genomics VCF files
    - Chromosome renaming.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- fix-vcf-line
  [line chr-map config]
  (letfn [(empty-attribute-info [info]
            (if (.startsWith info &quot;;&quot;)
              (subs info 1)
              info))
          (fix-info [xs]
            (assoc xs 7 (empty-attribute-info (nth xs 7))))
          (fix-chrom [new xs]
            (assoc xs 0 new))]
    (let [parts (string/split line #&quot;\t&quot;)
          cur-chrom (or (get chr-map (first parts)) (first parts))]
      {:chrom cur-chrom
       :line (-&gt;&gt; parts
                  (fix-chrom cur-chrom)
                  fix-info
                  (string/join &quot;\t&quot;))})))</pre></td></tr><tr><td class="docs"><p>Split input VCF into separate files by chromosome, returning a map of file names.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- vcf-by-chrom
  [vcf-file ref-file orig-ref-file tmp-dir config]
  (letfn [(ref-chr-files [ref-file]
            (into (ordered-map)
                  (map (fn [x] [x (str (fs/file tmp-dir (str &quot;prep&quot; x &quot;.vcf&quot;)))])
                       (chrs-from-fasta-file ref-file))))
          (write-by-chrom [ref-wrtrs chr-map line]
            (let [line-info (fix-vcf-line line chr-map config)]
              (if-let [wtr (get ref-wrtrs (:chrom line-info))]
                (.write wtr (str (:line line-info) &quot;\n&quot;))
                (throw (Exception. (format &quot;Could not find remapping of chromosome %s in reference: %s&quot;
                                           (:chrom line-info) (keys ref-wrtrs)))))))]
    (let [ref-chrs (ref-chr-files ref-file)
          ref-wrtrs (zipmap (keys ref-chrs) (map writer (vals ref-chrs)))
          chr-map (chr-name-remap (:prep-org config) ref-file orig-ref-file)]
      (with-open [rdr (reader vcf-file)]
        (-&gt;&gt; rdr
             line-seq
             (drop-while #(.startsWith % &quot;#&quot;))
             (map (partial write-by-chrom ref-wrtrs chr-map))
             doall)
        (doseq [x (vals ref-wrtrs)]
          (.close x)))
      ref-chrs)))</pre></td></tr><tr><td class="docs"><h2>Top level functionality to manage inputs and writing.</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Update header information, removing contig and adding sample names.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- update-header
  [sample config]
  (letfn [(clean-metadata [header]
            (apply ordered-set (remove #(= &quot;contig&quot; (.getKey %)) (.getMetaDataInInputOrder header))))]
    (fn [_ header]
      (let [cur-samples (.getGenotypeSamples header)
            new-samples (if (and (:fix-sample-header config)
                                 (not (nil? sample))
                                 (&lt; (count cur-samples) 2))
                          (ordered-set sample)
                          cur-samples)]
        (VCFHeader. (clean-metadata header) new-samples)))))</pre></td></tr><tr><td class="docs"><p>Update a VCF file with one item to have the given sample name.</p>
</td><td class="codes"><pre class="brush: clojure">(defn fix-vcf-sample
  [in-file sample ref]
  (let [out-file (itx/add-file-part in-file &quot;samplefix&quot;)]
    (when (itx/needs-run? out-file)
      (with-open [vcf-iter (get-vcf-iterator in-file ref)]
        (write-vcf-w-template in-file {:out out-file}
                              (map #(:vc (fix-vc sample {} %)) (parse-vcf vcf-iter))
                              ref :header-update-fn (update-header sample {}))))
    out-file))</pre></td></tr><tr><td class="docs"><p>Check a VCF file for alternative alleles that match reference, removing them.
   This avoids issues where callers output alleles that match expected reference
   causing GATK errors.</p>
</td><td class="codes"><pre class="brush: clojure">(defn remove-ref-alts
  [in-file ref-file]
  (letfn [(alt-matches-ref? [vc]
            (when-let [ref-seq (extract-sequence ref-file (:chr vc) (:start vc) (:end vc))]
              (contains? (set (map #(.getBaseString %) (:alt-alleles vc))) ref-seq)))]
    (let [out-file (itx/add-file-part in-file &quot;callprep&quot;)]
      (when (itx/needs-run? out-file)
        (with-open [vcf-iter (get-vcf-iterator in-file ref-file)]
          (write-vcf-w-template in-file {:out out-file}
                                (map :vc (remove alt-matches-ref? (parse-vcf vcf-iter)))
                                ref-file)))
      out-file)))</pre></td></tr><tr><td class="docs"><p>Write VCF file with correctly ordered and cleaned variants.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- write-prepped-vcf
  [vcf-file out-info ref-file orig-ref-file sample config]
  (itx/with-temp-dir [tmp-dir (fs/parent (:out out-info))]
    (let [reader-by-chr (into (ordered-map) (map (fn [[k v]] [k (reader v)])
                                                 (vcf-by-chrom vcf-file ref-file orig-ref-file
                                                               tmp-dir config)))]
      (with-open [vcf-reader (AsciiLineReader. (input-stream vcf-file))]
        (let [vcf-decoder (get-vcf-line-parser vcf-reader)]
          (write-vcf-w-template vcf-file out-info
                                (flatten
                                 (for [rdr (vals reader-by-chr)]
                                   (ordered-vc-iter rdr vcf-decoder sample config)))
                                ref-file
                                :header-update-fn (update-header sample config))))
      (doseq [x (vals reader-by-chr)]
        (.close x)))))</pre></td></tr><tr><td class="docs"><p>Prepare VCF for comparison by normalizing high level attributes
  Assumes by position sorting of variants in the input VCF. Chromosomes do
  not require a specific order, but positions internal to a chromosome do.
  Currently configured for human preparation.</p>
</td><td class="codes"><pre class="brush: clojure">(defn prep-vcf
  [in-vcf-file ref-file sample &amp; {:keys [out-dir out-fname config orig-ref-file]
                                  :or {config {}}}]
  (let [config (merge-with #(if (nil? %1) %2 %1) config
                           {:prep-org :GRCh37 :prep-allele-count 2
                            :prep-sort-pos false :prep-sv-genotype false
                            :fix-sample-header false
                            :remove-refcalls true})
        base-name (if (nil? out-fname) (itx/remove-zip-ext in-vcf-file) out-fname)
        out-file (itx/add-file-part base-name &quot;prep&quot; out-dir)]
    (when (itx/needs-run? out-file)
      (write-prepped-vcf in-vcf-file {:out out-file}
                         ref-file orig-ref-file
                         sample config))
    out-file))</pre></td></tr><tr><td class="docs"><p>Choose a reference genome for a variant file from set of choices.</p>
</td><td class="codes"><pre class="brush: clojure">(defn pick-best-ref
  [vcf refs]
  (letfn [(get-vcf-contig [fname]
            (with-open [rdr (reader fname)]
              (-&gt;&gt; (line-seq rdr)
                   (drop-while #(.startsWith % &quot;#&quot;))
                   first
                   (#(string/split % #&quot;\t&quot;))
                   first)))
          (has-contig? [contig ref-file]
            (contains?
             (set (keys (get-seq-name-map ref-file)))
             contig))]
    (let [test-contig (get-vcf-contig vcf)]
      (first (filter (partial has-contig? test-contig) refs)))))</pre></td></tr><tr><td class="docs"><h2>Remove problem characters</h2>

<p>Handle cleanup for VCF files before feeding to any verifying
parser.</p>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Given a VCF line, retrieve the reference base prior to the variant.
   Used to include the required reference padding in indels missing them.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-prev-pad
  [ref-file]
  (let [chr-map (prep-rename-map :GRCh37 ref-file)
        get-ref-chrom (fn [chrom]
                        (get chr-map chrom chrom))]
    (fn [xs]
      (let [before-start (dec (Integer/parseInt (second xs)))]
        (string/upper-case
         (str
          (or (extract-sequence ref-file (get-ref-chrom (first xs)) before-start before-start) &quot;N&quot;)))))))</pre></td></tr><tr><td class="docs"><p>Check reference and alt alleles for lack of a padding base on indels.
  The VCF spec requires this and GATK will parse incorrectly when a variant
  lacks a shared padding base for indels.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- maybe-add-indel-pad-base
  [ref-file prev-pad xs]
  (letfn [(get-ref-alts [xs]
            [(nth xs 3) (string/split (nth xs 4) #&quot;,&quot;)])
          (indel? [xs]
            (let [[vc-ref vc-alts] (get-ref-alts xs)]
              (some #(and (not (.startsWith % &quot;&lt;&quot;))
                          (not= (count vc-ref) (count %)))
                    vc-alts)))
          (is-5pad-n? [xs]
            (let [[vc-ref vc-alts] (get-ref-alts xs)]
              (every? #(and (.startsWith vc-ref &quot;N&quot;) (.startsWith % &quot;N&quot;)) vc-alts)))
          (fix-5pad-n [xs]
            (let [[vc-ref vc-alts] (get-ref-alts xs)]
              (-&gt; xs
                  (assoc 3 (str (prev-pad xs) (subs vc-ref 1)))
                  (assoc 4 (string/join &quot;,&quot;
                                        (map #(str (prev-pad xs) (subs % 1)) vc-alts))))))
          (no-pad? [xs]
            (let [[vc-ref vc-alts] (get-ref-alts xs)]
              (some #(and (not (.startsWith % &quot;&lt;&quot;))
                          (not= (first vc-ref) (first %)))
                    vc-alts)))
          (fix-nopad [xs]
            (let [[vc-ref vc-alts] (get-ref-alts xs)]
              (-&gt; xs
                  (assoc 1 (dec (Integer/parseInt (second xs))))
                  (assoc 3 (str (prev-pad xs) vc-ref))
                  (assoc 4 (string/join &quot;,&quot;
                                        (map #(str (prev-pad xs) %) vc-alts))))))]
    (if (empty? xs) []
        (-&gt; xs
            (-&gt;/as cur-xs
              (-&gt;/when (and (indel? cur-xs) (is-5pad-n? cur-xs))
                fix-5pad-n))
            (-&gt;/as cur-xs
              (-&gt;/when (and (indel? cur-xs) (no-pad? cur-xs))
                fix-nopad))))))</pre></td></tr><tr><td class="docs"><p>Remove calls where the reference base does not match expected reference allele.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- remove-bad-ref
  [ref-file xs]
  (letfn [(is-bad-ref? [xs]
            (let [check-bases #{&quot;A&quot; &quot;C&quot; &quot;G&quot; &quot;T&quot;}
                  [chrom start _ vc-ref] (take 4 xs)
                  real-ref (extract-sequence ref-file chrom (Integer/parseInt start)
                                             (Integer/parseInt start))]
              (and (= 1 (count vc-ref))
                   (not (nil? real-ref))
                   (contains? check-bases (string/upper-case real-ref))
                   (contains? check-bases (string/upper-case vc-ref))
                   (not= (string/upper-case vc-ref) (string/upper-case real-ref)))))]
    (cond
     (empty? xs) []
     (is-bad-ref? xs) []
     :else xs)))</pre></td></tr><tr><td class="docs"><p>Clean VCF file which GATK parsers cannot handle due to illegal characters.
  Fixes:
    - Gap characters (-) found in REF or ALT indels.
    - Fixes indels without reference padding or N padding.
    - Removes spaces in INFO fields.
    - Handles Illumina special case of SNPs with MAXGT and POLY calls.
      Uses the MAXGT calls which make no prior assumptions about polymorphism</p>
</td><td class="codes"><pre class="brush: clojure">(defn clean-problem-vcf
  [in-vcf-file ref-file sample &amp; {:keys [out-dir]}]
  (letfn [(fix-bad-alt-header [x]
            (str &quot;##ALT=&lt;ID&quot; (string/replace-first x &quot;##ALT=Type&quot; &quot;&quot;) &quot;&gt;&quot;))
          (rename-samples [xs want]
            (let [idx (ffirst (filter (fn [[i x]] (.startsWith x want))
                                      (map-indexed vector xs)))]
              (cond
               idx (assoc (vec xs) idx want)
               (contains? #{0 1} (count xs)) [want]
               (.contains (first xs) &quot;_MAXGT&quot;) (cons want (rest xs))
               :else xs)))
          (fix-sample-names [x]
            (if (&gt; (count (string/split x #&quot;\t&quot;)) 8)
              (let [[stay-parts samples] (split-at 9 (string/split x #&quot;\t&quot;))
                    fix-samples (if (contains? (set samples) sample)
                                  samples
                                  (rename-samples samples sample))]
                (string/join &quot;\t&quot; (concat stay-parts fix-samples)))
              x))
          (clean-header [x]
            (cond
             (.startsWith x &quot;##ALT=Type=&quot;) (fix-bad-alt-header x)
             (.startsWith x &quot;##FORMAT=&lt;ID=GL,Number=.,Type=String&quot;) &quot;&quot;
             (.startsWith x &quot;#CHROM&quot;) (fix-sample-names x)
             :else x))
          (remove-gap [n xs]
            (assoc xs n
                   (-&gt; (nth xs n)
                       (string/replace &quot;-&quot; &quot;&quot;)
                       (string/replace &quot;.&quot; &quot;&quot;))))
          (has-duplicate-alts? [alt]
            (let [alts (string/split alt #&quot;,&quot;)]
              (not= (count alts) (count (set alts)))))
          (remove-problem-alts [xs]
            (let [ref (nth xs 3)
                  alt (nth xs 4)]
              (cond
               (empty? xs) []
               (= ref alt) []
               (= &quot;.&quot; alt) []
               (has-duplicate-alts? alt) []
               :else xs)))
          (fix-info-spaces [xs]
            (assoc xs 7
                   (string/replace (nth xs 7) &quot; &quot; &quot;_&quot;)))
          (clean-line [line]
            (if (.startsWith line &quot;#&quot;)
              (clean-header line)
              (-&gt;&gt; (string/split line #&quot;\t&quot;)
                   (remove-gap 3)
                   (remove-gap 4)
                   (fix-info-spaces)
                   remove-problem-alts
                   (remove-bad-ref ref-file)
                   (maybe-add-indel-pad-base ref-file (get-prev-pad ref-file))
                   (string/join &quot;\t&quot;))))]
    (let [out-file (itx/add-file-part in-vcf-file &quot;preclean&quot; out-dir)]
      (when (itx/needs-run? out-file)
        (itx/with-tx-file [tx-out-file out-file]
          (with-open [rdr (reader in-vcf-file)
                      wtr (writer tx-out-file)]
            (doall
             (map #(.write wtr (str % &quot;\n&quot;))
                  (remove empty? (map clean-line (line-seq rdr))))))))
      out-file)))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.phasing" name="bcbio.variation.phasing"><h1 class="project-name">bcbio.variation.phasing</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Support phased haplotype comparisons between variant calls.
   Compares a phased set of calls versus haploid reference calls.</p>

<p>   The comparison logic is:</p>

<ul>
<li>Group calls into regions based on phasing</li>
<li>For each phase region:
<ul><li>Determine which set of haploid alleles to compare with the reference</li>
<li>With each position in this haploid:
<ul><li>Compare to reference allele</li>
<li>If mismatch and alternate allele matches reference, then phasing error</li>
<li>If mismatch and neither allele matches, then calling error</li></ul></li></ul></li>
</ul>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.phasing
  (:import [org.broadinstitute.sting.utils.interval IntervalUtils IntervalSetRule]
           [org.broadinstitute.sting.utils GenomeLocParser GenomeLoc])
  (:use [bcbio.variation.callable :only [get-bed-source features-in-region
                                         limit-bed-intervals get-bed-iterator]]
        [bcbio.variation.filter.intervals :only [intersection-of-bed-files
                                                 select-by-sample]]
        [bcbio.variation.structural :only [prep-itree get-itree-overlap
                                           remove-itree-vc get-itree-all]]
        [bcbio.variation.variantcontext :only [parse-vcf get-vcf-retriever get-vcf-iterator
                                               variants-in-region merge-headers
                                               write-vcf-w-template]]
        [bcbio.align.ref :only [get-seq-dict]]
        [ordered.map :only [ordered-map]])
  (:require [fs.core :as fs]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><h2>Find phased haplotypes in VCF</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Check for phasing on a single genotype variant context based on:
   - variant has a single allele
   - variant has phasing specified (VCF | notation)
   - variant range overlaps previous variant (overlapping indels)</p>
</td><td class="codes"><pre class="brush: clojure">(defn- is-phased?
  [vc prev-vc bed-s]
  {:pre [(= 1 (:num-samples vc))]}
  (letfn [(safe-same-regions? [[a b]]
            (if (not-any? nil? [a b]) (= a b) true))
          (same-regions? [prev cur]
            (if (nil? bed-s)
              true
              (safe-same-regions?
               (map #((juxt :chr :start :end)
                      (first (features-in-region bed-s (:chr %) (:start %) (:end %))))
                    [prev cur]))))]
    (let [g (-&gt; vc :genotypes first)]
      (and (= (:chr vc) (:chr prev-vc))
           (same-regions? prev-vc vc)
           (or (= 1 (count (:alleles g)))
               (.isPhased (:genotype g))
               (&lt;= (:start vc) (:end prev-vc)))))))</pre></td></tr><tr><td class="docs"><p>Separate phased haplotypes provided in diploid input genome.
   We split at each phase break, returning a lazy list of variant
   contexts grouped into phases.</p>
</td><td class="codes"><pre class="brush: clojure">(defn parse-phased-haplotypes
  [vcf-iter ref-file &amp; {:keys [intervals]}]
  (let [prev (atom nil)
        bed-source (when intervals
                     (get-bed-source intervals ref-file))]
    (letfn [(split-at-phased [vc]
              (let [continue-phase (or (nil? @prev)
                                       (is-phased? vc @prev bed-source))]
                (reset! prev vc)
                continue-phase))]
      (partition-by split-at-phased (parse-vcf vcf-iter)))))</pre></td></tr><tr><td class="docs"><h2>Compare phased variants</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Retrieve the item with the highest count in the supplied list.
  We break ties by sorting by the actual list items</p>
</td><td class="codes"><pre class="brush: clojure">(defn highest-count
  [xs]
  (-&gt;&gt; (frequencies xs)
       (sort-by val &gt;)
       (partition-by second)
       first
       (sort-by first)
       ffirst))</pre></td></tr><tr><td class="docs"><p>Convenience function to get alleles for a single genotype variant context.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-alleles
  [vc]
  {:pre [(= 1 (:num-samples vc))]}
  (-&gt; vc :genotypes first :alleles))</pre></td></tr><tr><td class="docs"><p>Determine allele index where the variant context matches haploid reference.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- matching-allele
  [vc ref-vcs]
  {:pre [(every? #(= 1 (:num-samples %)) ref-vcs)
         (= 1 (:num-samples vc))]}
  (cond
   (= 1 (count (get-alleles vc))) 0
   (empty? ref-vcs) (.indexOf (get-alleles vc) (:ref-allele vc))
   :else (highest-count
          (remove neg?
                  (map #(.indexOf (get-alleles vc) (-&gt; % get-alleles first)) ref-vcs)))))</pre></td></tr><tr><td class="docs"><p>Compare the haploid allele of a variant against the expected call.</p>
</td><td class="codes"><pre class="brush: clojure">(defn cmp-allele-to-expected
  [vc e-vc i]
  (letfn [(is-ref-allele? [x]
            (apply = (map #(.getDisplayString (% x)) [:cmp :ref])))
          (get-cmp-allele [i x]
            (when (&lt; i (count (get-alleles x)))
              {:ref (:ref-allele x)
               :cmp (nth (get-alleles x) i)}))
          (get-all-alleles [x]
            (map #(get-cmp-allele % x) (range (count (get-alleles x)))))]
    (let [e-allele (when-not (nil? e-vc)
                     (get-cmp-allele 0 e-vc))
          call-hap (when-not (or (nil? i) (nil? vc) (neg? i))
                     (get-cmp-allele i vc))]
      (cond
       (nil? call-hap) :discordant
       (and (is-ref-allele? call-hap)
            (or (nil? e-allele)
                (= e-allele call-hap))) :ref-concordant
       (nil? e-allele) :discordant
       (= e-allele call-hap) :concordant
       (some (partial = e-allele) (get-all-alleles vc)) :phasing-error
       :else :discordant))))</pre></td></tr><tr><td class="docs"><p>Retrieve the type of a set of variants involved in a comparison.</p>

<ul>
<li><code>:indel</code> -- insertions or deletions of more than 1bp</li>
<li><code>:snp</code> -- Single nucleotide changes or single basepair changes</li>
<li><code>:unknown</code> -- Other classs of variations (structural)</li>
</ul>
</td><td class="codes"><pre class="brush: clojure">(defn get-variant-type
  [vcs]
  (letfn [(is-indel? [x]
            (contains? #{&quot;MIXED&quot; &quot;INDEL&quot;} (:type x)))
          (is-multi-indel? [x]
            (and (is-indel? x)
                 (not-every? #(contains? #{0 1} %)
                             (map #(-&gt; % .getDisplayString count) (cons (:ref-allele x)
                                                                     (:alt-alleles x))))))
          (is-snp? [x]
            (= &quot;SNP&quot; (:type x)))]
    (cond
     (some is-multi-indel? vcs) :indel
     (some is-indel? vcs) :indel
     (every? is-snp? (remove nil? vcs)) :snp
     :else :unknown)))</pre></td></tr><tr><td class="docs"><p>Determine if the variant has a non-matching heterozygous alternative allele.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- nomatch-het-alt?
  [vc e-vc]
  {:pre [(not (nil? vc))]}
  (let [match-allele-i (matching-allele vc (if (nil? e-vc) [] [e-vc]))
        no-match-alleles (remove nil? (map-indexed
                                       (fn [i x] (if-not (= i match-allele-i) x))
                                       (get-alleles vc)))]
    (and (= &quot;HET&quot; (-&gt; vc :genotypes first :type))
         (not-every? #(.isReference %) no-match-alleles))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- deleted-bases
  [vc]
  (letfn [(is-deletion? [vc]
            (and (= (:type vc) &quot;INDEL&quot;)
                 (pos? (.length (:ref-allele vc)))))]
    (if (is-deletion? vc)
      (map vector (repeat (:chr vc)) (range (:start vc) (inc (:end vc))))
      [])))</pre></td></tr><tr><td class="docs"><p>Provide metrics for comparison of haploid expected alleles to variant calls.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- comparison-metrics
  [cmp-itree i e-vc]
  (let [cmp-vc (-&gt;&gt; (get-itree-overlap cmp-itree (:chr e-vc) (:start e-vc) (:end e-vc))
                    (filter #(= (:start %) (:start e-vc)))
                    first)]
    {:comparison (cmp-allele-to-expected cmp-vc e-vc i)
     :variant-type (get-variant-type [cmp-vc e-vc])
     :nomatch-het-alt (when-not (nil? cmp-vc) (nomatch-het-alt? cmp-vc e-vc))
     :start (if (nil? cmp-vc) (:start e-vc) (:start cmp-vc))
     :end (:end cmp-vc)
     :end-ref (:end e-vc)
     :deleted (deleted-bases e-vc)
     :vc (:vc cmp-vc)
     :ref-vc (:vc e-vc)}))</pre></td></tr><tr><td class="docs"><p>Provide scoring metrics for a phased region against expected haplotype variants.
    - Fetch all expected variants in the phased region.
    - Iterate over expected variants comparing to the called variants:
       - Keep IntervalTree of called variants, removing variants as evaluated.
       - Keep coordinates of expected deletion regions.
    - Add discordant variants for extra calls not in expected variants, avoiding
      variants in deleted regions.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- score-phased-region
  [expect-get vcs]
  (let [vc-itree (atom (prep-itree vcs :start :end))]
    (letfn [(get-ref-vcs [x]
              (variants-in-region expect-get (:chr x) (:start x) (:end x)))
            (ref-match-allele [x]
              (matching-allele x (variants-in-region expect-get (:chr x) (:start x) (:end x))))
            (get-regional-expected-vcs
              [itree]
              {:pre [(= 1 (count (keys itree)))]}
              (let [[chr tree] (first itree)]
                (let [start (-&gt; tree .min .getStart)]
                  (-&gt;&gt; (variants-in-region expect-get chr start (dec (-&gt; tree .max .getEnd)))
                       (remove #(&lt; (:start %) start))
                       (sort-by :start)))))
            (compare-and-update [cmp-i info e-vc]
              (let [cmp (comparison-metrics @vc-itree cmp-i e-vc)]
                (reset! vc-itree (remove-itree-vc @vc-itree (:chr e-vc)
                                                  (:start cmp) (:end cmp)))
                (-&gt; info
                    (assoc :out (cons cmp (:out info)))
                    (assoc :deleted (concat (:deleted info) (:deleted cmp))))))
            (in-deleted-region? [regions vc]
              (contains? regions [(:chr vc) (:start vc)]))
            (add-unmapped-cmps [cmp-i info]
              (concat (:out info)
                      (map (fn [vc] {:comparison (cmp-allele-to-expected vc nil cmp-i)
                                     :variant-type (get-variant-type [vc])
                                     :nomatch-het-alt (nomatch-het-alt? vc nil)
                                     :start (:start vc)
                                     :vc (:vc vc)
                                     :ref-vc nil})
                           (remove (partial in-deleted-region? (set (:deleted info)))
                                   (get-itree-all @vc-itree)))))]
      (let [cmp-allele-i (highest-count (remove #(or (nil? %) (neg? %))
                                                (map ref-match-allele vcs)))]
        (-&gt;&gt; (reduce (partial compare-and-update cmp-allele-i)
                     {:deleted [] :out []}
                     (get-regional-expected-vcs @vc-itree))
             (add-unmapped-cmps cmp-allele-i)
             (sort-by :start))))))</pre></td></tr><tr><td class="docs"><p>Score a called VCF against expected haploid variants based on phased regions.
  Partitions phased regions into blocks of two concurrent regions. For each block:
   - Evaluate second region with standard scoring: expected to called
   - Collect expected variants in the intervening region between phased blocks,
     report those missing in the comparison input as errors.</p>
</td><td class="codes"><pre class="brush: clojure">(defn score-phased-calls
  [call-vcf-iter expect-get ref-file &amp; {:keys [intervals]}]
  (let [prev (atom nil)]
    (letfn [(get-intervene-expect [region1 region2]
              (let [vc1 (last region1)
                    vc2 (first region2)
                    filter-end (if (nil? vc1) (dec (:start vc2)) (:end vc1))
                    vcs (cond
                         (nil? vc1)
                         (variants-in-region expect-get (:chr vc2) 0 (dec (:start vc2)))
                         (not= (:chr vc1) (:chr vc2))
                         (concat (variants-in-region expect-get (:chr vc1) (inc (:end vc1)) 1e10)
                                 (variants-in-region expect-get (:chr vc2) 0 (dec (:start vc2))))
                         :else
                         (variants-in-region expect-get (:chr vc1) (inc (:end vc1))
                                             (dec (:start vc2))))]
                (-&gt;&gt; vcs
                     (remove #(&lt; (:start %) filter-end))
                     (map (fn [x] {:comparison :discordant
                                   :variant-type (get-variant-type [x])
                                   :nomatch-het-alt false
                                   :start (:start x)
                                   :vc nil
                                   :ref-vc (:vc x)}))
                     (sort-by :start))))
            (score-phased-and-intervene [region]
              (let [out (concat (get-intervene-expect @prev region)
                                (when (not= (:chr (first region)) &quot;finished_sentinel&quot;)
                                  (score-phased-region expect-get region)))]
                (reset! prev region)
                out))]
      (map score-phased-and-intervene
           (concat (parse-phased-haplotypes call-vcf-iter ref-file
                                            :intervals intervals)
                   [[{:chr &quot;finished_sentinel&quot; :start 1}]])))))</pre></td></tr><tr><td class="docs"><h2>Summarize phased comparisons</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Write concordant and discordant variants to VCF output files.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- write-concordance-output
  [vc-info to-capture sample-name base-info other-info out-dir ref]
  (let [base-dir (if (nil? out-dir) (fs/parent (:file base-info)) out-dir)
        gen-file-name (fn [x] (str (fs/file base-dir (format &quot;%s-%s-%s-%s.vcf&quot;
                                                             sample-name (:name base-info)
                                                             (:name other-info) (name x)))))
        out-files (apply ordered-map (flatten (map (juxt identity gen-file-name)
                                                   to-capture)))]
    (if-not (fs/exists? base-dir)
      (fs/mkdirs base-dir))
    (when (itx/needs-run? (vals out-files))
      (write-vcf-w-template (:file base-info) out-files
                            (-&gt;&gt; (flatten vc-info)
                                 (map (juxt :comparison :vc))
                                 (filter #(contains? (set to-capture) (first %))))
                            ref
                            :header-update-fn (merge-headers (:file other-info))))
    out-files))</pre></td></tr><tr><td class="docs"><p>Provide counts for comparison: entire region plus user specified regions</p>
</td><td class="codes"><pre class="brush: clojure">(defn count-comparison-bases
  [total-bed call-bed ref-file]
  (letfn [(feature-size [x]
            (cond
             (instance? GenomeLoc x) (- (.getStop x) (dec (.getStart x)))
             :else (- (.getEnd x) (dec (.getStart x)))))
          (count-bases [xs]
            (apply + (map feature-size xs)))
          (merge-intervals [x y]
            (intersection-of-bed-files [x y] ref-file (GenomeLocParser. (get-seq-dict ref-file))))]
    (if (nil? total-bed)
      {:percent 0.0 :compared 0 :total 0}
      (with-open [bed-iter (get-bed-iterator total-bed ref-file)]
        (let [total (count-bases bed-iter)
              compared (if (or (nil? call-bed) (= total-bed call-bed)) total
                           (count-bases (merge-intervals total-bed call-bed)))]
          {:percent (* 100.0 (/ compared total))
           :compared compared
           :total total})))))</pre></td></tr><tr><td class="docs"><p>Collect summary metrics for concordant/discordant and phasing calls</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-phasing-metrics
  [vc-info exp-interval-file call-interval-file ref-file]
  (letfn [(count-nomatch-het-alt [xs]
            (count (filter #(and (contains? #{:concordant :ref-concordant} (:comparison %))
                                 (:nomatch-het-alt %))
                           (flatten vc-info))))
          (blank-count-dict []
            {:snp 0 :indel 0})
          (add-current-count [coll x]
            (let [cur-val (map x [:comparison :variant-type])]
              (assoc-in coll cur-val (inc (get-in coll cur-val)))))]
    (reduce add-current-count
            {:haplotype-blocks (count vc-info)
             :total-bases (count-comparison-bases exp-interval-file call-interval-file ref-file)
             :nonmatch-het-alt (count-nomatch-het-alt vc-info)
             :concordant (blank-count-dict)
             :ref-concordant (blank-count-dict)
             :discordant (blank-count-dict)
             :phasing-error (blank-count-dict)}
            (flatten vc-info))))</pre></td></tr><tr><td class="docs"><h2>Entry point for phased haploid VCF comparisons</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Compare two VCF files including phasing with a haplotype reference
  Handle grading special case as well as standard comparisons.</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti compare-two-vcf-phased
  (fn [_ exp _] (keyword (get exp :approach &quot;compare&quot;))))</pre></td></tr><tr><td class="docs"><p>Convert comparison into ready to write keywords for grading.
  Deals with discordant comparisons where the competition call
  is missing.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- convert-cmp-to-grade
  [cmp]
  (if (and (= (:comparison cmp) :discordant)
           (nil? (:vc cmp)))
    (-&gt; cmp
        (assoc :comparison :discordant-missing)
        (assoc :vc (:ref-vc cmp)))
    cmp))</pre></td></tr><tr><td class="docs"><p>Associate a grading category with each variant based on comparison.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- add-grading-info
  [cmp]
  (letfn [(assign-discordant-cat [{:keys [vc ref-vc]}]
            (println vc)
            (println ref-vc))]
    (let [cat (case (:comparison cmp)
                :ref-concordant &quot;concordant&quot;
                :concordant &quot;concordant&quot;
                :discordant (assign-discordant-cat cmp) 
                :discordant-missing &quot;discordant-nocall&quot;
                :phasing-error &quot;discordant-phasing&quot;)])
    cmp))</pre></td></tr><tr><td class="docs"><p>Retrieve the comparison file, filtering by intervals if present.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-compare-file
  [in-file cmp-name exp intervals]
  (if (nil? intervals)
    in-file
    (select-by-sample (:sample exp) in-file nil (:ref exp)
                      :intervals intervals :ext (str &quot;cmp&quot; cmp-name))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod compare-two-vcf-phased :grade
  [phased-calls exp config]
  {:pre [(= 1 (count (get phased-calls true)))
         (= 1 (count (get phased-calls false)))]}
  (let [ref (first (get phased-calls true))
        call (first (get phased-calls false))
        call-intervals (when-let [f (get call :intervals (:intervals exp))]
                         (limit-bed-intervals f call exp config))]
    (with-open [ref-get (get-vcf-retriever (:ref exp)
                                           (get-compare-file (:file ref) (:name call)
                                                             exp call-intervals))
                call-vcf-iter (get-vcf-iterator (:file call) (:ref exp))]
      (let [compared-calls (score-phased-calls call-vcf-iter ref-get (:ref exp)
                                               :intervals call-intervals)]
        {:c-files (write-concordance-output (-&gt;&gt; compared-calls
                                                 flatten
                                                 (map convert-cmp-to-grade)
                                                 (map add-grading-info))
                                            [:concordant :discordant
                                             :discordant-missing :phasing-error]
                                            (:sample exp) call ref
                                            (get-in config [:dir :out]) (:ref exp))
         :metrics (get-phasing-metrics compared-calls (:intervals exp)
                                       call-intervals (:ref exp))
         :c1 (assoc call :intervals call-intervals)
         :c2 ref :sample (:sample exp) :exp exp :dir (:dir config)}))))</pre></td></tr><tr><td class="docs"><p>Convert stream of variant context haploid comparison to standard,
  keyed by :concordant and :discordant-name keywords.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- convert-cmps-to-compare
  [cmps name1 name2]
  (letfn [(update-keyword [coll x]
            (let [ref-x (-&gt; x
                            (assoc :vc (:ref-vc x))
                            (dissoc :ref-vc))
                  [dis-kw1 dis-kw2] (map #(keyword (format &quot;%s-discordant&quot; %)) [name1 name2])]
              (case (:comparison x)
                :concordant (conj coll ref-x)
                (:discordant :phasing-error) (-&gt; coll
                                                 (conj (assoc x :comparison dis-kw2))
                                                 (conj (assoc ref-x :comparison dis-kw1)))
                coll)))
          (update-keyword-hapblock [xs]
            (remove #(or (nil? %) (nil? (:vc %)))
                    (reduce update-keyword [] xs)))]
    (map update-keyword-hapblock cmps)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod compare-two-vcf-phased :compare
  [phased-calls exp config]
  {:pre [(= 2 (count (flatten (vals phased-calls))))
         (pos? (count (get phased-calls true)))]}
  (let [cmp1 (first (get phased-calls true))
        cmp2 (if-let [nophased (get phased-calls false)]
               (first nophased)
               (second (get phased-calls true)))
        to-capture (concat [:concordant]
                           (map #(keyword (format &quot;%s-discordant&quot; (:name %)))
                                [cmp1 cmp2]))
        cmp-intervals (when-let [f (get cmp2 :intervals (:intervals exp))]
                        (limit-bed-intervals f cmp2 exp config))]
    (with-open [vcf1-get (get-vcf-retriever (:ref exp)
                                            (get-compare-file (:file cmp1) (:name cmp2)
                                                              exp cmp-intervals))
                vcf2-iter (get-vcf-iterator (:file cmp2) (:ref exp))]
      {:c-files (-&gt; (score-phased-calls vcf2-iter vcf1-get
                                        (:ref exp) :intervals cmp-intervals)
                    (convert-cmps-to-compare (:name cmp1) (:name cmp2))
                    (write-concordance-output to-capture (:sample exp) cmp1 cmp2
                                              (get-in config [:dir :out]) (:ref exp)))
       :c1 cmp1 :c2 cmp2 :sample (:sample exp) :exp exp :dir (:dir config)})))</pre></td></tr><tr><td class="docs"><h2>Utility functions</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Is the provided VCF file a haploid genome (one genotype or all homozygous).
  Samples the first set of variants, checking for haploid calls.</p>
</td><td class="codes"><pre class="brush: clojure">(defn is-haploid?
  [vcf-file ref-file]
  (let [sample-size 1000]
    (letfn [(is-vc-haploid? [vc]
              (when-not (= 0 (:num-samples vc))
                (= 1 (apply max (map #(count (:alleles %)) (:genotypes vc))))))]
      (with-open [vcf-iter (get-vcf-iterator vcf-file ref-file)]
        (let [vcf-iter (parse-vcf vcf-iter)]
          (if-not (empty? vcf-iter)
            (every? is-vc-haploid? (take sample-size vcf-iter))
            false))))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.recall" name="bcbio.variation.recall"><h1 class="project-name">bcbio.variation.recall</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Recall batched sets of variants containing no-call regions.
  Combined variant calls from batches contain regions called in
  some samples but not others. The approach:
    - Split sample into called and no-call variants
    - Re-call the no-call variants using the UnifiedGenotyper
    - Merge previously called and re-called into final set.
  http://www.broadinstitute.org/gsa/wiki/index.php/Merging<em>batched</em>call_sets</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.recall
  (:import [org.broadinstitute.sting.utils.variantcontext
            VariantContextBuilder GenotypesContext]
           [org.broadinstitute.sting.utils.codecs.vcf VCFHeader])
  (:use [clojure.java.io]
        [ordered.map :only [ordered-map]]
        [ordered.set :only [ordered-set]]
        [bcbio.variation.callable :only [get-callable-checker is-callable?]]
        [bcbio.variation.combine :only [combine-variants fix-minimal-combined]]
        [bcbio.variation.config :only [load-config]]
        [bcbio.variation.filter.intervals :only [select-by-sample]]
        [bcbio.variation.haploid :only [diploid-calls-to-haploid]]
        [bcbio.variation.multisample :only [multiple-samples?]]
        [bcbio.variation.normalize :only [fix-vcf-sample remove-ref-alts]]
        [bcbio.variation.phasing :only [is-haploid?]])
  (:require [clojure.string :as string]
            [fs.core :as fs]
            [bcbio.run.itx :as itx]
            [bcbio.run.broad :as broad]
            [bcbio.variation.filter.attr :as attr]
            [bcbio.variation.variantcontext :as gvc]))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- set-header-to-sample [sample _ header]
  (VCFHeader. (.getMetaDataInInputOrder header) (ordered-set sample)))</pre></td></tr><tr><td class="docs"><p>Provide split VCFs of call and no-call variants for the given sample.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- split-nocalls
  [in-vcf sample ref out-dir]
  (letfn [(sample-only-vc [vc]
            (-&gt; (VariantContextBuilder. vc)
                (.genotypes (GenotypesContext/create
                             (into-array [(-&gt; vc .getGenotypes (.get sample))])))
                (.attributes {})
                (.make)))
          (split-nocall-vc [vc]
            (when (empty? (:filters vc))
              (let [cur-vc (sample-only-vc (:vc vc))]
                [(if (.isNoCall (-&gt; cur-vc .getGenotypes (.get sample))) :nocall :called)
                 cur-vc])))]
    (let [sample-str (if (.contains in-vcf sample) &quot;&quot; (str sample &quot;-&quot;))
          out {:called (itx/add-file-part in-vcf (str sample-str &quot;called&quot;) out-dir)
               :nocall (itx/add-file-part in-vcf (str sample-str &quot;nocall&quot;) out-dir)}]
      (when (itx/needs-run? (vals out))
        (with-open [in-vcf-iter (gvc/get-vcf-iterator in-vcf ref)]
          (gvc/write-vcf-w-template in-vcf out
                                    (remove nil? (map split-nocall-vc (gvc/parse-vcf in-vcf-iter)))
                                    ref
                                    :header-update-fn (partial set-header-to-sample sample))))
      out)))</pre></td></tr><tr><td class="docs"><p>Do UnifiedGenotyper calling at known variation alleles.</p>
</td><td class="codes"><pre class="brush: clojure">(defn call-at-known-alleles
  [site-vcf align-bam ref &amp; {:keys [cores]}]
  (let [file-info {:out-vcf (itx/add-file-part site-vcf &quot;wrefs&quot;)}
        annotations [&quot;DepthPerAlleleBySample&quot;]
        args (concat [&quot;-R&quot; ref
                      &quot;-o&quot; :out-vcf
                      &quot;-I&quot; align-bam
                      &quot;--alleles&quot; site-vcf
                      &quot;-L&quot; site-vcf
                      &quot;--genotyping_mode&quot; &quot;GENOTYPE_GIVEN_ALLELES&quot;
                      &quot;--output_mode&quot; &quot;EMIT_ALL_SITES&quot;
                      &quot;-stand_call_conf&quot; &quot;0.0&quot;
                      &quot;-stand_emit_conf&quot; &quot;0.0&quot;
                      &quot;--max_deletion_fraction&quot; &quot;2.0&quot;
                      &quot;--min_indel_count_for_genotyping&quot; &quot;3&quot;
                      &quot;--genotype_likelihoods_model&quot; &quot;BOTH&quot;]
                     (if cores [&quot;-nt&quot; (str cores)] [])
                     (reduce #(concat %1 [&quot;-A&quot; %2]) [] annotations))]
    (broad/index-bam align-bam)
    (broad/run-gatk &quot;UnifiedGenotyper&quot; args file-info {:out [:out-vcf]})
    (:out-vcf file-info)))</pre></td></tr><tr><td class="docs"><p>Recall variations at no-calls in a sample using UnifiedGenotyper.</p>
</td><td class="codes"><pre class="brush: clojure">(defn recall-nocalls
  [in-vcf sample call-name align-bam ref &amp; {:keys [out-dir cores]}]
  (let [sample-str (if (.contains in-vcf call-name) &quot;&quot; (str call-name &quot;-&quot;))
        out-file (itx/add-file-part in-vcf (str sample-str &quot;wrefs&quot;) out-dir)]
    (when (itx/needs-run? out-file)
      (let [{:keys [called nocall]} (split-nocalls in-vcf sample ref out-dir)
            prep-nocall (remove-ref-alts nocall ref)
            orig-nocall (call-at-known-alleles prep-nocall align-bam ref :cores cores)
            fix-nocall (fix-vcf-sample orig-nocall sample ref)
            ready-nocall (if (is-haploid? called ref)
                           (diploid-calls-to-haploid fix-nocall ref)
                           fix-nocall)
            combine-out (combine-variants [called ready-nocall] ref :merge-type :full
                                          :quiet-out? true)]
        (fs/rename combine-out out-file)
        (fs/rename (str combine-out &quot;.idx&quot;) (str out-file &quot;.idx&quot;))))
    out-file))</pre></td></tr><tr><td class="docs"><p>Retrieve inputs VCFs not involved in preparing a recall VCF.
   Avoid double pulling inputs with the same initial call files.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- no-recall-vcfs
  [all-vcfs vcf-configs]
  (let [include-names (-&gt;&gt; vcf-configs
                           (group-by :file)
                           (map second)
                           (map first)
                           (map :name)
                           set)]
    (-&gt;&gt; (interleave all-vcfs vcf-configs)
         (partition 2)
         (map (fn [[x c]] (when (contains? include-names (:name c)) x)))
         (remove nil?))))</pre></td></tr><tr><td class="docs"><h2>Filtering with recall testing</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Does the supplied variant have a single supporting call</p>
</td><td class="codes"><pre class="brush: clojure">(defn- single-support?
  [vc]
  (when-let [callers (get-in vc [:attributes &quot;set&quot;])]
    (-&gt;&gt; (string/split callers #&quot;-&quot;)
         (map string/lower-case)
         (remove #(.startsWith % &quot;filter&quot;))
         (remove #(contains? #{&quot;intersection&quot; &quot;combo&quot;} %))
         count
         (= 1))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- variant-id [vc]
  [(:chr vc) (:start vc) (:ref-allele vc) (first (:alt-alleles vc))])</pre></td></tr><tr><td class="docs"><p>Test if a recalled posterior likelihood supports a variant call.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- supports-variant?
  [thresh vc]
  (when-let [pl (attr/get-vc-attr vc &quot;PL&quot; nil)]
    (&lt; pl thresh)))</pre></td></tr><tr><td class="docs"><p>Retrieve set of variants that a GATK UnifiedGenotyper recaller can't identify.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-norecall-variants
  [in-file bam-file sample ref]
  (let [support-thresh -7.5
        recall-file (-&gt; (gvc/select-variants in-file single-support? &quot;singles&quot; ref)
                        (call-at-known-alleles bam-file ref))]
    (with-open [in-vcf-iter (gvc/get-vcf-iterator recall-file ref)]
      (-&gt;&gt; (gvc/parse-vcf in-vcf-iter)
           (remove (partial supports-variant? support-thresh))
           (map variant-id)
           set))))</pre></td></tr><tr><td class="docs"><p>Filter problematic single support calls by ability to recall at defined sites.
   Single method support calls can be especially difficult to filter as concordant
   and discordant sites have similar metrics. Testing ability to recall is a useful
   mechanism to help identify ones with little read support.</p>
</td><td class="codes"><pre class="brush: clojure">(defn filter-by-recalling
  [in-file bam-file exp]
  (let [norecall (get-norecall-variants in-file bam-file (:sample exp) (:ref exp))]
    (letfn [(can-recall? [vc]
              (not (contains? norecall (variant-id vc))))]
      (gvc/select-variants in-file can-recall? &quot;recallfilter&quot; (:ref exp)))))</pre></td></tr><tr><td class="docs"><h2>Pick consensus variants</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Retrieve variant alleles for the sample, sorted in a stable order.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-sample-call
  [sample vc]
  (let [allele-order (-&gt;&gt; (:alt-alleles vc)
                          (sort-by #(.getBaseString %))
                          (cons (:ref-allele vc))
                          (map-indexed vector)
                          (map reverse)
                          (map vec)
                          (into {}))
        g (-&gt;&gt; (:genotypes vc)
                   (filter #(= sample (:sample-name %)))
                   first)]
    {:sample-name sample
     :qual (:qual vc)
     :vc-type (:type vc)
     :call-type (:type g)
     :ref-allele (:ref-allele vc)
     :alleles (sort-by allele-order (:alleles g))
     :attributes (select-keys (:attributes g) [&quot;PL&quot; &quot;DP&quot; &quot;AD&quot; &quot;PVAL&quot;])
     :has-likelihood (if (seq (get-in g [:attributes &quot;PL&quot;])) 1 0)
     :attr-count (+ (if (seq (get-in g [:attributes &quot;PL&quot;])) 1 0)
                    (if (seq (get-in g [:attributes &quot;PVAL&quot;])) 1 0)
                    (if (seq (get-in g [:attributes &quot;AD&quot;])) 1 0)
                    (if (get-in g [:attributes &quot;DP&quot;]) 1 0))
     :pl (attr/get-vc-attr vc &quot;PL&quot; nil)}))</pre></td></tr><tr><td class="docs"><p>Retrieve alleles with best support from multiple inputs.
   Use posterior likelihoods and quality scores to rank results
   with the same alleles and counts. We rank by total number of
   calls identified. We break ties in favor of homozygous calls
   if there isn't a consensus on het/hom variant calls, since
   we've failed to establish power for calling more difficult hets.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- best-supported-alleles
  [alleles]
  (letfn [(safe-sum [xs k]
            (apply + (remove nil? (map k xs))))
          (sum-plus-call-type [i xs]
            (let [pls (safe-sum xs :pl)
                  represent-x (last (sort-by #(vector (:has-likelihood %)
                                                      (or (:pl %) (- Integer/MIN_VALUE))
                                                      (:attr-count %))
                                             xs))
                  call-code (if (= &quot;HET&quot; (:call-type represent-x)) 0 1)]
              [(count xs) call-code (- pls) i represent-x]))]
    (-&gt;&gt; alleles
         (group-by :alleles)
         (map second)
         (map-indexed sum-plus-call-type)
         sort
         last ; Best item
         last ; Extract the alleles)))</pre></td></tr><tr><td class="docs"><p>Update a variant context with consensus genotype from multiple inputs.
   Calculates the consensus set of calls, swapping calls to that if it
   exists. If there is no consensus default to the existing allele call.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- update-vc-w-consensus
  [vc sample input-vc-getter]
  (let [match-fn (juxt :start :ref-allele)
        most-likely (-&gt;&gt; (gvc/variants-in-region input-vc-getter vc)
                         (filter #(= (match-fn %) (match-fn vc)))
                         (map (partial get-sample-call sample))
                         best-supported-alleles)]
    (when most-likely
      (-&gt; (VariantContextBuilder. (:vc vc))
          (.alleles (set (cons (:ref-allele vc) (:alleles most-likely))))
          (.genotypes (gvc/create-genotypes [most-likely] :attrs {&quot;PL&quot; &quot;PVAL&quot; &quot;DP&quot; &quot;AD&quot;}))
          .make))))</pre></td></tr><tr><td class="docs"><p>Recall variants in a combined set of variants based on consensus of all inputs.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- recall-w-consensus
  [base-vcf input-vcfs sample ref-file]
  (let [out-file (itx/add-file-part base-vcf &quot;consensus&quot;)]
    (when (itx/needs-run? out-file)
      (with-open [in-vcf-iter (gvc/get-vcf-iterator base-vcf ref-file)
                  input-vc-getter (apply gvc/get-vcf-retriever (cons ref-file input-vcfs))]
        (gvc/write-vcf-w-template base-vcf {:out out-file}
                                  (remove nil? (map #(update-vc-w-consensus % sample input-vc-getter)
                                                    (gvc/parse-vcf in-vcf-iter)))
                                  ref-file
                                  :header-update-fn (partial set-header-to-sample sample))))
    out-file))</pre></td></tr><tr><td class="docs"><p>Retrieve a minimal merged file with calls from input VCFs.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-min-merged
  [vcfs exp out-dir intervals]
  (-&gt; (combine-variants vcfs (:ref exp) :merge-type :minimal :intervals intervals
                        :out-dir out-dir :check-ploidy? false
                        :name-map (zipmap vcfs (map :name (:calls exp))))
      (fix-minimal-combined vcfs (:ref exp))))</pre></td></tr><tr><td class="docs"><p>Recall missing calls, handling merging or consensus based approaches</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti recall-vcf
  (fn [in-info &amp; _]
    (if (some nil? [in-info (:bam in-info) (:file in-info)])
      :consensus
      (keyword (get in-info :approach :consensus)))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod recall-vcf :gatk-ug
  ^{:doc &quot;Provide recalling of nocalls using GATK's UnifiedGenotyper&quot;}
  [in-info vcfs exp out-dir intervals]
  (-&gt; [(:file in-info) (get-min-merged vcfs exp out-dir intervals)]
      (combine-variants (:ref exp) :merge-type :full :intervals intervals
                        :out-dir out-dir :check-ploidy? false)
      (recall-nocalls (:sample exp) (:name in-info) (:bam in-info) (:ref exp)
                      :out-dir out-dir)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod recall-vcf :consensus
  ^{:doc &quot;Provide recalling of nocalls based on consensus from all inputs.&quot;}
  [in-info vcfs exp out-dir intervals]
  (-&gt; vcfs
      (get-min-merged exp out-dir intervals)
      (recall-w-consensus (no-recall-vcfs vcfs (:calls exp))
                          (:sample exp) (:ref exp))))</pre></td></tr><tr><td class="docs"><p>Create merged VCF files with no-call/ref-calls for each of the inputs.
  Works at a higher level than <code>recall-nocalls</code> and does the work of
  preparing a set of all merged variants, then re-calling at non-missing positions.</p>
</td><td class="codes"><pre class="brush: clojure">(defn create-merged
  [vcfs align-bams exp &amp; {:keys [out-dir intervals cores]}]
  (map (fn [[v b vcf-config]]
         (if (get vcf-config :recall false)
           (let [base-info {:name (:name vcf-config)
                            :approach (get-in exp [:params :recall-approach] :consensus)
                            :file v :bam b}
                 merged (recall-vcf base-info vcfs exp out-dir intervals)]
             (if (get vcf-config :remove-refcalls true)
               (select-by-sample (:sample exp) merged nil (:ref exp)
                                 :remove-refcalls true :ext &quot;cleaned&quot;)
               merged))
           v))
       (map vector vcfs align-bams (:calls exp))))</pre></td></tr><tr><td class="docs"><p>Split VCF line into shared attributes and sample specific genotypes.
  By default removes shared attributes which are no longer valid for split file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- split-vcf-sample-line
  ([line remove-info-attrs?]
     (let [parts (string/split line #&quot;\t&quot;)
           orig-shared (vec (take 9 parts))
           shared (if remove-info-attrs? (assoc orig-shared 7 &quot;.&quot;) orig-shared)]
       (for [s (drop 9 parts)] (conj shared s))))
  ([line]
     (split-vcf-sample-line line true)))</pre></td></tr><tr><td class="docs"><p>Split a multi-sample file to individual samples: writing the header.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- split-vcf-to-samples-header
  [vcf-iter out-files]
  (letfn [(not-chrom? [l] (not (.startsWith l &quot;#CHROM&quot;)))]
    (let [std-header (string/join &quot;\n&quot; (take-while not-chrom? vcf-iter))]
      (doseq [[i xs] (map-indexed vector (-&gt; (drop-while not-chrom? vcf-iter)
                                             first
                                             (split-vcf-sample-line false)))]
        (spit (get out-files i)
              (str std-header &quot;\n&quot; (string/join &quot;\t&quot; xs) &quot;\n&quot;))))))</pre></td></tr><tr><td class="docs"><p>Split multi-sample file to individual samples: variant lines
  Avoids opening all output handles, instead writing to individual files.
  Blocks writes into groups to reduce opening file penalties.</p>
</td><td class="codes"><pre class="brush: clojure">(defn split-vcf-to-samples-variants
  [vcf-iter out-files]
  (let [block-size 1000]
    (doseq [lines (partition-all block-size (drop-while #(.startsWith % &quot;#&quot;) vcf-iter))]
      (let [sample-lines (reduce (fn [coll l]
                                   (reduce (fn [inner-coll [i xs]]
                                             (assoc inner-coll i (conj (get inner-coll i [])
                                                                       (string/join &quot;\t&quot; xs))))
                                           coll (map-indexed vector (split-vcf-sample-line l))))
                                 {} lines)]
        (doseq [[i xs] sample-lines]
          (spit (get out-files i)
                (str (string/join &quot;\n&quot; xs) &quot;\n&quot;)
                :append true))))))</pre></td></tr><tr><td class="docs"><p>Create individual sample variant files from input VCF.</p>
</td><td class="codes"><pre class="brush: clojure">(defn split-vcf-to-samples
  [vcf-file &amp; {:keys [out-dir]}]
  (let [samples (-&gt; vcf-file gvc/get-vcf-header .getGenotypeSamples)
        out-files (into (ordered-map) (map (fn [x] [x (itx/add-file-part vcf-file x out-dir)])
                                           samples))]
    (when (itx/needs-run? (vals out-files))
      (with-open [rdr (reader vcf-file)]
        (itx/with-tx-files [tx-out-files out-files (keys out-files) []]
          (let [line-iter (line-seq rdr)]
            (split-vcf-to-samples-header line-iter (vec (vals tx-out-files)))
            (split-vcf-to-samples-variants line-iter (vec (vals tx-out-files)))))))
    out-files))</pre></td></tr><tr><td class="docs"><p>Split multiple sample inputs into individual samples before processing.
  This helps reduce the load on selecting from huge multi-sample files.
  Returns a list of configured calls with multi-samples set to individually
  separated input files.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- split-config-multi
  [calls ref out-dir]
  (let [multi-files (filter multiple-samples? (set (map :file calls)))
        cur-samples (set (map :name calls))]
    (vals
     (reduce (fn [coll vcf]
               (reduce (fn [inner-coll [sample split-vcf]]
                         (if (contains? cur-samples sample)
                           (assoc-in inner-coll [sample :file] split-vcf)
                           inner-coll))
                       coll (split-vcf-to-samples vcf :out-dir out-dir)))
             (into (ordered-map) (map (fn [x] [(:name x) x]) calls))
             multi-files))))</pre></td></tr><tr><td class="docs"><p>Provide a cleaned VCF file without sample genotype information.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- remove-sample-info
  [in-vcf out-dir]
  (letfn [(split-variant-line [line]
            (-&gt;&gt; (string/split line #&quot;\t&quot;)
                 (take 8)
                 (string/join &quot;\t&quot;)))
          (process-line [line]
            (cond
             (.startsWith line &quot;##fileformat&quot;) line
             (.startsWith line &quot;##INFO&quot;) line
             (.startsWith line &quot;#CHROM&quot;) (split-variant-line line)
             (.startsWith line &quot;#&quot;) nil
             :else (split-variant-line line)))]
    (let [out-file (itx/add-file-part in-vcf &quot;nosamples&quot; out-dir)]
      (when (itx/needs-run? out-file)
        (with-open [rdr (reader in-vcf)
                    wtr (writer out-file)]
          (doseq [line (map process-line (line-seq rdr))]
            (when line
              (.write wtr (str line &quot;\n&quot;))))))
      out-file)))</pre></td></tr><tr><td class="docs"><p>Combine large numbers of variants via batches to avoid memory issues.</p>
</td><td class="codes"><pre class="brush: clojure">(defn batch-combine-variants
  [vcfs ref &amp; {:keys [merge-type out-dir intervals unsafe name-map
                      base-ext check-ploidy? quiet-out? batch-size]
               :or {merge-type :unique
                    unsafe false
                    name-map {}
                    check-ploidy? true
                    batch-size 100}}]
  (letfn [(combine-w-args [xs]
            (combine-variants xs ref :merge-type merge-type :out-dir out-dir
                              :intervals intervals :unsafe unsafe :name-map name-map
                              :base-ext base-ext :check-ploidy? check-ploidy?
                              :quiet-out? quiet-out?))]
    (let [batch-vcfs (map combine-w-args (partition-all batch-size vcfs))]
      (combine-w-args batch-vcfs))))</pre></td></tr><tr><td class="docs"><p>Perform recalling on all specific inputs in an experiment</p>
</td><td class="codes"><pre class="brush: clojure">(defn- do-recall-exp
  [exp out-dir config]
  (let [recall-vcfs (map (fn [call]
                           (recall-nocalls (:file call) (:sample exp) (:name call) (:align call)
                                           (:ref exp) :out-dir out-dir
                                           :cores (get-in config [:resources :cores])))
                         (split-config-multi (:calls exp) (:ref exp) out-dir))
        clean-multi (map #(remove-sample-info % out-dir)
                         (filter multiple-samples? (set (map :file (:calls exp)))))]
    (batch-combine-variants (concat clean-multi recall-vcfs) (:ref exp) :merge-type :full
                            :quiet-out? true :check-ploidy? false)))</pre></td></tr><tr><td class="docs"><p>Convert no-calls into callable reference and real no-calls.
  Older functionality to re-call as reference when region is callable.
  Prefer <code>recall-nocalls</code></p>
</td><td class="codes"><pre class="brush: clojure">(defn convert-no-calls-w-callability
  [in-vcf align-bam ref &amp; {:keys [out-dir intervals num-alleles]}]
  (letfn [(maybe-callable-vc [vc call-source]
            {:pre (= 1 (:num-samples vc))}
            (let [g (-&gt; vc :genotypes first)]
              (if (.isNoCall (-&gt; g :alleles first))
                (if (is-callable? call-source (:chr vc) (:start vc) (:end vc))
                  (gvc/genotypes-&gt;refcall vc)
                  (-&gt; (VariantContextBuilder. (:vc vc))
                      (.filters #{&quot;NotCallable&quot;})
                      (.make)))
                (:vc vc))))
          (convert-vcs [vcf-source call-source]
            (for [vc (gvc/parse-vcf vcf-source)]
              [:out (maybe-callable-vc vc call-source)]))]
    (let [out-file (itx/add-file-part in-vcf &quot;wrefs&quot;)]
      (when (itx/needs-run? out-file)
        (with-open [in-vcf-iter (gvc/get-vcf-iterator in-vcf ref)
                    call-source (get-callable-checker align-bam ref :out-dir out-dir
                                                      :intervals intervals)]
          (gvc/write-vcf-w-template in-vcf {:out out-file}
                                    (convert-vcs in-vcf-iter call-source) ref)))
      out-file)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -main [config-file]
  (let [config (load-config config-file)
        out-dir (get-in config [:dir :out])]
    (doseq [exp (:experiments config)]
      (do-recall-exp exp out-dir config))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.remote.client" name="bcbio.variation.remote.client"><h1 class="project-name">bcbio.variation.remote.client</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Establish a connection with a remote service for file management.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.remote.client
  (:use [clojure.java.io])
  (:require [clojure.string :as string]
            [blend.galaxy.core :as galaxy]
            [clj-genomespace.core :as gs]))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defrecord RemoteClient [type conn username server])</pre></td></tr><tr><td class="docs"><p>Retrieve a remote client using authentication credentials
   creds is a map containing the :type of connection to establish
   and client specific authentication details.</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti get-client
  (fn [creds]
    (:type creds)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(def gs-default-server &quot;http://www.genomespace.org/&quot;)</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-client :gs
  ^{:doc &quot;Retrieve a GenomeSpace client connection&quot;}
  [creds]
  (let [{:keys [username password client allow-offline?]} creds
        gs-client (cond
                   (and client (gs/logged-in? client)) client
                   (and username password) (try (gs/get-client username :password password)
                                                (catch Exception e
                                                  (when-not allow-offline?
                                                    (throw e))))
                   :else nil)
        username (when gs-client
                   (gs/get-username gs-client))]
    (RemoteClient. :gs gs-client username gs-default-server)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-client :galaxy
  ^{:doc &quot;Retrieve a Galaxy client connection.&quot;}
  [creds]
  (let [{:keys [url api-key client allow-offline?]} creds
        galaxy-client (cond
                       (not (nil? client)) client
                       (and url api-key) (galaxy/get-client url api-key)
                       :else nil)
        user-info (try (galaxy/get-user-info galaxy-client)
                       (catch Exception e
                         (when-not allow-offline?
                           (throw e))))
        username (when user-info
                   (or (:username user-info) (:email user-info)))]
    (RemoteClient. :galaxy (when user-info galaxy-client) username url)))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.remote.core" name="bcbio.variation.remote.core"><h1 class="project-name">bcbio.variation.remote.core</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Top level API for working with remote filestores.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.remote.core
  (:require [bcbio.variation.remote.file :as file]
            [bcbio.variation.remote.client :as client]))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(def get-client client/get-client)
(def list-dirs file/list-dirs)
(def list-files file/list-files)
(def get-file file/get-file)
(def put-file file/put-file)</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.remote.file" name="bcbio.variation.remote.file"><h1 class="project-name">bcbio.variation.remote.file</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>List, retrieve and push files from a remote filestore.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.remote.file
  (:use [clojure.java.io]
        [bcbio.variation.api.shared :only [web-config url-&gt;dir]])
  (:require [clojure.string :as string]
            [fs.core :as fs]
            [blend.galaxy.core :as galaxy]
            [clj-genomespace.core :as gs]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><h2>Download</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Provide list of files currently under download.</p>
</td><td class="codes"><pre class="brush: clojure">(def ^{:doc 
       :private true}
  download-queue (atom #{}))</pre></td></tr><tr><td class="docs"><p>Generalized remote download to local cache directory.
   download-fn takes the client, remote name and local name, and
   handles the download step for a specific remote service.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- download-to-local
  [fname rclient to-fileinfo-fn download-fn &amp; {:keys [out-dir]}]
  (let [cache-dir (or out-dir (get-in @web-config [:dir :cache]))
        finfo (to-fileinfo-fn fname)
        local-file (str (file cache-dir (url-&gt;dir (:server rclient)) (:local-stub finfo)))
        local-dir (str (fs/parent local-file))]
    (when-not (fs/exists? local-file)
      (when-not (fs/exists? local-dir)
        (fs/mkdirs local-dir))
      (when-not (contains? @download-queue local-file)
        (itx/with-tx-file [out-file-tx local-file]
          (swap! download-queue conj local-file)
          (try
            (download-fn rclient finfo out-file-tx)
            (finally
             (swap! download-queue disj local-file))))))
    local-file))</pre></td></tr><tr><td class="docs"><p>Retrieve files by name, transparently handling remote files.</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti get-file
  (fn [fname &amp; args]
    (let [parts (string/split fname #&quot;:&quot; 2)]
      (when (= 2 (count parts))
        (keyword (first parts))))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-file :gs
  ^{:doc &quot;Retrieve a file from GenomeSpace to the local cache&quot;}
  [fname rclient &amp; {:keys [out-dir]}]
  (letfn [(fileinfo-gs [file-id]
            (let [remote-name (second (string/split file-id #&quot;:&quot; 2))]
              {:dirname (str (fs/parent remote-name))
               :fname (fs/base-name remote-name)
               :local-stub (if (.startsWith remote-name &quot;/&quot;)
                             (subs remote-name 1)
                             remote-name)}))
          (download-gs [rclient file-info out-file]
            (gs/download (:conn rclient) (:dirname file-info)
                         (:fname file-info) out-file))]
    (download-to-local fname rclient fileinfo-gs download-gs :out-dir out-dir)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- split-galaxy-id
  [file-id]
  (when file-id
    (-&gt; file-id
        (string/split #&quot;:&quot; 2)
        second
        (string/split #&quot;/&quot;))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-file :galaxy
  ^{:doc &quot;Retrieve a file from Galaxy to the local cache&quot;}
  [fname rclient &amp; {:keys [out-dir]}]
  (letfn [(fileinfo-galaxy [file-id]
            (let [[history-id ds-id] (split-galaxy-id file-id)
                  ds (galaxy/get-dataset-by-id (:conn rclient) history-id ds-id)
                  safe-username (string/replace (:username rclient) &quot; &quot; &quot;-&quot;)]
              {:local-stub (str (file safe-username history-id (:name ds)))
               :ds ds}))
          (download-galaxy [rclient file-info out-file]
            (galaxy/download-dataset (:conn rclient) (:ds file-info) out-file))]
    (download-to-local fname rclient fileinfo-galaxy download-galaxy :out-dir out-dir)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-file :default
  ^{:doc &quot;Get local file: no-op, just return the file.&quot;}
  [fname _]
  fname)</pre></td></tr><tr><td class="docs"><h2>List</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>List directories available on the remote server. Returns map of directory
   :id and display :name.</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti list-dirs
  (fn [rclient &amp; args]
    (:type rclient)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod list-dirs :gs
  ^{:doc &quot;Retrieve available directories from GenomeSpace under the parent directory.&quot;}
  [rclient dirname]
  (map (fn [x] {:id x :name x})
       (gs/list-dirs (:conn rclient) dirname)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod list-dirs :galaxy
  ^{:doc &quot;Retrieve available histories from Galaxy connection.&quot;}
  [rclient _]
  (galaxy/list-histories (:conn rclient)))</pre></td></tr><tr><td class="docs"><p>List files in a remote directory of a specified type.</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti list-files
  (fn [rclient &amp; args]
    (:type rclient)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod list-files :gs
  ^{:doc &quot;List available files in GenomeSpace directory by type.&quot;}
  [rclient rdir ftype]
  (let [remote-dir (or (:id rdir) &quot;.&quot;)]
    (concat
     (map (fn [finfo]
            {:id (str &quot;gs:&quot; (:dirname finfo) &quot;/&quot; (:name finfo))
             :tags (remove nil?
                           [(first (drop 3 (string/split (:dirname finfo) #&quot;/&quot; 4)))])
             :folder (:dirname finfo)
             :filename (:name finfo)
             :size (:size finfo)
             :created-on (:date finfo)})
          (gs/list-files (:conn rclient) remote-dir (name ftype)))
     (mapcat #(list-files rclient % ftype) (list-dirs rclient remote-dir)))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod list-files :galaxy
  ^{:doc &quot;List available files from a Galaxy history.&quot;}
  [rclient hid ftype]
  (let [history-id (if (contains? hid :id) (:id hid) hid)
        history-name (or (:name hid) &quot;&quot;)]
    (-&gt;&gt; (galaxy/get-datasets-by-type (:conn rclient) ftype :history-id history-id)
         (remove #(:deleted %))
         (map (fn [ds]
                {:id (str &quot;galaxy:&quot; (:history-id ds) &quot;/&quot; (:id ds))
                 :tags [history-name]
                 :folder history-name
                 :filename (:name ds)
                 :size (:file-size ds)
                 :created-on nil})))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod list-files :default
  ^{:doc &quot;Retrieval of pre-downloaded files in our local cache.&quot;}
  [_ dir-info ftype])</pre></td></tr><tr><td class="docs"><h2>Upload</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Upload a file to a remote repository.</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti put-file
  (fn [rclient &amp; args]
    (:type rclient)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod put-file :gs
  ^{:doc &quot;Push file to GenomeSpace in the specified upload directory.&quot;}
  [rclient local-file params]
  (let [remote-dir (str (fs/file (fs/parent (last (string/split (:input-file params) #&quot;:&quot; 2)))
                                 (:tag params)))]
    (gs/upload (:conn rclient) remote-dir local-file)
    remote-dir))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod put-file :galaxy
  ^{:doc &quot;Push file to the current Galaxy history, using a remotely available URL.&quot;}
  [rclient local-file params]
  (let [host-info (:host-info params)
        history-id (first (split-galaxy-id (:input-file params)))
        provide-url ((:expose-fn params) local-file (:server rclient))]
    (galaxy/upload-to-history (:conn rclient) provide-url
                              (get params :dbkey :hg19)
                              (:file-type params)
                              :history-id history-id
                              :display-name (fs/base-name local-file))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.report" name="bcbio.variation.report"><h1 class="project-name">bcbio.variation.report</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Parse and provide detailed information from GATKReport outputs.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.report
  (:use [ordered.map :only [ordered-map]]
        [clojure.math.combinatorics :only [cartesian-product]]
        [bcbio.variation.variantcontext :only [parse-vcf get-vcf-retriever
                                               variants-in-region
                                               get-vcf-iterator]]
        [bcbio.variation.callable :only [get-callable-checker is-callable?]]
        [bcbio.variation.evaluate :only [organize-gatk-report-table]]
        [bcbio.variation.metrics :only [ml-on-vcf-metrics passes-filter? nonref-passes-filter?]])
  (:require [clojure.string :as string]
            [clojure.data.csv :as csv]
            [doric.core :as doric]
            [lonocloud.synthread :as -&gt;]
            [bcbio.variation.grade :as grade]))</pre></td></tr><tr><td class="docs"><p>Retrieve high level concordance metrics from GATK VariantEval report.</p>
</td><td class="codes"><pre class="brush: clojure">(defn concordance-report-metrics
  [sample in-file]
  (letfn [(sample-in-row? [x]
            (and (= (:Sample x) sample)
                 (= (:Novelty x) &quot;all&quot;)
                 (= (:Filter x) &quot;called&quot;)))]
    (-&gt;&gt; (organize-gatk-report-table in-file &quot;GenotypeConcordance&quot; sample-in-row?)
         (map (fn [x] [(keyword (:variable x)) (:value x)]))
         (into {}))))</pre></td></tr><tr><td class="docs"><p>Count variants that pass an optional checker function.</p>
</td><td class="codes"><pre class="brush: clojure">(defn count-variants
  [f ref-file check?]
  (with-open [vcf-iter (get-vcf-iterator f ref-file)]
    (count (filter check? (parse-vcf vcf-iter)))))</pre></td></tr><tr><td class="docs"><p>Provide metrics to distinguish types of discordance in a comparison.
  These identify variants which differ due to being missing in one variant
  call versus calls present in both with different genotypes. It also pulls
  out variants in diploids that differ due to het/hom calls.</p>
</td><td class="codes"><pre class="brush: clojure">(defn shared-discordant
  [file1 file2 ref-file]
  (with-open [file1-iter (get-vcf-iterator file1 ref-file)
              vcf-retriever (get-vcf-retriever ref-file file2)]
    (reduce (fn [coll vc]
              (let [other-vcs (variants-in-region vcf-retriever
                                                  (:chr vc) (:start vc) (:end vc))
                    vc-type (if-not (empty? other-vcs) :total :unique)]
                (-&gt; coll
                    (assoc vc-type (inc (get coll vc-type)))
                    (assoc :hethom ((if (and (= :total vc-type)
                                             (grade/hethom-discordant? vc other-vcs))
                                      inc identity)
                                    (get coll :hethom))))))
            {:total 0 :unique 0 :hethom 0}
            (parse-vcf file1-iter))))</pre></td></tr><tr><td class="docs"><p>Calculate count of variant in input file without coverage in the comparison.</p>
</td><td class="codes"><pre class="brush: clojure">(defn nocoverage-count
  [in-vcf ref-file compare-kw compared]
  (let [out-dir (get-in compared [:dir :prep] (get-in compared [:dir :out]))
        align-file (get-in compared [compare-kw :align]
                           (get-in compared [:exp :align]))]
    (when-not (nil? align-file)
      (with-open [call-source (get-callable-checker align-file (-&gt; compared :exp :ref)
                                                    :out-dir out-dir)]
        (count-variants in-vcf ref-file
                        #(and (passes-filter? %)
                              (not (is-callable? call-source (:chr %) (:start %) (:end %)))))))))</pre></td></tr><tr><td class="docs"><p>Retrieve expected summary level from configuration</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-summary-level
  [config]
  (letfn [(level-from-string [x]
            (case (when-not (nil? x) (string/lower-case x))
              &quot;quick&quot; :quick
              &quot;full&quot; :full
              :standard))
          (get-string-level [config to-try]
            (loop [cur-try to-try]
              (if (empty? cur-try) nil
                  (let [cur-level (get-in config (first cur-try))]
                    (if-not (nil? cur-level) cur-level
                            (recur (rest cur-try)))))))]
    (let [to-check (cartesian-product [:exp :c1 :c2 :call] [:summary-level])]
      (level-from-string (get-string-level config to-check)))))</pre></td></tr><tr><td class="docs"><p>Retrieve structural variation metrics from SV concordance files.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-sv-metrics
  [compared ref-file]
  (when-let [finfo (seq (-&gt;&gt; (:c-files compared)
                             (drop-while #(not= (first %) :sv-concordant))
                             (take 3)))]
    (reduce (fn [coll [kw vcf-file]]
              (assoc coll kw
                     (ordered-map
                      :total (count-variants vcf-file ref-file passes-filter?))))
            (ordered-map) finfo)))</pre></td></tr><tr><td class="docs"><p>Provide counts in a file, split by type of variation.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- all-vrn-counts
  [fname cmp-kw compared]
  (letfn [(vrn-type-passes-filter? [vrn-type]
            (fn [vc]
              (and (passes-filter? vc)
                   (contains? vrn-type (:type vc)))))]
    (let [sum-level (get-summary-level compared)
          ref-file (get-in compared [:exp :ref])
          base {:total (count-variants fname ref-file passes-filter?)}]
      (if (= sum-level :quick) base
          (assoc base
            :nocoverage (nocoverage-count fname ref-file cmp-kw compared)
            :snp (count-variants fname ref-file
                                 (vrn-type-passes-filter? #{&quot;SNP&quot;}))
            :indel (count-variants fname ref-file
                                   (vrn-type-passes-filter? #{&quot;INDEL&quot;})))))))</pre></td></tr><tr><td class="docs"><p>Prepare grading based metrics to break down reasons for discordant calls</p>
</td><td class="codes"><pre class="brush: clojure">(defn- grading-discordance-metrics
  [vcf-file]
  (println vcf-file))</pre></td></tr><tr><td class="docs"><p>Add detailed discordance metrics to the summary information.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- add-discordance-metrics
  [m compared]
  (let [ref-file (get-in compared [:exp :ref])
        c-files (-&gt; compared :c-files vals)]
    (-&gt; m
        (assoc :discordant1 (all-vrn-counts (second c-files) :c2 compared))
        (-&gt;/when (&gt; (count c-files) 2)
          (assoc :discordant2 (all-vrn-counts (nth c-files 2) :c1 compared))
          (assoc :discordant_both (apply shared-discordant (conj (vec (take 2 (rest c-files)))
                                                                 ref-file)))))))</pre></td></tr><tr><td class="docs"><p>Add detailed concordance metrics to summary information.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- add-concordance-metrics
  [m compared]
  (let [ref-file (get-in compared [:exp :ref])
        c-files (-&gt; compared :c-files vals)]
    (-&gt; m
        (assoc :genotype_concordance (-&gt; compared :metrics :percent_overall_genotype_concordance))
        (assoc :callable_concordance (-&gt; compared :callable-metrics
                                         :percent_overall_genotype_concordance))
        (assoc :nonref_discrepency (-&gt; compared :metrics :percent_non_reference_discrepancy_rate))
        (assoc :nonref_sensitivity (-&gt; compared :metrics :percent_non_reference_sensitivity))
        (assoc :concordant (all-vrn-counts (first c-files) nil compared))
        (assoc :nonref_concordant (count-variants (first c-files) ref-file
                                                  nonref-passes-filter?)))))</pre></td></tr><tr><td class="docs"><p>Provide one-line summary of similarity metrics for a VCF comparison.</p>
</td><td class="codes"><pre class="brush: clojure">(defn top-level-metrics
  [compared]
  (let [sum-level (get-summary-level compared)
        ref-file (get-in compared [:exp :ref])
        c-files (-&gt; compared :c-files vals)]
    (-&gt; (ordered-map)
        (assoc :sample (-&gt; compared :exp :sample))
        (assoc :ftypes (take 3 (-&gt; compared :c-files keys)))
        (add-concordance-metrics compared)
        (add-discordance-metrics compared)
        (-&gt;/when-let [sv-metrics (get-sv-metrics compared ref-file)]
          (assoc :sv sv-metrics))
        (-&gt;/when (= sum-level :full)
          (assoc :ml_metrics (ml-on-vcf-metrics ref-file (take 2 c-files)))))))</pre></td></tr><tr><td class="docs"><p>Calculate an overall accuracy score from input metrics.
  The accuracy logic is:
  (#correctly aligned bases - (1*(simple substitutions and indels) +
                               2*(larger errors))
   / #correctly aligned bases)</p>
</td><td class="codes"><pre class="brush: clojure">(defn calc-accuracy
  [metrics error-items]
  (letfn [(get-penalty [[error-type call-type]]
            (case call-type
              :snp 1
              :indel 2
              :sv 2))]
    (let [error-items (cartesian-product error-items [:snp :indel :sv])
          error-score (apply + (map #(* (get-in metrics % 0) (get-penalty %)) error-items))
          total-bases (get-in metrics [:total-bases :compared] 1)]
      (float
       (* 100.0 (/ (- total-bases error-score) total-bases))))))</pre></td></tr><tr><td class="docs"><p>Summary table of high level variables and scoring metrics for comparison.</p>
</td><td class="codes"><pre class="brush: clojure">(defn prep-scoring-table
  [metrics sv-stats]
  (let [to-write (ordered-map :accuracy &quot;Accuracy score&quot;
                              :accuracy-phasing &quot;Accuracy score, including phasing&quot;
                              [:total-bases :percent] &quot;Completeness&quot;
                              [:total-bases :compared] &quot;Total bases scored&quot;
                              [:total-bases :total] &quot;Possible evaluation bases&quot;
                              [:discordant :snp] &quot;Discordant SNPs&quot;
                              [:discordant :indel] &quot;Discordant indels&quot;
                              [:discordant :sv] &quot;Discordant structural variants&quot;
                              [:phasing-error :snp] &quot;Phasing Error SNPs&quot;
                              [:phasing-error :indel] &quot;Phasing Error indels&quot;
                              :haplotype-blocks &quot;Phased haplotype blocks&quot;
                              ;:nonmatch-het-alt &quot;Non-matching heterozygous alternative alleles&quot;)
        sv-metrics (assoc-in metrics [:discordant :sv]
                             (-&gt; sv-stats vals second (get :total 0)))
        s-metrics (-&gt; sv-metrics
                      (assoc :accuracy (calc-accuracy sv-metrics [:discordant]))
                      (assoc :accuracy-phasing (calc-accuracy sv-metrics
                                                              [:discordant :phasing-error])))
        need-percents {:accuracy 6
                       :accuracy-phasing 6
                       [:total-bases :percent] 2}]
    (letfn [(prep-row [[k x]]
              (let [val (if (coll? k) (get-in s-metrics k) (get s-metrics k))]
                {:metric x
                 :value (if (contains? need-percents k)
                          (format (str &quot;%.&quot; (get need-percents k) &quot;f&quot;) val)
                          val)}))]
      (map prep-row to-write))))</pre></td></tr><tr><td class="docs"><p>Write high level metrics table in readable format.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- write-scoring-table
  [metrics sv-stats wrtr]
  (when-not (or (nil? metrics)
                (nil? (get-in metrics [:total-bases :total])))
    (.write wrtr (str (doric/table [:metric :value] (prep-scoring-table metrics sv-stats))
                      &quot;\n&quot;))))</pre></td></tr><tr><td class="docs"><p>Summary table of metrics for assessing the score of a variant comparison.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- write-concordance-metrics
  [metrics wrtr]
  (letfn [(metrics-info [ftype-i &amp; kvs]
            (if (&lt;= (count (:ftypes metrics)) ftype-i)
              []
              (let [cur-name (name (nth (:ftypes metrics) ftype-i))]
                (apply concat
                       (map (fn [[k v]] [k (str cur-name &quot;: &quot; v)]) (partition 2 kvs))))))]
    (let [to-write (apply ordered-map
                          (concat [:genotype_concordance &quot;Overall genotype concordance&quot;
                                   :callable_concordance &quot;Callable genotype concordance&quot;
                                   :nonref_discrepency &quot;Non-reference discrepancy rate&quot;
                                   :nonref_sensitivity &quot;Non-reference sensitivity&quot;]
                                  (metrics-info 0
                                                [:concordant :total] &quot;total&quot;
                                                :nonref_concordant &quot;non-reference&quot;
                                                [:concordant :snp] &quot;SNPs&quot;
                                                [:concordant :indel] &quot;indels&quot;)
                                  (metrics-info 1
                                                [:discordant1 :total] &quot;total&quot;
                                                [:discordant1 :nocoverage] &quot;unique&quot;
                                                [:discordant1 :snp] &quot;SNPs&quot;
                                                [:discordant1 :indel] &quot;indels&quot;)
                                  (metrics-info 2
                                                [:discordant2 :total] &quot;total&quot;
                                                [:discordant2 :nocoverage] &quot;unique&quot;
                                                [:discordant2 :snp] &quot;SNPs&quot;
                                                [:discordant2 :indel] &quot;indels&quot;)
                                  [[:discordant_both :total] &quot;Shared discordant&quot;
                                   [:discordant_both :hethom] &quot;het/hom discordant&quot;
                                   [:ml_metrics :top-metrics] &quot;Classification metrics&quot;]))]
      (letfn [(get-value [[k metric]]
                (when-let [val (if (coll? k) (get-in metrics k) (get metrics k))]
                  {:metric metric :value val}))]
        (.write wrtr (str (doric/table [:metric :value] (remove nil? (map get-value to-write)))
                          &quot;\n&quot;))))))</pre></td></tr><tr><td class="docs"><p>Summary table of structural variation comparions.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- write-sv-metrics
  [sv-metrics wrtr]
  (letfn [(get-values [[base xs]]
            (map (fn [[inner-kw val]]
                   {:metric (str (name base) &quot;: &quot; (name inner-kw))
                    :value val})
                 xs))]
    (.write wrtr &quot;** Structural variation\n&quot;)
    (.write wrtr (str (doric/table [:metric :value]
                                   (-&gt;&gt; (map get-values sv-metrics)
                                        flatten
                                        (remove nil?)))
                      &quot;\n&quot;))))</pre></td></tr><tr><td class="docs"><h2>Classification metrics</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Summary table of classification metrics from GATK variant recalibration.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- write-classification-metrics
  [cmp-info wrtr]
  (letfn [(get-metric-counts [in-vcf]
            (with-open [vcf-iter (get-vcf-iterator in-vcf (get-in cmp-info [:exp :ref]))]
              (reduce (fn [coll vc]
                        (let [culprit (get-in vc [:attributes &quot;culprit&quot;])]
                          (if (or (nil? culprit) (= (count (:filters vc)) 0)) coll
                              (assoc coll culprit (inc (get coll culprit 0))))))
                      {} (parse-vcf vcf-iter))))
          (get-recal-metrics [in-vcf]
            (sort-by :count &gt;
                     (map (fn [[m c]] {:metric m :count c}) (get-metric-counts in-vcf))))]
    (.write wrtr &quot;** GATK recalibration filter metrics\n&quot;)
    (doseq [call (map (partial get cmp-info) [:c1 :c2])]
      (when (= (:mod call) &quot;recal&quot;)
        (.write wrtr (str (doric/table [:metric :count]
                                       (get-recal-metrics (:file call)))
                          &quot;\n&quot;))))))</pre></td></tr><tr><td class="docs"><h2>Top level reports</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Write a summary text file with tables of useful concordance metrics.</p>
</td><td class="codes"><pre class="brush: clojure">(defn write-summary-txt
  [wtr comparisons]
  (doseq [x comparisons]
    (.write wtr (format &quot;* %s : %s vs %s\n&quot; (get-in x [:exp :sample])
                        (get-in x [:c1 :name]) (get-in x [:c2 :name])))
    (write-scoring-table (:metrics x) (get-in x [:summary :sv]) wtr)
    (write-concordance-metrics (:summary x) wtr)
    (when-let [sv-info (get-in x [:summary :sv])]
      (write-sv-metrics sv-info wtr))
    (when (get-in x [:c1 :mod])
      (write-classification-metrics x wtr))))</pre></td></tr><tr><td class="docs"><p>Retrieve values for CSV output checking for lots of special cases.
    - Display all values for :total lines
    - For :snp and :indel lines, only show values with dictionaries that
      have this detailed info.
    - Always display initial sample and call values (i &lt;= 3)</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-summary-csv-vals
  [header cmp cur-type]
  (for [v (map-indexed (fn [i k]
                         (let [v (get cmp k)]
                           (cond
                            (= :type k) (name cur-type)
                            (and (not= :total cur-type)
                                 (&gt; i 3)
                                 (not (map? v))) nil
                            :else v)))
                       header)]
    (if (map? v) (get v cur-type) v)))</pre></td></tr><tr><td class="docs"><p>Write a top level summary CSV file with useful concordance metrics.</p>
</td><td class="codes"><pre class="brush: clojure">(defn write-summary-csv
  [wtr comparisons]
  (doseq [[i [x cmp-orig]] (map-indexed vector (map (juxt identity :summary) comparisons))]
    (let [header (concat [:sample :call1 :call2 :type] (nnext (keys cmp-orig)))
          cmp (-&gt; cmp-orig
                  (dissoc :ftypes)
                  (assoc :call1 (-&gt; x :c1 :name))
                  (assoc :call2 (-&gt; x :c2 :name)))]
      (when (= i 0)
        (csv/write-csv wtr [(map name header)]))
      (csv/write-csv wtr (for [cur-type [:total :snp :indel]]
                           (get-summary-csv-vals header cmp cur-type))))))</pre></td></tr><tr><td class="docs"><p>Write a CSV file with locations of useful files.</p>
</td><td class="codes"><pre class="brush: clojure">(defn write-files-csv
  [wtr comparisons config]
  (csv/write-csv wtr [[&quot;call1&quot; &quot;call2&quot; &quot;type&quot; &quot;fname&quot;]])
  (doseq [x comparisons]
    (doseq [[k f] (:c-files x)]
      (csv/write-csv wtr [[(get-in x [:c1 :name]) (get-in x [:c2 :name]) (name k)
                           (string/replace-first f (str (get-in config [:dir :out]) &quot;/&quot;) &quot;&quot;)]]))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.structural" name="bcbio.variation.structural"><h1 class="project-name">bcbio.variation.structural</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Handle structural variations for larger insertions, deletions and
  genome rearrangements.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.structural
  (:import [org.broadinstitute.sting.utils.codecs.vcf VCFCodec]
           [org.broadinstitute.sting.utils.variantcontext VariantContextBuilder
            Allele]
           [org.broad.tribble.readers AsciiLineReader PositionalBufferedStream]
           [net.sf.picard.util IntervalTree])
  (:use [clojure.set :only [intersection]]
        [ordered.map :only [ordered-map]]
        [bcbio.variation.variantcontext :only [get-vcf-iterator parse-vcf merge-headers
                                               from-vc write-vcf-w-template]]
        [bcbio.variation.callable :only [get-bed-source features-in-region]])
  (:require [clojure.string :as string]
            [fs.core :as fs]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><p>Default maximum indel size for exact comparisons.
             Based on assessment by Gavin Oliver: http://f1000r.es/MsY1QZ</p>
</td><td class="codes"><pre class="brush: clojure">(def ^{:private true
       :doc }
  max-indel 30)</pre></td></tr><tr><td class="docs"><h2>Interval tree lookup</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Retrieve an Interval with the specified start/end keywords.</p>
</td><td class="codes"><pre class="brush: clojure">(defn prep-itree
  [vc-iter start-kw end-kw]
  (reduce (fn [coll vc]
            (assoc coll (:chr vc)
                   (doto (get coll (:chr vc) (IntervalTree.))
                     (.put (get vc start-kw) (inc (get vc end-kw)) vc))))
          (ordered-map) vc-iter))</pre></td></tr><tr><td class="docs"><p>Convert IntervalTree Iterator into clojure seq.
  Catch deleted sequences and continue ignoring the deleted node.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- itree-seq
  [iter]
  (lazy-seq
   (when (.hasNext iter)
     (try
       (cons (.getValue (.next iter)) (itree-seq iter))
       (catch java.util.ConcurrentModificationException e
         (itree-seq iter))))))</pre></td></tr><tr><td class="docs"><p>Lazy sequence of items that overlap a region in a nested IntervalTree.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-itree-overlap
  [itree chrom start end]
  (let [chr-itree (get itree chrom)]
    (if (nil? chr-itree)
      []
      (itree-seq (.overlappers chr-itree start end)))))</pre></td></tr><tr><td class="docs"><p>Lazy sequence of all items in an IntervalTree.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-itree-all
  [itree]
  (flatten
   (for [item (vals itree)]
     (sort-by :start
              (itree-seq (.iterator item))))))</pre></td></tr><tr><td class="docs"><p>Remove variant context from an IntervalTree</p>
</td><td class="codes"><pre class="brush: clojure">(defn remove-itree-vc
  [itree chr start end]
  (if (not-any? nil? [chr start end])
    (assoc itree chr
           (doto (get itree chr)
             (.remove start (inc end))))
    itree))</pre></td></tr><tr><td class="docs"><h2>Structural variation helpers</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Determine the type of a structural variant. Expected types are:</p>

<pre><code>- DEL: Deletion
- INS: Insertion
- DUP: Duplication
- INV: Inversion
- BND: Breakpoint end; paired with second variant
- CNV: Copy number variation
- nil: Not a structural variant.
</code></pre>
</td><td class="codes"><pre class="brush: clojure">(defn get-sv-type
  [vc params]
  (letfn [(max-allele-size [vc]
            (apply max (map #(.length %) (cons (:ref-allele vc) (:alt-alleles vc)))))
          (indel-type [vc]
            (if (&gt; (.length (:ref-allele vc))
                   (apply max (map #(.length %) (:alt-alleles vc)))) :DEL :INS))
          (sv-type-from-symbol [allele]
            (-&gt;&gt; allele
                 (re-find #&quot;^&lt;(\w+)(:|&gt;)&quot; )
                 second
                 keyword))
          (alt-sv-type [vc]
            (let [allele (-&gt; vc :alt-alleles first .getDisplayString)]
              (cond
               (.startsWith allele &quot;&lt;&quot;) (sv-type-from-symbol allele)
               (or (.contains allele &quot;[&quot;)
                   (.contains allele &quot;]&quot;)) :BND)))]
    (cond
     (and (= &quot;INDEL&quot; (:type vc))
          (&gt; (max-allele-size vc) (or (:max-indel params) max-indel))) (indel-type vc)
     (= &quot;SYMBOLIC&quot; (:type vc)) (alt-sv-type vc)
     :else nil)))</pre></td></tr><tr><td class="docs"><p>Retrieve normalized integer values from an attribute.</p>
</td><td class="codes"><pre class="brush: clojure">(defn value-from-attr
  ([vc attr-name]
     (value-from-attr vc attr-name 0))
  ([vc attr-name attr-index]
      (-&gt; vc
          :attributes
          (get attr-name (repeat (inc attr-index) &quot;0&quot;))
          (#(if (string? %) [%] %))
          (nth attr-index)
          (Integer/parseInt)
          Math/abs)))</pre></td></tr><tr><td class="docs"><h2>Concordance checking</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Check if coordinates from two structural variants overlap.
  Considered an overlap if the two confidence intervals
  have shared bases.</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti sv-ends-overlap?
  (fn [[end1 end2]] (type end1)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod sv-ends-overlap? clojure.lang.PersistentVector
  [[[s1 e1] [s2 e2]]]
  (seq (intersection (set (range s1 (inc e1)))
                     (set (range s2 (inc e2))))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod sv-ends-overlap? java.lang.String
  [[end1 end2]]
  (= end1 end2))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- length-from-svlen [x] (value-from-attr x &quot;SVLEN&quot;))</pre></td></tr><tr><td class="docs"><p>Length of variation from INFO annotations, handling SVLEN and END.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- length-from-info
  [x]
  (max (length-from-svlen x)
       (- (value-from-attr x &quot;END&quot;) (:start x))))</pre></td></tr><tr><td class="docs"><p>Length of insertion variation, handling ALT allele, INSEQ
  and well-known named insertions.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- insertion-length
  [x]
  (letfn [(get-insseq [x]
            (-&gt; x :attributes (get &quot;INSSEQ&quot;)))
          (length-by-insert-name [alt-allele]
            (cond
             (.startsWith alt-allele &quot;&lt;INS:ME:&quot;) (-&gt; alt-allele
                                                     (subs 1 (dec (count alt-allele)))
                                                     (string/split #&quot;:&quot;)
                                                     last)
             (= alt-allele &quot;&lt;INS&gt;&quot;) nil
             :else (throw (Exception. (str &quot;Unknown insert allele&quot; alt-allele)))))
          (get-allele-insert [x]
            (let [alt-allele (-&gt; x :alt-alleles first .getDisplayString)]
              (if (.startsWith alt-allele &quot;&lt;&quot;)
                (length-by-insert-name alt-allele)
                (dec (count alt-allele)))))]
    (if-let [seq (get-insseq x)]
      (count seq)
      (if-let [named-insert (get-allele-insert x)]
        named-insert
        (length-from-info x)))))</pre></td></tr><tr><td class="docs"><p>Length of deletion variations, handling SVLEN and allele specifications.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- deletion-length
  [vc]
  (let [svlen (length-from-svlen vc)]
    (if (pos? svlen)
      svlen
      (- (-&gt; vc :ref-allele .length)
         (apply min (map #(.length %) (:alt-alleles vc)))))))</pre></td></tr><tr><td class="docs"><p>Retrieve length of a structural variant for different variation types.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-sv-length
  [vc]
  (case (:sv-type vc)
         :DEL (deletion-length vc)
         :INS (insertion-length vc)
         :INV (length-from-info vc)
         :DUP (length-from-info vc)
         :CNV (length-from-info vc)
         :BND 0
         :UNASSEMBLED_EVENT 0
         (throw (Exception. (str &quot;Structural variant type not handled: &quot;
                                 (:sv-type vc))))))</pre></td></tr><tr><td class="docs"><p>Retrieve start and end with confidence intervals for a variation.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-ci-start-end
  [vc params &amp; {:keys [allow-named?]}]
  (letfn [(get-ci-range [orig attr default-ci]
            (let [left-ci (value-from-attr vc attr 0)
                  right-ci (value-from-attr vc attr 1)]
              [(- orig (if (pos? left-ci) left-ci default-ci))
               (+ orig (if (pos? right-ci) right-ci default-ci))]))
          (get-default-ci [length]
            (let [default (if-let [x (-&gt; (:default-cis params) first second)] x 0)
                  by-length (when-not (string? length)
                              (second (first (drop-while #(&lt; (first %) length)
                                                         (:default-cis params)))))]
              (if-not (nil? by-length) by-length default)))]
    (let [start (:start vc)
          length (get-sv-length vc)
          default-ci (get-default-ci length)
          end (cond
               (and allow-named? (string? length)) length
               (string? length) (:end vc)
               :else (max (+ start length) (:end vc)))]
      [(get-ci-range start &quot;CIPOS&quot; default-ci)
       (if (string? end) end
           (get-ci-range end &quot;CIEND&quot; default-ci))])))</pre></td></tr><tr><td class="docs"><p>Check for concordance of variants based on reported length:
  handles deletions, inversions. insertions and duplications.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- sv-len-concordant?
  [sv1 sv2 params]
  (every? sv-ends-overlap?
          (partition 2 (interleave (get-ci-start-end sv1 params :allow-named? true)
                                   (get-ci-start-end sv2 params :allow-named? true)))))</pre></td></tr><tr><td class="docs"><p>Check if structural variants are concordant.</p>
</td><td class="codes"><pre class="brush: clojure">(defn sv-concordant?
  [params sv1 sv2]
  (and (apply = (map :sv-type [sv1 sv2]))
       (case (:sv-type sv1)
         (:DEL :INS :INV :DUP) (sv-len-concordant? sv1 sv2 params)
         (:BND :UNASSEMBLED_EVENT) false
         (throw (Exception. (str &quot;Structural variant type not handled: &quot;
                                 (:sv-type sv1)))))))</pre></td></tr><tr><td class="docs"><h2>Parsing structural variants</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Parse VCF file returning structural variants with confidence intervals.
  The :out-format keyword specifies how to return the parsed structural variants:
   - :itree -- Interval tree for variant lookup by chromosome and start/end.
   - default -- List of variants (non-lazy).</p>
</td><td class="codes"><pre class="brush: clojure">(defn parse-vcf-sv
  [vcf-file ref-file &amp; {:keys [out-format interval-file params]
                        :or {params {}}}]
  (letfn [(updated-sv-vc [cur-vc]
            (when-let [sv-type (get-sv-type cur-vc params)]
              (let [[start-cis end-cis] (get-ci-start-end (assoc cur-vc :sv-type sv-type)
                                                          params)]
                (-&gt; cur-vc
                    (assoc :start-ci (first start-cis))
                    (assoc :end-ci (second end-cis))
                    (assoc :sv-type sv-type)))))
          (in-intervals? [bed-source vc]
            (or (nil? bed-source)
                (seq (features-in-region bed-source (:chr vc) (:start-ci vc) (:end-ci vc)))))]
    (with-open [vcf-iter (get-vcf-iterator vcf-file ref-file)]
      (let [vs-iter (filter (partial in-intervals? (when interval-file
                                                     (get-bed-source interval-file ref-file)))
                            (keep updated-sv-vc (parse-vcf vcf-iter)))]
        (case out-format
          :itree (prep-itree vs-iter :start-ci :end-ci)
          (vec vs-iter))))))</pre></td></tr><tr><td class="docs"><p>Compare two structural variant files, returning variant contexts keyed by concordance.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- find-concordant-svs
  [fname1 fname2 disc-kwds ref interval-file params]
  (let [cmp-tree (atom (parse-vcf-sv fname2 ref :out-format :itree :interval-file interval-file
                                     :params params))]
    (letfn [(check-sv-concordance [vc]
              (let [matches (filter (partial sv-concordant? params vc)
                                    (get-itree-overlap @cmp-tree (:chr vc)
                                                       (:start-ci vc) (inc (:end-ci vc))))]
                (doseq [m-vc matches]
                  (reset! cmp-tree (remove-itree-vc @cmp-tree (:chr m-vc)
                                                    (:start m-vc) (:end m-vc))))
                (if-let [match (first matches)]
                  [:sv-concordant (:vc match)]
                  [(:1 disc-kwds) (:vc vc)])))
            (remaining-cmp-svs [itree]
              (partition 2
                         (interleave (repeat (:2 disc-kwds)) (map :vc (get-itree-all itree)))))]
      (concat
       (map check-sv-concordance (parse-vcf-sv fname1 ref :interval-file interval-file
                                               :params params))
       (remaining-cmp-svs @cmp-tree)))))</pre></td></tr><tr><td class="docs"><p>Retrieve list of non-structural variants in the provided input file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn find-non-svs
  [kwd vcf-source params ignore-regions]
  (-&gt;&gt; (parse-vcf vcf-source)
       (filter #(nil? (get-sv-type % params)))
       (remove #(contains? ignore-regions [(:chr %) (:start %)]))
       (map :vc)
       (interleave (repeat kwd))
       (partition 2)))</pre></td></tr><tr><td class="docs"><p>Write output file containing only non-structural variants</p>
</td><td class="codes"><pre class="brush: clojure">(defn write-non-svs
  [in-file ref params]
  (let [out-file (itx/add-file-part in-file &quot;nosv&quot;)]
    (with-open [vcf-iter (get-vcf-iterator in-file ref)]
    (write-vcf-w-template in-file {:out out-file}
                          (find-non-svs :out vcf-iter params #{})
                          ref))
    out-file))</pre></td></tr><tr><td class="docs"><p>Produce set of coordinates resulting from large SV deletions.
   Useful for avoiding double comparisons where we match SVs and
   then match smaller variations: we want to avoid those in a SV</p>
</td><td class="codes"><pre class="brush: clojure">(defn- sv-deletion-coords
  [in-file ref params]
  (letfn [(deletion-positions [vc]
            (let [[[s _] [_ e]] (get-ci-start-end (assoc vc :sv-type :DEL) {})]
              (map #(list (:chr vc) %) (range s e))))]
    (with-open [vcf-iter (get-vcf-iterator in-file ref)]
      (-&gt;&gt; (parse-vcf vcf-iter)
           (filter #(= :DEL (get-sv-type % params)))
           (mapcat deletion-positions)
           set))))</pre></td></tr><tr><td class="docs"><p>Compare structural variants, producing concordant and discordant outputs</p>
</td><td class="codes"><pre class="brush: clojure">(defn compare-sv
  [c1 c2 ref &amp; {:keys [out-dir interval-file params]
                :or {params {}}}]
  (let [base-out (str (fs/file (if (nil? out-dir) (fs/parent (:file c1)) out-dir)
                               (str (-&gt; c1 :file fs/base-name (string/split #&quot;-&quot;) first)
                                     &quot;-%s-%s-%s.vcf&quot;)))
        disc-kwds {:1 (keyword (str &quot;sv-&quot; (:name c1) &quot;-discordant&quot;))
                   :2 (keyword (str &quot;sv-&quot; (:name c2) &quot;-discordant&quot;))}
        out-files (ordered-map
                   :sv-concordant (format base-out (:name c1) (:name c2) &quot;svconcordance&quot;)
                   (:1 disc-kwds) (format base-out (:name c1) (:name c2) &quot;svdiscordance&quot;)
                   (:2 disc-kwds) (format base-out (:name c2) (:name c1) &quot;svdiscordance&quot;)
                   :nosv1 (itx/add-file-part (:file c1) &quot;nosv&quot; out-dir)
                   :nosv2 (itx/add-file-part (:file c2) &quot;nosv&quot; out-dir))]
    (when (itx/needs-run? (vals out-files))
      (with-open [vcf1-iter (get-vcf-iterator (:file c1) ref)
                  vcf2-iter (get-vcf-iterator (:file c2) ref)]
        (write-vcf-w-template (:file c1) out-files
                              (concat
                               (find-concordant-svs (:file c1) (:file c2) disc-kwds
                                                    ref interval-file params)
                               (find-non-svs :nosv1 vcf1-iter params #{})
                               (find-non-svs :nosv2 vcf2-iter params
                                             (sv-deletion-coords (:file c1) ref params)))
                              ref :header-update-fn (merge-headers (:file c2))))
      ;; Remove SV VCF indexes since they use alternative Codecs
      (doseq [fname (vals out-files)]
        (let [x (str fname &quot;.idx&quot;)]
          (if (fs/exists? x)
            (fs/delete x)))))
    out-files))</pre></td></tr><tr><td class="docs"><p>Handle input decomposition running SV detection through the standard pipeline.</p>
</td><td class="codes"><pre class="brush: clojure">(defn compare-sv-pipeline
  [c1 c2 exp config]
  (let [out-dir (get-in config [:dir :prep] (get-in config [:dir :out]))
        intervals (get c1 :intervals (get c2 :intervals (:intervals exp)))
        default-params {:max-indel max-indel
                        :default-cis [[200 10] [500 100] [1000 200] [1e6 500]]}
        params (merge default-params (:params exp))
        out-files (compare-sv c1 c2 (:ref exp) :out-dir out-dir
                              :interval-file intervals :params params)]
    [(assoc c1 :file (:nosv1 out-files))
     (assoc c2 :file (:nosv2 out-files))
     (-&gt; out-files
         (dissoc :nosv1)
         (dissoc :nosv2))]))</pre></td></tr><tr><td class="docs"><h2>Utility functions</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Lazy stream of structural variants overlapping in both inputs.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- find-overlapping-svs
  [f1 f2 ref params]
  (letfn [(find-overlaps [cmp-tree vc]
            (when-let [cmp-vc (first (get-itree-overlap cmp-tree (:chr vc)
                                                        (:start-ci vc) (inc (:end-ci vc))))]
              [:out1 (:vc vc) :out2 (:vc cmp-vc)]))]
    (let [cmp-tree (parse-vcf-sv f2 ref :out-format :itree :params params)]
      (-&gt;&gt; (parse-vcf-sv f1 ref :params params)
           (map (partial find-overlaps cmp-tree))
           (remove nil?)
           flatten
           (partition 2)))))</pre></td></tr><tr><td class="docs"><p>Prepare VCF files of only overlapping structural variants present in both.</p>
</td><td class="codes"><pre class="brush: clojure">(defn overlapping-svs
  [f1 f2 ref params]
  (let [out-files {:out1 (itx/add-file-part f1 &quot;overlap&quot;)
                   :out2 (itx/add-file-part f2 &quot;overlap&quot;)}]
    (when (itx/needs-run? (vals out-files))
      (write-vcf-w-template f1 out-files (find-overlapping-svs f1 f2 ref params) ref
                            :header-update-fn (merge-headers f2)))
    out-files))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.utils.background" name="bcbio.variation.utils.background"><h1 class="project-name">bcbio.variation.utils.background</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Prepare annotated VCF files to use as background for variant calling and recalibration.
  Batch variant calling and recalibration with GATK improves resulting calls. This
  provides a ready to use set of calls to batch with a single sample using 1000 genomes data.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.utils.background
  (:use [clojure.java.io]
        [bcbio.variation.config :only [load-config]]
        [bcbio.variation.combine :only [combine-variants]]
        [bcbio.variation.filter.intervals :only [select-by-sample]]
        [bcbio.variation.annotation :only [add-gatk-annotations]])
  (:require [clojure.java.shell :as shell]
            [clojure.string :as string]
            [fs.core :as fs]
            [aws.sdk.s3 :as s3]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><h2>Combine and annotate VCFs</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Download BAM file and index for a sample from 1000 genomes FTP.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- download-sample-bam
  [sample ftp-config out-dir]
  (letfn [(download [url fname]
            (when-not (fs/exists? fname)
              (println &quot;Downloading&quot; url &quot;to&quot; fname)
              (shell/with-sh-dir out-dir
                (shell/sh &quot;wget&quot; &quot;-O&quot; fname url))))]
    (let [dl-url (format (:bam-url ftp-config) sample sample)
          local-file (str (fs/file out-dir (string/replace (fs/base-name dl-url) &quot;.*&quot; &quot;&quot;)))]
      (download dl-url local-file)
      (download (str dl-url &quot;.bai&quot;) (str local-file &quot;.bai&quot;))
      local-file)))</pre></td></tr><tr><td class="docs"><p>Check if a file exists, also checking for gzipped versions.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- gzip-needs-run?
  [x]
  (every? itx/needs-run? [x (str x &quot;.gz&quot;)]))</pre></td></tr><tr><td class="docs"><p>Annotate genome sample VCFs with GATK metrics.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- annotate-sample
  [sample-info ref ftp-config prep-dir out-dir]
  (let [final-file (str (fs/file out-dir (format &quot;%s-annotated.vcf&quot; (:sample sample-info))))]
    (when (gzip-needs-run? final-file)
      (let [sample-bam (download-sample-bam (:sample sample-info) ftp-config prep-dir)
            ann-vcf (add-gatk-annotations (:file sample-info) sample-bam ref)]
        (fs/rename ann-vcf final-file)
        (itx/remove-path sample-bam)))
    final-file))</pre></td></tr><tr><td class="docs"><p>Combine sample VCFs split by chromosome.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- combine-samples
  [sample-info ref out-dir]
  (letfn [(combine-sample [[name xs]]
            {:sample name
             :file (combine-variants (map :file xs) ref :merge-type :full
                                     :out-dir out-dir)})]
    (map combine-sample
         (group-by :sample (flatten sample-info)))))</pre></td></tr><tr><td class="docs"><h2>Subset VCF by sample</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Download chromosome VCF from 1000 genomes for processing.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- download-chrom-vcf
  [chrom ftp-config out-dir]
  (letfn [(download-vcf [url fname]
            (println &quot;Downloading&quot; url &quot;to&quot; fname)
            (shell/with-sh-dir out-dir
              (shell/sh &quot;wget&quot; &quot;-O&quot; fname url)
              (shell/sh &quot;gunzip&quot; (str (fs/base-name fname)))))]
    (let [dl-url (format (:vcf-url ftp-config) chrom)
          local-file (str (fs/file out-dir (fs/base-name dl-url)))
          final-file (itx/remove-zip-ext local-file)]
      (when-not (fs/exists? final-file)
        (download-vcf dl-url local-file))
      final-file)))</pre></td></tr><tr><td class="docs"><p>Select samples from input 1000 genomes chromosome VCF.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- select-samples-at-chrom
  [chrom samples ref ftp-config out-dir]
  (let [sample-info (map (fn [x] {:sample x
                                  :file (str (fs/file out-dir (format &quot;%s-%s.vcf&quot; x chrom)))})
                         samples)]
    (when (apply itx/needs-run? (map :file sample-info))
      (let [chrom-vcf (download-chrom-vcf chrom ftp-config out-dir)]
        (doseq [sample samples]
          (select-by-sample sample chrom-vcf chrom ref :out-dir out-dir
                            :remove-refcalls true))
        (itx/remove-path chrom-vcf)))
    sample-info))</pre></td></tr><tr><td class="docs"><h2>Create combined background file</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Prepare combined VCF file with background information from multiple inputs.</p>
</td><td class="codes"><pre class="brush: clojure">(defn prep-combined-background
  [vcfs config]
  (letfn [(maybe-bgzip-vcf [x]
            (first (filter fs/exists? [x (str x &quot;.gz&quot;)])))]
    (let [out-dir (get-in config [:dir :out])
          out-file (str (fs/file out-dir (get-in config [:upload :combined-vcf])))]
      (when (gzip-needs-run? out-file)
        (-&gt; (combine-variants (map maybe-bgzip-vcf vcfs) (:ref config)
                              :merge-type :full :out-dir out-dir)
            (fs/rename out-file)))
      out-file)))</pre></td></tr><tr><td class="docs"><h2>Tabix prep and upload</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Prep VCF for tabix access by bgzipping and indexing.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- tabix-prep-vcf
  [vcf]
  (let [out-dir (str (fs/parent vcf))
        vcf-gz (str vcf &quot;.gz&quot;)
        tbi-gz (str vcf-gz &quot;.tbi&quot;)]
    (shell/with-sh-dir out-dir
      (when (itx/needs-run? vcf-gz)
        (shell/sh &quot;bgzip&quot; (str (fs/base-name vcf))))
      (when (itx/needs-run? tbi-gz)
        (shell/sh &quot;tabix&quot; &quot;-p&quot; &quot;vcf&quot; (str (fs/base-name vcf-gz)))))
    [vcf-gz tbi-gz]))</pre></td></tr><tr><td class="docs"><p>Upload prepared sample VCF bgzipped and tabix indexed.</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti upload-result-vcf
  (fn [_ config] (keyword (get-in config [:upload :target]))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod upload-result-vcf :s3
  [vcf config]
  (let [cred {:access-key (System/getenv &quot;AWS_ACCESS_KEY_ID&quot;)
              :secret-key (System/getenv &quot;AWS_SECRET_ACCESS_KEY&quot;)}
        bucket (get-in config [:upload :bucket])]
    (when-not (s3/bucket-exists? cred bucket)
      (s3/create-bucket cred bucket)
      (s3/update-bucket-acl cred bucket (s3/grant :all-users :read)))
    (doseq [fname (tabix-prep-vcf vcf)]
      (let [s3-key (format &quot;%s/%s&quot; (get-in config [:upload :folder])
                           (str (fs/base-name fname)))]
        (when-not (s3/object-exists? cred bucket s3-key)
          (s3/put-object cred bucket s3-key (file fname))
          (s3/update-object-acl cred bucket s3-key
                                (s3/grant :all-users :read)))
        (println s3-key)))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn make-work-dirs [config]
  (doseq [dir-name (-&gt; config :dir keys)]
    (let [cur-dir (get-in config [:dir dir-name])]
      (when-not (fs/exists? cur-dir)
        (fs/mkdirs cur-dir)))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -main [config-file]
  (let [config (load-config config-file)]
    (make-work-dirs config)
    (let [prep-dir (get-in config [:dir :prep])
          samples (map #(select-samples-at-chrom % (:genomes config) (:ref config)
                                                 (:ftp config) prep-dir)
                                        (get-in config [:ftp :chromosomes]))
          combo-samples (combine-samples samples (:ref config) prep-dir)
          ann-samples (map #(annotate-sample % (:ref config) (:ftp config)
                                             prep-dir (get-in config [:dir :out]))
                           (sort-by :sample combo-samples))]
      (doseq [ready-vcf (cons (prep-combined-background ann-samples config)
                              ann-samples)]
        (upload-result-vcf ready-vcf config)))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.utils.callsummary" name="bcbio.variation.utils.callsummary"><h1 class="project-name">bcbio.variation.utils.callsummary</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Summarize a set of calls derived from multiple inputs to help with identifying filtering patterns.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.utils.callsummary
  (:use [clojure.java.io]
        [bcbio.variation.config :only [load-config]]
        [bcbio.variation.variantcontext :only [parse-vcf get-vcf-iterator
                                               get-vcf-retriever variants-in-region]])
  (:require [clojure.string :as string]
            [fs.core :as fs]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- get-prepped-fname
  [call exp config]
  (let [dirname (get-in config [:dir :prep])]
    (str (file dirname (format &quot;%s-%s-nomnp.vcf&quot; (:sample exp) (:name call))))))</pre></td></tr><tr><td class="docs"><p>Report details on a variant based on items found in inputs.</p>
</td><td class="codes"><pre class="brush: clojure">(defn report-vrn-summary
  [wtr vc retriever fname-map]
  (letfn [(get-alt-alleles [vc]
            (map #(.getBaseString %) (:alt-alleles vc)))
          (get-match-variants [vc]
            (filter #(= (:start %) (:start vc))
                    (variants-in-region retriever (:chr vc) (:start vc) (:end vc))))]
    (let [hits (get-match-variants vc)]
      (.write wtr (str (string/join &quot;,&quot;
                                    [(:chr vc) (:start vc)
                                     (.getBaseString (:ref-allele vc))
                                     (string/join &quot;;&quot; (get-alt-alleles vc))
                                     (string/join &quot;;&quot; (sort (vec (set (map #(get fname-map (:fname %))
                                                                           hits)))))
                                     (string/join &quot;;&quot; (set (mapcat get-alt-alleles hits)))])
                       &quot;\n&quot;)))))</pre></td></tr><tr><td class="docs"><p>Annotate input VCF with summary details from input files.</p>
</td><td class="codes"><pre class="brush: clojure">(defn annotate-with-callsummary
  [in-file config-file]
  (let [config (load-config config-file)
        exp (-&gt; config :experiments first)
        orig-files (filter fs/exists? (map #(get-prepped-fname % exp config) (:calls exp)))
        fname-map (zipmap orig-files (map :name (:calls exp)))
        retriever (apply get-vcf-retriever (cons (:ref exp) orig-files))
        out-file (str (itx/file-root in-file) &quot;.csv&quot;)]
    (with-open [vrn-iter (get-vcf-iterator in-file (:ref exp))
                wtr (writer out-file)]
      (doseq [vc (filter #(empty? (:filters %)) (parse-vcf vrn-iter))]
        (report-vrn-summary wtr vc retriever fname-map)))
    out-file))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.utils.cgmetrics" name="bcbio.variation.utils.cgmetrics"><h1 class="project-name">bcbio.variation.utils.cgmetrics</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Add metrics from Complete Genomics masterVar file to a VCF.
  This updates a converted VCF from Complete Genomics with metrics information
  allowing assessment and filtering.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.utils.cgmetrics
  (:import [org.broadinstitute.sting.utils.variantcontext VariantContextBuilder]
           [org.broadinstitute.sting.utils.codecs.vcf VCFHeader VCFInfoHeaderLine
            VCFHeaderLineCount VCFHeaderLineType])
  (:use [clojure.java.io]
        [ordered.set :only (ordered-set)]
        [bcbio.variation.normalize :only [hg19-map]]
        [bcbio.variation.variantcontext :only [parse-vcf write-vcf-w-template
                                               get-vcf-iterator]])
  (:require [clojure.data.csv :as csv]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><p>Get lookup dictionary of CG variant metrics by position.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-masterVar-metrics
  [in-file]
  (letfn [(variant-score [line name]
            (let [alleles [&quot;1&quot; &quot;2&quot;]]
              (/ (apply + (map #(Float/parseFloat (get line (format &quot;allele%sVarScore%s&quot; % name)))
                               alleles))
                 (count alleles))))
          (allele-balance [line]
            (/ (Float/parseFloat (get line &quot;referenceAlleleReadCount&quot;))
               (Float/parseFloat (get line &quot;totalReadCount&quot;))))]
    (with-open [rdr (reader in-file)]
      (let [csv-iter (drop-while #(&lt; (count %) 3)
                                 (csv/read-csv rdr :separator \tab))
            header (first csv-iter)]
        (reduce (fn [coll xs]
                  (let [line (zipmap header xs)]
                    (assoc coll [(get hg19-map (get line &quot;chromosome&quot;))
                                 (inc (Integer/parseInt (get line &quot;begin&quot;)))]
                           {:depth (get line &quot;totalReadCount&quot;)
                            :qual-eaf (variant-score line &quot;EAF&quot;)
                            :qual-vaf (variant-score line &quot;VAF&quot;)
                            :ab (allele-balance line)})))
                {} (rest csv-iter))))))</pre></td></tr><tr><td class="docs"><p>Provide iterator of variants with CG metrics added</p>
</td><td class="codes"><pre class="brush: clojure">(defn- add-cgmetrics-iter
  [vcf-source metrics]
  (letfn [(update-cgmetrics [vc x]
            (-&gt; (VariantContextBuilder. (:vc vc))
                (.attributes (assoc (:attributes vc)
                               &quot;DPCALL&quot; (:depth x)
                               &quot;AB&quot; (:ab x)
                               &quot;QUALEAF&quot; (:qual-eaf x)
                               &quot;QUALVAF&quot; (:qual-vaf x)))
                .make))]
    (map (fn [vc]
           (if-let [cur-metrics (get metrics [(:chr vc) (:start vc)])]
             (update-cgmetrics vc cur-metrics)
             (:vc vc)))
         (parse-vcf vcf-source))))</pre></td></tr><tr><td class="docs"><p>Add CG metrics definitions to the VCF input header.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- add-cgmetrics-header
  [_ header]
  (let [new #{(VCFInfoHeaderLine. &quot;DPCALL&quot; 1
                                  VCFHeaderLineType/Integer &quot;Total depth used for calls&quot;)
              (VCFInfoHeaderLine. &quot;QUALEAF&quot; 1
                                  VCFHeaderLineType/Float
                                  &quot;Variant quality under equal allele fraction model (EAF)&quot;)
              (VCFInfoHeaderLine. &quot;QUALVAF&quot; 1
                                  VCFHeaderLineType/Float
                                  &quot;Variant quality under maximum likelihood variable allele fraction model (VAF)&quot;)
              (VCFInfoHeaderLine. &quot;AB&quot; 1
                                  VCFHeaderLineType/Float &quot;Allele Balance&quot;)}]
    (VCFHeader. (apply ordered-set (concat (.getMetaDataInInputOrder header) new))
                (.getGenotypeSamples header))))</pre></td></tr><tr><td class="docs"><p>Add metrics from Complete Genomics masterVar file to VCF.</p>
</td><td class="codes"><pre class="brush: clojure">(defn add-cgmetrics
  [vcf-file mastervar-file ref-file &amp; {:keys [out-dir]}]
  (let [out-file (itx/add-file-part vcf-file &quot;cgmetrics&quot; out-dir)]
    (when (itx/needs-run? out-file)
      (with-open [vcf-iter (get-vcf-iterator vcf-file ref-file)]
        (write-vcf-w-template vcf-file {:out out-file}
                              (add-cgmetrics-iter vcf-iter
                                                  (get-masterVar-metrics mastervar-file))
                              ref-file :header-update-fn add-cgmetrics-header)))
    out-file))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.utils.core" name="bcbio.variation.utils.core"><h1 class="project-name">bcbio.variation.utils.core</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.utils.core
  (:require [bcbio.variation.utils.callsummary :as callsummary]
            [bcbio.variation.utils.gms :as gms]
            [bcbio.variation.utils.illumina :as illumina]
            [bcbio.variation.utils.popfreq :as popfreq]
            [bcbio.variation.utils.summarize :as summarize]
            [bcbio.variation.utils.svmerge :as svmerge]))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -main [cur-type &amp; args]
  (apply (case (keyword cur-type)
           :callsummary callsummary/annotate-with-callsummary
           :gms gms/prepare-gms-vcfs-from-config
           :illumina illumina/prep-illumina-variants
           :popfreq popfreq/annotate-with-popfreq
           :summarize summarize/vcf-to-table-config
           :svmerge svmerge/into-calls)
         args))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.utils.gms" name="bcbio.variation.utils.gms"><h1 class="project-name">bcbio.variation.utils.gms</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Build reference Genomic Mappability Score (GMS) variant file.
  Uses full GMS files to generate VCF of potentially problematic low-GMS regions:
  http://sourceforge.net/apps/mediawiki/gma-bio/index.php</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.utils.gms
  (:import [org.broadinstitute.sting.utils.variantcontext VariantContextBuilder Allele]
           [org.broadinstitute.sting.utils.variantcontext.writer VariantContextWriterFactory]
           [org.broadinstitute.sting.utils.codecs.vcf VCFHeader
            VCFInfoHeaderLine VCFHeaderLineCount VCFHeaderLineType])
  (:use [clojure.java.io]
        [ordered.map :only [ordered-map]]
        [bcbio.align.ref :only [get-seq-dict]]
        [bcbio.variation.combine :only [combine-variants]]
        [bcbio.variation.config :only [load-config]]
        [bcbio.variation.normalize :only [hg19-map]]
        [bcbio.variation.utils.background :only [make-work-dirs]])
  (:require [clojure.java.shell :as shell]
            [clojure.string :as string]
            [fs.core :as fs]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><p>Download GMS data for all technologies at a chromosome.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- download-chrom-gms-data
  [chrom ftp-config out-dir]
  (letfn [(download-gms [chrom tech]
            (let [dl-url (format (:gms-url ftp-config) (:genome-build ftp-config)
                                 tech chrom)
                  final-file (itx/add-file-part (itx/remove-zip-ext (fs/base-name dl-url))
                                                tech out-dir)
                  dl-file (str final-file &quot;.gz&quot;)]
              (when (itx/needs-run? final-file)
                (shell/with-sh-dir out-dir
                  (println (format &quot;Downloading %s to %s&quot; dl-url dl-file))
                  (shell/sh &quot;wget&quot; &quot;-O&quot; dl-file dl-url)
                  (shell/sh &quot;gunzip&quot; dl-file)))
              final-file))]
    (into (ordered-map)
          (map (juxt identity (partial download-gms chrom))
               (:technologies ftp-config)))))</pre></td></tr><tr><td class="docs"><p>Retrieve chromosome, position and GMS score for line in a GMS file</p>
</td><td class="codes"><pre class="brush: clojure">(defn- parse-gms-line
  [line]
  (let [[chrom pos base _ _ score] (string/split line #&quot;\t&quot;)]
    {:chrom chrom
     :pos (Integer/parseInt pos)
     :base base
     :score (Float/parseFloat score)}))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- low-gms-score? [config gms-data]
  (let [thresh (get config :max-gms-score 50.0)]
    (and (&gt; (:score gms-data) 0.0)
         (&lt; (:score gms-data) thresh))))</pre></td></tr><tr><td class="docs"><p>Prepare variant context from set of GMS scores</p>
</td><td class="codes"><pre class="brush: clojure">(defn- gms-scores-to-vc
  [techs scores]
  (let [contig (get hg19-map (-&gt; scores first :chrom))
        all-pos (filter pos? (map :pos scores))
        pos (if (= 1 (count (set all-pos)))
              (first all-pos)
              (throw (Exception. (str &quot;Multiple positions found: &quot; all-pos))))
        base (-&gt;&gt; (map :base scores)
                  (filter #(not= % &quot;*&quot;))
                  first)]
    (when-not (or (zero? pos) (nil? base))
      (-&gt; (VariantContextBuilder. contig contig pos pos [(Allele/create base true)])
          (.attributes (reduce (fn [coll [tech score]]
                                 (assoc coll (str &quot;GMS_&quot; tech) (format &quot;%.1f&quot; (:score score))))
                               {} (map vector techs scores)))
          (.make)))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- get-vcf-header [techs]
  (VCFHeader. (set
               (map #(VCFInfoHeaderLine. (format &quot;GMS_%s&quot; %) 1
                                         VCFHeaderLineType/Float
                                         (format &quot;Genome Mappability Score: %s&quot; %))
                    techs))))</pre></td></tr><tr><td class="docs"><p>Prepare an output VCF of low GMS values at the provided chromosome.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- prepare-vcf-at-chrom
  [chrom ftp-config ref out-dir]
  (let [out-file (file out-dir (format &quot;lowgms-scores-%s.vcf&quot; chrom))]
    (when (itx/needs-run? out-file)
      (let [gms-files (download-chrom-gms-data chrom ftp-config out-dir)
            readers (map reader (vals gms-files))]
        (with-open [writer (VariantContextWriterFactory/create (file out-file)
                                                               (get-seq-dict ref))]
          (.writeHeader writer (get-vcf-header (keys gms-files)))
          (loop [line-iters (-&gt;&gt; (map line-seq readers)
                                 (map (fn [x] (drop-while #(.startsWith % &quot;#&quot;) x))))]
            (when-not (or (empty? (first line-iters))
                          (some nil? (map first line-iters)))
              (let [cur-gms (map (comp parse-gms-line first) line-iters)]
                (when (some (partial low-gms-score? ftp-config) cur-gms)
                  (when-let [vc (gms-scores-to-vc (keys gms-files) cur-gms)]
                    (.add writer vc))))
              (recur (map rest line-iters))))
          (doseq [x readers]
            (.close x)))
        (doseq [x (vals gms-files)]
          (itx/remove-path x))))
    (str out-file)))</pre></td></tr><tr><td class="docs"><p>Prepare individual chromosome VCF files with low GMS data by sequencing technology.</p>
</td><td class="codes"><pre class="brush: clojure">(defn prepare-gms-vcfs
  [config]
  (let [ref (:ref config)
        out-dir (get-in config [:dir :out])
        gms-by-chrom (doall (map #(prepare-vcf-at-chrom % (:ftp config) ref out-dir)
                                  (get-in config [:ftp :chromosomes])))]
    (println gms-by-chrom)
    (combine-variants gms-by-chrom ref :merge-type :full :out-dir out-dir
                      :quiet-out? true))
  (shutdown-agents))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn prepare-gms-vcfs-from-config [config-file]
  (let [config (load-config config-file)]
    (make-work-dirs config)
    (prepare-gms-vcfs config)))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.utils.illumina" name="bcbio.variation.utils.illumina"><h1 class="project-name">bcbio.variation.utils.illumina</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Automate converting Illumina variant calls into GATK-ready format.
   - Select MAXGT calls from Illumina SNP file (no prior assumption of a variant)
   - Add sample names to SNP and Indel headers.
   - Remove illegal gap characters from indel files.
   - Convert into GRCh37 sorted coordinates.
   - Merge SNP and Indels into single callset.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.utils.illumina
  (:require [fs.core :as fs]
            [bcbio.run.itx :as itx]
            [bcbio.variation.combine :refer [gatk-normalize]]))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- get-illumina-vcf
  [base-dir base-name]
  (-&gt; (fs/file base-dir &quot;Variations&quot; (str base-name &quot;*.vcf&quot;))
      str
      fs/glob
      first
      str))</pre></td></tr><tr><td class="docs"><p>Prepare Illumina variants from a standard directory structure.
    - base-dir: Directory containing Illumina information (will have subdirs like
                Assembly, Consensus and Variations)
    - sample-name: The name to include in updated VCF headers
    - ref-file: Reference file we want to sort to
    - orig-ref-file: Original reference file (hg19 for Illumina)</p>
</td><td class="codes"><pre class="brush: clojure">(defn prep-illumina-variants
  [base-dir sample-name ref-file orig-ref-file]
  (let [base-dir (fs/expand-home base-dir)
        out-file (str (fs/file base-dir &quot;Variations&quot; (str sample-name &quot;.vcf&quot;)))]
    (when (itx/needs-run? out-file)
      (itx/with-temp-dir [out-dir base-dir]
        (let [call {:name &quot;iprep&quot; :file [(get-illumina-vcf base-dir &quot;SNPs&quot;)
                                         (get-illumina-vcf base-dir &quot;Indels&quot;)]
                    :preclean true :prep true :normalize true
                    :ref orig-ref-file}
              exp {:sample sample-name :ref ref-file}
              out-info (gatk-normalize call exp [] out-dir
                                       (fn [_ x] (println x)))]
          (fs/rename (:file out-info) out-file))))
    out-file))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.utils.popfreq" name="bcbio.variation.utils.popfreq"><h1 class="project-name">bcbio.variation.utils.popfreq</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Associate population allele frequency with a list of variants.
  Annotates the original file with population frequencies based on rs IDs.
  Arguments:
    - original VCF file
    - attribute ID to include population frequencies in file (ie. GMAF)
    - Description of new frequency for VCF header
    - population VCF file
    - attribute ID to use for frequencies from population file (ie. AF)
    - reference genome FASTA file</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.utils.popfreq
  (:import [org.broadinstitute.sting.utils.variantcontext VariantContextBuilder]
           [org.broadinstitute.sting.utils.codecs.vcf VCFHeader VCFInfoHeaderLine
            VCFHeaderLineCount VCFHeaderLineType])
  (:use [ordered.set :only [ordered-set]]
        [bcbio.variation.config :only [load-config]]
        [bcbio.variation.combine :only [combine-variants]]
        [bcbio.variation.variantcontext :only [parse-vcf write-vcf-w-template
                                               get-vcf-iterator]])
  (:require [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><p>Retrieve all rsIDs from the input vcf-file</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-rsids
  [vcf-file ref]
  (with-open [vcf-iter (get-vcf-iterator vcf-file ref)]
    (set (remove nil? (map :id (parse-vcf vcf-iter))))))</pre></td></tr><tr><td class="docs"><p>Retrieve allele frequencies from population VCF for IDs of interest.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-allele-freqs
  [vcf-file ref want-ids targets]
  (println &quot;Retrieving allele freqs&quot; (count want-ids) targets)
  (with-open [vcf-iter (get-vcf-iterator vcf-file ref)]
    (reduce (fn [coll vc]
              (if (and (not (nil? (:id vc)))
                       (contains? want-ids (:id vc)))
                (assoc coll (:id vc) (zipmap (map :new-id targets)
                                             (map #(get-in vc [:attributes (:orig-id %)] 0.0)
                                                  targets)))
                coll))
            {} (parse-vcf vcf-iter))))</pre></td></tr><tr><td class="docs"><p>Lazy generator of variant contexts with added population frequencies.</p>
</td><td class="codes"><pre class="brush: clojure">(defn add-pop-freqs
  [vcf-iter allele-freqs ann-ids]
  (letfn [(update-allele-freq [vc new-freqs]
            (-&gt; (VariantContextBuilder. (:vc vc))
                (.attributes (reduce (fn [coll cur-id]
                                       (assoc coll cur-id (get new-freqs cur-id 0.0)))
                                     (:attributes vc) ann-ids))
                .make))]
    (map #(update-allele-freq % (get allele-freqs (:id %) {}))
         (parse-vcf vcf-iter))))</pre></td></tr><tr><td class="docs"><p>Add new population frequency information to the VCF input header if needed.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- add-popfreq-header
  [new-ids]
  (letfn [(header-has-id? [header test-id]
            (contains? (set (map #(when (= &quot;INFO&quot; (.getKey %))
                                    (.getID %)) (.getMetaDataInInputOrder header)))
                       test-id))]
    (fn [_ header]
      (let [new (-&gt;&gt; new-ids
                     (remove #(header-has-id? header (:new-id %)))
                     (map #(VCFInfoHeaderLine. (:new-id %) 1
                                               VCFHeaderLineType/Float (:desc %)))
                     set)]
        (VCFHeader. (apply ordered-set (concat (.getMetaDataInInputOrder header) new))
                    (.getGenotypeSamples header))))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- add-annotations
  [call ref out-dir]
  (let [orig-vcf (if (coll? (:file call))
                   (combine-variants (:file call) ref :out-dir out-dir :merge-type :full)
                   (:file call))
        out-file (itx/add-file-part orig-vcf &quot;popfreq&quot; out-dir)
        allele-freqs (get-allele-freqs (get-in call [:annotate :file]) ref
                                       (get-rsids orig-vcf ref)
                                       (get-in call [:annotate :targets]))]
    (if (itx/needs-run? out-file)
      (with-open [vcf-iter (get-vcf-iterator orig-vcf ref)]
        (write-vcf-w-template orig-vcf {:out out-file}
                              (add-pop-freqs vcf-iter allele-freqs
                                             (map :new-id (get-in call [:annotate :targets])))
                              ref
                              :header-update-fn
                              (add-popfreq-header (get-in call [:annotate :targets])))))
    out-file))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn annotate-with-popfreq [config-file]
  (let [config (load-config config-file)]
    (doseq [exp (:experiments config)]
      (doseq [call (:calls exp)]
        (add-annotations call (:ref exp) (get-in config [:dir :out]))))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.utils.sanger" name="bcbio.variation.utils.sanger"><h1 class="project-name">bcbio.variation.utils.sanger</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Parse and organize results from Sanger validation into VCF</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.utils.sanger
  (:import [org.broadinstitute.sting.utils.variantcontext Allele
            VariantContextBuilder GenotypeBuilder GenotypesContext]
           [org.broadinstitute.sting.utils.codecs.vcf
            VCFHeader VCFInfoHeaderLine VCFHeaderLineCount VCFHeaderLineType
            VCFFormatHeaderLine]
           [org.broadinstitute.sting.utils.variantcontext.writer
            VariantContextWriterFactory])
  (:require [clojure.string :as string]
            [clojure.set :as set]
            [clojure.java.io :as io]
            [incanter.excel :as excel]
            [incanter.core :as icore]
            [fs.core :as fs]
            [bcbio.align.ref :refer [get-seq-dict]]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><p>Validates if one end passes and validates our variant, and the other
   failed to map.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- validates-only-one?
  [for rev]
  (or (and (.startsWith for &quot;Pass&quot;)
           (.startsWith rev &quot;Pass&quot;)
           (= for rev))
      (and (.startsWith for &quot;Pass&quot;)
           (= rev &quot;NA&quot;))
      (and (.startsWith rev &quot;Pass&quot;)
           (= for &quot;NA&quot;))))</pre></td></tr><tr><td class="docs"><p>Validates if both reads pass and match our expected result.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- validates?
  [for rev]
  (or (and (.startsWith for &quot;Pass&quot;)
           (.startsWith rev &quot;Pass&quot;)
           (= for rev))))</pre></td></tr><tr><td class="docs"><p>Supports the reference sequence if both fail to validate and at least one
   call identifies the reference.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- supports-ref?
  [for rev for-val rev-val]
  (and (= for &quot;Fail&quot;) (= rev &quot;Fail&quot;)
       (not (empty? (set/intersection #{&quot;,&quot; &quot;.&quot;} (into #{} [for-val rev-val]))))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- get-validate-allele
  [for rev]
  (-&gt; (if (.startsWith for &quot;Pass&quot;) for rev)
      (string/split #&quot;,&quot;)
      first
      (string/replace &quot;Pass_&quot; )))</pre></td></tr><tr><td class="docs"><p>Map a row to variant information</p>
</td><td class="codes"><pre class="brush: clojure">(defn- row-&gt;varinfo
  [key ref alt group for rev for-val rev-val]
  (let [val (cond (validates-only-one? for rev) (get-validate-allele for rev)
                  (supports-ref? for rev for-val rev-val) ref
                  :else nil)]
    (when val
      (let [[chrom start] (string/split key #&quot;_&quot;)
            alts (string/split alt #&quot;,&quot;)]
        {:chrom chrom
         :start (dec (Integer/parseInt start))
         :ref ref
         :alts alts
         :orig [for rev]
         :group group
         :val val}))))</pre></td></tr><tr><td class="docs"><p>Return confirmed calls from Sanger calls in input XLS file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- read-sanger-xls
  [in-file]
  (-&gt;&gt; (excel/read-xls (str in-file))
       (icore/$map row-&gt;varinfo [&quot;key&quot; &quot;vcf ref&quot; &quot;vcf allele&quot; &quot;set&quot;
                                 &quot;forward validated&quot; &quot;reverse validated&quot;
                                 &quot;CE validation forward&quot; &quot;CE validation reverse&quot;])
       (remove nil?)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- get-header [sample-name]
  (VCFHeader. #{(VCFInfoHeaderLine. &quot;valgroup&quot; 1 VCFHeaderLineType/String
                                    &quot;Validation group&quot;)
                (VCFFormatHeaderLine. &quot;GT&quot; 1 VCFHeaderLineType/String
                                      &quot;Genotype&quot;)}
              #{sample-name}))</pre></td></tr><tr><td class="docs"><p>Retrieve chromosome and real position</p>
</td><td class="codes"><pre class="brush: clojure">(defn- chrom-coord
  [ref-dict]
  (let [name-&gt;index (into {} (map-indexed (fn [i x] [(.getSequenceName x) i])
                                          (.getSequences ref-dict)))]
    (fn [x]
      [(name-&gt;index (:chrom x)) (:start x)])))</pre></td></tr><tr><td class="docs"><p>Convert a dictionary of validation information into a VariantContext.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- val-&gt;vc
  [sample-name x]
  (println x)
  (-&gt; (VariantContextBuilder. (:chrom x) (:chrom x)
                              (inc (:start x)) (+ (count (:ref x)) (:start x))
                              (cons (Allele/create (:ref x) true)
                                    (map #(Allele/create % false) (:alts x))))
      (.attributes {&quot;valgroup&quot; (:group x)})
      (.genotypes (GenotypesContext/create
                   (java.util.ArrayList.
                    [(GenotypeBuilder/create sample-name
                                             [(Allele/create (:val x) (= (:ref x) (:val x)))])])))
      .make))</pre></td></tr><tr><td class="docs"><p>Read directory of Sanger Illumina validation results in Excel format.
   Convert into VCF with validated and reference variants.</p>
</td><td class="codes"><pre class="brush: clojure">(defn sanger-&gt;vcf
  [sanger-dir sample-name ref-file]
  (let [seq-dict (get-seq-dict ref-file)
        out-file (str (fs/file sanger-dir (str sample-name &quot;-sanger-validate.vcf&quot;)))]
    (when true ;(itx/needs-run? out-file)
      (with-open [writer (VariantContextWriterFactory/create (io/file out-file)
                                                             seq-dict)]
        (.writeHeader writer (get-header sample-name))
        (doseq [vc (-&gt;&gt; (mapcat read-sanger-xls (fs/glob (fs/file sanger-dir &quot;*.xls*&quot;)))
                        (sort-by (chrom-coord seq-dict))
                        (map (partial val-&gt;vc sample-name)))]
          (.add writer vc))))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.utils.summarize" name="bcbio.variation.utils.summarize"><h1 class="project-name">bcbio.variation.utils.summarize</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Collapse a multi-sample VCF file into a CSV, R data.frame ready, parameter summary.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.utils.summarize
  (:use [clojure.java.io]
        [ordered.map :only [ordered-map]]
        [bcbio.variation.callable :only [get-bed-source features-in-region]]
        [bcbio.variation.config :only [load-config]]
        [bcbio.variation.metrics :only [passes-filter?]]
        [bcbio.variation.variantcontext :only [parse-vcf get-vcf-iterator]])
  (:require [clojure.string :as string]
            [clojure.data.csv :as csv]
            [incanter.stats :as istats]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- to-float [x]
  (try
    (Float/parseFloat x)
    (catch Exception e (float x))))</pre></td></tr><tr><td class="docs"><p>Provide sample information from variant genotypes.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- flatten-vc-samples
  [out vc attrs]
  (let [variant-types [&quot;HET&quot; &quot;HOM_VAR&quot;]]
    (letfn [(add-variant-totals [out gs]
              (let [counts (frequencies (map :type gs))]
                (reduce (fn [coll [k v]] (assoc coll k v))
                        out (map (fn [k] [k (get counts k 0)])
                                 variant-types))))
            (get-attr-avg [k gs]
              (istats/mean (-&gt;&gt; gs
                                (filter #(contains? (set variant-types) (:type %)))
                                (map #(get-in % [:attributes k]))
                                (remove nil?)
                                (map #(to-float %)))))
            (add-attr-avgs [out gs attrs]
              (reduce (fn [coll k] (assoc coll (str k &quot;_sample_mean&quot;)
                                          (get-attr-avg k gs)))
                      out attrs))]
      (-&gt; out
          (add-variant-totals (:genotypes vc))
          (add-attr-avgs (:genotypes vc) attrs)))))</pre></td></tr><tr><td class="docs"><p>Prepare attributes for feeding into flattened table</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti prep-attribute
  (fn [attr value default] attr))</pre></td></tr><tr><td class="docs"><p>Handle set attributes, where we want to report the total sets identified.</p>
</td><td class="codes"><pre class="brush: clojure">(defmethod prep-attribute &quot;set&quot;
  [_ value default]
  (cond
   (= value &quot;Intersection&quot;) default
   (= value &quot;FilteredInAll&quot;) 0
   (nil? value) 0
   :else (count (string/split value #&quot;\-&quot;))))</pre></td></tr><tr><td class="docs"><p>Handle remaining attributes. For multi-allele VCFs return the first value.</p>
</td><td class="codes"><pre class="brush: clojure">(defmethod prep-attribute :default
  [_ value _]
  (if (instance? java.util.ArrayList value)
    (first value)
    value))</pre></td></tr><tr><td class="docs"><p>Extract attributes of interest from INFO field of variant.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- flatten-vc-attrs
  [out vc attrs defaults]
  (reduce (fn [coll k] (assoc coll k (prep-attribute k (get-in vc [:attributes k])
                                                     (get defaults (keyword k)))))
          out attrs))</pre></td></tr><tr><td class="docs"><p>Check for presence of the variant in predefined intervals.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- flatten-vc-intervals
  [out vc intervals]
  (letfn [(check-intervals [vc bed-s]
            (if (empty? (features-in-region bed-s (:chr vc) (:start vc) (:end vc))) 0 1))]
    (reduce (fn [coll interval]
              (assoc coll (:name interval) (check-intervals vc (:source interval))))
            out intervals)))</pre></td></tr><tr><td class="docs"><p>Provide tabular variant representation with provided attributes and sample information.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- flatten-vc
  [config vc]
  (-&gt; (reduce (fn [coll k] (assoc coll k (get vc k)))
              (ordered-map) [:chr :start :id :type :qual])
      (flatten-vc-intervals vc (get config :intervals []))
      (flatten-vc-attrs vc (:attrs config) (get config :attrs-defaults {}))
      (flatten-vc-samples vc (:sample-attrs config))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- add-interval-retrievers
  [config ref]
  (letfn [(add-int-retriever [coll]
            (assoc coll :source (get-bed-source (:file coll) ref)))]
    (assoc config :intervals (map add-int-retriever (:intervals config)))))</pre></td></tr><tr><td class="docs"><p>Convert a VCF input to flattened CSV table with provided attributes.</p>
</td><td class="codes"><pre class="brush: clojure">(defn vcf-to-table
  [vcf ref config]
  (let [out-file (str (itx/file-root vcf) &quot;-variantsum.csv&quot;)]
    (when (itx/needs-run? out-file)
      (itx/with-tx-files [tx-out-files {:out out-file} [:out] []]
        (with-open [vcf-iter (get-vcf-iterator vcf ref)
                    wtr (writer (:out tx-out-files))]
          (doseq [[i out] (map-indexed vector
                                       (map (partial flatten-vc (add-interval-retrievers config ref))
                                            (filter passes-filter? (parse-vcf vcf-iter))))]
            (when (= i 0)
              (csv/write-csv wtr [(map name (keys out))]))
            (csv/write-csv wtr [(vals out)])
            (.flush wtr)))))
    out-file))</pre></td></tr><tr><td class="docs"><p>Prep a set of VCF to table conversions from input configuration file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn vcf-to-table-config
  [config-file]
  (let [config (load-config config-file)]
    (doall
     (flatten
      (for [exp (:experiments config)]
        (for [call (:calls exp)]
          (vcf-to-table (:file call) (:ref exp) (:summary call))))))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.utils.svmerge" name="bcbio.variation.utils.svmerge"><h1 class="project-name">bcbio.variation.utils.svmerge</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Merge structural variants into a set of smaller SNP/indel calls.
   Different software detects larger structural variants, requiring
   a final preparation step combining structural and standard calls,
   removing any smaller calls which overlap large insertions and
   deletions.
   This is currently tuned for fosmid merging and reconstruction but
   has knobs to generalize for diploid merging with appropriate phasing
   of variants.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.utils.svmerge
  (:require [clojure.java.io :as io]
            [fs.core :as fs]
            [bcbio.run.itx :as itx]
            [bcbio.variation.combine :as combine]
            [bcbio.variation.filter.intervals :as intervals]
            [bcbio.variation.normalize :as normalize]
            [bcbio.variation.structural :as structural]
            [bcbio.variation.variantcontext :as gvc]))</pre></td></tr><tr><td class="docs"><p>Create a BED file of structural variant regions from input VCF.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- sv-&gt;bed
  [sv-file ref-file]
  (let [out-file (str (itx/file-root sv-file) &quot;-regions.bed&quot;)]
    (with-open [wtr (io/writer out-file)]
      (doseq [vc (structural/parse-vcf-sv sv-file ref-file)]
        (when (contains? #{:DEL :INS} (:sv-type vc))
          (.write wtr (format &quot;%s\t%s\t%s\n&quot; (:chr vc) (dec (:start-ci vc)) (:end-ci vc))))))
    out-file))</pre></td></tr><tr><td class="docs"><p>Merge structural variants into calls, updating variants and BED regions to assess.</p>
</td><td class="codes"><pre class="brush: clojure">(defn into-calls
  [call-file region-file sv-file ref-file]
  (let [out-files {:calls (itx/add-file-part call-file &quot;wsvs&quot;)
                   :regions (itx/add-file-part region-file &quot;wsvs&quot;)}]
    (when (itx/needs-run? (vals out-files))
      (let [sample (first (intervals/get-sample-names call-file))
            svready-file (normalize/prep-vcf sv-file ref-file sample
                                             :config {:prep-sv-genotype true
                                                      :fix-sample-header true
                                                      :prep-allele-count 1})
            sv-bed (sv-&gt;bed svready-file ref-file)
            call-safesv (-&gt; (intervals/select-by-sample sample call-file nil ref-file
                                                        :ext &quot;safesv&quot;
                                                        :exclude-intervals sv-bed))]
        (-&gt; (combine/combine-variants [call-safesv svready-file] ref-file
                                      :merge-type :full)
            (fs/rename (:calls out-files)))
        (-&gt; (intervals/combine-multiple-intervals region-file [] ref-file
                                                  :combine-rule :union
                                                  :more-beds [sv-bed])
            (fs/rename (:regions out-files)))))
    out-files))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.validate" name="bcbio.variation.validate"><h1 class="project-name">bcbio.variation.validate</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Combine calls from a multiple technology comparison to produce a set of final
  variants plus a list for validation. The inputs are:
   - Target technology: The outlier technology for picking additional targets. This
     should be well understood enough to set threshold for validation.
   - Validation info: Details for prepping a set of variants for validation
      - thresholds: min and max thresholds for validation
      - approach: validation along the full range of thresholds, or validate top variants
      - count: total number of variants for validation.
  Produces:
   - Final calls
       - calls that overlap in all of the technologies
       - calls that overlap in all but the target, where the target technology quality
         is below the validation threshold.
   - Validate calls
       - calls that overlap in all but the target and fall below configurable threshold.
         These are either sampled from the distribution or picked off the top.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.validate
  (:use [ordered.map :only [ordered-map]]
        [bcbio.variation.combine :only [combine-variants]]
        [bcbio.variation.multiple :only [prep-cmp-name-lookup
                                         multiple-overlap-analysis]]
        [bcbio.variation.report :only [count-variants]]
        [bcbio.variation.variantcontext :only [parse-vcf get-vcf-iterator
                                               write-vcf-w-template]])
  (:require [bcbio.run.broad :as broad]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><p>Base functionality for subsetting a file with SelectVariants.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- select-by-general
  [select-args ext in-vcf ref]
  (let [file-info {:out-vcf (itx/add-file-part in-vcf ext)}
        args (concat [&quot;-R&quot; ref
                      &quot;--variant&quot; in-vcf
                      &quot;-o&quot; :out-vcf]
                      select-args)]
    (broad/run-gatk &quot;SelectVariants&quot; args file-info {:out [:out-vcf]})
    (:out-vcf file-info)))</pre></td></tr><tr><td class="docs"><p>Subset a VCF file with specific hard filters.</p>
</td><td class="codes"><pre class="brush: clojure">(defn select-by-filters
  [filters in-vcf ext ref]
  (select-by-general (interleave (repeat &quot;--select_expressions&quot;) filters)
                     ext in-vcf ref))</pre></td></tr><tr><td class="docs"><h2>Validation targets by random sampling</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Subset a VCF file with a random number of variants.</p>
</td><td class="codes"><pre class="brush: clojure">(defn select-by-random
  [n in-vcf ref]
  (let [total (count-variants in-vcf ref (fn [x] true)) 
        frac (if (pos? total) (float (/ n total)) 0.0)]
    (select-by-general [&quot;--select_random_fraction&quot; frac] &quot;randsubset&quot; in-vcf ref)))</pre></td></tr><tr><td class="docs"><p>Select set of variants to validate from total set of potentials.</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti get-to-validate
  (fn [in-vcf finalizer ref] (keyword (get-in finalizer [:params :validate :approach]))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-to-validate :random
  [in-vcf finalizer ref]
  (select-by-random (get-in finalizer [:params :validate :count]) in-vcf ref))</pre></td></tr><tr><td class="docs"><p>Provide function to extract metric used in sorting from a variant context.
  Returns a list with the first being the count of items found in set overlap
  and the second the metric to sort by. Currently only handles a single metric
  for sorting.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- extract-sort-metrics
  [finalizer]
  {:pre [(= 1 (count (get-in finalizer [:params :validate :top-metric])))]}
  (let [metric (get-in finalizer [:params :validate :top-metric 0 :name])
        mod (get-in finalizer [:params :validate :top-metric 0 :mod])]
    (fn [vc]
      (let [base (-&gt; vc :attributes (get metric &quot;-1000.0&quot;) (Float/parseFloat))]
        [(count (re-seq (re-pattern (:target finalizer))
                           (-&gt; vc :attributes (get &quot;set&quot; &quot;&quot;))))
         (if mod (* mod base) base)]))))</pre></td></tr><tr><td class="docs"><p>Retrieve top variants sorted by metrics of interest.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-top-variants
  [vcf-file finalizer ref]
  (with-open [vcf-iter (get-vcf-iterator vcf-file ref)]
    (let [metric-gettr (extract-sort-metrics finalizer)]
      (set
       (map (juxt :chr :start)
            (take (get-in finalizer [:params :validate :count])
                  (reverse
                   (sort-by metric-gettr (parse-vcf vcf-iter)))))))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-to-validate :top
  [in-vcf finalizer ref]
  (let [out-file (itx/add-file-part in-vcf &quot;topsubset&quot;)]
    (when (itx/needs-run? out-file)
      (let [to-keep (get-top-variants in-vcf finalizer ref)]
        (with-open [vcf-iter (get-vcf-iterator in-vcf ref)]
          (write-vcf-w-template in-vcf {:out out-file}
                                (map :vc
                                     (filter #(contains? to-keep ((juxt :chr :start) %))
                                             (parse-vcf vcf-iter)))
                                ref))))
    out-file))</pre></td></tr><tr><td class="docs"><p>Prepare files of calls: finalized and validation targets.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-final-and-tovalidate
  [cmps finalizer config]
  (let [cmps-by-name (prep-cmp-name-lookup (vals cmps) :remove-mods? true
                                           :ignore #{&quot;all&quot; &quot;validate&quot;})
        ref (-&gt; cmps-by-name vals first :exp :ref)
        multi-prep (multiple-overlap-analysis cmps-by-name config (:target finalizer)
                                              :dirname &quot;validate&quot;)]
    (ordered-map
     :final (if-let [keep-filters (get-in finalizer [:params :filters :keep])]
              (combine-variants [(:true-positives multi-prep)
                                 (select-by-filters keep-filters (:false-negatives multi-prep)
                                                    &quot;keepsubset&quot; ref)]
                                ref :merge-type :full)
              (:true-positives multi-prep))
     :validate (get-to-validate
                (let [orig (:target-overlaps multi-prep)]
                  (if-let [val-filters (get-in finalizer [:params :filters :validate])]
                    (select-by-filters val-filters orig &quot;checksubset&quot; ref)
                    orig))
                finalizer ref))))</pre></td></tr><tr><td class="docs"><p>High level pipeline entry for producing final and to-validate call sets.</p>
</td><td class="codes"><pre class="brush: clojure">(defn pipeline-validate
  [cmps finalizer exp config]
  {:c-files (get-final-and-tovalidate cmps finalizer config)
   :c1 {:name (:target finalizer)}
   :c2 {:name &quot;validate&quot;}
   :exp exp :dir (:dir config)})</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.variantcontext" name="bcbio.variation.variantcontext"><h1 class="project-name">bcbio.variation.variantcontext</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Helper functions to retrieve information from GATK VariantContext
   objects, which represent variant data stored in VCF files.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.variantcontext
  (:import [org.broad.tribble.index IndexFactory]
           [org.broad.tribble AbstractFeatureReader]
           [org.broad.tribble.readers AsciiLineReader]
           [org.broadinstitute.sting.utils.codecs.vcf
            VCFCodec VCFUtils VCFHeader VCFFilterHeaderLine]
           [org.broadinstitute.sting.utils.variantcontext VariantContextBuilder
            GenotypeBuilder GenotypesContext]
           [org.broadinstitute.sting.utils.variantcontext.writer VariantContextWriterFactory
            Options]
           [org.broadinstitute.sting.gatk.refdata.tracks RMDTrackBuilder]
           [org.broadinstitute.sting.gatk.arguments ValidationExclusion$TYPE]
           [org.apache.log4j Logger]
           [java.util EnumSet])
  (:use [clojure.java.io]
        [clojure.set :only [intersection union]]
        [lazymap.core :only [lazy-hash-map]]
        [ordered.set :only [ordered-set]]
        [bcbio.align.ref :only [get-seq-dict]])
  (:require [clojure.string :as string]
            [lonocloud.synthread :as -&gt;]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><h2>Represent VariantContext objects</h2>

<p>Provide simple map-based access to important attributes of
VariantContexts. There are 3 useful levels of abstraction:</p>

<ul>
<li>VariantContext: Details about a variation. This captures a
single line in a VCF file</li>
<li>Genotype: An individual genotype for a sample, at a variant position.</li>
<li>Allele: The actual alleles at a genotype.</li>
</ul>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Represent a sample genotype including alleles.
   :genotype stores the original java genotype object for direct access.</p>
</td><td class="codes"><pre class="brush: clojure">(defn from-genotype
  [g]
  (lazy-hash-map
   :sample-name (.getSampleName g)
   :qual (.getPhredScaledQual g)
   :type (-&gt; g .getType .name)
   :phased? (.isPhased g)
   :attributes (merge {&quot;DP&quot; (.getDP g) &quot;AD&quot; (vec (.getAD g))
                       &quot;GQ&quot; (.getGQ g) &quot;PL&quot; (vec (.getPL g))}
                      (into {} (.getExtendedAttributes g)))
   :alleles (vec (.getAlleles g))
   :genotype g))</pre></td></tr><tr><td class="docs"><p>Provide a top level map of information from a variant context.
   :vc stores the original java VariantContext object for direct access.</p>
</td><td class="codes"><pre class="brush: clojure">(defn from-vc
  [vc]
  (lazy-hash-map
   :chr (.getChr vc)
   :start (.getStart vc)
   :end (.getEnd vc)
   :id (when (.hasID vc) (.getID vc))
   :ref-allele (.getReference vc)
   :alt-alleles (vec (.getAlternateAlleles vc))
   :type (-&gt; vc .getType .name)
   :filters (set (.getFilters vc))
   :attributes (into {} (.getAttributes vc))
   :qual (.getPhredScaledQual vc)
   :num-samples (.getNSamples vc)
   :genotypes (map from-genotype
                   (-&gt; vc .getGenotypes .toArray vec))
   :vc vc))</pre></td></tr><tr><td class="docs"><h2>Parsing VCF files</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Create a Tribble FeatureSource for VCF file.
   Handles indexing and parsing of VCF into VariantContexts.
   We treat gzipped files as tabix indexed VCFs.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-vcf-source
  [in-file ref-file &amp; {:keys [ensure-safe codec]}]
  (let [cur-codec (if (nil? codec) (VCFCodec.) codec)]
    (if (.endsWith in-file &quot;.gz&quot;)
      (AbstractFeatureReader/getFeatureReader in-file cur-codec false)
      (let [validate (when (false? ensure-safe)
                       ValidationExclusion$TYPE/ALLOW_SEQ_DICT_INCOMPATIBILITY)
            idx (.loadIndex (RMDTrackBuilder. (get-seq-dict ref-file) nil validate)
                            (file in-file) cur-codec)]
        (AbstractFeatureReader/getFeatureReader (.getAbsolutePath (file in-file)) cur-codec idx)))))</pre></td></tr><tr><td class="docs"><p>Create an iterator over VCF VariantContexts.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-vcf-iterator
  [in-file ref-file &amp; {:keys [ensure-safe codec]}]
  (.iterator (get-vcf-source in-file ref-file :ensure-safe ensure-safe
                             :codec codec)))</pre></td></tr><tr><td class="docs"><p>Retrieve variants located in potentially multiple variant files</p>
</td><td class="codes"><pre class="brush: clojure">(defn variants-in-region
  ([retriever vc]
     (variants-in-region retriever (:chr vc) (:start vc) (:end vc)))
  ([retriever space start end]
     (letfn [(get-vcs-in-source [[source fname]]
               (with-open [vcf-iter (.query source space start end)]
                 (doall (map #(assoc (from-vc %) :fname fname) (iterator-seq vcf-iter)))))]
       (mapcat get-vcs-in-source (map vector (:sources retriever) (:fnames retriever))))))</pre></td></tr><tr><td class="docs"><p>Look for matching variants present in any of the variant files.</p>
</td><td class="codes"><pre class="brush: clojure">(defn has-variants?
  [retriever space start end ref alt]
  (some #(and (= start (:start %))
              (= end (:end %))
              (= ref (:ref-allele %))
              (seq (intersection (set (:alt-alleles %)) (set alt))))
        (variants-in-region retriever space start end)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defrecord VariantRetriever [sources fnames]
  java.io.Closeable
  (close [_]
    (doseq [x sources]
      (.close x))))</pre></td></tr><tr><td class="docs"><p>Indexed variant file retrieval for zero to multiple files with clean handle closing.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-vcf-retriever
  [ref &amp; vcf-files]
  (let [fnames (remove nil? vcf-files)]
    (VariantRetriever. (map #(get-vcf-source % ref) fnames)
                       fnames)))</pre></td></tr><tr><td class="docs"><p>Lazy iterator of VariantContext information from VCF file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn parse-vcf
  [vcf-source]
  (map from-vc (iterator-seq (.iterator vcf-source))))</pre></td></tr><tr><td class="docs"><p>Retrieve parser to do line-by-line parsing of VCF files.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-vcf-line-parser
  [vcf-reader]
  (let [codec (VCFCodec.)]
    (.readHeader codec vcf-reader)
    (fn [line]
      (from-vc (.decode codec line)))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- line-vcf-parser
  [vcf]
  (let [parser (with-open [rdr (AsciiLineReader. (input-stream vcf))]
                 (get-vcf-line-parser rdr))]
    (map parser (drop-while #(.startsWith % &quot;#&quot;) (line-seq (reader vcf))))))</pre></td></tr><tr><td class="docs"><p>Retrieve header from input VCF file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-vcf-header
  [vcf-file]
  (with-open [vcf-reader (AsciiLineReader. (input-stream vcf-file))]
    (.readHeader (VCFCodec.) vcf-reader)))</pre></td></tr><tr><td class="docs"><h2>Writing VCF files</h2>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn merge-headers
  [&amp; merge-files]
  (fn [_ header]
    (VCFHeader. (VCFUtils/smartMergeHeaders (cons header (map get-vcf-header merge-files))
                                            (Logger/getLogger ))
                (.getGenotypeSamples header))))</pre></td></tr><tr><td class="docs"><p>Update a header with new INFO and FILTER metadata.</p>
</td><td class="codes"><pre class="brush: clojure">(defn header-w-md
  [header new-md]
  (VCFHeader. (apply ordered-set (concat (.getMetaDataInInputOrder header) new-md))
              (.getGenotypeSamples header)))</pre></td></tr><tr><td class="docs"><p>Write VCF output files starting with an original input template VCF.
   Handles writing to multiple VCF files simultaneously with the different
   file handles represented as keywords. This allows lazy splitting of VCF files:
   <code>vc-iter</code> is a lazy sequence of <code>(writer-keyword variant-context)</code>.
   <code>out-file-map</code> is a map of writer-keywords to output filenames.</p>
</td><td class="codes"><pre class="brush: clojure">(defn write-vcf-w-template
  [tmpl-file out-file-map vc-iter ref &amp; {:keys [header-update-fn]}]
  (letfn [(make-vcf-writer [f ref]
            (VariantContextWriterFactory/create (file f) (get-seq-dict ref)
                                                (EnumSet/of Options/INDEX_ON_THE_FLY
                                                            Options/ALLOW_MISSING_FIELDS_IN_HEADER)))
          (convert-to-output [info]
            [(if (and (coll? info) (= 2 (count info))) (first info) :out)
             (if (coll? info) (last info) info)])]
    (itx/with-tx-files [tx-out-files out-file-map (keys out-file-map) [&quot;.idx&quot;]]
      (let [tmpl-header (get-vcf-header tmpl-file)
            writer-map (zipmap (keys tx-out-files)
                               (map #(make-vcf-writer % ref) (vals tx-out-files)))]
        (doseq [[key out-vcf] writer-map]
          (.writeHeader out-vcf (if-not (nil? header-update-fn)
                                  (header-update-fn key tmpl-header)
                                  tmpl-header)))
        (doseq [[fkey item] (map convert-to-output vc-iter)]
          (let [ready-vc (if (and (map? item) (contains? item :vc)) (:vc item) item)]
            (when-not (nil? ready-vc)
              (.add (get writer-map fkey) ready-vc))))
        (doseq [x (vals writer-map)]
          (.close x))))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- add-filter-header
  [fname fdesc]
  (fn [_ header]
    (header-w-md header
                 #{(VCFFilterHeaderLine. fname fdesc)})))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- maybe-add-filter
  [fname passes? vc]
  (if (passes? vc)
    (:vc vc)
    (-&gt; (VariantContextBuilder. (:vc vc))
        (.filters (union #{fname} (:filters vc)))
        .make)))</pre></td></tr><tr><td class="docs"><p>Write VCF file from input using a filter function.</p>
</td><td class="codes"><pre class="brush: clojure">(defn write-vcf-from-filter
  [vcf ref out-part fname fdesc passes?]
  (let [out-file (itx/add-file-part vcf out-part)]
    (when (itx/needs-run? out-file)
      (with-open [vcf-iter (get-vcf-iterator vcf ref)]
        (write-vcf-w-template vcf {:out out-file}
                              (map (partial maybe-add-filter fname passes?) (parse-vcf vcf-iter))
                              ref
                              :header-update-fn (add-filter-header fname fdesc))))
    out-file))</pre></td></tr><tr><td class="docs"><p>Select variants from an input file with supplied filter.</p>
</td><td class="codes"><pre class="brush: clojure">(defn select-variants
  [in-file passes? file-out-part ref-file &amp; {:keys [out-dir]}]
  (let [out-file (itx/add-file-part in-file file-out-part out-dir)]
    (when (itx/needs-run? out-file)
      (with-open [in-iter (get-vcf-iterator in-file ref-file)]
        (write-vcf-w-template in-file {:out out-file}
                              (map :vc (filter passes? (parse-vcf in-iter)))
                              ref-file)))
    out-file))</pre></td></tr><tr><td class="docs"><h2>Genotype manipulation</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Create Genotype objects for a samples with defined alleles,
   optionally including attributes from the parent genotype.
   gs is a list of genotype dictionaries, with the alleles modified
   to the new values desired. This converts them into GATK-ready objects.</p>
</td><td class="codes"><pre class="brush: clojure">(defn create-genotypes
  [gs &amp; {:keys [attrs]}]
  (let [all-attrs [[&quot;PL&quot; seq (fn [x _ v] (.PL x (int-array v)))]
                   [&quot;PVAL&quot; identity (fn [x k v] (.attribute x k v))]
                   [&quot;DP&quot; identity (fn [x _ v] (.DP x v))]
                   [&quot;AD&quot; seq (fn [x _ v] (.AD x (int-array v)))]]]
    (letfn [(alleles-&gt;genotype [g]
              (-&gt; (GenotypeBuilder. (:sample-name g) (:alleles g))
                  (-&gt;/for [[attr val-fn add-fn] all-attrs]
                    (-&gt;/when (contains? attrs attr)
                      (-&gt;/when-let [val (val-fn (get-in g [:attributes attr]))]
                        (#(add-fn % attr val)))))
                  .make))]
      (-&gt;&gt; gs
           (map alleles-&gt;genotype)
           java.util.ArrayList.
           GenotypesContext/create))))</pre></td></tr><tr><td class="docs"><p>Convert variant context genotypes into all reference calls (0/0).</p>
</td><td class="codes"><pre class="brush: clojure">(defn genotypes-&gt;refcall
  [vc &amp; {:keys [attrs num-alleles]}]
  (letfn [(make-refcall [g]
            (assoc g :alleles
                   (repeat (if (nil? num-alleles)
                             (count (:alleles g))
                             num-alleles)
                           (:ref-allele vc))))]
    (-&gt; (VariantContextBuilder. (:vc vc))
        (.genotypes (create-genotypes (map make-refcall (:genotypes vc))
                                      :attrs attrs))
        .make)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -main [vcf ref approach]
  (with-open [vcf-iter (get-vcf-iterator vcf ref)]
    (letfn [(item-iter []
              (case approach
                &quot;line&quot; (map :vc (line-vcf-parser vcf))
                &quot;gatk&quot; (iterator-seq (.iterator vcf-iter))
                &quot;orig&quot; (map :vc (parse-vcf vcf-iter))))]
      (write-vcf-w-template vcf {:out &quot;vctest.vcf&quot;} (item-iter) ref)
      ;; (doseq [[i x] (map-indexed vector (item-iter))]
      ;;   (when (= 0 (mod i 10000))
      ;;      (println x))))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.vcfwalker" name="bcbio.variation.vcfwalker"><h1 class="project-name">bcbio.variation.vcfwalker</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Simple walker to parse a VCF file and display distribution of call
  quality scores</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.vcfwalker
  (:import [bcbio.variation BaseVariantWalker])
  (:use [bcbio.variation.variantcontext :only [from-vc]])
  (:require ;[incanter.charts :as icharts]
            [incanter.core :as icore])
  (:gen-class
   :name bcbio.variation.vcfwalker.VcfSimpleStatsWalker
   :extends bcbio.variation.BaseVariantWalker))</pre></td></tr><tr><td class="docs"><p>Retrieve VariantContexts and extract the variant quality score.</p>
</td><td class="codes"><pre class="brush: clojure">(defn -map
  [this tracker ref context]
  (if-not (nil? tracker)
    (for [vc (map from-vc
                    (.getValues tracker (.variants (.invrns this))
                                (.getLocation context)))]
      (:qual vc))))</pre></td></tr><tr><td class="docs"><p>Initialize an empty list to collect our quality information</p>
</td><td class="codes"><pre class="brush: clojure">(defn -reduceInit
  [this]
  [])</pre></td></tr><tr><td class="docs"><p>Add current quality information to the collected list.</p>
</td><td class="codes"><pre class="brush: clojure">(defn -reduce
  [this cur coll]
  (if-not (nil? cur)
    (vec (flatten [coll cur]))
    coll))</pre></td></tr><tr><td class="docs"><p>Plot histogram of quality scores.</p>
</td><td class="codes"><pre class="brush: clojure">(defn -onTraversalDone
  [this result]
  (println result))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.web.db" name="bcbio.variation.web.db"><h1 class="project-name">bcbio.variation.web.db</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Provide basic persistence of user files and processes in local DB.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.web.db
  (:import [com.mchange.v2.c3p0 ComboPooledDataSource])
  (:require [clojure.string :as string]
            [clojure.java.jdbc :as sql]
            [fs.core :as fs]))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn get-sqlite-db [fname &amp; {:as opts}]
  &quot;Retrieve SQLite database connection&quot;
  (merge
   {:classname &quot;org.sqlite.JDBC&quot;
    :subprotocol &quot;sqlite&quot;
    :subname fname}
   opts))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn get-sqlite-db-pool [fname]
  (let [spec (get-sqlite-db fname)]
    {:datasource (doto (ComboPooledDataSource.)
                   (.setDriverClass (:classname spec))
                   (.setJdbcUrl (str &quot;jdbc:&quot; (:subprotocol spec) &quot;:&quot;
                                     (:subname spec))))}))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- create-user-tables []
  (sql/create-table :analysis
                    [:analysis_id :text &quot;PRIMARY KEY&quot;]
                    [:username :text]
                    [:type :text]
                    [:description :text]
                    [:location :text]
                    [:created :timestamp &quot;NOT NULL&quot; &quot;DEFAULT CURRENT_TIMESTAMP&quot;])
  (sql/create-table :files
                    [:analysis_id :text]
                    [:name :text]
                    [:location :text]))</pre></td></tr><tr><td class="docs"><p>Prepare input database for storing user and file information in SQLite.</p>
</td><td class="codes"><pre class="brush: clojure">(defn prepare-web-db
  [db-file]
  (when-not (fs/exists? (fs/parent db-file))
    (fs/mkdirs (fs/parent db-file)))
  (when-not (fs/exists? db-file)
    (sql/with-connection (get-sqlite-db db-file :create true)
      (sql/transaction
       (create-user-tables))))
  db-file)</pre></td></tr><tr><td class="docs"><p>Retrieve list of analyses run for a specific user and analysis type</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-analyses
  [username atype db-file]
  (sql/with-connection (get-sqlite-db db-file)
    (sql/with-query-results rows
      [&quot;SELECT * FROM analysis WHERE username = ? AND type = ? ORDER BY created DESC&quot;
       username atype]
      (vec (map #(assoc % :created (java.sql.Timestamp. (:created %))) rows)))))</pre></td></tr><tr><td class="docs"><p>Add an analysis and associated files to the database.</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti add-analysis
  (fn [info _] (:type info)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod add-analysis :scoring
  [info db-file]
  (letfn [(get-analysis-files [info]
            (map (fn [[k f]]
                   {:analysis_id (:analysis_id info)
                    :name (name k)
                    :location (string/replace f (str (:location info) &quot;/&quot;) &quot;&quot;)})
                 (:files info)))]
    (sql/with-connection (get-sqlite-db db-file)
      (sql/transaction
       (sql/insert-record :analysis (-&gt; info
                                        (dissoc :files)
                                        (assoc :created (java.sql.Timestamp. (.getTime (java.util.Date.))))))
       (doseq [x (get-analysis-files info)]
         (sql/insert-record :files x))))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.workflow.xprize" name="bcbio.variation.workflow.xprize"><h1 class="project-name">bcbio.variation.workflow.xprize</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Perform X Prize scoring workflow, handling comparison of contestant input with reference.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.workflow.xprize
  (:import [java.util UUID])
  (:use [clojure.java.io]
        [bcbio.variation.config :only [traceback-to-log load-config]]
        [bcbio.variation.compare :only [variant-comparison-from-config]]
        [bcbio.variation.combine :only [combine-variants]]
        [bcbio.variation.normalize :only [pick-best-ref]]
        [bcbio.variation.report :only [prep-scoring-table]])
  (:require [clj-yaml.core :as yaml]
            [doric.core :as doric]
            [fs.core :as fs]
            [hiccup.core :as hiccup]
            [net.cgrand.enlive-html :as html]))</pre></td></tr><tr><td class="docs"><p>Create configuration for processing inputs using references supplied in config.</p>
</td><td class="codes"><pre class="brush: clojure">(defn create-work-config
  [work-info config]
  (if-not (fs/exists? (:dir work-info))
    (fs/mkdirs (:dir work-info)))
  (let [config-file (str (fs/file (:dir work-info) &quot;process.yaml&quot;))
        ref (first (filter #(= (:sample %) (:comparison-genome work-info))
                           (:ref config)))
        contestant-vcf (if-let [x (:variant-file work-info)]
                         (str (fs/file x))
                         (:default-compare ref))]
    (-&gt;&gt; {:dir {:out (str (fs/file (:dir work-info) &quot;grading&quot;))
                :prep (str (fs/file (:dir work-info) &quot;grading&quot; &quot;prep&quot;))}
          :experiments [{:sample (:sample ref)
                         :ref (:genome ref)
                         :intervals (:intervals ref)
                         :approach &quot;grade&quot;
                         :calls [{:name &quot;reference&quot;
                                  :file (:variants ref)
                                  :normalize false}
                                 {:name &quot;contestant&quot;
                                  :prep true
                                  :preclean true
                                  :remove-refcalls true
                                  :ref (pick-best-ref contestant-vcf (cons (:genome ref)
                                                                           (:genome-alts ref)))
                                  :file contestant-vcf
                                  :intervals (if-let [x (:region-file work-info)]
                                               (str (fs/file x))
                                               (:intervals ref))}]}]}
         yaml/generate-string
         (spit config-file))
    config-file))</pre></td></tr><tr><td class="docs"><p>Output text summary file with scoring information.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- write-scoring-summary
  [work-info comparison]
  (let [summary-file (str (fs/file (:dir work-info)
                                   (format &quot;%s-scoring.tsv&quot;
                                           (get-in comparison [:summary :sample]))))]
    (with-open [wtr (writer summary-file)]
      (doseq [x (prep-scoring-table (:metrics comparison)
                                    (get-in comparison [:summary :sv]))]
        (.write wtr (format &quot;%s\t%s\n&quot; (:metric x) (:value x)))))
    summary-file))</pre></td></tr><tr><td class="docs"><p>Generate a summary table of scoring results.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- html-summary-table
  [comparison]
  (let [scoring-table (prep-scoring-table (:metrics comparison)
                                          (get-in comparison [:summary :sv]))]
    (apply str
           (-&gt; (str (doric/table ^{:format doric/html} [:metric :value] scoring-table))
               java.io.StringReader.
               html/html-resource
               (html/transform [:table] (html/set-attr :class &quot;table table-condensed&quot;))
               html/emit*))))</pre></td></tr><tr><td class="docs"><p>Generate summary of scoring results for display.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- write-html-scoring-summary
  [work-info comparison]
  (let [out-file (str (file (:dir work-info) &quot;scoring-summary.html&quot;))]
    (spit out-file
          (hiccup/html
           [:h3 &quot;Summary&quot;]
           [:div {:id &quot;score-table&quot;}
            (html-summary-table comparison)]
           [:h3 &quot;Variant files in VCF format&quot;]
           [:div {:id &quot;variant-file-download&quot;}
            [:ul
             (for [[key txt] [[&quot;concordant&quot; &quot;Concordant variants&quot;]
                              [&quot;discordant&quot; &quot;Discordant variants&quot;]
                              [&quot;discordant-missing&quot; &quot;Missing variants&quot;]
                              [&quot;phasing&quot; &quot;Variants with phasing errors&quot;]]]
               [:li [:a {:href (format &quot;/dataset/%s/%s&quot; (:id work-info) key)} txt]])]]))
    out-file))</pre></td></tr><tr><td class="docs"><p>Merge standard and structural variant outputs into final set of upload files.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- prepare-final-files
  [comparison]
  (letfn [(merge-files-into [comparison orig-kw addin-kw]
            (let [ref (get-in comparison [:exp :ref])
                  orig (get-in comparison [:c-files orig-kw])
                  addin (get-in comparison [:c-files addin-kw])
                  combine-vcf (combine-variants [orig addin] ref :merge-type :full
                                                :quiet-out? true)]
              (fs/rename combine-vcf orig)
              (fs/rename (str combine-vcf &quot;.idx&quot;) (str orig &quot;.idx&quot;))))]
      (merge-files-into comparison :concordant :sv-concordant)
      (merge-files-into comparison :discordant :sv-contestant-discordant)
      (merge-files-into comparison :discordant-missing :sv-reference-discordant)))</pre></td></tr><tr><td class="docs"><p>Run X Prize scoring analysis from provided work information.</p>
</td><td class="codes"><pre class="brush: clojure">(defn run-scoring-analysis*
  [work-info rclient config-file]
  (let [comparison (first (variant-comparison-from-config config-file))]
    (prepare-final-files comparison)
    {:work-info work-info
     :comparison (-&gt; comparison
                     (assoc-in [:c-files :summary] (write-scoring-summary work-info comparison))
                     (assoc-in [:c-files :summary-html] (write-html-scoring-summary work-info comparison)))}))</pre></td></tr><tr><td class="docs"><p>Safe running of X Prize workflow with exception catching.</p>
</td><td class="codes"><pre class="brush: clojure">(defn run-scoring-analysis
  [work-info rclient input-config]
  (prn input-config)
  (let [config-file (create-work-config work-info input-config)]
    (try
      (run-scoring-analysis* work-info rclient config-file)
      (catch Exception e
        (do
          (traceback-to-log e (load-config config-file))
          (throw e))))))</pre></td></tr><tr><td class="docs"><p>Prep directory for scoring analysis.</p>
</td><td class="codes"><pre class="brush: clojure">(defn prep-scoring
  [params config]
  (let [tmp-dir (file (get-in config [:dir :work]) &quot;score&quot;)
        work-id (str (UUID/randomUUID))
        cur-dir (file tmp-dir work-id)]
    (fs/mkdirs cur-dir)
    (-&gt; params
        (assoc :id work-id)
        (assoc :dir (str cur-dir)))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr></table><div class="footer">Generated by <a href="https://github.com/fogus/marginalia">Marginalia</a>.&nbsp;&nbsp;Syntax highlighting provided by Alex Gorbatchev's <a href="http://alexgorbatchev.com/SyntaxHighlighter/">SyntaxHighlighter</a></div><script type="text/javascript">SyntaxHighlighter.defaults['gutter'] = false;
       SyntaxHighlighter.all()</script></body></html>