<!DOCTYPE html>
<html><head><meta charset="utf-8" content="text/html" http-equiv="Content-Type" /><meta content="Clojure API for variation data, built on GATK" name="description" /><style type="text/css">/**
 * SyntaxHighlighter
 * http://alexgorbatchev.com/SyntaxHighlighter
 *
 * SyntaxHighlighter is donationware. If you are using it, please donate.
 * http://alexgorbatchev.com/SyntaxHighlighter/donate.html
 *
 * @version
 * 3.0.83 (July 02 2010)
 * 
 * @copyright
 * Copyright (C) 2004-2010 Alex Gorbatchev.
 *
 * @license
 * Dual licensed under the MIT and GPL licenses.
 */
.syntaxhighlighter a,
.syntaxhighlighter div,
.syntaxhighlighter code,
.syntaxhighlighter table,
.syntaxhighlighter table td,
.syntaxhighlighter table tr,
.syntaxhighlighter table tbody,
.syntaxhighlighter table thead,
.syntaxhighlighter table caption,
.syntaxhighlighter textarea {
  -moz-border-radius: 0 0 0 0 !important;
  -webkit-border-radius: 0 0 0 0 !important;
  background: none !important;
  border: 0 !important;
  bottom: auto !important;
  float: none !important;
  height: auto !important;
  left: auto !important;
  line-height: 1.1em !important;
/*  margin: 0 !important; */
  outline: 0 !important;
  overflow: visible !important;
  padding: 0 !important;
  position: static !important;
  right: auto !important;
  text-align: left !important;
  top: auto !important;
  vertical-align: baseline !important;
  width: auto !important;
  box-sizing: content-box !important;
  font-family: "Consolas", "Bitstream Vera Sans Mono", "Courier New", Courier, monospace !important;
  font-weight: normal !important;
  font-style: normal !important;
  min-height: inherit !important;
  min-height: auto !important;
}

.syntaxhighlighter {
/*  width: 100% !important; */
  margin: 1em 0 1em 0 !important;
  position: relative !important;
  overflow: auto !important;
}
.syntaxhighlighter.source {
  overflow: hidden !important;
}
.syntaxhighlighter .bold {
  font-weight: bold !important;
}
.syntaxhighlighter .italic {
  font-style: italic !important;
}
.syntaxhighlighter .line {
  white-space: pre !important;
}
.syntaxhighlighter table {
/*    width: 100% !important;*/
}
.syntaxhighlighter table caption {
  text-align: left !important;
  padding: .5em 0 0.5em 1em !important;
}
.syntaxhighlighter table td.code {
  width: 100% !important;
}
.syntaxhighlighter table td.code .container {
  position: relative !important;
}
.syntaxhighlighter table td.code .container textarea {
  box-sizing: border-box !important;
  position: absolute !important;
  left: 0 !important;
  top: 0 !important;
  width: 100% !important;
  height: 100% !important;
  border: none !important;
  background: white !important;
  padding-left: 1em !important;
  overflow: hidden !important;
  white-space: pre !important;
}
.syntaxhighlighter table td.gutter .line {
  text-align: right !important;
  padding: 0 0.5em 0 1em !important;
}
.syntaxhighlighter table td.code .line {
  padding: 0 1em !important;
}
.syntaxhighlighter.nogutter td.code .container textarea, .syntaxhighlighter.nogutter td.code .line {
  padding-left: 0em !important;
}
.syntaxhighlighter.show {
  display: block !important;
}
.syntaxhighlighter.collapsed table {
  display: none !important;
}
.syntaxhighlighter.collapsed .toolbar {
    display: none;
/*  padding: 0.1em 0.8em 0em 0.8em !important;
  font-size: 1em !important;
  position: static !important;
  width: auto !important;
  height: auto !important;*/
}
.syntaxhighlighter.collapsed .toolbar span {
  display: inline !important;
  margin-right: 1em !important;
}
.syntaxhighlighter.collapsed .toolbar span a {
  padding: 0 !important;
  display: none !important;
}
.syntaxhighlighter.collapsed .toolbar span a.expandSource {
  display: inline !important;
}
.syntaxhighlighter .toolbar {
    display: none;
/*  position: absolute !important;
  right: 1px !important;
  top: 1px !important;
  width: 11px !important;
  height: 11px !important;
  font-size: 10px !important;
  z-index: 10 !important;*/
}
.syntaxhighlighter .toolbar span.title {
  display: inline !important;
}
.syntaxhighlighter .toolbar a {
  display: block !important;
  text-align: center !important;
  text-decoration: none !important;
  padding-top: 1px !important;
}
.syntaxhighlighter .toolbar a.expandSource {
  display: none !important;
}
.syntaxhighlighter.ie {
  font-size: .9em !important;
  padding: 1px 0 1px 0 !important;
}
.syntaxhighlighter.ie .toolbar {
  line-height: 8px !important;
}
.syntaxhighlighter.ie .toolbar a {
  padding-top: 0px !important;
}
.syntaxhighlighter.printing .line.alt1 .content,
.syntaxhighlighter.printing .line.alt2 .content,
.syntaxhighlighter.printing .line.highlighted .number,
.syntaxhighlighter.printing .line.highlighted.alt1 .content,
.syntaxhighlighter.printing .line.highlighted.alt2 .content {
  background: none !important;
}
.syntaxhighlighter.printing .line .number {
  color: #bbbbbb !important;
}
.syntaxhighlighter.printing .line .content {
  color: black !important;
}
.syntaxhighlighter.printing .toolbar {
  display: none !important;
}
.syntaxhighlighter.printing a {
  text-decoration: none !important;
}
.syntaxhighlighter.printing .plain, .syntaxhighlighter.printing .plain a {
  color: black !important;
}
.syntaxhighlighter.printing .comments, .syntaxhighlighter.printing .comments a {
  color: #008200 !important;
}
.syntaxhighlighter.printing .string, .syntaxhighlighter.printing .string a {
  color: blue !important;
}
.syntaxhighlighter.printing .keyword {
  color: #006699 !important;
  font-weight: bold !important;
}
.syntaxhighlighter.printing .preprocessor {
  color: gray !important;
}
.syntaxhighlighter.printing .variable {
  color: #aa7700 !important;
}
.syntaxhighlighter.printing .value {
  color: #009900 !important;
}
.syntaxhighlighter.printing .functions {
  color: #ff1493 !important;
}
.syntaxhighlighter.printing .constants {
  color: #0066cc !important;
}
.syntaxhighlighter.printing .script {
  font-weight: bold !important;
}
.syntaxhighlighter.printing .color1, .syntaxhighlighter.printing .color1 a {
  color: gray !important;
}
.syntaxhighlighter.printing .color2, .syntaxhighlighter.printing .color2 a {
  color: #ff1493 !important;
}
.syntaxhighlighter.printing .color3, .syntaxhighlighter.printing .color3 a {
  color: red !important;
}
.syntaxhighlighter.printing .break, .syntaxhighlighter.printing .break a {
  color: black !important;
}
</style><style type="text/css">.syntaxhighlighter{overflow:hidden !important;}</style><style type="text/css">/**
 * http://alexgorbatchev.com/SyntaxHighlighter/donate.html
 *
 * @version
 * 3.0.83 (July 02 2010)
 * 
 * @copyright
 * Copyright (C) 2004-2010 Alex Gorbatchev.
 *
 * @license
 * Dual licensed under the MIT and GPL licenses.
 */
.syntaxhighlighter {
  background-color: transparent !important;
}
.syntaxhighlighter .line.alt1 {
  background-color: transparent !important;
}
.syntaxhighlighter .line.alt2 {
  background-color: transparent !important;
}
.syntaxhighlighter .line.highlighted.alt1, .syntaxhighlighter .line.highlighted.alt2 {
  background-color: #c3defe !important;
}
.syntaxhighlighter .line.highlighted.number {
  color: white !important;
}
.syntaxhighlighter table caption {
  color: black !important;
}
.syntaxhighlighter .gutter {
  color: #787878 !important;
}
.syntaxhighlighter .gutter .line {
  border-right: 3px solid #d4d0c8 !important;
}
.syntaxhighlighter .gutter .line.highlighted {
  background-color: #d4d0c8 !important;
  color: white !important;
}
.syntaxhighlighter.printing .line .content {
  border: none !important;
}
.syntaxhighlighter.collapsed {
  overflow: visible !important;
}
.syntaxhighlighter.collapsed .toolbar {
  color: #3f5fbf !important;
  background: white !important;
  border: 1px solid #d4d0c8 !important;
}
.syntaxhighlighter.collapsed .toolbar a {
  color: #3f5fbf !important;
}
.syntaxhighlighter.collapsed .toolbar a:hover {
  color: #aa7700 !important;
}
.syntaxhighlighter .toolbar {
  color: #a0a0a0 !important;
  background: #d4d0c8 !important;
  border: none !important;
}
.syntaxhighlighter .toolbar a {
  color: #a0a0a0 !important;
}
.syntaxhighlighter .toolbar a:hover {
  color: red !important;
}
.syntaxhighlighter .plain, .syntaxhighlighter .plain a {
  color: black !important;
}
.syntaxhighlighter .comments, .syntaxhighlighter .comments a {
  color: #3f5fbf !important;
}
.syntaxhighlighter .string, .syntaxhighlighter .string a {
  color: #2a00ff !important;
}
.syntaxhighlighter .keyword {
  color: #7f0055 !important;
}
.syntaxhighlighter .preprocessor {
  color: #646464 !important;
}
.syntaxhighlighter .variable {
  color: #aa7700 !important;
}
.syntaxhighlighter .value {
  color: #009900 !important;
}
.syntaxhighlighter .functions {
  color: #ff1493 !important;
}
.syntaxhighlighter .constants {
  color: #0066cc !important;
}
.syntaxhighlighter .script {
  font-weight: bold !important;
  color: #7f0055 !important;
  background-color: none !important;
}
.syntaxhighlighter .color1, .syntaxhighlighter .color1 a {
  color: gray !important;
}
.syntaxhighlighter .color2, .syntaxhighlighter .color2 a {
  color: #ff1493 !important;
}
.syntaxhighlighter .color3, .syntaxhighlighter .color3 a {
  color: red !important;
}

.syntaxhighlighter .xml .keyword {
  color: #3f7f7f !important;
  font-weight: normal !important;
}
.syntaxhighlighter .xml .color1, .syntaxhighlighter .xml .color1 a {
  color: #7f007f !important;
}
.syntaxhighlighter .xml .string {
  font-style: italic !important;
  color: #2a00ff !important;
}

.clojure.syntaxhighlighter .invalid { 
   background-color: #FAA !important;
}

.clojure.syntaxhighlighter .quoted {      
    font-style: italic !important;
}

.syntaxhighlighter .clojure.variable,
.syntaxhighlighter .clojure.symbol,
.syntaxhighlighter .clojure.value
{
    color: #006060 !important;
}

.syntaxhighlighter .clojure.string {
    color: #55B !important;
}

.syntaxhighlighter .clojure.functions {
    color: black !important;
}

.syntaxhighlighter .clojure.color1 {
    color: #666 !important;
}

.syntaxhighlighter .clojure.color3 {
    color: #900 !important;
}

.syntaxhighlighter .clojure.constants {
    color: #1A734D !important;
}

</style><style type="text/css">html{margin:0;padding:0;}h1{margin:0;padding:0;}h2{margin:0;padding:0;}h3{margin:0;padding:0;}h4{margin:0;padding:0;}a{color:#261A3B;}a:visited{color:#261A3B;}</style><style type="text/css">.header{margin-top:30px;}h1.project-name{display:inline;font-size:34px;}h2.project-version{display:inline;margin-left:10px;margin-top:0;font-size:18px;}.toc-link{margin-left:10px;color:#252519;font-size:12px;text-decoration:none;}.toc-link:hover{color:#5050A6;}.toc h1{margin:0;font-size:34px;}.docs-header{margin-bottom:25px;padding-bottom:10px;border-bottom:dotted #aaa 1px;}.toc h1{font-size:24px;}.toc{margin-bottom:40px;border-bottom:solid #bbb 1px;}.toc ul{padding-left:0px;margin-left:20px;margin-top:0;padding-top:0;}.toc li{padding-left:0;list-style-type:none;}.dependencies{}.dependencies table{border:none;width:99.99%;margin-left:20px;font-size:16px;}.dependencies td{padding-right:20px;;white-space:nowrap;}.dependencies .dotted{width:99%;}.dependencies .dotted hr{margin-bottom:-6px;noshade:noshade;border-top:none;color:transparent;border-left:none;border-bottom:dotted #bbb 1px;border-right:none;background-color:transparent;height:0;}.dependencies .dep-version{text-align:right;}.plugins ul{padding-left:0px;margin-left:20px;margin-top:0;padding-top:0;}.plugins li{padding-left:0;list-style-type:none;}.header p{margin-left:20px;}</style><style type="text/css">#floating-toc{position:fixed;text-align:right;overflow:hidden;top:10px;right:20px;height:20px;}#floating-toc li{margin:0;padding:0;list-style-type:none;}</style><style type="text/css">body{margin:0;padding:0;color:#252519;font-size:16px;background-color:#F5F5FF;font-family:'Palatino Linotype', 'Book Antiqua', Palatino, FreeSerif, serif;;}h1{margin-top:0;font-size:20px;}a.anchor{color:#252519;text-decoration:none;}a.anchor:hover{color:#5050A6;}table{margin-bottom:10px;border-bottom:solid #ddd 1px;;border-spacing:0;}code{display:inline;}p{margin-top:8px;}tr{margin:0px;padding:0px;}td.docs{border:none;margin:0px;padding-left:55px;width:410px;padding-right:20px;vertical-align:top;max-width:410px;background-color:#FFF;}td.docs pre{font-size:12px;overflow:hidden;}td.codes{border:none;margin:0px;padding-left:20px;width:55%;border-left:solid #E5E5EE 1px;font-size:10pt;vertical-align:top;overflow:hidden;background-color:#F5F5FF;}td.spacer{padding-bottom:40px;}pre code{display:block;padding:4px;}code{border:solid #DEDEDE 1px;padding-left:3px;padding-right:3px;font-size:14px;background-color:ghostWhite;}.syntaxhighlighter code{font-size:13px;}.footer{text-align:center;}</style><script type="text/javascript">/*!
 * jQuery JavaScript Library v1.4.4
 * http://jquery.com/
 *
 * Copyright 2010, John Resig
 * Dual licensed under the MIT or GPL Version 2 licenses.
 * http://jquery.org/license
 *
 * Includes Sizzle.js
 * http://sizzlejs.com/
 * Copyright 2010, The Dojo Foundation
 * Released under the MIT, BSD, and GPL Licenses.
 *
 * Date: Thu Nov 11 19:04:53 2010 -0500
 */
(function(E,B){function ka(a,b,d){if(d===B&&a.nodeType===1){d=a.getAttribute("data-"+b);if(typeof d==="string"){try{d=d==="true"?true:d==="false"?false:d==="null"?null:!c.isNaN(d)?parseFloat(d):Ja.test(d)?c.parseJSON(d):d}catch(e){}c.data(a,b,d)}else d=B}return d}function U(){return false}function ca(){return true}function la(a,b,d){d[0].type=a;return c.event.handle.apply(b,d)}function Ka(a){var b,d,e,f,h,l,k,o,x,r,A,C=[];f=[];h=c.data(this,this.nodeType?"events":"__events__");if(typeof h==="function")h=
h.events;if(!(a.liveFired===this||!h||!h.live||a.button&&a.type==="click")){if(a.namespace)A=RegExp("(^|\\.)"+a.namespace.split(".").join("\\.(?:.*\\.)?")+"(\\.|$)");a.liveFired=this;var J=h.live.slice(0);for(k=0;k<J.length;k++){h=J[k];h.origType.replace(X,"")===a.type?f.push(h.selector):J.splice(k--,1)}f=c(a.target).closest(f,a.currentTarget);o=0;for(x=f.length;o<x;o++){r=f[o];for(k=0;k<J.length;k++){h=J[k];if(r.selector===h.selector&&(!A||A.test(h.namespace))){l=r.elem;e=null;if(h.preType==="mouseenter"||
h.preType==="mouseleave"){a.type=h.preType;e=c(a.relatedTarget).closest(h.selector)[0]}if(!e||e!==l)C.push({elem:l,handleObj:h,level:r.level})}}}o=0;for(x=C.length;o<x;o++){f=C[o];if(d&&f.level>d)break;a.currentTarget=f.elem;a.data=f.handleObj.data;a.handleObj=f.handleObj;A=f.handleObj.origHandler.apply(f.elem,arguments);if(A===false||a.isPropagationStopped()){d=f.level;if(A===false)b=false;if(a.isImmediatePropagationStopped())break}}return b}}function Y(a,b){return(a&&a!=="*"?a+".":"")+b.replace(La,
"`").replace(Ma,"&")}function ma(a,b,d){if(c.isFunction(b))return c.grep(a,function(f,h){return!!b.call(f,h,f)===d});else if(b.nodeType)return c.grep(a,function(f){return f===b===d});else if(typeof b==="string"){var e=c.grep(a,function(f){return f.nodeType===1});if(Na.test(b))return c.filter(b,e,!d);else b=c.filter(b,e)}return c.grep(a,function(f){return c.inArray(f,b)>=0===d})}function na(a,b){var d=0;b.each(function(){if(this.nodeName===(a[d]&&a[d].nodeName)){var e=c.data(a[d++]),f=c.data(this,
e);if(e=e&&e.events){delete f.handle;f.events={};for(var h in e)for(var l in e[h])c.event.add(this,h,e[h][l],e[h][l].data)}}})}function Oa(a,b){b.src?c.ajax({url:b.src,async:false,dataType:"script"}):c.globalEval(b.text||b.textContent||b.innerHTML||"");b.parentNode&&b.parentNode.removeChild(b)}function oa(a,b,d){var e=b==="width"?a.offsetWidth:a.offsetHeight;if(d==="border")return e;c.each(b==="width"?Pa:Qa,function(){d||(e-=parseFloat(c.css(a,"padding"+this))||0);if(d==="margin")e+=parseFloat(c.css(a,
"margin"+this))||0;else e-=parseFloat(c.css(a,"border"+this+"Width"))||0});return e}function da(a,b,d,e){if(c.isArray(b)&&b.length)c.each(b,function(f,h){d||Ra.test(a)?e(a,h):da(a+"["+(typeof h==="object"||c.isArray(h)?f:"")+"]",h,d,e)});else if(!d&&b!=null&&typeof b==="object")c.isEmptyObject(b)?e(a,""):c.each(b,function(f,h){da(a+"["+f+"]",h,d,e)});else e(a,b)}function S(a,b){var d={};c.each(pa.concat.apply([],pa.slice(0,b)),function(){d[this]=a});return d}function qa(a){if(!ea[a]){var b=c("<"+
a+">").appendTo("body"),d=b.css("display");b.remove();if(d==="none"||d==="")d="block";ea[a]=d}return ea[a]}function fa(a){return c.isWindow(a)?a:a.nodeType===9?a.defaultView||a.parentWindow:false}var t=E.document,c=function(){function a(){if(!b.isReady){try{t.documentElement.doScroll("left")}catch(j){setTimeout(a,1);return}b.ready()}}var b=function(j,s){return new b.fn.init(j,s)},d=E.jQuery,e=E.$,f,h=/^(?:[^<]*(<[\w\W]+>)[^>]*$|#([\w\-]+)$)/,l=/\S/,k=/^\s+/,o=/\s+$/,x=/\W/,r=/\d/,A=/^<(\w+)\s*\/?>(?:<\/\1>)?$/,
C=/^[\],:{}\s]*$/,J=/\\(?:["\\\/bfnrt]|u[0-9a-fA-F]{4})/g,w=/"[^"\\\n\r]*"|true|false|null|-?\d+(?:\.\d*)?(?:[eE][+\-]?\d+)?/g,I=/(?:^|:|,)(?:\s*\[)+/g,L=/(webkit)[ \/]([\w.]+)/,g=/(opera)(?:.*version)?[ \/]([\w.]+)/,i=/(msie) ([\w.]+)/,n=/(mozilla)(?:.*? rv:([\w.]+))?/,m=navigator.userAgent,p=false,q=[],u,y=Object.prototype.toString,F=Object.prototype.hasOwnProperty,M=Array.prototype.push,N=Array.prototype.slice,O=String.prototype.trim,D=Array.prototype.indexOf,R={};b.fn=b.prototype={init:function(j,
s){var v,z,H;if(!j)return this;if(j.nodeType){this.context=this[0]=j;this.length=1;return this}if(j==="body"&&!s&&t.body){this.context=t;this[0]=t.body;this.selector="body";this.length=1;return this}if(typeof j==="string")if((v=h.exec(j))&&(v[1]||!s))if(v[1]){H=s?s.ownerDocument||s:t;if(z=A.exec(j))if(b.isPlainObject(s)){j=[t.createElement(z[1])];b.fn.attr.call(j,s,true)}else j=[H.createElement(z[1])];else{z=b.buildFragment([v[1]],[H]);j=(z.cacheable?z.fragment.cloneNode(true):z.fragment).childNodes}return b.merge(this,
j)}else{if((z=t.getElementById(v[2]))&&z.parentNode){if(z.id!==v[2])return f.find(j);this.length=1;this[0]=z}this.context=t;this.selector=j;return this}else if(!s&&!x.test(j)){this.selector=j;this.context=t;j=t.getElementsByTagName(j);return b.merge(this,j)}else return!s||s.jquery?(s||f).find(j):b(s).find(j);else if(b.isFunction(j))return f.ready(j);if(j.selector!==B){this.selector=j.selector;this.context=j.context}return b.makeArray(j,this)},selector:"",jquery:"1.4.4",length:0,size:function(){return this.length},
toArray:function(){return N.call(this,0)},get:function(j){return j==null?this.toArray():j<0?this.slice(j)[0]:this[j]},pushStack:function(j,s,v){var z=b();b.isArray(j)?M.apply(z,j):b.merge(z,j);z.prevObject=this;z.context=this.context;if(s==="find")z.selector=this.selector+(this.selector?" ":"")+v;else if(s)z.selector=this.selector+"."+s+"("+v+")";return z},each:function(j,s){return b.each(this,j,s)},ready:function(j){b.bindReady();if(b.isReady)j.call(t,b);else q&&q.push(j);return this},eq:function(j){return j===
-1?this.slice(j):this.slice(j,+j+1)},first:function(){return this.eq(0)},last:function(){return this.eq(-1)},slice:function(){return this.pushStack(N.apply(this,arguments),"slice",N.call(arguments).join(","))},map:function(j){return this.pushStack(b.map(this,function(s,v){return j.call(s,v,s)}))},end:function(){return this.prevObject||b(null)},push:M,sort:[].sort,splice:[].splice};b.fn.init.prototype=b.fn;b.extend=b.fn.extend=function(){var j,s,v,z,H,G=arguments[0]||{},K=1,Q=arguments.length,ga=false;
if(typeof G==="boolean"){ga=G;G=arguments[1]||{};K=2}if(typeof G!=="object"&&!b.isFunction(G))G={};if(Q===K){G=this;--K}for(;K<Q;K++)if((j=arguments[K])!=null)for(s in j){v=G[s];z=j[s];if(G!==z)if(ga&&z&&(b.isPlainObject(z)||(H=b.isArray(z)))){if(H){H=false;v=v&&b.isArray(v)?v:[]}else v=v&&b.isPlainObject(v)?v:{};G[s]=b.extend(ga,v,z)}else if(z!==B)G[s]=z}return G};b.extend({noConflict:function(j){E.$=e;if(j)E.jQuery=d;return b},isReady:false,readyWait:1,ready:function(j){j===true&&b.readyWait--;
if(!b.readyWait||j!==true&&!b.isReady){if(!t.body)return setTimeout(b.ready,1);b.isReady=true;if(!(j!==true&&--b.readyWait>0))if(q){var s=0,v=q;for(q=null;j=v[s++];)j.call(t,b);b.fn.trigger&&b(t).trigger("ready").unbind("ready")}}},bindReady:function(){if(!p){p=true;if(t.readyState==="complete")return setTimeout(b.ready,1);if(t.addEventListener){t.addEventListener("DOMContentLoaded",u,false);E.addEventListener("load",b.ready,false)}else if(t.attachEvent){t.attachEvent("onreadystatechange",u);E.attachEvent("onload",
b.ready);var j=false;try{j=E.frameElement==null}catch(s){}t.documentElement.doScroll&&j&&a()}}},isFunction:function(j){return b.type(j)==="function"},isArray:Array.isArray||function(j){return b.type(j)==="array"},isWindow:function(j){return j&&typeof j==="object"&&"setInterval"in j},isNaN:function(j){return j==null||!r.test(j)||isNaN(j)},type:function(j){return j==null?String(j):R[y.call(j)]||"object"},isPlainObject:function(j){if(!j||b.type(j)!=="object"||j.nodeType||b.isWindow(j))return false;if(j.constructor&&
!F.call(j,"constructor")&&!F.call(j.constructor.prototype,"isPrototypeOf"))return false;for(var s in j);return s===B||F.call(j,s)},isEmptyObject:function(j){for(var s in j)return false;return true},error:function(j){throw j;},parseJSON:function(j){if(typeof j!=="string"||!j)return null;j=b.trim(j);if(C.test(j.replace(J,"@").replace(w,"]").replace(I,"")))return E.JSON&&E.JSON.parse?E.JSON.parse(j):(new Function("return "+j))();else b.error("Invalid JSON: "+j)},noop:function(){},globalEval:function(j){if(j&&
l.test(j)){var s=t.getElementsByTagName("head")[0]||t.documentElement,v=t.createElement("script");v.type="text/javascript";if(b.support.scriptEval)v.appendChild(t.createTextNode(j));else v.text=j;s.insertBefore(v,s.firstChild);s.removeChild(v)}},nodeName:function(j,s){return j.nodeName&&j.nodeName.toUpperCase()===s.toUpperCase()},each:function(j,s,v){var z,H=0,G=j.length,K=G===B||b.isFunction(j);if(v)if(K)for(z in j){if(s.apply(j[z],v)===false)break}else for(;H<G;){if(s.apply(j[H++],v)===false)break}else if(K)for(z in j){if(s.call(j[z],
z,j[z])===false)break}else for(v=j[0];H<G&&s.call(v,H,v)!==false;v=j[++H]);return j},trim:O?function(j){return j==null?"":O.call(j)}:function(j){return j==null?"":j.toString().replace(k,"").replace(o,"")},makeArray:function(j,s){var v=s||[];if(j!=null){var z=b.type(j);j.length==null||z==="string"||z==="function"||z==="regexp"||b.isWindow(j)?M.call(v,j):b.merge(v,j)}return v},inArray:function(j,s){if(s.indexOf)return s.indexOf(j);for(var v=0,z=s.length;v<z;v++)if(s[v]===j)return v;return-1},merge:function(j,
s){var v=j.length,z=0;if(typeof s.length==="number")for(var H=s.length;z<H;z++)j[v++]=s[z];else for(;s[z]!==B;)j[v++]=s[z++];j.length=v;return j},grep:function(j,s,v){var z=[],H;v=!!v;for(var G=0,K=j.length;G<K;G++){H=!!s(j[G],G);v!==H&&z.push(j[G])}return z},map:function(j,s,v){for(var z=[],H,G=0,K=j.length;G<K;G++){H=s(j[G],G,v);if(H!=null)z[z.length]=H}return z.concat.apply([],z)},guid:1,proxy:function(j,s,v){if(arguments.length===2)if(typeof s==="string"){v=j;j=v[s];s=B}else if(s&&!b.isFunction(s)){v=
s;s=B}if(!s&&j)s=function(){return j.apply(v||this,arguments)};if(j)s.guid=j.guid=j.guid||s.guid||b.guid++;return s},access:function(j,s,v,z,H,G){var K=j.length;if(typeof s==="object"){for(var Q in s)b.access(j,Q,s[Q],z,H,v);return j}if(v!==B){z=!G&&z&&b.isFunction(v);for(Q=0;Q<K;Q++)H(j[Q],s,z?v.call(j[Q],Q,H(j[Q],s)):v,G);return j}return K?H(j[0],s):B},now:function(){return(new Date).getTime()},uaMatch:function(j){j=j.toLowerCase();j=L.exec(j)||g.exec(j)||i.exec(j)||j.indexOf("compatible")<0&&n.exec(j)||
[];return{browser:j[1]||"",version:j[2]||"0"}},browser:{}});b.each("Boolean Number String Function Array Date RegExp Object".split(" "),function(j,s){R["[object "+s+"]"]=s.toLowerCase()});m=b.uaMatch(m);if(m.browser){b.browser[m.browser]=true;b.browser.version=m.version}if(b.browser.webkit)b.browser.safari=true;if(D)b.inArray=function(j,s){return D.call(s,j)};if(!/\s/.test("\u00a0")){k=/^[\s\xA0]+/;o=/[\s\xA0]+$/}f=b(t);if(t.addEventListener)u=function(){t.removeEventListener("DOMContentLoaded",u,
false);b.ready()};else if(t.attachEvent)u=function(){if(t.readyState==="complete"){t.detachEvent("onreadystatechange",u);b.ready()}};return E.jQuery=E.$=b}();(function(){c.support={};var a=t.documentElement,b=t.createElement("script"),d=t.createElement("div"),e="script"+c.now();d.style.display="none";d.innerHTML="   <link/><table></table><a href='/a' style='color:red;float:left;opacity:.55;'>a</a><input type='checkbox'/>";var f=d.getElementsByTagName("*"),h=d.getElementsByTagName("a")[0],l=t.createElement("select"),
k=l.appendChild(t.createElement("option"));if(!(!f||!f.length||!h)){c.support={leadingWhitespace:d.firstChild.nodeType===3,tbody:!d.getElementsByTagName("tbody").length,htmlSerialize:!!d.getElementsByTagName("link").length,style:/red/.test(h.getAttribute("style")),hrefNormalized:h.getAttribute("href")==="/a",opacity:/^0.55$/.test(h.style.opacity),cssFloat:!!h.style.cssFloat,checkOn:d.getElementsByTagName("input")[0].value==="on",optSelected:k.selected,deleteExpando:true,optDisabled:false,checkClone:false,
scriptEval:false,noCloneEvent:true,boxModel:null,inlineBlockNeedsLayout:false,shrinkWrapBlocks:false,reliableHiddenOffsets:true};l.disabled=true;c.support.optDisabled=!k.disabled;b.type="text/javascript";try{b.appendChild(t.createTextNode("window."+e+"=1;"))}catch(o){}a.insertBefore(b,a.firstChild);if(E[e]){c.support.scriptEval=true;delete E[e]}try{delete b.test}catch(x){c.support.deleteExpando=false}a.removeChild(b);if(d.attachEvent&&d.fireEvent){d.attachEvent("onclick",function r(){c.support.noCloneEvent=
false;d.detachEvent("onclick",r)});d.cloneNode(true).fireEvent("onclick")}d=t.createElement("div");d.innerHTML="<input type='radio' name='radiotest' checked='checked'/>";a=t.createDocumentFragment();a.appendChild(d.firstChild);c.support.checkClone=a.cloneNode(true).cloneNode(true).lastChild.checked;c(function(){var r=t.createElement("div");r.style.width=r.style.paddingLeft="1px";t.body.appendChild(r);c.boxModel=c.support.boxModel=r.offsetWidth===2;if("zoom"in r.style){r.style.display="inline";r.style.zoom=
1;c.support.inlineBlockNeedsLayout=r.offsetWidth===2;r.style.display="";r.innerHTML="<div style='width:4px;'></div>";c.support.shrinkWrapBlocks=r.offsetWidth!==2}r.innerHTML="<table><tr><td style='padding:0;display:none'></td><td>t</td></tr></table>";var A=r.getElementsByTagName("td");c.support.reliableHiddenOffsets=A[0].offsetHeight===0;A[0].style.display="";A[1].style.display="none";c.support.reliableHiddenOffsets=c.support.reliableHiddenOffsets&&A[0].offsetHeight===0;r.innerHTML="";t.body.removeChild(r).style.display=
"none"});a=function(r){var A=t.createElement("div");r="on"+r;var C=r in A;if(!C){A.setAttribute(r,"return;");C=typeof A[r]==="function"}return C};c.support.submitBubbles=a("submit");c.support.changeBubbles=a("change");a=b=d=f=h=null}})();var ra={},Ja=/^(?:\{.*\}|\[.*\])$/;c.extend({cache:{},uuid:0,expando:"jQuery"+c.now(),noData:{embed:true,object:"clsid:D27CDB6E-AE6D-11cf-96B8-444553540000",applet:true},data:function(a,b,d){if(c.acceptData(a)){a=a==E?ra:a;var e=a.nodeType,f=e?a[c.expando]:null,h=
c.cache;if(!(e&&!f&&typeof b==="string"&&d===B)){if(e)f||(a[c.expando]=f=++c.uuid);else h=a;if(typeof b==="object")if(e)h[f]=c.extend(h[f],b);else c.extend(h,b);else if(e&&!h[f])h[f]={};a=e?h[f]:h;if(d!==B)a[b]=d;return typeof b==="string"?a[b]:a}}},removeData:function(a,b){if(c.acceptData(a)){a=a==E?ra:a;var d=a.nodeType,e=d?a[c.expando]:a,f=c.cache,h=d?f[e]:e;if(b){if(h){delete h[b];d&&c.isEmptyObject(h)&&c.removeData(a)}}else if(d&&c.support.deleteExpando)delete a[c.expando];else if(a.removeAttribute)a.removeAttribute(c.expando);
else if(d)delete f[e];else for(var l in a)delete a[l]}},acceptData:function(a){if(a.nodeName){var b=c.noData[a.nodeName.toLowerCase()];if(b)return!(b===true||a.getAttribute("classid")!==b)}return true}});c.fn.extend({data:function(a,b){var d=null;if(typeof a==="undefined"){if(this.length){var e=this[0].attributes,f;d=c.data(this[0]);for(var h=0,l=e.length;h<l;h++){f=e[h].name;if(f.indexOf("data-")===0){f=f.substr(5);ka(this[0],f,d[f])}}}return d}else if(typeof a==="object")return this.each(function(){c.data(this,
a)});var k=a.split(".");k[1]=k[1]?"."+k[1]:"";if(b===B){d=this.triggerHandler("getData"+k[1]+"!",[k[0]]);if(d===B&&this.length){d=c.data(this[0],a);d=ka(this[0],a,d)}return d===B&&k[1]?this.data(k[0]):d}else return this.each(function(){var o=c(this),x=[k[0],b];o.triggerHandler("setData"+k[1]+"!",x);c.data(this,a,b);o.triggerHandler("changeData"+k[1]+"!",x)})},removeData:function(a){return this.each(function(){c.removeData(this,a)})}});c.extend({queue:function(a,b,d){if(a){b=(b||"fx")+"queue";var e=
c.data(a,b);if(!d)return e||[];if(!e||c.isArray(d))e=c.data(a,b,c.makeArray(d));else e.push(d);return e}},dequeue:function(a,b){b=b||"fx";var d=c.queue(a,b),e=d.shift();if(e==="inprogress")e=d.shift();if(e){b==="fx"&&d.unshift("inprogress");e.call(a,function(){c.dequeue(a,b)})}}});c.fn.extend({queue:function(a,b){if(typeof a!=="string"){b=a;a="fx"}if(b===B)return c.queue(this[0],a);return this.each(function(){var d=c.queue(this,a,b);a==="fx"&&d[0]!=="inprogress"&&c.dequeue(this,a)})},dequeue:function(a){return this.each(function(){c.dequeue(this,
a)})},delay:function(a,b){a=c.fx?c.fx.speeds[a]||a:a;b=b||"fx";return this.queue(b,function(){var d=this;setTimeout(function(){c.dequeue(d,b)},a)})},clearQueue:function(a){return this.queue(a||"fx",[])}});var sa=/[\n\t]/g,ha=/\s+/,Sa=/\r/g,Ta=/^(?:href|src|style)$/,Ua=/^(?:button|input)$/i,Va=/^(?:button|input|object|select|textarea)$/i,Wa=/^a(?:rea)?$/i,ta=/^(?:radio|checkbox)$/i;c.props={"for":"htmlFor","class":"className",readonly:"readOnly",maxlength:"maxLength",cellspacing:"cellSpacing",rowspan:"rowSpan",
colspan:"colSpan",tabindex:"tabIndex",usemap:"useMap",frameborder:"frameBorder"};c.fn.extend({attr:function(a,b){return c.access(this,a,b,true,c.attr)},removeAttr:function(a){return this.each(function(){c.attr(this,a,"");this.nodeType===1&&this.removeAttribute(a)})},addClass:function(a){if(c.isFunction(a))return this.each(function(x){var r=c(this);r.addClass(a.call(this,x,r.attr("class")))});if(a&&typeof a==="string")for(var b=(a||"").split(ha),d=0,e=this.length;d<e;d++){var f=this[d];if(f.nodeType===
1)if(f.className){for(var h=" "+f.className+" ",l=f.className,k=0,o=b.length;k<o;k++)if(h.indexOf(" "+b[k]+" ")<0)l+=" "+b[k];f.className=c.trim(l)}else f.className=a}return this},removeClass:function(a){if(c.isFunction(a))return this.each(function(o){var x=c(this);x.removeClass(a.call(this,o,x.attr("class")))});if(a&&typeof a==="string"||a===B)for(var b=(a||"").split(ha),d=0,e=this.length;d<e;d++){var f=this[d];if(f.nodeType===1&&f.className)if(a){for(var h=(" "+f.className+" ").replace(sa," "),
l=0,k=b.length;l<k;l++)h=h.replace(" "+b[l]+" "," ");f.className=c.trim(h)}else f.className=""}return this},toggleClass:function(a,b){var d=typeof a,e=typeof b==="boolean";if(c.isFunction(a))return this.each(function(f){var h=c(this);h.toggleClass(a.call(this,f,h.attr("class"),b),b)});return this.each(function(){if(d==="string")for(var f,h=0,l=c(this),k=b,o=a.split(ha);f=o[h++];){k=e?k:!l.hasClass(f);l[k?"addClass":"removeClass"](f)}else if(d==="undefined"||d==="boolean"){this.className&&c.data(this,
"__className__",this.className);this.className=this.className||a===false?"":c.data(this,"__className__")||""}})},hasClass:function(a){a=" "+a+" ";for(var b=0,d=this.length;b<d;b++)if((" "+this[b].className+" ").replace(sa," ").indexOf(a)>-1)return true;return false},val:function(a){if(!arguments.length){var b=this[0];if(b){if(c.nodeName(b,"option")){var d=b.attributes.value;return!d||d.specified?b.value:b.text}if(c.nodeName(b,"select")){var e=b.selectedIndex;d=[];var f=b.options;b=b.type==="select-one";
if(e<0)return null;var h=b?e:0;for(e=b?e+1:f.length;h<e;h++){var l=f[h];if(l.selected&&(c.support.optDisabled?!l.disabled:l.getAttribute("disabled")===null)&&(!l.parentNode.disabled||!c.nodeName(l.parentNode,"optgroup"))){a=c(l).val();if(b)return a;d.push(a)}}return d}if(ta.test(b.type)&&!c.support.checkOn)return b.getAttribute("value")===null?"on":b.value;return(b.value||"").replace(Sa,"")}return B}var k=c.isFunction(a);return this.each(function(o){var x=c(this),r=a;if(this.nodeType===1){if(k)r=
a.call(this,o,x.val());if(r==null)r="";else if(typeof r==="number")r+="";else if(c.isArray(r))r=c.map(r,function(C){return C==null?"":C+""});if(c.isArray(r)&&ta.test(this.type))this.checked=c.inArray(x.val(),r)>=0;else if(c.nodeName(this,"select")){var A=c.makeArray(r);c("option",this).each(function(){this.selected=c.inArray(c(this).val(),A)>=0});if(!A.length)this.selectedIndex=-1}else this.value=r}})}});c.extend({attrFn:{val:true,css:true,html:true,text:true,data:true,width:true,height:true,offset:true},
attr:function(a,b,d,e){if(!a||a.nodeType===3||a.nodeType===8)return B;if(e&&b in c.attrFn)return c(a)[b](d);e=a.nodeType!==1||!c.isXMLDoc(a);var f=d!==B;b=e&&c.props[b]||b;var h=Ta.test(b);if((b in a||a[b]!==B)&&e&&!h){if(f){b==="type"&&Ua.test(a.nodeName)&&a.parentNode&&c.error("type property can't be changed");if(d===null)a.nodeType===1&&a.removeAttribute(b);else a[b]=d}if(c.nodeName(a,"form")&&a.getAttributeNode(b))return a.getAttributeNode(b).nodeValue;if(b==="tabIndex")return(b=a.getAttributeNode("tabIndex"))&&
b.specified?b.value:Va.test(a.nodeName)||Wa.test(a.nodeName)&&a.href?0:B;return a[b]}if(!c.support.style&&e&&b==="style"){if(f)a.style.cssText=""+d;return a.style.cssText}f&&a.setAttribute(b,""+d);if(!a.attributes[b]&&a.hasAttribute&&!a.hasAttribute(b))return B;a=!c.support.hrefNormalized&&e&&h?a.getAttribute(b,2):a.getAttribute(b);return a===null?B:a}});var X=/\.(.*)$/,ia=/^(?:textarea|input|select)$/i,La=/\./g,Ma=/ /g,Xa=/[^\w\s.|`]/g,Ya=function(a){return a.replace(Xa,"\\$&")},ua={focusin:0,focusout:0};
c.event={add:function(a,b,d,e){if(!(a.nodeType===3||a.nodeType===8)){if(c.isWindow(a)&&a!==E&&!a.frameElement)a=E;if(d===false)d=U;else if(!d)return;var f,h;if(d.handler){f=d;d=f.handler}if(!d.guid)d.guid=c.guid++;if(h=c.data(a)){var l=a.nodeType?"events":"__events__",k=h[l],o=h.handle;if(typeof k==="function"){o=k.handle;k=k.events}else if(!k){a.nodeType||(h[l]=h=function(){});h.events=k={}}if(!o)h.handle=o=function(){return typeof c!=="undefined"&&!c.event.triggered?c.event.handle.apply(o.elem,
arguments):B};o.elem=a;b=b.split(" ");for(var x=0,r;l=b[x++];){h=f?c.extend({},f):{handler:d,data:e};if(l.indexOf(".")>-1){r=l.split(".");l=r.shift();h.namespace=r.slice(0).sort().join(".")}else{r=[];h.namespace=""}h.type=l;if(!h.guid)h.guid=d.guid;var A=k[l],C=c.event.special[l]||{};if(!A){A=k[l]=[];if(!C.setup||C.setup.call(a,e,r,o)===false)if(a.addEventListener)a.addEventListener(l,o,false);else a.attachEvent&&a.attachEvent("on"+l,o)}if(C.add){C.add.call(a,h);if(!h.handler.guid)h.handler.guid=
d.guid}A.push(h);c.event.global[l]=true}a=null}}},global:{},remove:function(a,b,d,e){if(!(a.nodeType===3||a.nodeType===8)){if(d===false)d=U;var f,h,l=0,k,o,x,r,A,C,J=a.nodeType?"events":"__events__",w=c.data(a),I=w&&w[J];if(w&&I){if(typeof I==="function"){w=I;I=I.events}if(b&&b.type){d=b.handler;b=b.type}if(!b||typeof b==="string"&&b.charAt(0)==="."){b=b||"";for(f in I)c.event.remove(a,f+b)}else{for(b=b.split(" ");f=b[l++];){r=f;k=f.indexOf(".")<0;o=[];if(!k){o=f.split(".");f=o.shift();x=RegExp("(^|\\.)"+
c.map(o.slice(0).sort(),Ya).join("\\.(?:.*\\.)?")+"(\\.|$)")}if(A=I[f])if(d){r=c.event.special[f]||{};for(h=e||0;h<A.length;h++){C=A[h];if(d.guid===C.guid){if(k||x.test(C.namespace)){e==null&&A.splice(h--,1);r.remove&&r.remove.call(a,C)}if(e!=null)break}}if(A.length===0||e!=null&&A.length===1){if(!r.teardown||r.teardown.call(a,o)===false)c.removeEvent(a,f,w.handle);delete I[f]}}else for(h=0;h<A.length;h++){C=A[h];if(k||x.test(C.namespace)){c.event.remove(a,r,C.handler,h);A.splice(h--,1)}}}if(c.isEmptyObject(I)){if(b=
w.handle)b.elem=null;delete w.events;delete w.handle;if(typeof w==="function")c.removeData(a,J);else c.isEmptyObject(w)&&c.removeData(a)}}}}},trigger:function(a,b,d,e){var f=a.type||a;if(!e){a=typeof a==="object"?a[c.expando]?a:c.extend(c.Event(f),a):c.Event(f);if(f.indexOf("!")>=0){a.type=f=f.slice(0,-1);a.exclusive=true}if(!d){a.stopPropagation();c.event.global[f]&&c.each(c.cache,function(){this.events&&this.events[f]&&c.event.trigger(a,b,this.handle.elem)})}if(!d||d.nodeType===3||d.nodeType===
8)return B;a.result=B;a.target=d;b=c.makeArray(b);b.unshift(a)}a.currentTarget=d;(e=d.nodeType?c.data(d,"handle"):(c.data(d,"__events__")||{}).handle)&&e.apply(d,b);e=d.parentNode||d.ownerDocument;try{if(!(d&&d.nodeName&&c.noData[d.nodeName.toLowerCase()]))if(d["on"+f]&&d["on"+f].apply(d,b)===false){a.result=false;a.preventDefault()}}catch(h){}if(!a.isPropagationStopped()&&e)c.event.trigger(a,b,e,true);else if(!a.isDefaultPrevented()){var l;e=a.target;var k=f.replace(X,""),o=c.nodeName(e,"a")&&k===
"click",x=c.event.special[k]||{};if((!x._default||x._default.call(d,a)===false)&&!o&&!(e&&e.nodeName&&c.noData[e.nodeName.toLowerCase()])){try{if(e[k]){if(l=e["on"+k])e["on"+k]=null;c.event.triggered=true;e[k]()}}catch(r){}if(l)e["on"+k]=l;c.event.triggered=false}}},handle:function(a){var b,d,e,f;d=[];var h=c.makeArray(arguments);a=h[0]=c.event.fix(a||E.event);a.currentTarget=this;b=a.type.indexOf(".")<0&&!a.exclusive;if(!b){e=a.type.split(".");a.type=e.shift();d=e.slice(0).sort();e=RegExp("(^|\\.)"+
d.join("\\.(?:.*\\.)?")+"(\\.|$)")}a.namespace=a.namespace||d.join(".");f=c.data(this,this.nodeType?"events":"__events__");if(typeof f==="function")f=f.events;d=(f||{})[a.type];if(f&&d){d=d.slice(0);f=0;for(var l=d.length;f<l;f++){var k=d[f];if(b||e.test(k.namespace)){a.handler=k.handler;a.data=k.data;a.handleObj=k;k=k.handler.apply(this,h);if(k!==B){a.result=k;if(k===false){a.preventDefault();a.stopPropagation()}}if(a.isImmediatePropagationStopped())break}}}return a.result},props:"altKey attrChange attrName bubbles button cancelable charCode clientX clientY ctrlKey currentTarget data detail eventPhase fromElement handler keyCode layerX layerY metaKey newValue offsetX offsetY pageX pageY prevValue relatedNode relatedTarget screenX screenY shiftKey srcElement target toElement view wheelDelta which".split(" "),
fix:function(a){if(a[c.expando])return a;var b=a;a=c.Event(b);for(var d=this.props.length,e;d;){e=this.props[--d];a[e]=b[e]}if(!a.target)a.target=a.srcElement||t;if(a.target.nodeType===3)a.target=a.target.parentNode;if(!a.relatedTarget&&a.fromElement)a.relatedTarget=a.fromElement===a.target?a.toElement:a.fromElement;if(a.pageX==null&&a.clientX!=null){b=t.documentElement;d=t.body;a.pageX=a.clientX+(b&&b.scrollLeft||d&&d.scrollLeft||0)-(b&&b.clientLeft||d&&d.clientLeft||0);a.pageY=a.clientY+(b&&b.scrollTop||
d&&d.scrollTop||0)-(b&&b.clientTop||d&&d.clientTop||0)}if(a.which==null&&(a.charCode!=null||a.keyCode!=null))a.which=a.charCode!=null?a.charCode:a.keyCode;if(!a.metaKey&&a.ctrlKey)a.metaKey=a.ctrlKey;if(!a.which&&a.button!==B)a.which=a.button&1?1:a.button&2?3:a.button&4?2:0;return a},guid:1E8,proxy:c.proxy,special:{ready:{setup:c.bindReady,teardown:c.noop},live:{add:function(a){c.event.add(this,Y(a.origType,a.selector),c.extend({},a,{handler:Ka,guid:a.handler.guid}))},remove:function(a){c.event.remove(this,
Y(a.origType,a.selector),a)}},beforeunload:{setup:function(a,b,d){if(c.isWindow(this))this.onbeforeunload=d},teardown:function(a,b){if(this.onbeforeunload===b)this.onbeforeunload=null}}}};c.removeEvent=t.removeEventListener?function(a,b,d){a.removeEventListener&&a.removeEventListener(b,d,false)}:function(a,b,d){a.detachEvent&&a.detachEvent("on"+b,d)};c.Event=function(a){if(!this.preventDefault)return new c.Event(a);if(a&&a.type){this.originalEvent=a;this.type=a.type}else this.type=a;this.timeStamp=
c.now();this[c.expando]=true};c.Event.prototype={preventDefault:function(){this.isDefaultPrevented=ca;var a=this.originalEvent;if(a)if(a.preventDefault)a.preventDefault();else a.returnValue=false},stopPropagation:function(){this.isPropagationStopped=ca;var a=this.originalEvent;if(a){a.stopPropagation&&a.stopPropagation();a.cancelBubble=true}},stopImmediatePropagation:function(){this.isImmediatePropagationStopped=ca;this.stopPropagation()},isDefaultPrevented:U,isPropagationStopped:U,isImmediatePropagationStopped:U};
var va=function(a){var b=a.relatedTarget;try{for(;b&&b!==this;)b=b.parentNode;if(b!==this){a.type=a.data;c.event.handle.apply(this,arguments)}}catch(d){}},wa=function(a){a.type=a.data;c.event.handle.apply(this,arguments)};c.each({mouseenter:"mouseover",mouseleave:"mouseout"},function(a,b){c.event.special[a]={setup:function(d){c.event.add(this,b,d&&d.selector?wa:va,a)},teardown:function(d){c.event.remove(this,b,d&&d.selector?wa:va)}}});if(!c.support.submitBubbles)c.event.special.submit={setup:function(){if(this.nodeName.toLowerCase()!==
"form"){c.event.add(this,"click.specialSubmit",function(a){var b=a.target,d=b.type;if((d==="submit"||d==="image")&&c(b).closest("form").length){a.liveFired=B;return la("submit",this,arguments)}});c.event.add(this,"keypress.specialSubmit",function(a){var b=a.target,d=b.type;if((d==="text"||d==="password")&&c(b).closest("form").length&&a.keyCode===13){a.liveFired=B;return la("submit",this,arguments)}})}else return false},teardown:function(){c.event.remove(this,".specialSubmit")}};if(!c.support.changeBubbles){var V,
xa=function(a){var b=a.type,d=a.value;if(b==="radio"||b==="checkbox")d=a.checked;else if(b==="select-multiple")d=a.selectedIndex>-1?c.map(a.options,function(e){return e.selected}).join("-"):"";else if(a.nodeName.toLowerCase()==="select")d=a.selectedIndex;return d},Z=function(a,b){var d=a.target,e,f;if(!(!ia.test(d.nodeName)||d.readOnly)){e=c.data(d,"_change_data");f=xa(d);if(a.type!=="focusout"||d.type!=="radio")c.data(d,"_change_data",f);if(!(e===B||f===e))if(e!=null||f){a.type="change";a.liveFired=
B;return c.event.trigger(a,b,d)}}};c.event.special.change={filters:{focusout:Z,beforedeactivate:Z,click:function(a){var b=a.target,d=b.type;if(d==="radio"||d==="checkbox"||b.nodeName.toLowerCase()==="select")return Z.call(this,a)},keydown:function(a){var b=a.target,d=b.type;if(a.keyCode===13&&b.nodeName.toLowerCase()!=="textarea"||a.keyCode===32&&(d==="checkbox"||d==="radio")||d==="select-multiple")return Z.call(this,a)},beforeactivate:function(a){a=a.target;c.data(a,"_change_data",xa(a))}},setup:function(){if(this.type===
"file")return false;for(var a in V)c.event.add(this,a+".specialChange",V[a]);return ia.test(this.nodeName)},teardown:function(){c.event.remove(this,".specialChange");return ia.test(this.nodeName)}};V=c.event.special.change.filters;V.focus=V.beforeactivate}t.addEventListener&&c.each({focus:"focusin",blur:"focusout"},function(a,b){function d(e){e=c.event.fix(e);e.type=b;return c.event.trigger(e,null,e.target)}c.event.special[b]={setup:function(){ua[b]++===0&&t.addEventListener(a,d,true)},teardown:function(){--ua[b]===
0&&t.removeEventListener(a,d,true)}}});c.each(["bind","one"],function(a,b){c.fn[b]=function(d,e,f){if(typeof d==="object"){for(var h in d)this[b](h,e,d[h],f);return this}if(c.isFunction(e)||e===false){f=e;e=B}var l=b==="one"?c.proxy(f,function(o){c(this).unbind(o,l);return f.apply(this,arguments)}):f;if(d==="unload"&&b!=="one")this.one(d,e,f);else{h=0;for(var k=this.length;h<k;h++)c.event.add(this[h],d,l,e)}return this}});c.fn.extend({unbind:function(a,b){if(typeof a==="object"&&!a.preventDefault)for(var d in a)this.unbind(d,
a[d]);else{d=0;for(var e=this.length;d<e;d++)c.event.remove(this[d],a,b)}return this},delegate:function(a,b,d,e){return this.live(b,d,e,a)},undelegate:function(a,b,d){return arguments.length===0?this.unbind("live"):this.die(b,null,d,a)},trigger:function(a,b){return this.each(function(){c.event.trigger(a,b,this)})},triggerHandler:function(a,b){if(this[0]){var d=c.Event(a);d.preventDefault();d.stopPropagation();c.event.trigger(d,b,this[0]);return d.result}},toggle:function(a){for(var b=arguments,d=
1;d<b.length;)c.proxy(a,b[d++]);return this.click(c.proxy(a,function(e){var f=(c.data(this,"lastToggle"+a.guid)||0)%d;c.data(this,"lastToggle"+a.guid,f+1);e.preventDefault();return b[f].apply(this,arguments)||false}))},hover:function(a,b){return this.mouseenter(a).mouseleave(b||a)}});var ya={focus:"focusin",blur:"focusout",mouseenter:"mouseover",mouseleave:"mouseout"};c.each(["live","die"],function(a,b){c.fn[b]=function(d,e,f,h){var l,k=0,o,x,r=h||this.selector;h=h?this:c(this.context);if(typeof d===
"object"&&!d.preventDefault){for(l in d)h[b](l,e,d[l],r);return this}if(c.isFunction(e)){f=e;e=B}for(d=(d||"").split(" ");(l=d[k++])!=null;){o=X.exec(l);x="";if(o){x=o[0];l=l.replace(X,"")}if(l==="hover")d.push("mouseenter"+x,"mouseleave"+x);else{o=l;if(l==="focus"||l==="blur"){d.push(ya[l]+x);l+=x}else l=(ya[l]||l)+x;if(b==="live"){x=0;for(var A=h.length;x<A;x++)c.event.add(h[x],"live."+Y(l,r),{data:e,selector:r,handler:f,origType:l,origHandler:f,preType:o})}else h.unbind("live."+Y(l,r),f)}}return this}});
c.each("blur focus focusin focusout load resize scroll unload click dblclick mousedown mouseup mousemove mouseover mouseout mouseenter mouseleave change select submit keydown keypress keyup error".split(" "),function(a,b){c.fn[b]=function(d,e){if(e==null){e=d;d=null}return arguments.length>0?this.bind(b,d,e):this.trigger(b)};if(c.attrFn)c.attrFn[b]=true});E.attachEvent&&!E.addEventListener&&c(E).bind("unload",function(){for(var a in c.cache)if(c.cache[a].handle)try{c.event.remove(c.cache[a].handle.elem)}catch(b){}});
(function(){function a(g,i,n,m,p,q){p=0;for(var u=m.length;p<u;p++){var y=m[p];if(y){var F=false;for(y=y[g];y;){if(y.sizcache===n){F=m[y.sizset];break}if(y.nodeType===1&&!q){y.sizcache=n;y.sizset=p}if(y.nodeName.toLowerCase()===i){F=y;break}y=y[g]}m[p]=F}}}function b(g,i,n,m,p,q){p=0;for(var u=m.length;p<u;p++){var y=m[p];if(y){var F=false;for(y=y[g];y;){if(y.sizcache===n){F=m[y.sizset];break}if(y.nodeType===1){if(!q){y.sizcache=n;y.sizset=p}if(typeof i!=="string"){if(y===i){F=true;break}}else if(k.filter(i,
[y]).length>0){F=y;break}}y=y[g]}m[p]=F}}}var d=/((?:\((?:\([^()]+\)|[^()]+)+\)|\[(?:\[[^\[\]]*\]|['"][^'"]*['"]|[^\[\]'"]+)+\]|\\.|[^ >+~,(\[\\]+)+|[>+~])(\s*,\s*)?((?:.|\r|\n)*)/g,e=0,f=Object.prototype.toString,h=false,l=true;[0,0].sort(function(){l=false;return 0});var k=function(g,i,n,m){n=n||[];var p=i=i||t;if(i.nodeType!==1&&i.nodeType!==9)return[];if(!g||typeof g!=="string")return n;var q,u,y,F,M,N=true,O=k.isXML(i),D=[],R=g;do{d.exec("");if(q=d.exec(R)){R=q[3];D.push(q[1]);if(q[2]){F=q[3];
break}}}while(q);if(D.length>1&&x.exec(g))if(D.length===2&&o.relative[D[0]])u=L(D[0]+D[1],i);else for(u=o.relative[D[0]]?[i]:k(D.shift(),i);D.length;){g=D.shift();if(o.relative[g])g+=D.shift();u=L(g,u)}else{if(!m&&D.length>1&&i.nodeType===9&&!O&&o.match.ID.test(D[0])&&!o.match.ID.test(D[D.length-1])){q=k.find(D.shift(),i,O);i=q.expr?k.filter(q.expr,q.set)[0]:q.set[0]}if(i){q=m?{expr:D.pop(),set:C(m)}:k.find(D.pop(),D.length===1&&(D[0]==="~"||D[0]==="+")&&i.parentNode?i.parentNode:i,O);u=q.expr?k.filter(q.expr,
q.set):q.set;if(D.length>0)y=C(u);else N=false;for(;D.length;){q=M=D.pop();if(o.relative[M])q=D.pop();else M="";if(q==null)q=i;o.relative[M](y,q,O)}}else y=[]}y||(y=u);y||k.error(M||g);if(f.call(y)==="[object Array]")if(N)if(i&&i.nodeType===1)for(g=0;y[g]!=null;g++){if(y[g]&&(y[g]===true||y[g].nodeType===1&&k.contains(i,y[g])))n.push(u[g])}else for(g=0;y[g]!=null;g++)y[g]&&y[g].nodeType===1&&n.push(u[g]);else n.push.apply(n,y);else C(y,n);if(F){k(F,p,n,m);k.uniqueSort(n)}return n};k.uniqueSort=function(g){if(w){h=
l;g.sort(w);if(h)for(var i=1;i<g.length;i++)g[i]===g[i-1]&&g.splice(i--,1)}return g};k.matches=function(g,i){return k(g,null,null,i)};k.matchesSelector=function(g,i){return k(i,null,null,[g]).length>0};k.find=function(g,i,n){var m;if(!g)return[];for(var p=0,q=o.order.length;p<q;p++){var u,y=o.order[p];if(u=o.leftMatch[y].exec(g)){var F=u[1];u.splice(1,1);if(F.substr(F.length-1)!=="\\"){u[1]=(u[1]||"").replace(/\\/g,"");m=o.find[y](u,i,n);if(m!=null){g=g.replace(o.match[y],"");break}}}}m||(m=i.getElementsByTagName("*"));
return{set:m,expr:g}};k.filter=function(g,i,n,m){for(var p,q,u=g,y=[],F=i,M=i&&i[0]&&k.isXML(i[0]);g&&i.length;){for(var N in o.filter)if((p=o.leftMatch[N].exec(g))!=null&&p[2]){var O,D,R=o.filter[N];D=p[1];q=false;p.splice(1,1);if(D.substr(D.length-1)!=="\\"){if(F===y)y=[];if(o.preFilter[N])if(p=o.preFilter[N](p,F,n,y,m,M)){if(p===true)continue}else q=O=true;if(p)for(var j=0;(D=F[j])!=null;j++)if(D){O=R(D,p,j,F);var s=m^!!O;if(n&&O!=null)if(s)q=true;else F[j]=false;else if(s){y.push(D);q=true}}if(O!==
B){n||(F=y);g=g.replace(o.match[N],"");if(!q)return[];break}}}if(g===u)if(q==null)k.error(g);else break;u=g}return F};k.error=function(g){throw"Syntax error, unrecognized expression: "+g;};var o=k.selectors={order:["ID","NAME","TAG"],match:{ID:/#((?:[\w\u00c0-\uFFFF\-]|\\.)+)/,CLASS:/\.((?:[\w\u00c0-\uFFFF\-]|\\.)+)/,NAME:/\[name=['"]*((?:[\w\u00c0-\uFFFF\-]|\\.)+)['"]*\]/,ATTR:/\[\s*((?:[\w\u00c0-\uFFFF\-]|\\.)+)\s*(?:(\S?=)\s*(['"]*)(.*?)\3|)\s*\]/,TAG:/^((?:[\w\u00c0-\uFFFF\*\-]|\\.)+)/,CHILD:/:(only|nth|last|first)-child(?:\((even|odd|[\dn+\-]*)\))?/,
POS:/:(nth|eq|gt|lt|first|last|even|odd)(?:\((\d*)\))?(?=[^\-]|$)/,PSEUDO:/:((?:[\w\u00c0-\uFFFF\-]|\\.)+)(?:\((['"]?)((?:\([^\)]+\)|[^\(\)]*)+)\2\))?/},leftMatch:{},attrMap:{"class":"className","for":"htmlFor"},attrHandle:{href:function(g){return g.getAttribute("href")}},relative:{"+":function(g,i){var n=typeof i==="string",m=n&&!/\W/.test(i);n=n&&!m;if(m)i=i.toLowerCase();m=0;for(var p=g.length,q;m<p;m++)if(q=g[m]){for(;(q=q.previousSibling)&&q.nodeType!==1;);g[m]=n||q&&q.nodeName.toLowerCase()===
i?q||false:q===i}n&&k.filter(i,g,true)},">":function(g,i){var n,m=typeof i==="string",p=0,q=g.length;if(m&&!/\W/.test(i))for(i=i.toLowerCase();p<q;p++){if(n=g[p]){n=n.parentNode;g[p]=n.nodeName.toLowerCase()===i?n:false}}else{for(;p<q;p++)if(n=g[p])g[p]=m?n.parentNode:n.parentNode===i;m&&k.filter(i,g,true)}},"":function(g,i,n){var m,p=e++,q=b;if(typeof i==="string"&&!/\W/.test(i)){m=i=i.toLowerCase();q=a}q("parentNode",i,p,g,m,n)},"~":function(g,i,n){var m,p=e++,q=b;if(typeof i==="string"&&!/\W/.test(i)){m=
i=i.toLowerCase();q=a}q("previousSibling",i,p,g,m,n)}},find:{ID:function(g,i,n){if(typeof i.getElementById!=="undefined"&&!n)return(g=i.getElementById(g[1]))&&g.parentNode?[g]:[]},NAME:function(g,i){if(typeof i.getElementsByName!=="undefined"){for(var n=[],m=i.getElementsByName(g[1]),p=0,q=m.length;p<q;p++)m[p].getAttribute("name")===g[1]&&n.push(m[p]);return n.length===0?null:n}},TAG:function(g,i){return i.getElementsByTagName(g[1])}},preFilter:{CLASS:function(g,i,n,m,p,q){g=" "+g[1].replace(/\\/g,
"")+" ";if(q)return g;q=0;for(var u;(u=i[q])!=null;q++)if(u)if(p^(u.className&&(" "+u.className+" ").replace(/[\t\n]/g," ").indexOf(g)>=0))n||m.push(u);else if(n)i[q]=false;return false},ID:function(g){return g[1].replace(/\\/g,"")},TAG:function(g){return g[1].toLowerCase()},CHILD:function(g){if(g[1]==="nth"){var i=/(-?)(\d*)n((?:\+|-)?\d*)/.exec(g[2]==="even"&&"2n"||g[2]==="odd"&&"2n+1"||!/\D/.test(g[2])&&"0n+"+g[2]||g[2]);g[2]=i[1]+(i[2]||1)-0;g[3]=i[3]-0}g[0]=e++;return g},ATTR:function(g,i,n,
m,p,q){i=g[1].replace(/\\/g,"");if(!q&&o.attrMap[i])g[1]=o.attrMap[i];if(g[2]==="~=")g[4]=" "+g[4]+" ";return g},PSEUDO:function(g,i,n,m,p){if(g[1]==="not")if((d.exec(g[3])||"").length>1||/^\w/.test(g[3]))g[3]=k(g[3],null,null,i);else{g=k.filter(g[3],i,n,true^p);n||m.push.apply(m,g);return false}else if(o.match.POS.test(g[0])||o.match.CHILD.test(g[0]))return true;return g},POS:function(g){g.unshift(true);return g}},filters:{enabled:function(g){return g.disabled===false&&g.type!=="hidden"},disabled:function(g){return g.disabled===
true},checked:function(g){return g.checked===true},selected:function(g){return g.selected===true},parent:function(g){return!!g.firstChild},empty:function(g){return!g.firstChild},has:function(g,i,n){return!!k(n[3],g).length},header:function(g){return/h\d/i.test(g.nodeName)},text:function(g){return"text"===g.type},radio:function(g){return"radio"===g.type},checkbox:function(g){return"checkbox"===g.type},file:function(g){return"file"===g.type},password:function(g){return"password"===g.type},submit:function(g){return"submit"===
g.type},image:function(g){return"image"===g.type},reset:function(g){return"reset"===g.type},button:function(g){return"button"===g.type||g.nodeName.toLowerCase()==="button"},input:function(g){return/input|select|textarea|button/i.test(g.nodeName)}},setFilters:{first:function(g,i){return i===0},last:function(g,i,n,m){return i===m.length-1},even:function(g,i){return i%2===0},odd:function(g,i){return i%2===1},lt:function(g,i,n){return i<n[3]-0},gt:function(g,i,n){return i>n[3]-0},nth:function(g,i,n){return n[3]-
0===i},eq:function(g,i,n){return n[3]-0===i}},filter:{PSEUDO:function(g,i,n,m){var p=i[1],q=o.filters[p];if(q)return q(g,n,i,m);else if(p==="contains")return(g.textContent||g.innerText||k.getText([g])||"").indexOf(i[3])>=0;else if(p==="not"){i=i[3];n=0;for(m=i.length;n<m;n++)if(i[n]===g)return false;return true}else k.error("Syntax error, unrecognized expression: "+p)},CHILD:function(g,i){var n=i[1],m=g;switch(n){case "only":case "first":for(;m=m.previousSibling;)if(m.nodeType===1)return false;if(n===
"first")return true;m=g;case "last":for(;m=m.nextSibling;)if(m.nodeType===1)return false;return true;case "nth":n=i[2];var p=i[3];if(n===1&&p===0)return true;var q=i[0],u=g.parentNode;if(u&&(u.sizcache!==q||!g.nodeIndex)){var y=0;for(m=u.firstChild;m;m=m.nextSibling)if(m.nodeType===1)m.nodeIndex=++y;u.sizcache=q}m=g.nodeIndex-p;return n===0?m===0:m%n===0&&m/n>=0}},ID:function(g,i){return g.nodeType===1&&g.getAttribute("id")===i},TAG:function(g,i){return i==="*"&&g.nodeType===1||g.nodeName.toLowerCase()===
i},CLASS:function(g,i){return(" "+(g.className||g.getAttribute("class"))+" ").indexOf(i)>-1},ATTR:function(g,i){var n=i[1];n=o.attrHandle[n]?o.attrHandle[n](g):g[n]!=null?g[n]:g.getAttribute(n);var m=n+"",p=i[2],q=i[4];return n==null?p==="!=":p==="="?m===q:p==="*="?m.indexOf(q)>=0:p==="~="?(" "+m+" ").indexOf(q)>=0:!q?m&&n!==false:p==="!="?m!==q:p==="^="?m.indexOf(q)===0:p==="$="?m.substr(m.length-q.length)===q:p==="|="?m===q||m.substr(0,q.length+1)===q+"-":false},POS:function(g,i,n,m){var p=o.setFilters[i[2]];
if(p)return p(g,n,i,m)}}},x=o.match.POS,r=function(g,i){return"\\"+(i-0+1)},A;for(A in o.match){o.match[A]=RegExp(o.match[A].source+/(?![^\[]*\])(?![^\(]*\))/.source);o.leftMatch[A]=RegExp(/(^(?:.|\r|\n)*?)/.source+o.match[A].source.replace(/\\(\d+)/g,r))}var C=function(g,i){g=Array.prototype.slice.call(g,0);if(i){i.push.apply(i,g);return i}return g};try{Array.prototype.slice.call(t.documentElement.childNodes,0)}catch(J){C=function(g,i){var n=0,m=i||[];if(f.call(g)==="[object Array]")Array.prototype.push.apply(m,
g);else if(typeof g.length==="number")for(var p=g.length;n<p;n++)m.push(g[n]);else for(;g[n];n++)m.push(g[n]);return m}}var w,I;if(t.documentElement.compareDocumentPosition)w=function(g,i){if(g===i){h=true;return 0}if(!g.compareDocumentPosition||!i.compareDocumentPosition)return g.compareDocumentPosition?-1:1;return g.compareDocumentPosition(i)&4?-1:1};else{w=function(g,i){var n,m,p=[],q=[];n=g.parentNode;m=i.parentNode;var u=n;if(g===i){h=true;return 0}else if(n===m)return I(g,i);else if(n){if(!m)return 1}else return-1;
for(;u;){p.unshift(u);u=u.parentNode}for(u=m;u;){q.unshift(u);u=u.parentNode}n=p.length;m=q.length;for(u=0;u<n&&u<m;u++)if(p[u]!==q[u])return I(p[u],q[u]);return u===n?I(g,q[u],-1):I(p[u],i,1)};I=function(g,i,n){if(g===i)return n;for(g=g.nextSibling;g;){if(g===i)return-1;g=g.nextSibling}return 1}}k.getText=function(g){for(var i="",n,m=0;g[m];m++){n=g[m];if(n.nodeType===3||n.nodeType===4)i+=n.nodeValue;else if(n.nodeType!==8)i+=k.getText(n.childNodes)}return i};(function(){var g=t.createElement("div"),
i="script"+(new Date).getTime(),n=t.documentElement;g.innerHTML="<a name='"+i+"'/>";n.insertBefore(g,n.firstChild);if(t.getElementById(i)){o.find.ID=function(m,p,q){if(typeof p.getElementById!=="undefined"&&!q)return(p=p.getElementById(m[1]))?p.id===m[1]||typeof p.getAttributeNode!=="undefined"&&p.getAttributeNode("id").nodeValue===m[1]?[p]:B:[]};o.filter.ID=function(m,p){var q=typeof m.getAttributeNode!=="undefined"&&m.getAttributeNode("id");return m.nodeType===1&&q&&q.nodeValue===p}}n.removeChild(g);
n=g=null})();(function(){var g=t.createElement("div");g.appendChild(t.createComment(""));if(g.getElementsByTagName("*").length>0)o.find.TAG=function(i,n){var m=n.getElementsByTagName(i[1]);if(i[1]==="*"){for(var p=[],q=0;m[q];q++)m[q].nodeType===1&&p.push(m[q]);m=p}return m};g.innerHTML="<a href='#'></a>";if(g.firstChild&&typeof g.firstChild.getAttribute!=="undefined"&&g.firstChild.getAttribute("href")!=="#")o.attrHandle.href=function(i){return i.getAttribute("href",2)};g=null})();t.querySelectorAll&&
function(){var g=k,i=t.createElement("div");i.innerHTML="<p class='TEST'></p>";if(!(i.querySelectorAll&&i.querySelectorAll(".TEST").length===0)){k=function(m,p,q,u){p=p||t;m=m.replace(/\=\s*([^'"\]]*)\s*\]/g,"='$1']");if(!u&&!k.isXML(p))if(p.nodeType===9)try{return C(p.querySelectorAll(m),q)}catch(y){}else if(p.nodeType===1&&p.nodeName.toLowerCase()!=="object"){var F=p.getAttribute("id"),M=F||"__sizzle__";F||p.setAttribute("id",M);try{return C(p.querySelectorAll("#"+M+" "+m),q)}catch(N){}finally{F||
p.removeAttribute("id")}}return g(m,p,q,u)};for(var n in g)k[n]=g[n];i=null}}();(function(){var g=t.documentElement,i=g.matchesSelector||g.mozMatchesSelector||g.webkitMatchesSelector||g.msMatchesSelector,n=false;try{i.call(t.documentElement,"[test!='']:sizzle")}catch(m){n=true}if(i)k.matchesSelector=function(p,q){q=q.replace(/\=\s*([^'"\]]*)\s*\]/g,"='$1']");if(!k.isXML(p))try{if(n||!o.match.PSEUDO.test(q)&&!/!=/.test(q))return i.call(p,q)}catch(u){}return k(q,null,null,[p]).length>0}})();(function(){var g=
t.createElement("div");g.innerHTML="<div class='test e'></div><div class='test'></div>";if(!(!g.getElementsByClassName||g.getElementsByClassName("e").length===0)){g.lastChild.className="e";if(g.getElementsByClassName("e").length!==1){o.order.splice(1,0,"CLASS");o.find.CLASS=function(i,n,m){if(typeof n.getElementsByClassName!=="undefined"&&!m)return n.getElementsByClassName(i[1])};g=null}}})();k.contains=t.documentElement.contains?function(g,i){return g!==i&&(g.contains?g.contains(i):true)}:t.documentElement.compareDocumentPosition?
function(g,i){return!!(g.compareDocumentPosition(i)&16)}:function(){return false};k.isXML=function(g){return(g=(g?g.ownerDocument||g:0).documentElement)?g.nodeName!=="HTML":false};var L=function(g,i){for(var n,m=[],p="",q=i.nodeType?[i]:i;n=o.match.PSEUDO.exec(g);){p+=n[0];g=g.replace(o.match.PSEUDO,"")}g=o.relative[g]?g+"*":g;n=0;for(var u=q.length;n<u;n++)k(g,q[n],m);return k.filter(p,m)};c.find=k;c.expr=k.selectors;c.expr[":"]=c.expr.filters;c.unique=k.uniqueSort;c.text=k.getText;c.isXMLDoc=k.isXML;
c.contains=k.contains})();var Za=/Until$/,$a=/^(?:parents|prevUntil|prevAll)/,ab=/,/,Na=/^.[^:#\[\.,]*$/,bb=Array.prototype.slice,cb=c.expr.match.POS;c.fn.extend({find:function(a){for(var b=this.pushStack("","find",a),d=0,e=0,f=this.length;e<f;e++){d=b.length;c.find(a,this[e],b);if(e>0)for(var h=d;h<b.length;h++)for(var l=0;l<d;l++)if(b[l]===b[h]){b.splice(h--,1);break}}return b},has:function(a){var b=c(a);return this.filter(function(){for(var d=0,e=b.length;d<e;d++)if(c.contains(this,b[d]))return true})},
not:function(a){return this.pushStack(ma(this,a,false),"not",a)},filter:function(a){return this.pushStack(ma(this,a,true),"filter",a)},is:function(a){return!!a&&c.filter(a,this).length>0},closest:function(a,b){var d=[],e,f,h=this[0];if(c.isArray(a)){var l,k={},o=1;if(h&&a.length){e=0;for(f=a.length;e<f;e++){l=a[e];k[l]||(k[l]=c.expr.match.POS.test(l)?c(l,b||this.context):l)}for(;h&&h.ownerDocument&&h!==b;){for(l in k){e=k[l];if(e.jquery?e.index(h)>-1:c(h).is(e))d.push({selector:l,elem:h,level:o})}h=
h.parentNode;o++}}return d}l=cb.test(a)?c(a,b||this.context):null;e=0;for(f=this.length;e<f;e++)for(h=this[e];h;)if(l?l.index(h)>-1:c.find.matchesSelector(h,a)){d.push(h);break}else{h=h.parentNode;if(!h||!h.ownerDocument||h===b)break}d=d.length>1?c.unique(d):d;return this.pushStack(d,"closest",a)},index:function(a){if(!a||typeof a==="string")return c.inArray(this[0],a?c(a):this.parent().children());return c.inArray(a.jquery?a[0]:a,this)},add:function(a,b){var d=typeof a==="string"?c(a,b||this.context):
c.makeArray(a),e=c.merge(this.get(),d);return this.pushStack(!d[0]||!d[0].parentNode||d[0].parentNode.nodeType===11||!e[0]||!e[0].parentNode||e[0].parentNode.nodeType===11?e:c.unique(e))},andSelf:function(){return this.add(this.prevObject)}});c.each({parent:function(a){return(a=a.parentNode)&&a.nodeType!==11?a:null},parents:function(a){return c.dir(a,"parentNode")},parentsUntil:function(a,b,d){return c.dir(a,"parentNode",d)},next:function(a){return c.nth(a,2,"nextSibling")},prev:function(a){return c.nth(a,
2,"previousSibling")},nextAll:function(a){return c.dir(a,"nextSibling")},prevAll:function(a){return c.dir(a,"previousSibling")},nextUntil:function(a,b,d){return c.dir(a,"nextSibling",d)},prevUntil:function(a,b,d){return c.dir(a,"previousSibling",d)},siblings:function(a){return c.sibling(a.parentNode.firstChild,a)},children:function(a){return c.sibling(a.firstChild)},contents:function(a){return c.nodeName(a,"iframe")?a.contentDocument||a.contentWindow.document:c.makeArray(a.childNodes)}},function(a,
b){c.fn[a]=function(d,e){var f=c.map(this,b,d);Za.test(a)||(e=d);if(e&&typeof e==="string")f=c.filter(e,f);f=this.length>1?c.unique(f):f;if((this.length>1||ab.test(e))&&$a.test(a))f=f.reverse();return this.pushStack(f,a,bb.call(arguments).join(","))}});c.extend({filter:function(a,b,d){if(d)a=":not("+a+")";return b.length===1?c.find.matchesSelector(b[0],a)?[b[0]]:[]:c.find.matches(a,b)},dir:function(a,b,d){var e=[];for(a=a[b];a&&a.nodeType!==9&&(d===B||a.nodeType!==1||!c(a).is(d));){a.nodeType===1&&
e.push(a);a=a[b]}return e},nth:function(a,b,d){b=b||1;for(var e=0;a;a=a[d])if(a.nodeType===1&&++e===b)break;return a},sibling:function(a,b){for(var d=[];a;a=a.nextSibling)a.nodeType===1&&a!==b&&d.push(a);return d}});var za=/ jQuery\d+="(?:\d+|null)"/g,$=/^\s+/,Aa=/<(?!area|br|col|embed|hr|img|input|link|meta|param)(([\w:]+)[^>]*)\/>/ig,Ba=/<([\w:]+)/,db=/<tbody/i,eb=/<|&#?\w+;/,Ca=/<(?:script|object|embed|option|style)/i,Da=/checked\s*(?:[^=]|=\s*.checked.)/i,fb=/\=([^="'>\s]+\/)>/g,P={option:[1,
"<select multiple='multiple'>","</select>"],legend:[1,"<fieldset>","</fieldset>"],thead:[1,"<table>","</table>"],tr:[2,"<table><tbody>","</tbody></table>"],td:[3,"<table><tbody><tr>","</tr></tbody></table>"],col:[2,"<table><tbody></tbody><colgroup>","</colgroup></table>"],area:[1,"<map>","</map>"],_default:[0,"",""]};P.optgroup=P.option;P.tbody=P.tfoot=P.colgroup=P.caption=P.thead;P.th=P.td;if(!c.support.htmlSerialize)P._default=[1,"div<div>","</div>"];c.fn.extend({text:function(a){if(c.isFunction(a))return this.each(function(b){var d=
c(this);d.text(a.call(this,b,d.text()))});if(typeof a!=="object"&&a!==B)return this.empty().append((this[0]&&this[0].ownerDocument||t).createTextNode(a));return c.text(this)},wrapAll:function(a){if(c.isFunction(a))return this.each(function(d){c(this).wrapAll(a.call(this,d))});if(this[0]){var b=c(a,this[0].ownerDocument).eq(0).clone(true);this[0].parentNode&&b.insertBefore(this[0]);b.map(function(){for(var d=this;d.firstChild&&d.firstChild.nodeType===1;)d=d.firstChild;return d}).append(this)}return this},
wrapInner:function(a){if(c.isFunction(a))return this.each(function(b){c(this).wrapInner(a.call(this,b))});return this.each(function(){var b=c(this),d=b.contents();d.length?d.wrapAll(a):b.append(a)})},wrap:function(a){return this.each(function(){c(this).wrapAll(a)})},unwrap:function(){return this.parent().each(function(){c.nodeName(this,"body")||c(this).replaceWith(this.childNodes)}).end()},append:function(){return this.domManip(arguments,true,function(a){this.nodeType===1&&this.appendChild(a)})},
prepend:function(){return this.domManip(arguments,true,function(a){this.nodeType===1&&this.insertBefore(a,this.firstChild)})},before:function(){if(this[0]&&this[0].parentNode)return this.domManip(arguments,false,function(b){this.parentNode.insertBefore(b,this)});else if(arguments.length){var a=c(arguments[0]);a.push.apply(a,this.toArray());return this.pushStack(a,"before",arguments)}},after:function(){if(this[0]&&this[0].parentNode)return this.domManip(arguments,false,function(b){this.parentNode.insertBefore(b,
this.nextSibling)});else if(arguments.length){var a=this.pushStack(this,"after",arguments);a.push.apply(a,c(arguments[0]).toArray());return a}},remove:function(a,b){for(var d=0,e;(e=this[d])!=null;d++)if(!a||c.filter(a,[e]).length){if(!b&&e.nodeType===1){c.cleanData(e.getElementsByTagName("*"));c.cleanData([e])}e.parentNode&&e.parentNode.removeChild(e)}return this},empty:function(){for(var a=0,b;(b=this[a])!=null;a++)for(b.nodeType===1&&c.cleanData(b.getElementsByTagName("*"));b.firstChild;)b.removeChild(b.firstChild);
return this},clone:function(a){var b=this.map(function(){if(!c.support.noCloneEvent&&!c.isXMLDoc(this)){var d=this.outerHTML,e=this.ownerDocument;if(!d){d=e.createElement("div");d.appendChild(this.cloneNode(true));d=d.innerHTML}return c.clean([d.replace(za,"").replace(fb,'="$1">').replace($,"")],e)[0]}else return this.cloneNode(true)});if(a===true){na(this,b);na(this.find("*"),b.find("*"))}return b},html:function(a){if(a===B)return this[0]&&this[0].nodeType===1?this[0].innerHTML.replace(za,""):null;
else if(typeof a==="string"&&!Ca.test(a)&&(c.support.leadingWhitespace||!$.test(a))&&!P[(Ba.exec(a)||["",""])[1].toLowerCase()]){a=a.replace(Aa,"<$1></$2>");try{for(var b=0,d=this.length;b<d;b++)if(this[b].nodeType===1){c.cleanData(this[b].getElementsByTagName("*"));this[b].innerHTML=a}}catch(e){this.empty().append(a)}}else c.isFunction(a)?this.each(function(f){var h=c(this);h.html(a.call(this,f,h.html()))}):this.empty().append(a);return this},replaceWith:function(a){if(this[0]&&this[0].parentNode){if(c.isFunction(a))return this.each(function(b){var d=
c(this),e=d.html();d.replaceWith(a.call(this,b,e))});if(typeof a!=="string")a=c(a).detach();return this.each(function(){var b=this.nextSibling,d=this.parentNode;c(this).remove();b?c(b).before(a):c(d).append(a)})}else return this.pushStack(c(c.isFunction(a)?a():a),"replaceWith",a)},detach:function(a){return this.remove(a,true)},domManip:function(a,b,d){var e,f,h,l=a[0],k=[];if(!c.support.checkClone&&arguments.length===3&&typeof l==="string"&&Da.test(l))return this.each(function(){c(this).domManip(a,
b,d,true)});if(c.isFunction(l))return this.each(function(x){var r=c(this);a[0]=l.call(this,x,b?r.html():B);r.domManip(a,b,d)});if(this[0]){e=l&&l.parentNode;e=c.support.parentNode&&e&&e.nodeType===11&&e.childNodes.length===this.length?{fragment:e}:c.buildFragment(a,this,k);h=e.fragment;if(f=h.childNodes.length===1?h=h.firstChild:h.firstChild){b=b&&c.nodeName(f,"tr");f=0;for(var o=this.length;f<o;f++)d.call(b?c.nodeName(this[f],"table")?this[f].getElementsByTagName("tbody")[0]||this[f].appendChild(this[f].ownerDocument.createElement("tbody")):
this[f]:this[f],f>0||e.cacheable||this.length>1?h.cloneNode(true):h)}k.length&&c.each(k,Oa)}return this}});c.buildFragment=function(a,b,d){var e,f,h;b=b&&b[0]?b[0].ownerDocument||b[0]:t;if(a.length===1&&typeof a[0]==="string"&&a[0].length<512&&b===t&&!Ca.test(a[0])&&(c.support.checkClone||!Da.test(a[0]))){f=true;if(h=c.fragments[a[0]])if(h!==1)e=h}if(!e){e=b.createDocumentFragment();c.clean(a,b,e,d)}if(f)c.fragments[a[0]]=h?e:1;return{fragment:e,cacheable:f}};c.fragments={};c.each({appendTo:"append",
prependTo:"prepend",insertBefore:"before",insertAfter:"after",replaceAll:"replaceWith"},function(a,b){c.fn[a]=function(d){var e=[];d=c(d);var f=this.length===1&&this[0].parentNode;if(f&&f.nodeType===11&&f.childNodes.length===1&&d.length===1){d[b](this[0]);return this}else{f=0;for(var h=d.length;f<h;f++){var l=(f>0?this.clone(true):this).get();c(d[f])[b](l);e=e.concat(l)}return this.pushStack(e,a,d.selector)}}});c.extend({clean:function(a,b,d,e){b=b||t;if(typeof b.createElement==="undefined")b=b.ownerDocument||
b[0]&&b[0].ownerDocument||t;for(var f=[],h=0,l;(l=a[h])!=null;h++){if(typeof l==="number")l+="";if(l){if(typeof l==="string"&&!eb.test(l))l=b.createTextNode(l);else if(typeof l==="string"){l=l.replace(Aa,"<$1></$2>");var k=(Ba.exec(l)||["",""])[1].toLowerCase(),o=P[k]||P._default,x=o[0],r=b.createElement("div");for(r.innerHTML=o[1]+l+o[2];x--;)r=r.lastChild;if(!c.support.tbody){x=db.test(l);k=k==="table"&&!x?r.firstChild&&r.firstChild.childNodes:o[1]==="<table>"&&!x?r.childNodes:[];for(o=k.length-
1;o>=0;--o)c.nodeName(k[o],"tbody")&&!k[o].childNodes.length&&k[o].parentNode.removeChild(k[o])}!c.support.leadingWhitespace&&$.test(l)&&r.insertBefore(b.createTextNode($.exec(l)[0]),r.firstChild);l=r.childNodes}if(l.nodeType)f.push(l);else f=c.merge(f,l)}}if(d)for(h=0;f[h];h++)if(e&&c.nodeName(f[h],"script")&&(!f[h].type||f[h].type.toLowerCase()==="text/javascript"))e.push(f[h].parentNode?f[h].parentNode.removeChild(f[h]):f[h]);else{f[h].nodeType===1&&f.splice.apply(f,[h+1,0].concat(c.makeArray(f[h].getElementsByTagName("script"))));
d.appendChild(f[h])}return f},cleanData:function(a){for(var b,d,e=c.cache,f=c.event.special,h=c.support.deleteExpando,l=0,k;(k=a[l])!=null;l++)if(!(k.nodeName&&c.noData[k.nodeName.toLowerCase()]))if(d=k[c.expando]){if((b=e[d])&&b.events)for(var o in b.events)f[o]?c.event.remove(k,o):c.removeEvent(k,o,b.handle);if(h)delete k[c.expando];else k.removeAttribute&&k.removeAttribute(c.expando);delete e[d]}}});var Ea=/alpha\([^)]*\)/i,gb=/opacity=([^)]*)/,hb=/-([a-z])/ig,ib=/([A-Z])/g,Fa=/^-?\d+(?:px)?$/i,
jb=/^-?\d/,kb={position:"absolute",visibility:"hidden",display:"block"},Pa=["Left","Right"],Qa=["Top","Bottom"],W,Ga,aa,lb=function(a,b){return b.toUpperCase()};c.fn.css=function(a,b){if(arguments.length===2&&b===B)return this;return c.access(this,a,b,true,function(d,e,f){return f!==B?c.style(d,e,f):c.css(d,e)})};c.extend({cssHooks:{opacity:{get:function(a,b){if(b){var d=W(a,"opacity","opacity");return d===""?"1":d}else return a.style.opacity}}},cssNumber:{zIndex:true,fontWeight:true,opacity:true,
zoom:true,lineHeight:true},cssProps:{"float":c.support.cssFloat?"cssFloat":"styleFloat"},style:function(a,b,d,e){if(!(!a||a.nodeType===3||a.nodeType===8||!a.style)){var f,h=c.camelCase(b),l=a.style,k=c.cssHooks[h];b=c.cssProps[h]||h;if(d!==B){if(!(typeof d==="number"&&isNaN(d)||d==null)){if(typeof d==="number"&&!c.cssNumber[h])d+="px";if(!k||!("set"in k)||(d=k.set(a,d))!==B)try{l[b]=d}catch(o){}}}else{if(k&&"get"in k&&(f=k.get(a,false,e))!==B)return f;return l[b]}}},css:function(a,b,d){var e,f=c.camelCase(b),
h=c.cssHooks[f];b=c.cssProps[f]||f;if(h&&"get"in h&&(e=h.get(a,true,d))!==B)return e;else if(W)return W(a,b,f)},swap:function(a,b,d){var e={},f;for(f in b){e[f]=a.style[f];a.style[f]=b[f]}d.call(a);for(f in b)a.style[f]=e[f]},camelCase:function(a){return a.replace(hb,lb)}});c.curCSS=c.css;c.each(["height","width"],function(a,b){c.cssHooks[b]={get:function(d,e,f){var h;if(e){if(d.offsetWidth!==0)h=oa(d,b,f);else c.swap(d,kb,function(){h=oa(d,b,f)});if(h<=0){h=W(d,b,b);if(h==="0px"&&aa)h=aa(d,b,b);
if(h!=null)return h===""||h==="auto"?"0px":h}if(h<0||h==null){h=d.style[b];return h===""||h==="auto"?"0px":h}return typeof h==="string"?h:h+"px"}},set:function(d,e){if(Fa.test(e)){e=parseFloat(e);if(e>=0)return e+"px"}else return e}}});if(!c.support.opacity)c.cssHooks.opacity={get:function(a,b){return gb.test((b&&a.currentStyle?a.currentStyle.filter:a.style.filter)||"")?parseFloat(RegExp.$1)/100+"":b?"1":""},set:function(a,b){var d=a.style;d.zoom=1;var e=c.isNaN(b)?"":"alpha(opacity="+b*100+")",f=
d.filter||"";d.filter=Ea.test(f)?f.replace(Ea,e):d.filter+" "+e}};if(t.defaultView&&t.defaultView.getComputedStyle)Ga=function(a,b,d){var e;d=d.replace(ib,"-$1").toLowerCase();if(!(b=a.ownerDocument.defaultView))return B;if(b=b.getComputedStyle(a,null)){e=b.getPropertyValue(d);if(e===""&&!c.contains(a.ownerDocument.documentElement,a))e=c.style(a,d)}return e};if(t.documentElement.currentStyle)aa=function(a,b){var d,e,f=a.currentStyle&&a.currentStyle[b],h=a.style;if(!Fa.test(f)&&jb.test(f)){d=h.left;
e=a.runtimeStyle.left;a.runtimeStyle.left=a.currentStyle.left;h.left=b==="fontSize"?"1em":f||0;f=h.pixelLeft+"px";h.left=d;a.runtimeStyle.left=e}return f===""?"auto":f};W=Ga||aa;if(c.expr&&c.expr.filters){c.expr.filters.hidden=function(a){var b=a.offsetHeight;return a.offsetWidth===0&&b===0||!c.support.reliableHiddenOffsets&&(a.style.display||c.css(a,"display"))==="none"};c.expr.filters.visible=function(a){return!c.expr.filters.hidden(a)}}var mb=c.now(),nb=/<script\b[^<]*(?:(?!<\/script>)<[^<]*)*<\/script>/gi,
ob=/^(?:select|textarea)/i,pb=/^(?:color|date|datetime|email|hidden|month|number|password|range|search|tel|text|time|url|week)$/i,qb=/^(?:GET|HEAD)$/,Ra=/\[\]$/,T=/\=\?(&|$)/,ja=/\?/,rb=/([?&])_=[^&]*/,sb=/^(\w+:)?\/\/([^\/?#]+)/,tb=/%20/g,ub=/#.*$/,Ha=c.fn.load;c.fn.extend({load:function(a,b,d){if(typeof a!=="string"&&Ha)return Ha.apply(this,arguments);else if(!this.length)return this;var e=a.indexOf(" ");if(e>=0){var f=a.slice(e,a.length);a=a.slice(0,e)}e="GET";if(b)if(c.isFunction(b)){d=b;b=null}else if(typeof b===
"object"){b=c.param(b,c.ajaxSettings.traditional);e="POST"}var h=this;c.ajax({url:a,type:e,dataType:"html",data:b,complete:function(l,k){if(k==="success"||k==="notmodified")h.html(f?c("<div>").append(l.responseText.replace(nb,"")).find(f):l.responseText);d&&h.each(d,[l.responseText,k,l])}});return this},serialize:function(){return c.param(this.serializeArray())},serializeArray:function(){return this.map(function(){return this.elements?c.makeArray(this.elements):this}).filter(function(){return this.name&&
!this.disabled&&(this.checked||ob.test(this.nodeName)||pb.test(this.type))}).map(function(a,b){var d=c(this).val();return d==null?null:c.isArray(d)?c.map(d,function(e){return{name:b.name,value:e}}):{name:b.name,value:d}}).get()}});c.each("ajaxStart ajaxStop ajaxComplete ajaxError ajaxSuccess ajaxSend".split(" "),function(a,b){c.fn[b]=function(d){return this.bind(b,d)}});c.extend({get:function(a,b,d,e){if(c.isFunction(b)){e=e||d;d=b;b=null}return c.ajax({type:"GET",url:a,data:b,success:d,dataType:e})},
getScript:function(a,b){return c.get(a,null,b,"script")},getJSON:function(a,b,d){return c.get(a,b,d,"json")},post:function(a,b,d,e){if(c.isFunction(b)){e=e||d;d=b;b={}}return c.ajax({type:"POST",url:a,data:b,success:d,dataType:e})},ajaxSetup:function(a){c.extend(c.ajaxSettings,a)},ajaxSettings:{url:location.href,global:true,type:"GET",contentType:"application/x-www-form-urlencoded",processData:true,async:true,xhr:function(){return new E.XMLHttpRequest},accepts:{xml:"application/xml, text/xml",html:"text/html",
script:"text/javascript, application/javascript",json:"application/json, text/javascript",text:"text/plain",_default:"*/*"}},ajax:function(a){var b=c.extend(true,{},c.ajaxSettings,a),d,e,f,h=b.type.toUpperCase(),l=qb.test(h);b.url=b.url.replace(ub,"");b.context=a&&a.context!=null?a.context:b;if(b.data&&b.processData&&typeof b.data!=="string")b.data=c.param(b.data,b.traditional);if(b.dataType==="jsonp"){if(h==="GET")T.test(b.url)||(b.url+=(ja.test(b.url)?"&":"?")+(b.jsonp||"callback")+"=?");else if(!b.data||
!T.test(b.data))b.data=(b.data?b.data+"&":"")+(b.jsonp||"callback")+"=?";b.dataType="json"}if(b.dataType==="json"&&(b.data&&T.test(b.data)||T.test(b.url))){d=b.jsonpCallback||"jsonp"+mb++;if(b.data)b.data=(b.data+"").replace(T,"="+d+"$1");b.url=b.url.replace(T,"="+d+"$1");b.dataType="script";var k=E[d];E[d]=function(m){if(c.isFunction(k))k(m);else{E[d]=B;try{delete E[d]}catch(p){}}f=m;c.handleSuccess(b,w,e,f);c.handleComplete(b,w,e,f);r&&r.removeChild(A)}}if(b.dataType==="script"&&b.cache===null)b.cache=
false;if(b.cache===false&&l){var o=c.now(),x=b.url.replace(rb,"$1_="+o);b.url=x+(x===b.url?(ja.test(b.url)?"&":"?")+"_="+o:"")}if(b.data&&l)b.url+=(ja.test(b.url)?"&":"?")+b.data;b.global&&c.active++===0&&c.event.trigger("ajaxStart");o=(o=sb.exec(b.url))&&(o[1]&&o[1].toLowerCase()!==location.protocol||o[2].toLowerCase()!==location.host);if(b.dataType==="script"&&h==="GET"&&o){var r=t.getElementsByTagName("head")[0]||t.documentElement,A=t.createElement("script");if(b.scriptCharset)A.charset=b.scriptCharset;
A.src=b.url;if(!d){var C=false;A.onload=A.onreadystatechange=function(){if(!C&&(!this.readyState||this.readyState==="loaded"||this.readyState==="complete")){C=true;c.handleSuccess(b,w,e,f);c.handleComplete(b,w,e,f);A.onload=A.onreadystatechange=null;r&&A.parentNode&&r.removeChild(A)}}}r.insertBefore(A,r.firstChild);return B}var J=false,w=b.xhr();if(w){b.username?w.open(h,b.url,b.async,b.username,b.password):w.open(h,b.url,b.async);try{if(b.data!=null&&!l||a&&a.contentType)w.setRequestHeader("Content-Type",
b.contentType);if(b.ifModified){c.lastModified[b.url]&&w.setRequestHeader("If-Modified-Since",c.lastModified[b.url]);c.etag[b.url]&&w.setRequestHeader("If-None-Match",c.etag[b.url])}o||w.setRequestHeader("X-Requested-With","XMLHttpRequest");w.setRequestHeader("Accept",b.dataType&&b.accepts[b.dataType]?b.accepts[b.dataType]+", */*; q=0.01":b.accepts._default)}catch(I){}if(b.beforeSend&&b.beforeSend.call(b.context,w,b)===false){b.global&&c.active--===1&&c.event.trigger("ajaxStop");w.abort();return false}b.global&&
c.triggerGlobal(b,"ajaxSend",[w,b]);var L=w.onreadystatechange=function(m){if(!w||w.readyState===0||m==="abort"){J||c.handleComplete(b,w,e,f);J=true;if(w)w.onreadystatechange=c.noop}else if(!J&&w&&(w.readyState===4||m==="timeout")){J=true;w.onreadystatechange=c.noop;e=m==="timeout"?"timeout":!c.httpSuccess(w)?"error":b.ifModified&&c.httpNotModified(w,b.url)?"notmodified":"success";var p;if(e==="success")try{f=c.httpData(w,b.dataType,b)}catch(q){e="parsererror";p=q}if(e==="success"||e==="notmodified")d||
c.handleSuccess(b,w,e,f);else c.handleError(b,w,e,p);d||c.handleComplete(b,w,e,f);m==="timeout"&&w.abort();if(b.async)w=null}};try{var g=w.abort;w.abort=function(){w&&Function.prototype.call.call(g,w);L("abort")}}catch(i){}b.async&&b.timeout>0&&setTimeout(function(){w&&!J&&L("timeout")},b.timeout);try{w.send(l||b.data==null?null:b.data)}catch(n){c.handleError(b,w,null,n);c.handleComplete(b,w,e,f)}b.async||L();return w}},param:function(a,b){var d=[],e=function(h,l){l=c.isFunction(l)?l():l;d[d.length]=
encodeURIComponent(h)+"="+encodeURIComponent(l)};if(b===B)b=c.ajaxSettings.traditional;if(c.isArray(a)||a.jquery)c.each(a,function(){e(this.name,this.value)});else for(var f in a)da(f,a[f],b,e);return d.join("&").replace(tb,"+")}});c.extend({active:0,lastModified:{},etag:{},handleError:function(a,b,d,e){a.error&&a.error.call(a.context,b,d,e);a.global&&c.triggerGlobal(a,"ajaxError",[b,a,e])},handleSuccess:function(a,b,d,e){a.success&&a.success.call(a.context,e,d,b);a.global&&c.triggerGlobal(a,"ajaxSuccess",
[b,a])},handleComplete:function(a,b,d){a.complete&&a.complete.call(a.context,b,d);a.global&&c.triggerGlobal(a,"ajaxComplete",[b,a]);a.global&&c.active--===1&&c.event.trigger("ajaxStop")},triggerGlobal:function(a,b,d){(a.context&&a.context.url==null?c(a.context):c.event).trigger(b,d)},httpSuccess:function(a){try{return!a.status&&location.protocol==="file:"||a.status>=200&&a.status<300||a.status===304||a.status===1223}catch(b){}return false},httpNotModified:function(a,b){var d=a.getResponseHeader("Last-Modified"),
e=a.getResponseHeader("Etag");if(d)c.lastModified[b]=d;if(e)c.etag[b]=e;return a.status===304},httpData:function(a,b,d){var e=a.getResponseHeader("content-type")||"",f=b==="xml"||!b&&e.indexOf("xml")>=0;a=f?a.responseXML:a.responseText;f&&a.documentElement.nodeName==="parsererror"&&c.error("parsererror");if(d&&d.dataFilter)a=d.dataFilter(a,b);if(typeof a==="string")if(b==="json"||!b&&e.indexOf("json")>=0)a=c.parseJSON(a);else if(b==="script"||!b&&e.indexOf("javascript")>=0)c.globalEval(a);return a}});
if(E.ActiveXObject)c.ajaxSettings.xhr=function(){if(E.location.protocol!=="file:")try{return new E.XMLHttpRequest}catch(a){}try{return new E.ActiveXObject("Microsoft.XMLHTTP")}catch(b){}};c.support.ajax=!!c.ajaxSettings.xhr();var ea={},vb=/^(?:toggle|show|hide)$/,wb=/^([+\-]=)?([\d+.\-]+)(.*)$/,ba,pa=[["height","marginTop","marginBottom","paddingTop","paddingBottom"],["width","marginLeft","marginRight","paddingLeft","paddingRight"],["opacity"]];c.fn.extend({show:function(a,b,d){if(a||a===0)return this.animate(S("show",
3),a,b,d);else{d=0;for(var e=this.length;d<e;d++){a=this[d];b=a.style.display;if(!c.data(a,"olddisplay")&&b==="none")b=a.style.display="";b===""&&c.css(a,"display")==="none"&&c.data(a,"olddisplay",qa(a.nodeName))}for(d=0;d<e;d++){a=this[d];b=a.style.display;if(b===""||b==="none")a.style.display=c.data(a,"olddisplay")||""}return this}},hide:function(a,b,d){if(a||a===0)return this.animate(S("hide",3),a,b,d);else{a=0;for(b=this.length;a<b;a++){d=c.css(this[a],"display");d!=="none"&&c.data(this[a],"olddisplay",
d)}for(a=0;a<b;a++)this[a].style.display="none";return this}},_toggle:c.fn.toggle,toggle:function(a,b,d){var e=typeof a==="boolean";if(c.isFunction(a)&&c.isFunction(b))this._toggle.apply(this,arguments);else a==null||e?this.each(function(){var f=e?a:c(this).is(":hidden");c(this)[f?"show":"hide"]()}):this.animate(S("toggle",3),a,b,d);return this},fadeTo:function(a,b,d,e){return this.filter(":hidden").css("opacity",0).show().end().animate({opacity:b},a,d,e)},animate:function(a,b,d,e){var f=c.speed(b,
d,e);if(c.isEmptyObject(a))return this.each(f.complete);return this[f.queue===false?"each":"queue"](function(){var h=c.extend({},f),l,k=this.nodeType===1,o=k&&c(this).is(":hidden"),x=this;for(l in a){var r=c.camelCase(l);if(l!==r){a[r]=a[l];delete a[l];l=r}if(a[l]==="hide"&&o||a[l]==="show"&&!o)return h.complete.call(this);if(k&&(l==="height"||l==="width")){h.overflow=[this.style.overflow,this.style.overflowX,this.style.overflowY];if(c.css(this,"display")==="inline"&&c.css(this,"float")==="none")if(c.support.inlineBlockNeedsLayout)if(qa(this.nodeName)===
"inline")this.style.display="inline-block";else{this.style.display="inline";this.style.zoom=1}else this.style.display="inline-block"}if(c.isArray(a[l])){(h.specialEasing=h.specialEasing||{})[l]=a[l][1];a[l]=a[l][0]}}if(h.overflow!=null)this.style.overflow="hidden";h.curAnim=c.extend({},a);c.each(a,function(A,C){var J=new c.fx(x,h,A);if(vb.test(C))J[C==="toggle"?o?"show":"hide":C](a);else{var w=wb.exec(C),I=J.cur()||0;if(w){var L=parseFloat(w[2]),g=w[3]||"px";if(g!=="px"){c.style(x,A,(L||1)+g);I=(L||
1)/J.cur()*I;c.style(x,A,I+g)}if(w[1])L=(w[1]==="-="?-1:1)*L+I;J.custom(I,L,g)}else J.custom(I,C,"")}});return true})},stop:function(a,b){var d=c.timers;a&&this.queue([]);this.each(function(){for(var e=d.length-1;e>=0;e--)if(d[e].elem===this){b&&d[e](true);d.splice(e,1)}});b||this.dequeue();return this}});c.each({slideDown:S("show",1),slideUp:S("hide",1),slideToggle:S("toggle",1),fadeIn:{opacity:"show"},fadeOut:{opacity:"hide"},fadeToggle:{opacity:"toggle"}},function(a,b){c.fn[a]=function(d,e,f){return this.animate(b,
d,e,f)}});c.extend({speed:function(a,b,d){var e=a&&typeof a==="object"?c.extend({},a):{complete:d||!d&&b||c.isFunction(a)&&a,duration:a,easing:d&&b||b&&!c.isFunction(b)&&b};e.duration=c.fx.off?0:typeof e.duration==="number"?e.duration:e.duration in c.fx.speeds?c.fx.speeds[e.duration]:c.fx.speeds._default;e.old=e.complete;e.complete=function(){e.queue!==false&&c(this).dequeue();c.isFunction(e.old)&&e.old.call(this)};return e},easing:{linear:function(a,b,d,e){return d+e*a},swing:function(a,b,d,e){return(-Math.cos(a*
Math.PI)/2+0.5)*e+d}},timers:[],fx:function(a,b,d){this.options=b;this.elem=a;this.prop=d;if(!b.orig)b.orig={}}});c.fx.prototype={update:function(){this.options.step&&this.options.step.call(this.elem,this.now,this);(c.fx.step[this.prop]||c.fx.step._default)(this)},cur:function(){if(this.elem[this.prop]!=null&&(!this.elem.style||this.elem.style[this.prop]==null))return this.elem[this.prop];var a=parseFloat(c.css(this.elem,this.prop));return a&&a>-1E4?a:0},custom:function(a,b,d){function e(l){return f.step(l)}
var f=this,h=c.fx;this.startTime=c.now();this.start=a;this.end=b;this.unit=d||this.unit||"px";this.now=this.start;this.pos=this.state=0;e.elem=this.elem;if(e()&&c.timers.push(e)&&!ba)ba=setInterval(h.tick,h.interval)},show:function(){this.options.orig[this.prop]=c.style(this.elem,this.prop);this.options.show=true;this.custom(this.prop==="width"||this.prop==="height"?1:0,this.cur());c(this.elem).show()},hide:function(){this.options.orig[this.prop]=c.style(this.elem,this.prop);this.options.hide=true;
this.custom(this.cur(),0)},step:function(a){var b=c.now(),d=true;if(a||b>=this.options.duration+this.startTime){this.now=this.end;this.pos=this.state=1;this.update();this.options.curAnim[this.prop]=true;for(var e in this.options.curAnim)if(this.options.curAnim[e]!==true)d=false;if(d){if(this.options.overflow!=null&&!c.support.shrinkWrapBlocks){var f=this.elem,h=this.options;c.each(["","X","Y"],function(k,o){f.style["overflow"+o]=h.overflow[k]})}this.options.hide&&c(this.elem).hide();if(this.options.hide||
this.options.show)for(var l in this.options.curAnim)c.style(this.elem,l,this.options.orig[l]);this.options.complete.call(this.elem)}return false}else{a=b-this.startTime;this.state=a/this.options.duration;b=this.options.easing||(c.easing.swing?"swing":"linear");this.pos=c.easing[this.options.specialEasing&&this.options.specialEasing[this.prop]||b](this.state,a,0,1,this.options.duration);this.now=this.start+(this.end-this.start)*this.pos;this.update()}return true}};c.extend(c.fx,{tick:function(){for(var a=
c.timers,b=0;b<a.length;b++)a[b]()||a.splice(b--,1);a.length||c.fx.stop()},interval:13,stop:function(){clearInterval(ba);ba=null},speeds:{slow:600,fast:200,_default:400},step:{opacity:function(a){c.style(a.elem,"opacity",a.now)},_default:function(a){if(a.elem.style&&a.elem.style[a.prop]!=null)a.elem.style[a.prop]=(a.prop==="width"||a.prop==="height"?Math.max(0,a.now):a.now)+a.unit;else a.elem[a.prop]=a.now}}});if(c.expr&&c.expr.filters)c.expr.filters.animated=function(a){return c.grep(c.timers,function(b){return a===
b.elem}).length};var xb=/^t(?:able|d|h)$/i,Ia=/^(?:body|html)$/i;c.fn.offset="getBoundingClientRect"in t.documentElement?function(a){var b=this[0],d;if(a)return this.each(function(l){c.offset.setOffset(this,a,l)});if(!b||!b.ownerDocument)return null;if(b===b.ownerDocument.body)return c.offset.bodyOffset(b);try{d=b.getBoundingClientRect()}catch(e){}var f=b.ownerDocument,h=f.documentElement;if(!d||!c.contains(h,b))return d||{top:0,left:0};b=f.body;f=fa(f);return{top:d.top+(f.pageYOffset||c.support.boxModel&&
h.scrollTop||b.scrollTop)-(h.clientTop||b.clientTop||0),left:d.left+(f.pageXOffset||c.support.boxModel&&h.scrollLeft||b.scrollLeft)-(h.clientLeft||b.clientLeft||0)}}:function(a){var b=this[0];if(a)return this.each(function(x){c.offset.setOffset(this,a,x)});if(!b||!b.ownerDocument)return null;if(b===b.ownerDocument.body)return c.offset.bodyOffset(b);c.offset.initialize();var d,e=b.offsetParent,f=b.ownerDocument,h=f.documentElement,l=f.body;d=(f=f.defaultView)?f.getComputedStyle(b,null):b.currentStyle;
for(var k=b.offsetTop,o=b.offsetLeft;(b=b.parentNode)&&b!==l&&b!==h;){if(c.offset.supportsFixedPosition&&d.position==="fixed")break;d=f?f.getComputedStyle(b,null):b.currentStyle;k-=b.scrollTop;o-=b.scrollLeft;if(b===e){k+=b.offsetTop;o+=b.offsetLeft;if(c.offset.doesNotAddBorder&&!(c.offset.doesAddBorderForTableAndCells&&xb.test(b.nodeName))){k+=parseFloat(d.borderTopWidth)||0;o+=parseFloat(d.borderLeftWidth)||0}e=b.offsetParent}if(c.offset.subtractsBorderForOverflowNotVisible&&d.overflow!=="visible"){k+=
parseFloat(d.borderTopWidth)||0;o+=parseFloat(d.borderLeftWidth)||0}d=d}if(d.position==="relative"||d.position==="static"){k+=l.offsetTop;o+=l.offsetLeft}if(c.offset.supportsFixedPosition&&d.position==="fixed"){k+=Math.max(h.scrollTop,l.scrollTop);o+=Math.max(h.scrollLeft,l.scrollLeft)}return{top:k,left:o}};c.offset={initialize:function(){var a=t.body,b=t.createElement("div"),d,e,f,h=parseFloat(c.css(a,"marginTop"))||0;c.extend(b.style,{position:"absolute",top:0,left:0,margin:0,border:0,width:"1px",
height:"1px",visibility:"hidden"});b.innerHTML="<div style='position:absolute;top:0;left:0;margin:0;border:5px solid #000;padding:0;width:1px;height:1px;'><div></div></div><table style='position:absolute;top:0;left:0;margin:0;border:5px solid #000;padding:0;width:1px;height:1px;' cellpadding='0' cellspacing='0'><tr><td></td></tr></table>";a.insertBefore(b,a.firstChild);d=b.firstChild;e=d.firstChild;f=d.nextSibling.firstChild.firstChild;this.doesNotAddBorder=e.offsetTop!==5;this.doesAddBorderForTableAndCells=
f.offsetTop===5;e.style.position="fixed";e.style.top="20px";this.supportsFixedPosition=e.offsetTop===20||e.offsetTop===15;e.style.position=e.style.top="";d.style.overflow="hidden";d.style.position="relative";this.subtractsBorderForOverflowNotVisible=e.offsetTop===-5;this.doesNotIncludeMarginInBodyOffset=a.offsetTop!==h;a.removeChild(b);c.offset.initialize=c.noop},bodyOffset:function(a){var b=a.offsetTop,d=a.offsetLeft;c.offset.initialize();if(c.offset.doesNotIncludeMarginInBodyOffset){b+=parseFloat(c.css(a,
"marginTop"))||0;d+=parseFloat(c.css(a,"marginLeft"))||0}return{top:b,left:d}},setOffset:function(a,b,d){var e=c.css(a,"position");if(e==="static")a.style.position="relative";var f=c(a),h=f.offset(),l=c.css(a,"top"),k=c.css(a,"left"),o=e==="absolute"&&c.inArray("auto",[l,k])>-1;e={};var x={};if(o)x=f.position();l=o?x.top:parseInt(l,10)||0;k=o?x.left:parseInt(k,10)||0;if(c.isFunction(b))b=b.call(a,d,h);if(b.top!=null)e.top=b.top-h.top+l;if(b.left!=null)e.left=b.left-h.left+k;"using"in b?b.using.call(a,
e):f.css(e)}};c.fn.extend({position:function(){if(!this[0])return null;var a=this[0],b=this.offsetParent(),d=this.offset(),e=Ia.test(b[0].nodeName)?{top:0,left:0}:b.offset();d.top-=parseFloat(c.css(a,"marginTop"))||0;d.left-=parseFloat(c.css(a,"marginLeft"))||0;e.top+=parseFloat(c.css(b[0],"borderTopWidth"))||0;e.left+=parseFloat(c.css(b[0],"borderLeftWidth"))||0;return{top:d.top-e.top,left:d.left-e.left}},offsetParent:function(){return this.map(function(){for(var a=this.offsetParent||t.body;a&&!Ia.test(a.nodeName)&&
c.css(a,"position")==="static";)a=a.offsetParent;return a})}});c.each(["Left","Top"],function(a,b){var d="scroll"+b;c.fn[d]=function(e){var f=this[0],h;if(!f)return null;if(e!==B)return this.each(function(){if(h=fa(this))h.scrollTo(!a?e:c(h).scrollLeft(),a?e:c(h).scrollTop());else this[d]=e});else return(h=fa(f))?"pageXOffset"in h?h[a?"pageYOffset":"pageXOffset"]:c.support.boxModel&&h.document.documentElement[d]||h.document.body[d]:f[d]}});c.each(["Height","Width"],function(a,b){var d=b.toLowerCase();
c.fn["inner"+b]=function(){return this[0]?parseFloat(c.css(this[0],d,"padding")):null};c.fn["outer"+b]=function(e){return this[0]?parseFloat(c.css(this[0],d,e?"margin":"border")):null};c.fn[d]=function(e){var f=this[0];if(!f)return e==null?null:this;if(c.isFunction(e))return this.each(function(l){var k=c(this);k[d](e.call(this,l,k[d]()))});if(c.isWindow(f))return f.document.compatMode==="CSS1Compat"&&f.document.documentElement["client"+b]||f.document.body["client"+b];else if(f.nodeType===9)return Math.max(f.documentElement["client"+
b],f.body["scroll"+b],f.documentElement["scroll"+b],f.body["offset"+b],f.documentElement["offset"+b]);else if(e===B){f=c.css(f,d);var h=parseFloat(f);return c.isNaN(h)?f:h}else return this.css(d,typeof e==="string"?e:e+"px")}})})(window);
</script><script type="text/javascript">//XRegExp 1.5.0 <xregexp.com> MIT License
var XRegExp;if(XRegExp){throw Error("can't load XRegExp twice in the same frame")}(function(){XRegExp=function(w,r){var q=[],u=XRegExp.OUTSIDE_CLASS,x=0,p,s,v,t,y;if(XRegExp.isRegExp(w)){if(r!==undefined){throw TypeError("can't supply flags when constructing one RegExp from another")}return j(w)}if(g){throw Error("can't call the XRegExp constructor within token definition functions")}r=r||"";p={hasNamedCapture:false,captureNames:[],hasFlag:function(z){return r.indexOf(z)>-1},setFlag:function(z){r+=z}};while(x<w.length){s=o(w,x,u,p);if(s){q.push(s.output);x+=(s.match[0].length||1)}else{if(v=m.exec.call(i[u],w.slice(x))){q.push(v[0]);x+=v[0].length}else{t=w.charAt(x);if(t==="["){u=XRegExp.INSIDE_CLASS}else{if(t==="]"){u=XRegExp.OUTSIDE_CLASS}}q.push(t);x++}}}y=RegExp(q.join(""),m.replace.call(r,h,""));y._xregexp={source:w,captureNames:p.hasNamedCapture?p.captureNames:null};return y};XRegExp.version="1.5.0";XRegExp.INSIDE_CLASS=1;XRegExp.OUTSIDE_CLASS=2;var c=/\$(?:(\d\d?|[$&`'])|{([$\w]+)})/g,h=/[^gimy]+|([\s\S])(?=[\s\S]*\1)/g,n=/^(?:[?*+]|{\d+(?:,\d*)?})\??/,g=false,k=[],m={exec:RegExp.prototype.exec,test:RegExp.prototype.test,match:String.prototype.match,replace:String.prototype.replace,split:String.prototype.split},a=m.exec.call(/()??/,"")[1]===undefined,e=function(){var p=/^/g;m.test.call(p,"");return !p.lastIndex}(),f=function(){var p=/x/g;m.replace.call("x",p,"");return !p.lastIndex}(),b=RegExp.prototype.sticky!==undefined,i={};i[XRegExp.INSIDE_CLASS]=/^(?:\\(?:[0-3][0-7]{0,2}|[4-7][0-7]?|x[\dA-Fa-f]{2}|u[\dA-Fa-f]{4}|c[A-Za-z]|[\s\S]))/;i[XRegExp.OUTSIDE_CLASS]=/^(?:\\(?:0(?:[0-3][0-7]{0,2}|[4-7][0-7]?)?|[1-9]\d*|x[\dA-Fa-f]{2}|u[\dA-Fa-f]{4}|c[A-Za-z]|[\s\S])|\(\?[:=!]|[?*+]\?|{\d+(?:,\d*)?}\??)/;XRegExp.addToken=function(s,r,q,p){k.push({pattern:j(s,"g"+(b?"y":"")),handler:r,scope:q||XRegExp.OUTSIDE_CLASS,trigger:p||null})};XRegExp.cache=function(r,p){var q=r+"/"+(p||"");return XRegExp.cache[q]||(XRegExp.cache[q]=XRegExp(r,p))};XRegExp.copyAsGlobal=function(p){return j(p,"g")};XRegExp.escape=function(p){return p.replace(/[-[\]{}()*+?.,\\^$|#\s]/g,"\\$&")};XRegExp.execAt=function(s,r,t,q){r=j(r,"g"+((q&&b)?"y":""));r.lastIndex=t=t||0;var p=r.exec(s);if(q){return(p&&p.index===t)?p:null}else{return p}};XRegExp.freezeTokens=function(){XRegExp.addToken=function(){throw Error("can't run addToken after freezeTokens")}};XRegExp.isRegExp=function(p){return Object.prototype.toString.call(p)==="[object RegExp]"};XRegExp.iterate=function(u,p,v,s){var t=j(p,"g"),r=-1,q;while(q=t.exec(u)){v.call(s,q,++r,u,t);if(t.lastIndex===q.index){t.lastIndex++}}if(p.global){p.lastIndex=0}};XRegExp.matchChain=function(q,p){return function r(s,x){var v=p[x].regex?p[x]:{regex:p[x]},u=j(v.regex,"g"),w=[],t;for(t=0;t<s.length;t++){XRegExp.iterate(s[t],u,function(y){w.push(v.backref?(y[v.backref]||""):y[0])})}return((x===p.length-1)||!w.length)?w:r(w,x+1)}([q],0)};RegExp.prototype.apply=function(q,p){return this.exec(p[0])};RegExp.prototype.call=function(p,q){return this.exec(q)};RegExp.prototype.exec=function(t){var r=m.exec.apply(this,arguments),q,p;if(r){if(!a&&r.length>1&&l(r,"")>-1){p=RegExp(this.source,m.replace.call(d(this),"g",""));m.replace.call(t.slice(r.index),p,function(){for(var u=1;u<arguments.length-2;u++){if(arguments[u]===undefined){r[u]=undefined}}})}if(this._xregexp&&this._xregexp.captureNames){for(var s=1;s<r.length;s++){q=this._xregexp.captureNames[s-1];if(q){r[q]=r[s]}}}if(!e&&this.global&&!r[0].length&&(this.lastIndex>r.index)){this.lastIndex--}}return r};if(!e){RegExp.prototype.test=function(q){var p=m.exec.call(this,q);if(p&&this.global&&!p[0].length&&(this.lastIndex>p.index)){this.lastIndex--}return !!p}}String.prototype.match=function(q){if(!XRegExp.isRegExp(q)){q=RegExp(q)}if(q.global){var p=m.match.apply(this,arguments);q.lastIndex=0;return p}return q.exec(this)};String.prototype.replace=function(r,s){var t=XRegExp.isRegExp(r),q,p,u;if(t&&typeof s.valueOf()==="string"&&s.indexOf("${")===-1&&f){return m.replace.apply(this,arguments)}if(!t){r=r+""}else{if(r._xregexp){q=r._xregexp.captureNames}}if(typeof s==="function"){p=m.replace.call(this,r,function(){if(q){arguments[0]=new String(arguments[0]);for(var v=0;v<q.length;v++){if(q[v]){arguments[0][q[v]]=arguments[v+1]}}}if(t&&r.global){r.lastIndex=arguments[arguments.length-2]+arguments[0].length}return s.apply(null,arguments)})}else{u=this+"";p=m.replace.call(u,r,function(){var v=arguments;return m.replace.call(s,c,function(x,w,A){if(w){switch(w){case"$":return"$";case"&":return v[0];case"`":return v[v.length-1].slice(0,v[v.length-2]);case"'":return v[v.length-1].slice(v[v.length-2]+v[0].length);default:var y="";w=+w;if(!w){return x}while(w>v.length-3){y=String.prototype.slice.call(w,-1)+y;w=Math.floor(w/10)}return(w?v[w]||"":"$")+y}}else{var z=+A;if(z<=v.length-3){return v[z]}z=q?l(q,A):-1;return z>-1?v[z+1]:x}})})}if(t&&r.global){r.lastIndex=0}return p};String.prototype.split=function(u,p){if(!XRegExp.isRegExp(u)){return m.split.apply(this,arguments)}var w=this+"",r=[],v=0,t,q;if(p===undefined||+p<0){p=Infinity}else{p=Math.floor(+p);if(!p){return[]}}u=XRegExp.copyAsGlobal(u);while(t=u.exec(w)){if(u.lastIndex>v){r.push(w.slice(v,t.index));if(t.length>1&&t.index<w.length){Array.prototype.push.apply(r,t.slice(1))}q=t[0].length;v=u.lastIndex;if(r.length>=p){break}}if(u.lastIndex===t.index){u.lastIndex++}}if(v===w.length){if(!m.test.call(u,"")||q){r.push("")}}else{r.push(w.slice(v))}return r.length>p?r.slice(0,p):r};function j(r,q){if(!XRegExp.isRegExp(r)){throw TypeError("type RegExp expected")}var p=r._xregexp;r=XRegExp(r.source,d(r)+(q||""));if(p){r._xregexp={source:p.source,captureNames:p.captureNames?p.captureNames.slice(0):null}}return r}function d(p){return(p.global?"g":"")+(p.ignoreCase?"i":"")+(p.multiline?"m":"")+(p.extended?"x":"")+(p.sticky?"y":"")}function o(v,u,w,p){var r=k.length,y,s,x;g=true;try{while(r--){x=k[r];if((w&x.scope)&&(!x.trigger||x.trigger.call(p))){x.pattern.lastIndex=u;s=x.pattern.exec(v);if(s&&s.index===u){y={output:x.handler.call(p,s,w),match:s};break}}}}catch(q){throw q}finally{g=false}return y}function l(s,q,r){if(Array.prototype.indexOf){return s.indexOf(q,r)}for(var p=r||0;p<s.length;p++){if(s[p]===q){return p}}return -1}XRegExp.addToken(/\(\?#[^)]*\)/,function(p){return m.test.call(n,p.input.slice(p.index+p[0].length))?"":"(?:)"});XRegExp.addToken(/\((?!\?)/,function(){this.captureNames.push(null);return"("});XRegExp.addToken(/\(\?<([$\w]+)>/,function(p){this.captureNames.push(p[1]);this.hasNamedCapture=true;return"("});XRegExp.addToken(/\\k<([\w$]+)>/,function(q){var p=l(this.captureNames,q[1]);return p>-1?"\\"+(p+1)+(isNaN(q.input.charAt(q.index+q[0].length))?"":"(?:)"):q[0]});XRegExp.addToken(/\[\^?]/,function(p){return p[0]==="[]"?"\\b\\B":"[\\s\\S]"});XRegExp.addToken(/^\(\?([imsx]+)\)/,function(p){this.setFlag(p[1]);return""});XRegExp.addToken(/(?:\s+|#.*)+/,function(p){return m.test.call(n,p.input.slice(p.index+p[0].length))?"":"(?:)"},XRegExp.OUTSIDE_CLASS,function(){return this.hasFlag("x")});XRegExp.addToken(/\./,function(){return"[\\s\\S]"},XRegExp.OUTSIDE_CLASS,function(){return this.hasFlag("s")})})();
</script><script type="text/javascript">/**
 * SyntaxHighlighter
 * http://alexgorbatchev.com/SyntaxHighlighter
 *
 * SyntaxHighlighter is donationware. If you are using it, please donate.
 * http://alexgorbatchev.com/SyntaxHighlighter/donate.html
 *
 * @version
 * 3.0.83 (July 02 2010)
 * 
 * @copyright
 * Copyright (C) 2004-2010 Alex Gorbatchev.
 *
 * @license
 * Dual licensed under the MIT and GPL licenses.
 */
//
// Begin anonymous function. This is used to contain local scope variables without polutting global scope.
//
var SyntaxHighlighter = function() { 

// CommonJS
if (typeof(require) != 'undefined' && typeof(XRegExp) == 'undefined')
{
	XRegExp = require('XRegExp').XRegExp;
}

// Shortcut object which will be assigned to the SyntaxHighlighter variable.
// This is a shorthand for local reference in order to avoid long namespace 
// references to SyntaxHighlighter.whatever...
var sh = {
	defaults : {
		/** Additional CSS class names to be added to highlighter elements. */
		'class-name' : '',
		
		/** First line number. */
		'first-line' : 1,
		
		/**
		 * Pads line numbers. Possible values are:
		 *
		 *   false - don't pad line numbers.
		 *   true  - automaticaly pad numbers with minimum required number of leading zeroes.
		 *   [int] - length up to which pad line numbers.
		 */
		'pad-line-numbers' : false,
		
		/** Lines to highlight. */
		'highlight' : null,
		
		/** Title to be displayed above the code block. */
		'title' : null,
		
		/** Enables or disables smart tabs. */
		'smart-tabs' : true,
		
		/** Gets or sets tab size. */
		'tab-size' : 4,
		
		/** Enables or disables gutter. */
		'gutter' : true,
		
		/** Enables or disables toolbar. */
		'toolbar' : true,
		
		/** Enables quick code copy and paste from double click. */
		'quick-code' : true,
		
		/** Forces code view to be collapsed. */
		'collapse' : false,
		
		/** Enables or disables automatic links. */
		'auto-links' : true,
		
		/** Gets or sets light mode. Equavalent to turning off gutter and toolbar. */
		'light' : false,
		
		'html-script' : false
	},
	
	config : {
		space : '&nbsp;',
		
		/** Enables use of <SCRIPT type="syntaxhighlighter" /> tags. */
		useScriptTags : true,
		
		/** Blogger mode flag. */
		bloggerMode : false,
		
		stripBrs : false,
		
		/** Name of the tag that SyntaxHighlighter will automatically look for. */
		tagName : 'pre',
		
		strings : {
			expandSource : 'expand source',
			help : '?',
			alert: 'SyntaxHighlighter\n\n',
			noBrush : 'Can\'t find brush for: ',
			brushNotHtmlScript : 'Brush wasn\'t configured for html-script option: ',
			
			// this is populated by the build script
			aboutDialog : '<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8" /><title>About SyntaxHighlighter</title></head><body style="font-family:Geneva,Arial,Helvetica,sans-serif;background-color:#fff;color:#000;font-size:1em;text-align:center;"><div style="text-align:center;margin-top:1.5em;"><div style="font-size:xx-large;">SyntaxHighlighter</div><div style="font-size:.75em;margin-bottom:3em;"><div>version 3.0.83 (July 02 2010)</div><div><a href="http://alexgorbatchev.com/SyntaxHighlighter" target="_blank" style="color:#005896">http://alexgorbatchev.com/SyntaxHighlighter</a></div><div>JavaScript code syntax highlighter.</div><div>Copyright 2004-2010 Alex Gorbatchev.</div></div><div>If you like this script, please <a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=2930402" style="color:#005896">donate</a> to <br/>keep development active!</div></div></body></html>'
		}
	},
	
	/** Internal 'global' variables. */
	vars : {
		discoveredBrushes : null,
		highlighters : {}
	},
	
	/** This object is populated by user included external brush files. */
	brushes : {},

	/** Common regular expressions. */
	regexLib : {
		multiLineCComments			: /\/\*[\s\S]*?\*\//gm,
		singleLineCComments			: /\/\/.*$/gm,
		singleLinePerlComments		: /#.*$/gm,
		doubleQuotedString			: /"([^\\"\n]|\\.)*"/g,
		singleQuotedString			: /'([^\\'\n]|\\.)*'/g,
		multiLineDoubleQuotedString	: new XRegExp('"([^\\\\"]|\\\\.)*"', 'gs'),
		multiLineSingleQuotedString	: new XRegExp("'([^\\\\']|\\\\.)*'", 'gs'),
		xmlComments					: /(&lt;|<)!--[\s\S]*?--(&gt;|>)/gm,
		url							: /\w+:\/\/[\w-.\/?%&=:@;]*/g,
		
		/** <?= ?> tags. */
		phpScriptTags 				: { left: /(&lt;|<)\?=?/g, right: /\?(&gt;|>)/g },
		
		/** <%= %> tags. */
		aspScriptTags				: { left: /(&lt;|<)%=?/g, right: /%(&gt;|>)/g },
		
		scriptScriptTags			: { left: /(&lt;|<)\s*script.*?(&gt;|>)/gi, right: /(&lt;|<)\/\s*script\s*(&gt;|>)/gi }
	},

	toolbar: {
		/**
		 * Generates HTML markup for the toolbar.
		 * @param {Highlighter} highlighter Highlighter instance.
		 * @return {String} Returns HTML markup.
		 */
		getHtml: function(highlighter)
		{
			var html = '<div class="toolbar">',
				items = sh.toolbar.items,
				list = items.list
				;
			
			function defaultGetHtml(highlighter, name)
			{
				return sh.toolbar.getButtonHtml(highlighter, name, sh.config.strings[name]);
			};
			
			for (var i = 0; i < list.length; i++)
				html += (items[list[i]].getHtml || defaultGetHtml)(highlighter, list[i]);
			
			html += '</div>';
			
			return html;
		},
		
		/**
		 * Generates HTML markup for a regular button in the toolbar.
		 * @param {Highlighter} highlighter Highlighter instance.
		 * @param {String} commandName		Command name that would be executed.
		 * @param {String} label			Label text to display.
		 * @return {String}					Returns HTML markup.
		 */
		getButtonHtml: function(highlighter, commandName, label)
		{
			return '<span><a href="#" class="toolbar_item'
				+ ' command_' + commandName
				+ ' ' + commandName
				+ '">' + label + '</a></span>'
				;
		},
		
		/**
		 * Event handler for a toolbar anchor.
		 */
		handler: function(e)
		{
			var target = e.target,
				className = target.className || ''
				;

			function getValue(name)
			{
				var r = new RegExp(name + '_(\\w+)'),
					match = r.exec(className)
					;

				return match ? match[1] : null;
			};
			
			var highlighter = getHighlighterById(findParentElement(target, '.syntaxhighlighter').id),
				commandName = getValue('command')
				;
			
			// execute the toolbar command
			if (highlighter && commandName)
				sh.toolbar.items[commandName].execute(highlighter);

			// disable default A click behaviour
			e.preventDefault();
		},
		
		/** Collection of toolbar items. */
		items : {
			// Ordered lis of items in the toolbar. Can't expect `for (var n in items)` to be consistent.
			list: ['expandSource', 'help'],

			expandSource: {
				getHtml: function(highlighter)
				{
					if (highlighter.getParam('collapse') != true)
						return '';
						
					var title = highlighter.getParam('title');
					return sh.toolbar.getButtonHtml(highlighter, 'expandSource', title ? title : sh.config.strings.expandSource);
				},
			
				execute: function(highlighter)
				{
					var div = getHighlighterDivById(highlighter.id);
					removeClass(div, 'collapsed');
				}
			},

			/** Command to display the about dialog window. */
			help: {
				execute: function(highlighter)
				{	
					var wnd = popup('', '_blank', 500, 250, 'scrollbars=0'),
						doc = wnd.document
						;
					
					doc.write(sh.config.strings.aboutDialog);
					doc.close();
					wnd.focus();
				}
			}
		}
	},

	/**
	 * Finds all elements on the page which should be processes by SyntaxHighlighter.
	 *
	 * @param {Object} globalParams		Optional parameters which override element's 
	 * 									parameters. Only used if element is specified.
	 * 
	 * @param {Object} element	Optional element to highlight. If none is
	 * 							provided, all elements in the current document 
	 * 							are returned which qualify.
	 *
	 * @return {Array}	Returns list of <code>{ target: DOMElement, params: Object }</code> objects.
	 */
	findElements: function(globalParams, element)
	{
		var elements = element ? [element] : toArray(document.getElementsByTagName(sh.config.tagName)), 
			conf = sh.config,
			result = []
			;

		// support for <SCRIPT TYPE="syntaxhighlighter" /> feature
		if (conf.useScriptTags)
			elements = elements.concat(getSyntaxHighlighterScriptTags());

		if (elements.length === 0) 
			return result;
	
		for (var i = 0; i < elements.length; i++) 
		{
			var item = {
				target: elements[i], 
				// local params take precedence over globals
				params: merge(globalParams, parseParams(elements[i].className))
			};

			if (item.params['brush'] == null)
				continue;
				
			result.push(item);
		}
		
		return result;
	},

	/**
	 * Shorthand to highlight all elements on the page that are marked as 
	 * SyntaxHighlighter source code.
	 * 
	 * @param {Object} globalParams		Optional parameters which override element's 
	 * 									parameters. Only used if element is specified.
	 * 
	 * @param {Object} element	Optional element to highlight. If none is
	 * 							provided, all elements in the current document 
	 * 							are highlighted.
	 */ 
	highlight: function(globalParams, element)
	{
		var elements = this.findElements(globalParams, element),
			propertyName = 'innerHTML', 
			highlighter = null,
			conf = sh.config
			;

		if (elements.length === 0) 
			return;
	
		for (var i = 0; i < elements.length; i++) 
		{
			var element = elements[i],
				target = element.target,
				params = element.params,
				brushName = params.brush,
				code
				;

			if (brushName == null)
				continue;

			// Instantiate a brush
			if (params['html-script'] == 'true' || sh.defaults['html-script'] == true) 
			{
				highlighter = new sh.HtmlScript(brushName);
				brushName = 'htmlscript';
			}
			else
			{
				var brush = findBrush(brushName);
				
				if (brush)
					highlighter = new brush();
				else
					continue;
			}
			
			code = target[propertyName];
			
			// remove CDATA from <SCRIPT/> tags if it's present
			if (conf.useScriptTags)
				code = stripCData(code);
				
			// Inject title if the attribute is present
			if ((target.title || '') != '')
				params.title = target.title;
				
			params['brush'] = brushName;
			highlighter.init(params);
			element = highlighter.getDiv(code);
			
			// carry over ID
			if ((target.id || '') != '')
				element.id = target.id;
			
			target.parentNode.replaceChild(element, target);
		}
	},

	/**
	 * Main entry point for the SyntaxHighlighter.
	 * @param {Object} params Optional params to apply to all highlighted elements.
	 */
	all: function(params)
	{
		attachEvent(
			window,
			'load',
			function() { sh.highlight(params); }
		);
	}
}; // end of sh

sh['all']			= sh.all;
sh['highlight']		= sh.highlight;

/**
 * Checks if target DOM elements has specified CSS class.
 * @param {DOMElement} target Target DOM element to check.
 * @param {String} className Name of the CSS class to check for.
 * @return {Boolean} Returns true if class name is present, false otherwise.
 */
function hasClass(target, className)
{
	return target.className.indexOf(className) != -1;
};

/**
 * Adds CSS class name to the target DOM element.
 * @param {DOMElement} target Target DOM element.
 * @param {String} className New CSS class to add.
 */
function addClass(target, className)
{
	if (!hasClass(target, className))
		target.className += ' ' + className;
};

/**
 * Removes CSS class name from the target DOM element.
 * @param {DOMElement} target Target DOM element.
 * @param {String} className CSS class to remove.
 */
function removeClass(target, className)
{
	target.className = target.className.replace(className, '');
};

/**
 * Converts the source to array object. Mostly used for function arguments and 
 * lists returned by getElementsByTagName() which aren't Array objects.
 * @param {List} source Source list.
 * @return {Array} Returns array.
 */
function toArray(source)
{
	var result = [];
	
	for (var i = 0; i < source.length; i++) 
		result.push(source[i]);
		
	return result;
};

/**
 * Splits block of text into lines.
 * @param {String} block Block of text.
 * @return {Array} Returns array of lines.
 */
function splitLines(block)
{
	return block.split('\n');
}

/**
 * Generates HTML ID for the highlighter.
 * @param {String} highlighterId Highlighter ID.
 * @return {String} Returns HTML ID.
 */
function getHighlighterId(id)
{
	var prefix = 'highlighter_';
	return id.indexOf(prefix) == 0 ? id : prefix + id;
};

/**
 * Finds Highlighter instance by ID.
 * @param {String} highlighterId Highlighter ID.
 * @return {Highlighter} Returns instance of the highlighter.
 */
function getHighlighterById(id)
{
	return sh.vars.highlighters[getHighlighterId(id)];
};

/**
 * Finds highlighter's DIV container.
 * @param {String} highlighterId Highlighter ID.
 * @return {Element} Returns highlighter's DIV element.
 */
function getHighlighterDivById(id)
{
	return document.getElementById(getHighlighterId(id));
};

/**
 * Stores highlighter so that getHighlighterById() can do its thing. Each
 * highlighter must call this method to preserve itself.
 * @param {Highilghter} highlighter Highlighter instance.
 */
function storeHighlighter(highlighter)
{
	sh.vars.highlighters[getHighlighterId(highlighter.id)] = highlighter;
};

/**
 * Looks for a child or parent node which has specified classname.
 * Equivalent to jQuery's $(container).find(".className")
 * @param {Element} target Target element.
 * @param {String} search Class name or node name to look for.
 * @param {Boolean} reverse If set to true, will go up the node tree instead of down.
 * @return {Element} Returns found child or parent element on null.
 */
function findElement(target, search, reverse /* optional */)
{
	if (target == null)
		return null;
		
	var nodes			= reverse != true ? target.childNodes : [ target.parentNode ],
		propertyToFind	= { '#' : 'id', '.' : 'className' }[search.substr(0, 1)] || 'nodeName',
		expectedValue,
		found
		;

	expectedValue = propertyToFind != 'nodeName'
		? search.substr(1)
		: search.toUpperCase()
		;
		
	// main return of the found node
	if ((target[propertyToFind] || '').indexOf(expectedValue) != -1)
		return target;
	
	for (var i = 0; nodes && i < nodes.length && found == null; i++)
		found = findElement(nodes[i], search, reverse);
	
	return found;
};

/**
 * Looks for a parent node which has specified classname.
 * This is an alias to <code>findElement(container, className, true)</code>.
 * @param {Element} target Target element.
 * @param {String} className Class name to look for.
 * @return {Element} Returns found parent element on null.
 */
function findParentElement(target, className)
{
	return findElement(target, className, true);
};

/**
 * Finds an index of element in the array.
 * @ignore
 * @param {Object} searchElement
 * @param {Number} fromIndex
 * @return {Number} Returns index of element if found; -1 otherwise.
 */
function indexOf(array, searchElement, fromIndex)
{
	fromIndex = Math.max(fromIndex || 0, 0);

	for (var i = fromIndex; i < array.length; i++)
		if(array[i] == searchElement)
			return i;
	
	return -1;
};

/**
 * Generates a unique element ID.
 */
function guid(prefix)
{
	return (prefix || '') + Math.round(Math.random() * 1000000).toString();
};

/**
 * Merges two objects. Values from obj2 override values in obj1.
 * Function is NOT recursive and works only for one dimensional objects.
 * @param {Object} obj1 First object.
 * @param {Object} obj2 Second object.
 * @return {Object} Returns combination of both objects.
 */
function merge(obj1, obj2)
{
	var result = {}, name;

	for (name in obj1) 
		result[name] = obj1[name];
	
	for (name in obj2) 
		result[name] = obj2[name];
		
	return result;
};

/**
 * Attempts to convert string to boolean.
 * @param {String} value Input string.
 * @return {Boolean} Returns true if input was "true", false if input was "false" and value otherwise.
 */
function toBoolean(value)
{
	var result = { "true" : true, "false" : false }[value];
	return result == null ? value : result;
};

/**
 * Opens up a centered popup window.
 * @param {String} url		URL to open in the window.
 * @param {String} name		Popup name.
 * @param {int} width		Popup width.
 * @param {int} height		Popup height.
 * @param {String} options	window.open() options.
 * @return {Window}			Returns window instance.
 */
function popup(url, name, width, height, options)
{
	var x = (screen.width - width) / 2,
		y = (screen.height - height) / 2
		;
		
	options +=	', left=' + x + 
				', top=' + y +
				', width=' + width +
				', height=' + height
		;
	options = options.replace(/^,/, '');

	var win = window.open(url, name, options);
	win.focus();
	return win;
};

/**
 * Adds event handler to the target object.
 * @param {Object} obj		Target object.
 * @param {String} type		Name of the event.
 * @param {Function} func	Handling function.
 */
function attachEvent(obj, type, func, scope)
{
	function handler(e)
	{
		e = e || window.event;
		
		if (!e.target)
		{
			e.target = e.srcElement;
			e.preventDefault = function()
			{
				this.returnValue = false;
			};
		}
			
		func.call(scope || window, e);
	};
	
	if (obj.attachEvent) 
	{
		obj.attachEvent('on' + type, handler);
	}
	else 
	{
		obj.addEventListener(type, handler, false);
	}
};

/**
 * Displays an alert.
 * @param {String} str String to display.
 */
function alert(str)
{
	window.alert(sh.config.strings.alert + str);
};

/**
 * Finds a brush by its alias.
 *
 * @param {String} alias		Brush alias.
 * @param {Boolean} showAlert	Suppresses the alert if false.
 * @return {Brush}				Returns bursh constructor if found, null otherwise.
 */
function findBrush(alias, showAlert)
{
	var brushes = sh.vars.discoveredBrushes,
		result = null
		;
	
	if (brushes == null) 
	{
		brushes = {};
		
		// Find all brushes
		for (var brush in sh.brushes) 
		{
			var info = sh.brushes[brush],
				aliases = info.aliases
				;
			
			if (aliases == null) 
				continue;
			
			// keep the brush name
			info.brushName = brush.toLowerCase();
			
			for (var i = 0; i < aliases.length; i++) 
				brushes[aliases[i]] = brush;
		}
		
		sh.vars.discoveredBrushes = brushes;
	}
	
	result = sh.brushes[brushes[alias]];

	if (result == null && showAlert != false)
		alert(sh.config.strings.noBrush + alias);
	
	return result;
};

/**
 * Executes a callback on each line and replaces each line with result from the callback.
 * @param {Object} str			Input string.
 * @param {Object} callback		Callback function taking one string argument and returning a string.
 */
function eachLine(str, callback)
{
	var lines = splitLines(str);
	
	for (var i = 0; i < lines.length; i++)
		lines[i] = callback(lines[i], i);
		
	return lines.join('\n');
};

/**
 * This is a special trim which only removes first and last empty lines
 * and doesn't affect valid leading space on the first line.
 * 
 * @param {String} str   Input string
 * @return {String}      Returns string without empty first and last lines.
 */
function trimFirstAndLastLines(str)
{
	return str.replace(/^[ ]*[\n]+|[\n]*[ ]*$/g, '');
};

/**
 * Parses key/value pairs into hash object.
 * 
 * Understands the following formats:
 * - name: word;
 * - name: [word, word];
 * - name: "string";
 * - name: 'string';
 * 
 * For example:
 *   name1: value; name2: [value, value]; name3: 'value'
 *   
 * @param {String} str    Input string.
 * @return {Object}       Returns deserialized object.
 */
function parseParams(str)
{
	var match, 
		result = {},
		arrayRegex = new XRegExp("^\\[(?<values>(.*?))\\]$"),
		regex = new XRegExp(
			"(?<name>[\\w-]+)" +
			"\\s*:\\s*" +
			"(?<value>" +
				"[\\w-%#]+|" +		// word
				"\\[.*?\\]|" +		// [] array
				'".*?"|' +			// "" string
				"'.*?'" +			// '' string
			")\\s*;?",
			"g"
		)
		;

	while ((match = regex.exec(str)) != null) 
	{
		var value = match.value
			.replace(/^['"]|['"]$/g, '') // strip quotes from end of strings
			;
		
		// try to parse array value
		if (value != null && arrayRegex.test(value))
		{
			var m = arrayRegex.exec(value);
			value = m.values.length > 0 ? m.values.split(/\s*,\s*/) : [];
		}
		
		result[match.name] = value;
	}
	
	return result;
};

/**
 * Wraps each line of the string into <code/> tag with given style applied to it.
 * 
 * @param {String} str   Input string.
 * @param {String} css   Style name to apply to the string.
 * @return {String}      Returns input string with each line surrounded by <span/> tag.
 */
function wrapLinesWithCode(str, css)
{
	if (str == null || str.length == 0 || str == '\n') 
		return str;

	str = str.replace(/</g, '&lt;');

	// Replace two or more sequential spaces with &nbsp; leaving last space untouched.
	str = str.replace(/ {2,}/g, function(m)
	{
		var spaces = '';
		
		for (var i = 0; i < m.length - 1; i++)
			spaces += sh.config.space;
		
		return spaces + ' ';
	});

	// Split each line and apply <span class="...">...</span> to them so that
	// leading spaces aren't included.
	if (css != null) 
		str = eachLine(str, function(line)
		{
			if (line.length == 0) 
				return '';
			
			var spaces = '';
			
			line = line.replace(/^(&nbsp;| )+/, function(s)
			{
				spaces = s;
				return '';
			});
			
			if (line.length == 0) 
				return spaces;
			
			return spaces + '<code class="' + css + '">' + line + '</code>';
		});

	return str;
};

/**
 * Pads number with zeros until it's length is the same as given length.
 * 
 * @param {Number} number	Number to pad.
 * @param {Number} length	Max string length with.
 * @return {String}			Returns a string padded with proper amount of '0'.
 */
function padNumber(number, length)
{
	var result = number.toString();
	
	while (result.length < length)
		result = '0' + result;
	
	return result;
};

/**
 * Replaces tabs with spaces.
 * 
 * @param {String} code		Source code.
 * @param {Number} tabSize	Size of the tab.
 * @return {String}			Returns code with all tabs replaces by spaces.
 */
function processTabs(code, tabSize)
{
	var tab = '';
	
	for (var i = 0; i < tabSize; i++)
		tab += ' ';

	return code.replace(/\t/g, tab);
};

/**
 * Replaces tabs with smart spaces.
 * 
 * @param {String} code    Code to fix the tabs in.
 * @param {Number} tabSize Number of spaces in a column.
 * @return {String}        Returns code with all tabs replaces with roper amount of spaces.
 */
function processSmartTabs(code, tabSize)
{
	var lines = splitLines(code),
		tab = '\t',
		spaces = ''
		;
	
	// Create a string with 1000 spaces to copy spaces from... 
	// It's assumed that there would be no indentation longer than that.
	for (var i = 0; i < 50; i++) 
		spaces += '                    '; // 20 spaces * 50
			
	// This function inserts specified amount of spaces in the string
	// where a tab is while removing that given tab.
	function insertSpaces(line, pos, count)
	{
		return line.substr(0, pos)
			+ spaces.substr(0, count)
			+ line.substr(pos + 1, line.length) // pos + 1 will get rid of the tab
			;
	};

	// Go through all the lines and do the 'smart tabs' magic.
	code = eachLine(code, function(line)
	{
		if (line.indexOf(tab) == -1) 
			return line;
		
		var pos = 0;
		
		while ((pos = line.indexOf(tab)) != -1) 
		{
			// This is pretty much all there is to the 'smart tabs' logic.
			// Based on the position within the line and size of a tab,
			// calculate the amount of spaces we need to insert.
			var spaces = tabSize - pos % tabSize;
			line = insertSpaces(line, pos, spaces);
		}
		
		return line;
	});
	
	return code;
};

/**
 * Performs various string fixes based on configuration.
 */
function fixInputString(str)
{
	var br = /<br\s*\/?>|&lt;br\s*\/?&gt;/gi;
	
	if (sh.config.bloggerMode == true)
		str = str.replace(br, '\n');

	if (sh.config.stripBrs == true)
		str = str.replace(br, '');
		
	return str;
};

/**
 * Removes all white space at the begining and end of a string.
 * 
 * @param {String} str   String to trim.
 * @return {String}      Returns string without leading and following white space characters.
 */
function trim(str)
{
	return str.replace(/^\s+|\s+$/g, '');
};

/**
 * Unindents a block of text by the lowest common indent amount.
 * @param {String} str   Text to unindent.
 * @return {String}      Returns unindented text block.
 */
function unindent(str)
{
	var lines = splitLines(fixInputString(str)),
		indents = new Array(),
		regex = /^\s*/,
		min = 1000
		;
	
	// go through every line and check for common number of indents
	for (var i = 0; i < lines.length && min > 0; i++) 
	{
		var line = lines[i];
		
		if (trim(line).length == 0) 
			continue;
		
		var matches = regex.exec(line);
		
		// In the event that just one line doesn't have leading white space
		// we can't unindent anything, so bail completely.
		if (matches == null) 
			return str;
			
		min = Math.min(matches[0].length, min);
	}
	
	// trim minimum common number of white space from the begining of every line
	if (min > 0) 
		for (var i = 0; i < lines.length; i++) 
			lines[i] = lines[i].substr(min);
	
	return lines.join('\n');
};

/**
 * Callback method for Array.sort() which sorts matches by
 * index position and then by length.
 * 
 * @param {Match} m1	Left object.
 * @param {Match} m2    Right object.
 * @return {Number}     Returns -1, 0 or -1 as a comparison result.
 */
function matchesSortCallback(m1, m2)
{
	// sort matches by index first
	if(m1.index < m2.index)
		return -1;
	else if(m1.index > m2.index)
		return 1;
	else
	{
		// if index is the same, sort by length
		if(m1.length < m2.length)
			return -1;
		else if(m1.length > m2.length)
			return 1;
	}
	
	return 0;
};

/**
 * Executes given regular expression on provided code and returns all
 * matches that are found.
 * 
 * @param {String} code    Code to execute regular expression on.
 * @param {Object} regex   Regular expression item info from <code>regexList</code> collection.
 * @return {Array}         Returns a list of Match objects.
 */ 
function getMatches(code, regexInfo)
{
	function defaultAdd(match, regexInfo)
	{
		return match[0];
	};
	
	var index = 0,
		match = null,
		matches = [],
		func = regexInfo.func ? regexInfo.func : defaultAdd
		;
	
	while((match = regexInfo.regex.exec(code)) != null)
	{
		var resultMatch = func(match, regexInfo);
		
		if (typeof(resultMatch) == 'string')
			resultMatch = [new sh.Match(resultMatch, match.index, regexInfo.css)];

		matches = matches.concat(resultMatch);
	}
	
	return matches;
};

/**
 * Turns all URLs in the code into <a/> tags.
 * @param {String} code Input code.
 * @return {String} Returns code with </a> tags.
 */
function processUrls(code)
{
	var gt = /(.*)((&gt;|&lt;).*)/;
	
	return code.replace(sh.regexLib.url, function(m)
	{
		var suffix = '',
			match = null
			;
		
		// We include &lt; and &gt; in the URL for the common cases like <http://google.com>
		// The problem is that they get transformed into &lt;http://google.com&gt;
		// Where as &gt; easily looks like part of the URL string.
	
		if (match = gt.exec(m))
		{
			m = match[1];
			suffix = match[2];
		}
		
		return '<a href="' + m + '">' + m + '</a>' + suffix;
	});
};

/**
 * Finds all <SCRIPT TYPE="syntaxhighlighter" /> elementss.
 * @return {Array} Returns array of all found SyntaxHighlighter tags.
 */
function getSyntaxHighlighterScriptTags()
{
	var tags = document.getElementsByTagName('script'),
		result = []
		;
	
	for (var i = 0; i < tags.length; i++)
		if (tags[i].type == 'syntaxhighlighter')
			result.push(tags[i]);
			
	return result;
};

/**
 * Strips <![CDATA[]]> from <SCRIPT /> content because it should be used
 * there in most cases for XHTML compliance.
 * @param {String} original	Input code.
 * @return {String} Returns code without leading <![CDATA[]]> tags.
 */
function stripCData(original)
{
	var left = '<![CDATA[',
		right = ']]>',
		// for some reason IE inserts some leading blanks here
		copy = trim(original),
		changed = false,
		leftLength = left.length,
		rightLength = right.length
		;
	
	if (copy.indexOf(left) == 0)
	{
		copy = copy.substring(leftLength);
		changed = true;
	}
	
	var copyLength = copy.length;
	
	if (copy.indexOf(right) == copyLength - rightLength)
	{
		copy = copy.substring(0, copyLength - rightLength);
		changed = true;
	}
	
	return changed ? copy : original;
};


/**
 * Quick code mouse double click handler.
 */
function quickCodeHandler(e)
{
	var target = e.target,
		highlighterDiv = findParentElement(target, '.syntaxhighlighter'),
		container = findParentElement(target, '.container'),
		textarea = document.createElement('textarea'),
		highlighter
		;

	if (!container || !highlighterDiv || findElement(container, 'textarea'))
		return;

	highlighter = getHighlighterById(highlighterDiv.id);
	
	// add source class name
	addClass(highlighterDiv, 'source');

	// Have to go over each line and grab it's text, can't just do it on the
	// container because Firefox loses all \n where as Webkit doesn't.
	var lines = container.childNodes,
		code = []
		;
	
	for (var i = 0; i < lines.length; i++)
		code.push(lines[i].innerText || lines[i].textContent);
	
	// using \r instead of \r or \r\n makes this work equally well on IE, FF and Webkit
	code = code.join('\r');
	
	// inject <textarea/> tag
	textarea.appendChild(document.createTextNode(code));
	container.appendChild(textarea);
	
	// preselect all text
	textarea.focus();
	textarea.select();
	
	// set up handler for lost focus
	attachEvent(textarea, 'blur', function(e)
	{
		textarea.parentNode.removeChild(textarea);
		removeClass(highlighterDiv, 'source');
	});
};

/**
 * Match object.
 */
sh.Match = function(value, index, css)
{
	this.value = value;
	this.index = index;
	this.length = value.length;
	this.css = css;
	this.brushName = null;
};

sh.Match.prototype.toString = function()
{
	return this.value;
};

/**
 * Simulates HTML code with a scripting language embedded.
 * 
 * @param {String} scriptBrushName Brush name of the scripting language.
 */
sh.HtmlScript = function(scriptBrushName)
{
	var brushClass = findBrush(scriptBrushName),
		scriptBrush,
		xmlBrush = new sh.brushes.Xml(),
		bracketsRegex = null,
		ref = this,
		methodsToExpose = 'getDiv getHtml init'.split(' ')
		;

	if (brushClass == null)
		return;
	
	scriptBrush = new brushClass();
	
	for(var i = 0; i < methodsToExpose.length; i++)
		// make a closure so we don't lose the name after i changes
		(function() {
			var name = methodsToExpose[i];
			
			ref[name] = function()
			{
				return xmlBrush[name].apply(xmlBrush, arguments);
			};
		})();
	
	if (scriptBrush.htmlScript == null)
	{
		alert(sh.config.strings.brushNotHtmlScript + scriptBrushName);
		return;
	}
	
	xmlBrush.regexList.push(
		{ regex: scriptBrush.htmlScript.code, func: process }
	);
	
	function offsetMatches(matches, offset)
	{
		for (var j = 0; j < matches.length; j++) 
			matches[j].index += offset;
	}
	
	function process(match, info)
	{
		var code = match.code,
			matches = [],
			regexList = scriptBrush.regexList,
			offset = match.index + match.left.length,
			htmlScript = scriptBrush.htmlScript,
			result
			;

		// add all matches from the code
		for (var i = 0; i < regexList.length; i++)
		{
			result = getMatches(code, regexList[i]);
			offsetMatches(result, offset);
			matches = matches.concat(result);
		}
		
		// add left script bracket
		if (htmlScript.left != null && match.left != null)
		{
			result = getMatches(match.left, htmlScript.left);
			offsetMatches(result, match.index);
			matches = matches.concat(result);
		}
		
		// add right script bracket
		if (htmlScript.right != null && match.right != null)
		{
			result = getMatches(match.right, htmlScript.right);
			offsetMatches(result, match.index + match[0].lastIndexOf(match.right));
			matches = matches.concat(result);
		}
		
		for (var j = 0; j < matches.length; j++)
			matches[j].brushName = brushClass.brushName;
			
		return matches;
	}
};

/**
 * Main Highlither class.
 * @constructor
 */
sh.Highlighter = function()
{
	// not putting any code in here because of the prototype inheritance
};

sh.Highlighter.prototype = {
	/**
	 * Returns value of the parameter passed to the highlighter.
	 * @param {String} name				Name of the parameter.
	 * @param {Object} defaultValue		Default value.
	 * @return {Object}					Returns found value or default value otherwise.
	 */
	getParam: function(name, defaultValue)
	{
		var result = this.params[name];
		return toBoolean(result == null ? defaultValue : result);
	},
	
	/**
	 * Shortcut to document.createElement().
	 * @param {String} name		Name of the element to create (DIV, A, etc).
	 * @return {HTMLElement}	Returns new HTML element.
	 */
	create: function(name)
	{
		return document.createElement(name);
	},
	
	/**
	 * Applies all regular expression to the code and stores all found
	 * matches in the `this.matches` array.
	 * @param {Array} regexList		List of regular expressions.
	 * @param {String} code			Source code.
	 * @return {Array}				Returns list of matches.
	 */
	findMatches: function(regexList, code)
	{
		var result = [];
		
		if (regexList != null)
			for (var i = 0; i < regexList.length; i++) 
				// BUG: length returns len+1 for array if methods added to prototype chain (oising@gmail.com)
				if (typeof (regexList[i]) == "object")
					result = result.concat(getMatches(code, regexList[i]));
		
		// sort and remove nested the matches
		return this.removeNestedMatches(result.sort(matchesSortCallback));
	},
	
	/**
	 * Checks to see if any of the matches are inside of other matches. 
	 * This process would get rid of highligted strings inside comments, 
	 * keywords inside strings and so on.
	 */
	removeNestedMatches: function(matches)
	{
		// Optimized by Jose Prado (http://joseprado.com)
		for (var i = 0; i < matches.length; i++) 
		{ 
			if (matches[i] === null)
				continue;
			
			var itemI = matches[i],
				itemIEndPos = itemI.index + itemI.length
				;
			
			for (var j = i + 1; j < matches.length && matches[i] !== null; j++) 
			{
				var itemJ = matches[j];
				
				if (itemJ === null) 
					continue;
				else if (itemJ.index > itemIEndPos) 
					break;
				else if (itemJ.index == itemI.index && itemJ.length > itemI.length)
					matches[i] = null;
				else if (itemJ.index >= itemI.index && itemJ.index < itemIEndPos) 
					matches[j] = null;
			}
		}
		
		return matches;
	},
	
	/**
	 * Creates an array containing integer line numbers starting from the 'first-line' param.
	 * @return {Array} Returns array of integers.
	 */
	figureOutLineNumbers: function(code)
	{
		var lines = [],
			firstLine = parseInt(this.getParam('first-line'))
			;
		
		eachLine(code, function(line, index)
		{
			lines.push(index + firstLine);
		});
		
		return lines;
	},
	
	/**
	 * Determines if specified line number is in the highlighted list.
	 */
	isLineHighlighted: function(lineNumber)
	{
		var list = this.getParam('highlight', []);
		
		if (typeof(list) != 'object' && list.push == null) 
			list = [ list ];
		
		return indexOf(list, lineNumber.toString()) != -1;
	},
	
	/**
	 * Generates HTML markup for a single line of code while determining alternating line style.
	 * @param {Integer} lineNumber	Line number.
	 * @param {String} code Line	HTML markup.
	 * @return {String}				Returns HTML markup.
	 */
	getLineHtml: function(lineIndex, lineNumber, code)
	{
		var classes = [
			'line',
			'number' + lineNumber,
			'index' + lineIndex,
			'alt' + (lineNumber % 2 == 0 ? 1 : 2).toString()
		];
		
		if (this.isLineHighlighted(lineNumber))
		 	classes.push('highlighted');
		
		if (lineNumber == 0)
			classes.push('break');
			
		return '<div class="' + classes.join(' ') + '">' + code + '</div>';
	},
	
	/**
	 * Generates HTML markup for line number column.
	 * @param {String} code			Complete code HTML markup.
	 * @param {Array} lineNumbers	Calculated line numbers.
	 * @return {String}				Returns HTML markup.
	 */
	getLineNumbersHtml: function(code, lineNumbers)
	{
		var html = '',
			count = splitLines(code).length,
			firstLine = parseInt(this.getParam('first-line')),
			pad = this.getParam('pad-line-numbers')
			;
		
		if (pad == true)
			pad = (firstLine + count - 1).toString().length;
		else if (isNaN(pad) == true)
			pad = 0;
			
		for (var i = 0; i < count; i++)
		{
			var lineNumber = lineNumbers ? lineNumbers[i] : firstLine + i,
				code = lineNumber == 0 ? sh.config.space : padNumber(lineNumber, pad)
				;
				
			html += this.getLineHtml(i, lineNumber, code);
		}
		
		return html;
	},
	
	/**
	 * Splits block of text into individual DIV lines.
	 * @param {String} code			Code to highlight.
	 * @param {Array} lineNumbers	Calculated line numbers.
	 * @return {String}				Returns highlighted code in HTML form.
	 */
	getCodeLinesHtml: function(html, lineNumbers)
	{
		html = trim(html);
		
		var lines = splitLines(html),
			padLength = this.getParam('pad-line-numbers'),
			firstLine = parseInt(this.getParam('first-line')),
			html = '',
			brushName = this.getParam('brush')
			;

		for (var i = 0; i < lines.length; i++)
		{
			var line = lines[i],
				indent = /^(&nbsp;|\s)+/.exec(line),
				spaces = null,
				lineNumber = lineNumbers ? lineNumbers[i] : firstLine + i;
				;

			if (indent != null)
			{
				spaces = indent[0].toString();
				line = line.substr(spaces.length);
				spaces = spaces.replace(' ', sh.config.space);
			}

			line = trim(line);
			
			if (line.length == 0)
				line = sh.config.space;
			
			html += this.getLineHtml(
				i,
				lineNumber, 
				(spaces != null ? '<code class="' + brushName + ' spaces">' + spaces + '</code>' : '') + line
			);
		}
		
		return html;
	},
	
	/**
	 * Returns HTML for the table title or empty string if title is null.
	 */
	getTitleHtml: function(title)
	{
		return title ? '<caption>' + title + '</caption>' : '';
	},
	
	/**
	 * Finds all matches in the source code.
	 * @param {String} code		Source code to process matches in.
	 * @param {Array} matches	Discovered regex matches.
	 * @return {String} Returns formatted HTML with processed mathes.
	 */
	getMatchesHtml: function(code, matches)
	{
		var pos = 0, 
			result = '',
			brushName = this.getParam('brush', '')
			;
		
		function getBrushNameCss(match)
		{
			var result = match ? (match.brushName || brushName) : brushName;
			return result ? result + ' ' : '';
		};
		
		// Finally, go through the final list of matches and pull the all
		// together adding everything in between that isn't a match.
		for (var i = 0; i < matches.length; i++) 
		{
			var match = matches[i],
				matchBrushName
				;
			
			if (match === null || match.length === 0) 
				continue;
			
			matchBrushName = getBrushNameCss(match);
			
			result += wrapLinesWithCode(code.substr(pos, match.index - pos), matchBrushName + 'plain')
					+ wrapLinesWithCode(match.value, matchBrushName + match.css)
					;

			pos = match.index + match.length + (match.offset || 0);
		}

		// don't forget to add whatever's remaining in the string
		result += wrapLinesWithCode(code.substr(pos), getBrushNameCss() + 'plain');

		return result;
	},
	
	/**
	 * Generates HTML markup for the whole syntax highlighter.
	 * @param {String} code Source code.
	 * @return {String} Returns HTML markup.
	 */
	getHtml: function(code)
	{
		var html = '',
			classes = [ 'syntaxhighlighter' ],
			tabSize,
			matches,
			lineNumbers
			;
		
		// process light mode
		if (this.getParam('light') == true)
			this.params.toolbar = this.params.gutter = false;

		className = 'syntaxhighlighter';

		if (this.getParam('collapse') == true)
			classes.push('collapsed');
		
		if ((gutter = this.getParam('gutter')) == false)
			classes.push('nogutter');

		// add custom user style name
		classes.push(this.getParam('class-name'));

		// add brush alias to the class name for custom CSS
		classes.push(this.getParam('brush'));

		code = trimFirstAndLastLines(code)
			.replace(/\r/g, ' ') // IE lets these buggers through
			;

		tabSize = this.getParam('tab-size');

		// replace tabs with spaces
		code = this.getParam('smart-tabs') == true
			? processSmartTabs(code, tabSize)
			: processTabs(code, tabSize)
			;

		// unindent code by the common indentation
		code = unindent(code);

		if (gutter)
			lineNumbers = this.figureOutLineNumbers(code);
		
		// find matches in the code using brushes regex list
		matches = this.findMatches(this.regexList, code);
		// processes found matches into the html
		html = this.getMatchesHtml(code, matches);
		// finally, split all lines so that they wrap well
		html = this.getCodeLinesHtml(html, lineNumbers);

		// finally, process the links
		if (this.getParam('auto-links'))
			html = processUrls(html);
		
		if (typeof(navigator) != 'undefined' && navigator.userAgent && navigator.userAgent.match(/MSIE/))
			classes.push('ie');
		
		html = 
			'<div id="' + getHighlighterId(this.id) + '" class="' + classes.join(' ') + '">'
				+ (this.getParam('toolbar') ? sh.toolbar.getHtml(this) : '')
				+ '<table border="0" cellpadding="0" cellspacing="0">'
					+ this.getTitleHtml(this.getParam('title'))
					+ '<tbody>'
						+ '<tr>'
							+ (gutter ? '<td class="gutter">' + this.getLineNumbersHtml(code) + '</td>' : '')
							+ '<td class="code">'
								+ '<div class="container">'
									+ html
								+ '</div>'
							+ '</td>'
						+ '</tr>'
					+ '</tbody>'
				+ '</table>'
			+ '</div>'
			;
			
		return html;
	},
	
	/**
	 * Highlights the code and returns complete HTML.
	 * @param {String} code     Code to highlight.
	 * @return {Element}        Returns container DIV element with all markup.
	 */
	getDiv: function(code)
	{
		if (code === null) 
			code = '';
		
		this.code = code;

		var div = this.create('div');

		// create main HTML
		div.innerHTML = this.getHtml(code);
		
		// set up click handlers
		if (this.getParam('toolbar'))
			attachEvent(findElement(div, '.toolbar'), 'click', sh.toolbar.handler);
		
		if (this.getParam('quick-code'))
			attachEvent(findElement(div, '.code'), 'dblclick', quickCodeHandler);
		
		return div;
	},
	
	/**
	 * Initializes the highlighter/brush.
	 *
	 * Constructor isn't used for initialization so that nothing executes during necessary
	 * `new SyntaxHighlighter.Highlighter()` call when setting up brush inheritence.
	 *
	 * @param {Hash} params Highlighter parameters.
	 */
	init: function(params)
	{
		this.id = guid();
		
		// register this instance in the highlighters list
		storeHighlighter(this);
		
		// local params take precedence over defaults
		this.params = merge(sh.defaults, params || {})
		
		// process light mode
		if (this.getParam('light') == true)
			this.params.toolbar = this.params.gutter = false;
	},
	
	/**
	 * Converts space separated list of keywords into a regular expression string.
	 * @param {String} str    Space separated keywords.
	 * @return {String}       Returns regular expression string.
	 */
	getKeywords: function(str)
	{
		str = str
			.replace(/^\s+|\s+$/g, '')
			.replace(/\s+/g, '|')
			;
		
		return '\\b(?:' + str + ')\\b';
	},
	
	/**
	 * Makes a brush compatible with the `html-script` functionality.
	 * @param {Object} regexGroup Object containing `left` and `right` regular expressions.
	 */
	forHtmlScript: function(regexGroup)
	{
		this.htmlScript = {
			left : { regex: regexGroup.left, css: 'script' },
			right : { regex: regexGroup.right, css: 'script' },
			code : new XRegExp(
				"(?<left>" + regexGroup.left.source + ")" +
				"(?<code>.*?)" +
				"(?<right>" + regexGroup.right.source + ")",
				"sgi"
				)
		};
	}
}; // end of Highlighter

return sh;
}(); // end of anonymous function

// CommonJS
typeof(exports) != 'undefined' ? exports['SyntaxHighlighter'] = SyntaxHighlighter : null;
</script><script type="text/javascript">// (inc clojure-brush) ;; an improved SyntaxHighlighter brush for clojure
//
// Copyright (C) 2011 Andrew Brehaut
//
// Distributed under the Eclipse Public License, the same as Clojure.
//
// https://github.com/brehaut/inc-clojure-brush
//
// Written by Andrew Brehaut
// V0.9.1, November 2011

if (typeof net == "undefined") net = {};
if (!(net.brehaut)) net.brehaut = {};

net.brehaut.ClojureTools = (function (SH) {
  "use strict";
  // utiliies
  if (!Object.create) Object.create = function object(o) {
    function F() {};
    F.prototype = o;  
    return new F();
  };
        
  // data
  
  function Token(value, index, tag, length) {
    this.value = value;
    this.index = index;
    this.length = length || value.length;
    this.tag = tag;
    this.secondary_tags = {};
  }
  
  // null_token exists so that LispNodes that have not had a closing tag attached
  // can have a dummy token to simplify annotation
  var null_token = new Token("", -1, "null", -1);
  
  /* LispNodes are aggregate nodes for sexpressions. 
   *
   */
  function LispNode(tag, children, opening) {
    this.tag = tag;            // current metadata for syntax inference
    this.parent = null;        // the parent expression
    this.list = children;      // all the child forms in order
    this.opening = opening;    // the token that opens this form.
    this.closing = null_token; // the token that closes this form.
    this.meta = null;          // metadata nodes will be attached here if they are found
  }

  var null_lispnode = new LispNode("null", [], null_token);

  
  function PrefixNode(tag, token, attached_node) {
    this.tag = tag;
    this.token = token;
    this.attached_node = attached_node;
    this.parent = null;
  }

  
  
  // tokenize

  function tokenize(code) {
    var tokens = [];
    var tn = 0;
    
    var zero = "0".charCodeAt(0);
    var nine = "9".charCodeAt(0); 
    var lower_a = "a".charCodeAt(0);
    var lower_f = "f".charCodeAt(0);    
    var upper_a = "A".charCodeAt(0);
    var upper_f = "F".charCodeAt(0);
    
    var dispatch = false; // have we just seen a # character?
    
    // i tracks the start of the current window
    // extent is the window for slicing
    
    for (var i = 0, 
             extent = i, 
             j = code.length; 
             i < j && extent <= j;) {          
                
      var c = code[i];
      
      // we care about capturing the whole token when dispatch is used, so back up the
      // starting index by 1
      if (dispatch) i--; 
      
      switch (c) {
        // dispatch alters the value of the next thing read
        case "#":
          dispatch = true;
          i++;
          extent++;
          continue;
          
        case " ":    // ignore whitespace
        case "\t":
        case "\n":
        case "\r":
        case ",":   
          extent++
          break; 
          
        // simple terms
        case "^":
        case "`":
        case ")":
        case "[":
        case "]":
        case "}":
        case "@":
          tokens[tn++] = new Token(c, i, c, ++extent - i);
          break;
        
        case "'":
          tokens[tn++] = new Token(code.slice(i, ++extent), i, dispatch ? "#'" : "'", extent - i);
          break
        
        case "(":
          tokens[tn++] = new Token(code.slice(i, ++extent), i, "(", extent - i);
          break;          
          
        case "{":
          tokens[tn++] = new Token(code.slice(i, ++extent), i, dispatch ? "#{" : "{", extent - i);
          break;  
        
        case "\\":
          if (code.slice(i + 1, i + 8) === "newline") {
            tokens[tn++] = new Token("\\newline", i, "value", 8);
            extent = i + 9; 
          }
          else if (code.slice(i + 1, i + 6) === "space") {
            tokens[tn++] = new Token("\\space", i, "value", 6);
            extent = i + 6;
          }
          else if (code.slice(i + 1, i + 4) === "tab") {
            tokens[tn++] = new Token("\\tab", i, "value", 4);
            extent = i + 5;
          } // work around fun bug with &,>,< in character literals
          else if (code.slice(i + 1, i + 6) === "&amp;") {
            tokens[tn++] = new Token("\\&amp;", i, "value", 6);
            extent = i + 6; 
          }
          else if (code.slice(i + 1, i + 5) === "&lt;") {
            tokens[tn++] = new Token("\\&lt;", i, "value", 5);
            extent = i + 5;
          }
          else if (code.slice(i + 1, i + 5) === "&gt;") {
            tokens[tn++] = new Token("\\&gt;", i, "value", 5);
            extent = i + 5;
          }
          
          else {
            extent += 2;
            tokens[tn++] = new Token(code.slice(i, extent), i, "value", 2);
          }
          break;
        
        case "~": // slice
          if (code[i + 1] === "@") {
            extent += 2;
            tokens[tn++] = new Token(code.slice(i, extent), i, "splice", 2);
          }
          else {
            tokens[tn++] = new Token(code.slice(i, ++extent), i, "unquote", 2);
          }
          break;
        
        // complicated terms
        case "\"": // strings and regexps
          for (extent++; extent <= j; extent++) {
            if (code[extent] === "\\") extent++;
            else if (code[extent] === "\"") break;
          }
          tokens[tn++] = new Token(code.slice(i, ++extent), i, dispatch ? "regexp" : "string", extent - i);       
          break;
          
        case ";":
          for (; extent <= j && code[extent] !== "\n" && code[extent] !== "\r"; extent++);
          tokens[tn++] = new Token(code.slice(i, ++extent), i, "comments", extent - i);   
          break;
        
        case "+": // numbers; fall through to symbol for + and - not prefixing a number
        case "-":
        case "0":
        case "1":
        case "2":
        case "3":
        case "4":
        case "5":
        case "6":
        case "7":
        case "8":
        case "9":
        // todo: exponents, hex
        // http://my.safaribooksonline.com/9781449310387/14?reader=pf&readerfullscreen=&readerleftmenu=1
          var c2 = code.charCodeAt(i + 1);
          if (((c === "+" || c === "-") && (c2 >= zero && c2 <= nine)) // prefixes
              || (c !== "+" && c !== "-")) {
            if (c === "+" || c === "-") extent++; 
            for (; extent <= j; extent++) {
              var charCode = code.charCodeAt(extent);
              if (charCode < zero || charCode > nine) break;
            }
            
            c = code[extent];
            c2 = code.charCodeAt(extent + 1);
            if ((c === "r" || c === "R" || c === "/" || c === ".") // interstitial characters
                && (c2 >= zero && c2 <= nine)) {
              for (extent++; extent <= j; extent++) {
                var charCode = code.charCodeAt(extent);
                if (charCode < zero || charCode > nine) break;
              }
            }
            
            c = code[extent];
            c2 = code.charCodeAt(extent + 1);
            if ((c === "x" || c === "X") && 
                ((c2 >= zero && c2 <= nine) 
                 || (c2 >= lower_a && c2 <= lower_f)
                 || (c2 >= upper_a && c2 <= upper_f))) {
              for (extent++; extent <= j; extent++) {
                var charCode = code.charCodeAt(extent);
                if (((charCode >= zero && charCode <= nine) 
                    || (charCode >= lower_a && charCode <= lower_f)
                    || (charCode >= upper_a && charCode <= upper_f))) continue;
                break;
              }
            }
            
            c = code[extent];
            c2 = code.charCodeAt(extent + 1);
            if ((c === "e" || c === "E") 
                && (c2 >= zero && c2 <= nine)) {
              for (extent++; extent <= j; extent++) {
                var charCode = code.charCodeAt(extent);
                if (charCode < zero || charCode > nine) break;
              }
            }
            
            c = code[extent];
            if (c === "N" || c === "M") extent++;

            tokens[tn++] = new Token(code.slice(i, extent), i, "value", extent - i);
            break;
          }

        case "_":
          if (dispatch && c === "_") {
            tokens[tn++] = new Token(code.slice(i, ++extent), i, "skip", extent - i);
            break;
          } // if not a skip, fall through to symbols
        
        // Allow just about any other symbol as a symbol. This is far more permissive than 
        // clojure actually allows, but should catch any weirdo crap that accidentally gets
        // into the code.
        default: 
          for (extent++; extent <= j; extent++) {
            switch (code[extent]) {
              case " ":
              case "\t":
              case "\n":
              case "\r":
              case "\\":
              case ",":
              case "{":
              case "}":
              case "(":
              case ")":
              case "[":
              case "]":
              case "^":
              case "`":
              case "@":   
                break;
              case ";":   
                // theres a weird bug via syntax highligher that gives us escaped entities.
                // need to watch out for these
                if (code.slice(extent-3, extent+1) === "&lt;"
                    ||code.slice(extent-3, extent+1) === "&gt;"
                    ||code.slice(extent-4, extent+1) === "&amp;") {
                  continue;
                }
                break;
              default:
                continue;
            }
            break;
          }
          
          var value = code.slice(i, extent);
          var tag = "symbol";
          if (value[0] == ":") {
            tag = "keyword";
          }
          else if (value === "true" || value === "false" || value === "nil") {
            tag = "value";
          }
          tokens[tn++] = new Token(value, i, tag, extent - i);
      }
      
      dispatch = false;
      i = extent;
    } 

    return tokens;
  }


  function build_tree(tokens) {
    var toplevel = {
      list: [], 
      tag: "toplevel", 
      parent: null, 
      opening: null,
      closing: null,
      depth: -1
    };
    
    // loop variables hoisted out as semi globals to track position in token stream
    var i = -1;
    var j = tokens.length;
    
    function parse_one(t) {
      // ignore special tokens and forms that dont belong in the tree
      for (; t && (t.tag === "comments" || t.tag === "invalid" || t.tag == "skip") && i < j; ) {
        if (t.tag === "skip") {
          t.tag = "preprocessor";
          annotate_comment(parse_one(tokens[++i]));
        }
        t = tokens[++i];
      }
      
      if (!t) return {}; // hackity hack
      
      switch (t.tag) {
        case "{":
          return build_aggregate(new LispNode("map", [], t), "}");
        case "(":
          return build_aggregate(new LispNode("list", [], t), ")");
        case "#{":
          return build_aggregate(new LispNode("set", [], t), "}");
        case "[":
          return build_aggregate(new LispNode("vector", [], t), "]");
        case "'":
          return new PrefixNode("quote", t, parse_one(tokens[++i]));
        case "#'":
          return new PrefixNode("varquote", t, parse_one(tokens[++i]));  
        case "@":
          return new PrefixNode("deref", t, parse_one(tokens[++i]));  
        case "`":
          return new PrefixNode("quasiquote", t, parse_one(tokens[++i]));  
        case "unquote":
          return new PrefixNode("unquote", t, parse_one(tokens[++i]));
        case "splice":
          return new PrefixNode("splice", t, parse_one(tokens[++i]));  
        case "^":
          t.tag = "meta";
          var meta = parse_one(tokens[++i]);
          var next = parse_one(tokens[++i]);
          next.meta = meta;
          return next;
      }
      
      return t;
    }
    
    // build_aggregate collects to ether sub forms for one aggregate for. 
    function build_aggregate(current, expected_closing) {
      for (i++; i < j; i++) {
        var t = tokens[i];

        if (t.tag === "}" || t.tag === ")" || t.tag === "]") {
          if (t.tag !== expected_closing) t.tag = "invalid";
          current.closing = t;
          if (expected_closing) return current;
        }
        var node = parse_one(t);

        node.parent = current;
        current.list[current.list.length] = node;
      }
      
      return current;
    }
    
    build_aggregate(toplevel, null);
    
    return toplevel;
  }

  // annotation rules to apply to a form based on its head

  var show_locals = true;  // HACK. would rather not use a (semi)-global.

  /* annotate_comment is a special case annotation. 
   * in addition to its role in styling specific forms, it is called by parse_one to
   * ignore any forms skipped with #_
   */ 
  function annotate_comment(exp) {
    exp.tag = "comments";

    if (exp.list) {
      exp.opening.tag = "comments";
      exp.closing.tag = "comments";
    
      for (var i = 0; i < exp.list.length; i++) {
        var child = exp.list[i];
        if (child.list) {
          annotate_comment(child);
        }
        if (child.attached_node) {
          annotate_comment(child.attached_node);
        }
        else {
          child.tag = "comments";
        }
      }
    }
  }

  /* custom annotation rules are stored here */
  var annotation_rules = {};
  
  // this function is exposed to allow ad hoc extension of the customisation rules
  function register_annotation_rule(names, rule) {
    for (var i = 0; i < names.length; i++) {
      annotation_rules[names[i]] = rule;
    }
  }


  function annotate_destructuring (exp, scope) {
    if (exp.list) {
      if (exp.tag === "vector") {
        for (var i = 0; i < exp.list.length; i++) {
          annotate_destructuring(exp.list[i], scope);
        }
      } 
      else if (exp.tag === "map") {
        for (var i = 0; i < exp.list.length; i += 2) {
          var key = exp.list[i];
          var val = exp.list[i + 1];
          
          if (key.tag === "keyword" && val.tag === "vector") {
            for (var ii = 0, jj = val.list.length; ii < jj; ii++) {
              if (val.list[ii].tag !== "symbol") continue;
              val.list[ii].tag = "variable";
              scope[val.list[ii].value] = true;
            }
          }
          else {
            annotate_destructuring(key, scope);
            annotate_expressions(val, scope);
          }
        } 
      }
    } 
    else if (exp.tag === "symbol" && (exp.value !== "&" && exp.value !== "&amp;")){
      exp.tag = "variable";
      scope[exp.value] = true;
    }
  }

  function _annotate_binding_vector (exp, scope) {
    if (exp.tag !== "vector") return;
  
    var bindings = exp.list;

    if (bindings.length % 2 === 1) return;
    
    for (var i = 0; i < bindings.length; i += 2) {
      annotate_destructuring(bindings[i], scope);
      annotate_expressions(bindings[i + 1], scope);
    }    
  }

  function annotate_binding (exp, scope) {
    var bindings = exp.list[1];
    if (!show_locals) return; // HACK

    if (bindings) {
      scope = Object.create(scope);
      _annotate_binding_vector(bindings, scope);
    }
    for (var i = 2; i < exp.list.length; i++) {
      annotate_expressions(exp.list[i], scope);
    }
  }
  
  function _annotate_function_body (exp, scope, start_idx) {
    var argvec = exp.list[start_idx];
    if (argvec.tag !== "vector") return;

    scope = Object.create(scope);

    for (var i = 0, j = argvec.list.length; i < j; i++) {
      annotate_destructuring(argvec.list[i], scope);
    }
    
    for (var i = start_idx, j = exp.list.length; i < j; i++) {
      annotate_expressions(exp.list[i], scope);
    }
  }
  
  function annotate_function (exp, scope) {
    for (var i = 1, j = exp.list.length; i < j; i++) {
      var child = exp.list[i];
      
      if (child.tag === "vector") {
        _annotate_function_body (exp, scope, i);
        return;
      }
      else if (child.tag === "list") {
        _annotate_function_body(child, scope, 0)
      }
    }
  }
  
  function annotate_letfn (exp, scope) {
    scope = Object.create(scope);
    var bindings = exp.list[1];
    
    var fn;
    for (var i = 0, j = bindings.list.length; i < j; i++) {
      fn = bindings.list[i];
      if (!fn.list[0]) continue;
      fn.list[0].tag = "variable";
      scope[fn.list[0].value] = true;
    }
    
    for (i = 0, j = bindings.list.length; i < j; i++) {
      var fn = bindings.list[i];
      annotate_function(fn, scope);
    }
    
    for (i = 2, j = exp.list.length; i < j; i++) {
      annotate_expressions(exp.list[i], scope);
    }
  }

  register_annotation_rule(
    ["comment"],
    annotate_comment
  );
  
  register_annotation_rule(
    ["let", "when-let", "if-let", "binding", "doseq", "for", "dotimes", "let*"],
    annotate_binding
  );
  
  register_annotation_rule(
    ["defn", "defn-", "fn", "bound-fn", "defmacro", "fn*", "defmethod"],
    annotate_function
  );
  
  register_annotation_rule(
    ["letfn"],
    annotate_letfn
  );

  // standard annotations

  function _annotate_metadata_recursive(meta, scope) {
    if (!meta) return;

    if (meta.list !== undefined && meta.list !== null) {
      for (var i = 0, j = meta.list.length; i < j; i++) {
        meta.opening.secondary_tags.meta = true
        meta.closing.secondary_tags.meta = true
        _annotate_metadata_recursive(meta.list[i], scope);
      }
    }
    else if (meta.attached_node) {
      meta.token.secondary_tags.meta = true;
      _annotate_metadata_recursive(meta.attached_node, scope);
    }
    else {
      meta.secondary_tags.meta = true;
    }
  }
  
  function annotate_metadata(exp) {
    if (!(exp && exp.meta)) return;
    var meta = exp.meta;
    
     annotate_expressions(meta, {});    
    _annotate_metadata_recursive(meta, {});
  }


  function annotate_quoted(exp, scope) {
    if (!exp) return;

    if (exp.list !== undefined && exp.list !== null) {
      for (var i = 0, j = exp.list.length; i < j; i++) {
        exp.opening.secondary_tags.quoted = true
        exp.closing.secondary_tags.quoted = true
        annotate_quoted(exp.list[i], scope);
      }
    }
    else if (exp.attached_node) {
      if (exp.tag === "unquote" || exp.tag === "splice") return;
      exp.token.secondary_tags.quoted = true;
      annotate_quoted(exp.attached_node, scope);
    }
    else {
      exp.secondary_tags.quoted = true;
    }
  }


  function annotate_expressions(exp, scope) {
    annotate_metadata(exp);
    
    switch (exp.tag) {
      case "toplevel": 
        for (var i = 0; i < exp.list.length; i++) {
          annotate_expressions(exp.list[i], scope);
        }
        break;
      
      case "list": // functions, macros, special forms, comments
        var head = exp.list[0];
      
        if (head) {
          if (head.tag === "list" || head.tag === "vector" 
           || head.tag === "map" || head.tag === "set") {
            annotate_expressions(head, scope);
          }
          else if (head.attached_node) {
            annotate_expressions(head.attached_node, scope);
          }
          else {
            head.tag = (head.value.match(/(^\.)|(\.$)|[A-Z].*\//)
                        ? "method"
                        : "function");
          }

          // apply specific rules
          if (annotation_rules.hasOwnProperty(head.value)) {
            annotation_rules[head.value](exp, scope);
          } 
          else {
            for (var i = 1; i < exp.list.length; i++) {
              annotate_expressions(exp.list[i], scope);
            }
          } 
        }
        else { // empty list
          exp.opening.tag = "value";
          exp.closing.tag = "value";
        }
      
        break;
      
      case "vector": // data
      case "map":
      case "set":
        for (var i = 0; i < exp.list.length; i++) {
          annotate_expressions(exp.list[i], scope);
        }
        break;
      
      case "symbol":
        if (exp.value.match(/[A-Z].*\/[A-Z_]+/)) {
          exp.tag = "constant";
        }
        else if (show_locals && scope[exp.value]) {
          exp.tag = "variable";
        }
        else if (exp.tag === "symbol" && exp.value.match(/([A-Z].*\/)?[A-Z_]+/)) {
          exp.tag = "type";
        }
        break;
      
      case "quote":
      case "quasiquote":
        annotate_quoted(exp.attached_node, scope);
        
      default:
        if (exp.attached_node) annotate_expressions(exp.attached_node, scope);
    }
  }

  // translation of tag to css:
  var css_translation = {
    "constant":     "constants",
    "keyword":      "constants",
    "method":       "color1",
    "type":         "color3", 
    "function":     "functions",
    "string":       "string",
    "regexp":       "string",
    "value":        "value",
    "comments":     "comments",
    "symbol":       "symbol",
    "variable":     "variable",
    "splice":       "preprocessor", 
    "unquote":      "preprocessor",     
    "preprocessor": "preprocessor",
    "meta":         "preprocessor", 
    "'":            "preprocessor", 
    "#'":           "preprocessor",    
    "(":            "plain",
    ")":            "plain",
    "{":            "keyword",
    "}":            "keyword",
    "#{":           "keyword",   
    "[":            "keyword",
    "]":            "keyword",
    "invalid":      "invalid",
    "@":            "plain" 
  };
  
  function translate_tags_to_css(tokens) {
    for (var i = 0, j = tokens.length; i < j; i++) {
      var token = tokens[i];
      token.css = css_translation[token.tag];
      for (var k in token.secondary_tags) if (token.secondary_tags.hasOwnProperty(k))
        token.css += " " + k ;
    };
  }
  
  
  // create the new brush

  SH.brushes.Clojure = function () {};
  SH.brushes.Clojure.prototype = new SyntaxHighlighter.Highlighter();
  
  SH.brushes.Clojure.prototype.findMatches = function find_matches (regexpList, code) {
    // this is a nasty global hack. need to resolve this
    if (this.params && this.params.locals) {
      show_locals = this.params.locals === true || this.params.locals === "true"; 
    }
    else {
      show_locals = true;
    }
    
    var tokens = tokenize(code);
    annotate_expressions(build_tree(tokens), {});
    translate_tags_to_css(tokens);

    return tokens;
  };
  
  SH.brushes.Clojure.aliases = ['clojure', 'Clojure', 'clj'];
  SH.brushes.Clojure.register_annotation_rule = register_annotation_rule;

  return {
    tokenize: tokenize,
    build_tree: build_tree
  };
})(SyntaxHighlighter);
</script><title>bcbio.variation -- Marginalia</title></head><body><table><tr><td class="docs"><div class="header"><h1 class="project-name">bcbio.variation</h1><h2 class="project-version">0.0.1-SNAPSHOT</h2><br /><p>Clojure API for variation data, built on GATK</p>
</div><div class="dependencies"><h3>dependencies</h3><table><tr><td class="dep-name">org.clojure/clojure</td><td class="dotted"><hr /></td><td class="dep-version">1.4.0</td></tr><tr><td class="dep-name">org.clojure/math.combinatorics</td><td class="dotted"><hr /></td><td class="dep-version">0.0.2</td></tr><tr><td class="dep-name">org.clojure/data.csv</td><td class="dotted"><hr /></td><td class="dep-version">0.1.2</td></tr><tr><td class="dep-name">org.clojars.chapmanb/gatk</td><td class="dotted"><hr /></td><td class="dep-version">1.6.13</td></tr><tr><td class="dep-name">org.clojars.chapmanb/picard</td><td class="dotted"><hr /></td><td class="dep-version">1.64</td></tr><tr><td class="dep-name">org.biojava/biojava3-core</td><td class="dotted"><hr /></td><td class="dep-version">3.0.4</td></tr><tr><td class="dep-name">org.biojava/biojava3-alignment</td><td class="dotted"><hr /></td><td class="dep-version">3.0.4</td></tr><tr><td class="dep-name">clj-genomespace</td><td class="dotted"><hr /></td><td class="dep-version">0.1-SNAPSHOT</td></tr><tr><td class="dep-name">incanter/incanter-core</td><td class="dotted"><hr /></td><td class="dep-version">1.3.0-SNAPSHOT</td></tr><tr><td class="dep-name">incanter/incanter-charts</td><td class="dotted"><hr /></td><td class="dep-version">1.3.0-SNAPSHOT</td></tr><tr><td class="dep-name">nz.ac.waikato.cms.weka/weka-stable</td><td class="dotted"><hr /></td><td class="dep-version">3.6.6</td></tr><tr><td class="dep-name">org.clojars.chapmanb/fast-random-forest</td><td class="dotted"><hr /></td><td class="dep-version">0.98</td></tr><tr><td class="dep-name">com.leadtune/clj-ml</td><td class="dotted"><hr /></td><td class="dep-version">0.2.2</td></tr><tr><td class="dep-name">fs</td><td class="dotted"><hr /></td><td class="dep-version">1.1.2</td></tr><tr><td class="dep-name">clj-yaml</td><td class="dotted"><hr /></td><td class="dep-version">0.3.1</td></tr><tr><td class="dep-name">doric</td><td class="dotted"><hr /></td><td class="dep-version">0.7.0</td></tr><tr><td class="dep-name">ordered</td><td class="dotted"><hr /></td><td class="dep-version">1.0.0</td></tr><tr><td class="dep-name">de.kotka/lazymap</td><td class="dotted"><hr /></td><td class="dep-version">3.0.0</td></tr><tr><td class="dep-name">pallet-fsm</td><td class="dotted"><hr /></td><td class="dep-version">0.1.0</td></tr><tr><td class="dep-name">clj-time</td><td class="dotted"><hr /></td><td class="dep-version">0.4.3</td></tr><tr><td class="dep-name">clj-aws-s3</td><td class="dotted"><hr /></td><td class="dep-version">0.3.1</td></tr><tr><td class="dep-name">org.clojure/java.jdbc</td><td class="dotted"><hr /></td><td class="dep-version">0.2.2</td></tr><tr><td class="dep-name">org.xerial/sqlite-jdbc</td><td class="dotted"><hr /></td><td class="dep-version">3.7.2</td></tr><tr><td class="dep-name">noir</td><td class="dotted"><hr /></td><td class="dep-version">1.2.2</td></tr><tr><td class="dep-name">ring-anti-forgery</td><td class="dotted"><hr /></td><td class="dep-version">0.1.3</td></tr><tr><td class="dep-name">fetch</td><td class="dotted"><hr /></td><td class="dep-version">0.1.0-alpha2</td></tr><tr><td class="dep-name">crate</td><td class="dotted"><hr /></td><td class="dep-version">0.2.0-alpha3</td></tr><tr><td class="dep-name">enlive</td><td class="dotted"><hr /></td><td class="dep-version">1.0.0</td></tr><tr><td class="dep-name">hiccup</td><td class="dotted"><hr /></td><td class="dep-version">0.3.8</td></tr><tr><td class="dep-name">domina</td><td class="dotted"><hr /></td><td class="dep-version">1.0.0-beta4</td></tr><tr><td class="dep-name">jayq</td><td class="dotted"><hr /></td><td class="dep-version">0.1.0-alpha4</td></tr><tr><td class="dep-name">com.keminglabs/chosen</td><td class="dotted"><hr /></td><td class="dep-version">0.1.6</td></tr></table></div></td><td class="codes" style="text-align: center; vertical-align: middle;color: #666;padding-right:20px"><br /><br /><br />(this space intentionally left almost blank)</td></tr><tr><td class="docs"><div class="toc"><a name="toc"><h3>namespaces</h3></a><ul><li><a href="#bcbio.align.ref">bcbio.align.ref</a></li><li><a href="#bcbio.align.reorder">bcbio.align.reorder</a></li><li><a href="#bcbio.run.broad">bcbio.run.broad</a></li><li><a href="#bcbio.run.itx">bcbio.run.itx</a></li><li><a href="#bcbio.variation.annotate.nbq">bcbio.variation.annotate.nbq</a></li><li><a href="#bcbio.variation.annotation">bcbio.variation.annotation</a></li><li><a href="#bcbio.variation.api.metrics">bcbio.variation.api.metrics</a></li><li><a href="#bcbio.variation.callable">bcbio.variation.callable</a></li><li><a href="#bcbio.variation.combine">bcbio.variation.combine</a></li><li><a href="#bcbio.variation.compare">bcbio.variation.compare</a></li><li><a href="#bcbio.variation.complex">bcbio.variation.complex</a></li><li><a href="#bcbio.variation.config">bcbio.variation.config</a></li><li><a href="#bcbio.variation.core">bcbio.variation.core</a></li><li><a href="#bcbio.variation.evaluate">bcbio.variation.evaluate</a></li><li><a href="#bcbio.variation.filter">bcbio.variation.filter</a></li><li><a href="#bcbio.variation.filter.classify">bcbio.variation.filter.classify</a></li><li><a href="#bcbio.variation.haploid">bcbio.variation.haploid</a></li><li><a href="#bcbio.variation.metrics">bcbio.variation.metrics</a></li><li><a href="#bcbio.variation.multiple">bcbio.variation.multiple</a></li><li><a href="#bcbio.variation.normalize">bcbio.variation.normalize</a></li><li><a href="#bcbio.variation.phasing">bcbio.variation.phasing</a></li><li><a href="#bcbio.variation.recall">bcbio.variation.recall</a></li><li><a href="#bcbio.variation.report">bcbio.variation.report</a></li><li><a href="#bcbio.variation.structural">bcbio.variation.structural</a></li><li><a href="#bcbio.variation.utils.background">bcbio.variation.utils.background</a></li><li><a href="#bcbio.variation.utils.cgmetrics">bcbio.variation.utils.cgmetrics</a></li><li><a href="#bcbio.variation.utils.gms">bcbio.variation.utils.gms</a></li><li><a href="#bcbio.variation.utils.popfreq">bcbio.variation.utils.popfreq</a></li><li><a href="#bcbio.variation.utils.summarize">bcbio.variation.utils.summarize</a></li><li><a href="#bcbio.variation.validate">bcbio.variation.validate</a></li><li><a href="#bcbio.variation.variantcontext">bcbio.variation.variantcontext</a></li><li><a href="#bcbio.variation.vcfwalker">bcbio.variation.vcfwalker</a></li><li><a href="#bcbio.variation.web.db">bcbio.variation.web.db</a></li><li><a href="#bcbio.variation.web.process">bcbio.variation.web.process</a></li><li><a href="#bcbio.variation.web.server">bcbio.variation.web.server</a></li><li><a href="#bcbio.variation.web.shared">bcbio.variation.web.shared</a></li><li><a href="#bcbio.variation.analyses">bcbio.variation.analyses</a></li><li><a href="#bcbio.variation.login">bcbio.variation.login</a></li><li><a href="#bcbio.variation.score">bcbio.variation.score</a></li></ul></div></td><td class="codes">&nbsp;</td></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.align.ref" name="bcbio.align.ref"><h1 class="project-name">bcbio.align.ref</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Deal with reference sequences for alignment and variant calling.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.align.ref
  (:import [org.broadinstitute.sting.gatk.datasources.reference ReferenceDataSource]
           [net.sf.picard.reference ReferenceSequenceFileFactory])
  (:use [clojure.java.io]
        [ordered.map :only [ordered-map]])
  (:require [clojure.string :as string]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><p>Retrieve Picard sequence dictionary from FASTA reference file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-seq-dict
  [ref-file]
  (ReferenceDataSource. (file ref-file))
  (-&gt; ref-file
      file
      ReferenceSequenceFileFactory/getReferenceSequenceFile
      .getSequenceDictionary))</pre></td></tr><tr><td class="docs"><p>Retrieve map of sequence names to index positions in the input reference.
   This is useful for sorting by position.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-seq-name-map
  [ref-file]
  (reduce (fn [coll [i x]] (assoc coll x i))
          (ordered-map)
          (map-indexed vector
                       (map #(.getSequenceName %) (.getSequences (get-seq-dict ref-file))))))</pre></td></tr><tr><td class="docs"><p>Sort a BED file relative to the input reference</p>
</td><td class="codes"><pre class="brush: clojure">(defn sort-bed-file
  [bed-file ref-file]
  (letfn [(process-line [line]
            (let [parts (if (&gt; (count (string/split line #&quot;\t&quot;)) 1)
                          (string/split line #&quot;\t&quot;)
                          (string/split line #&quot; &quot;))]
              (let [[chr start end] (take 3 parts)]
                [[chr (Integer/parseInt start) (Integer/parseInt end)] line])))
          (ref-sort-fn [ref-file]
            (let [contig-map (get-seq-name-map ref-file)]
              (fn [x]
                (let [sort-vals (first x)]
                  (vec (cons (get contig-map (first sort-vals))
                             (rest sort-vals)))))))]
    (let [out-file (itx/add-file-part bed-file &quot;sorted&quot;)]
      (when (itx/needs-run? out-file)
        (with-open [rdr (reader bed-file)
                    wtr (writer out-file)]
          (doseq [[_ line] (sort-by (ref-sort-fn ref-file)
                                    (map process-line (line-seq rdr)))]
            (.write wtr (str line &quot;\n&quot;)))))
      out-file)))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.align.reorder" name="bcbio.align.reorder"><h1 class="project-name">bcbio.align.reorder</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Reorder BAM alignment files to a reference dictionary, potentially swapping naming.
  Handles Human hg19 to GRCh37 naming conversions.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.align.reorder
  (:import [net.sf.samtools SAMFileReader SAMFileWriterFactory SAMReadGroupRecord
            SAMTag SAMFileReader$ValidationStringency])
  (:use [clojure.java.io]
        [bcbio.align.ref :only [get-seq-dict]]
        [bcbio.run.broad :only [index-bam]]
        [bcbio.variation.normalize :only [hg19-map]])
  (:require [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><p>Add updated sequence dictionary and run group information to header.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- updated-bam-header
  [in-bam ref-file call exp]
  (letfn [(update-rgs [rgs]
            (if-not (empty? rgs) rgs
                    [(doto (SAMReadGroupRecord. &quot;1&quot;)
                       (.setLibrary (:sample exp))
                       (.setPlatform (get call :platform &quot;illumina&quot;))
                       (.setSample (:sample exp))
                       (.setPlatformUnit (:sample exp)))]))]
    (let [read-groups (update-rgs (-&gt; in-bam .getFileHeader .getReadGroups))]
      (doto (-&gt; in-bam .getFileHeader .clone)
        (.setSequenceDictionary (-&gt; ref-file get-seq-dict))
        (.setReadGroups read-groups)))))</pre></td></tr><tr><td class="docs"><p>Retrieve order of chromosomes to fetch and mapping to new index.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-new-chr-order
  [bam-names ref-names]
  (letfn [(get-bam-name-map [bam-names orig-ref-names]
            (let [ref-names (set orig-ref-names)]
              (reduce (fn [coll x]
                        (assoc coll (cond
                                     (contains? ref-names x) x
                                     (contains? hg19-map x) (get hg19-map x)
                                     :else (throw (Exception. (str &quot;Could not map &quot; x))))
                               x))
                      {} bam-names)))
          (get-index-map [name-map]
            (let [bam-name-map (reduce (fn [coll [x y]] (assoc coll y x))
                                       {} name-map)]
              (reduce (fn [coll [i x]]
                        (assoc coll i (.indexOf ref-names (get bam-name-map x))))
                      {} (map-indexed vector bam-names))))]
    (when-not (every? #(apply = %) (partition 2 (interleave ref-names bam-names)))
      (let [name-map (get-bam-name-map bam-names ref-names)]
        {:names (remove nil? (map #(get name-map %) ref-names))
         :indexes (get-index-map name-map)}))))</pre></td></tr><tr><td class="docs"><p>Lazy sequence for BAM reads from a Picard iterator.</p>
</td><td class="codes"><pre class="brush: clojure">(defn bam-read-seq
  [iter]
  (lazy-seq
   (when (.hasNext iter)
     (cons (.next iter) (bam-read-seq iter)))))</pre></td></tr><tr><td class="docs"><p>Write reordered BAM file in specified chromosome order.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- write-reorder-bam
  [in-bam out-bam chr-order header]
  (let [default-rg-id (-&gt; header .getReadGroups first .getId)]
    (letfn [(update-read [read]
              (let [new-rg-id (if-let [x (.getAttribute read (.name SAMTag/RG))] x
                                      default-rg-id)]
                (doto read
                  (.setHeader header)
                  (.setReferenceIndex (get (:indexes chr-order)
                                           (.getReferenceIndex read) -1))
                  (.setMateReferenceIndex (get (:indexes chr-order)
                                               (.getMateReferenceIndex read) -1))
                  (.setAttribute (.name SAMTag/RG) new-rg-id))))]
      (doseq [cur-chr (:names chr-order)]
        (with-open [iter (.query in-bam cur-chr 0 0 false)]
          (doseq [read (bam-read-seq iter)]
            (.addAlignment out-bam (update-read read)))))
      (with-open [iter (.queryUnmapped in-bam)]
        (doseq [read (bam-read-seq iter)]
          (.addAlignment out-bam (update-read read)))))))</pre></td></tr><tr><td class="docs"><p>Reorder and remap BAM file to match supplied reference file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn reorder-bam
  [bam-file ref-file call exp &amp; {:keys [out-dir]}]
  (let [out-file (itx/add-file-part bam-file &quot;reorder&quot; out-dir)]
    (when (itx/needs-run? out-file)
      (index-bam bam-file)
      (SAMFileReader/setDefaultValidationStringency SAMFileReader$ValidationStringency/LENIENT)
      (with-open [in-bam (SAMFileReader. (file bam-file))]
        (let [ref-names (map #(.getSequenceName %) (-&gt; ref-file get-seq-dict .getSequences))
              bam-names (map #(.getSequenceName %) (-&gt; in-bam .getFileHeader .getSequenceDictionary
                                                       .getSequences))
              header (updated-bam-header in-bam ref-file call exp)]
          (if-let [chr-order (get-new-chr-order bam-names ref-names)]
            (do
              (with-open [out-bam (.makeSAMOrBAMWriter (SAMFileWriterFactory.)
                                                       header true (file out-file))]
                (write-reorder-bam in-bam out-bam chr-order header))
              out-file)
            bam-file))))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -main [bam-file ref-file sample-name]
  (reorder-bam bam-file ref-file {} {:sample sample-name}))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.run.broad" name="bcbio.run.broad"><h1 class="project-name">bcbio.run.broad</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>High level functions to run software from Broad: GATK, Picard</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.run.broad
  (:import [org.broadinstitute.sting.gatk CommandLineGATK]
           [net.sf.samtools SAMFileReader SAMFileReader$ValidationStringency]
           [net.sf.picard.sam BuildBamIndex])
  (:use [clojure.java.io]
        [bcbio.align.ref :only [sort-bed-file]])
  (:require [fs.core :as fs]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><p>Run a GATK commandline in an idempotent file-safe transaction.</p>
</td><td class="codes"><pre class="brush: clojure">(defn run-gatk
  [program args file-info map-info]
  (if (itx/needs-run? (map #(% file-info) (get map-info :out [])))
    (let [std-args [&quot;-T&quot; program]]
      (itx/with-tx-files [tx-file-info file-info (get map-info :out []) [&quot;.idx&quot;]]
        (CommandLineGATK/start (CommandLineGATK.)
                               (into-array (map str (itx/subs-kw-files
                                                     (concat std-args args)
                                                     tx-file-info))))))))</pre></td></tr><tr><td class="docs"><p>Generate BAM index, skipping if already present.</p>
</td><td class="codes"><pre class="brush: clojure">(defn index-bam
  [in-bam]
  (let [index-file (str in-bam &quot;.bai&quot;)]
    (if (itx/needs-run? index-file)
      (do
        (SAMFileReader/setDefaultValidationStringency SAMFileReader$ValidationStringency/LENIENT)
        (BuildBamIndex/createIndex (SAMFileReader. (file in-bam)) (file index-file))))
    index-file))</pre></td></tr><tr><td class="docs"><p>Supply GATK commandline arguments for interval files, merging via intersection.</p>
</td><td class="codes"><pre class="brush: clojure">(defn gatk-cl-intersect-intervals
  [intervals ref-file &amp; {:keys [vcf]}]
  (cond
   (nil? intervals) (if vcf [&quot;-L&quot; vcf] [])
   (coll? intervals) (concat (flatten (map #(list &quot;-L&quot; %)
                                           (map #(sort-bed-file % ref-file) intervals)))
                             [&quot;--interval_set_rule&quot; &quot;INTERSECTION&quot;])
   :else [&quot;-L&quot; (sort-bed-file intervals ref-file)]))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.run.itx" name="bcbio.run.itx"><h1 class="project-name">bcbio.run.itx</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Functionality for running idempotent, transactional processes.
   Provides an API for long running processes in computational
   pipelines. Avoids re-running a process if it has produced the
   output file on a previous run, and leaving partially finished
   files in the case of premature termination.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.run.itx
  (:import (java.io File))
  (:use [clojure.java.io])
  (:require [fs.core :as fs]))</pre></td></tr><tr><td class="docs"><h2>Idempotent processing</h2>

<p>avoid re-running when output files exist</p>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Check if an output files need a run: any do not exist or empty file</p>
</td><td class="codes"><pre class="brush: clojure">(defn needs-run?
  [&amp; fnames]
  (letfn [(file-non-empty? [f]
            (and (fs/exists? f)
                 (&gt; (fs/size f) 0)))]
    (not-every? true?
                (map file-non-empty? (flatten fnames)))))</pre></td></tr><tr><td class="docs"><p>Substitute any keywords in the arguments from file information map.</p>
</td><td class="codes"><pre class="brush: clojure">(defn subs-kw-files
  [args file-info]
  (letfn [(maybe-sub-kw [x]
            (if (and (keyword? x)
                     (contains? file-info x))
              (get file-info x)
              x))]
    (map maybe-sub-kw args)))</pre></td></tr><tr><td class="docs"><h2>Transactions</h2>

<p>Handle output files in a separate transaction directory to avoid
partially finished output files if long-running processes fail.</p>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn temp-dir-w-prefix [root prefix]
  (let [dir (File/createTempFile prefix  (file root))]
    (fs/delete dir)
    (fs/mkdir dir)
    dir))</pre></td></tr><tr><td class="docs"><p>Provide a temporary directory, removed when exiting the body.</p>
</td><td class="codes"><pre class="brush: clojure">(defmacro with-temp-dir
  [[tmp-dir base-dir] &amp; body]
  `(let [~tmp-dir (temp-dir-w-prefix ~base-dir &quot;tmp&quot;)]
     (try
       ~@body
       (finally
        (fs/delete-dir ~tmp-dir)))))</pre></td></tr><tr><td class="docs"><p>Update file-info with need-tx files in a safe transaction directory.</p>
</td><td class="codes"><pre class="brush: clojure">(defn safe-tx-files
  [file-info need-tx]
  (let [tx-files (map #(get file-info %) need-tx)
        tx-dir (temp-dir-w-prefix (fs/parent (first tx-files)) &quot;txtmp&quot;)]
    (reduce (fn [m [k v]]
              (assoc m k v))
            file-info
            (zipmap need-tx
                    (map #(str (fs/file tx-dir (fs/base-name %))) tx-files)))))</pre></td></tr><tr><td class="docs"><p>Rename generated transaction files into expected file location.</p>
</td><td class="codes"><pre class="brush: clojure">(defn rename-tx-files
  [tx-file-info file-info need-tx exts]
  (doseq [tx-key need-tx]
    (let [tx-safe (get tx-file-info tx-key) 
          tx-final (get file-info tx-key)]
      (fs/rename tx-safe tx-final)
      (doseq [ext exts]
        (when (fs/exists? (str tx-safe ext))
          (fs/rename (str tx-safe ext) (str tx-final ext)))))))</pre></td></tr><tr><td class="docs"><p>Perform action with files, keeping need-tx files in a transaction.</p>
</td><td class="codes"><pre class="brush: clojure">(defmacro with-tx-files
  [[tx-file-info file-info need-tx exts] &amp; body]
  (if (= (count need-tx) 0)
    `(do ~@body)
    `(let [~tx-file-info (safe-tx-files ~file-info ~need-tx)]
       (try
         ~@body
         (rename-tx-files ~tx-file-info ~file-info ~need-tx ~exts)
         (finally
          (fs/delete-dir (fs/parent (get ~tx-file-info (first ~need-tx)))))))))</pre></td></tr><tr><td class="docs"><h2>Naming</h2>

<p>Generate new file names from existing ones</p>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Retrieve file name without extension: /path/to/fname.txt -> /path/to/fname</p>
</td><td class="codes"><pre class="brush: clojure">(defn file-root
  [fname]
  (let [i (.lastIndexOf fname &quot;.&quot;)]
    (if (pos? i)
      (subs fname 0 i)
      fname)))</pre></td></tr><tr><td class="docs"><p>Add file extender: base.txt -> base-part.txt</p>
</td><td class="codes"><pre class="brush: clojure">(defn add-file-part
  ([fname part]
     (add-file-part fname part nil))
  ([fname part out-dir]
     (let [out-fname (format &quot;%s-%s%s&quot; (file-root fname) part (fs/extension fname))]
       (if-not (nil? out-dir)
         (str (fs/file out-dir (fs/base-name out-fname)))
         out-fname))))</pre></td></tr><tr><td class="docs"><p>Remove any zip extensions from the input filename</p>
</td><td class="codes"><pre class="brush: clojure">(defn remove-zip-ext
  [fname]
  (letfn [(maybe-remove-ext [fname ext]
            (if (.endsWith fname ext)
              (subs fname 0 (- (.length fname) (.length ext)))
              fname))]
    (let [exts [&quot;.tar.gz&quot; &quot;tar.bz2&quot; &quot;.gz&quot; &quot;.bz2&quot; &quot;.zip&quot;]]
      (reduce maybe-remove-ext fname exts))))</pre></td></tr><tr><td class="docs"><h2>File and directory manipulation</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Remove file or directory only if it exists.</p>
</td><td class="codes"><pre class="brush: clojure">(defn remove-path
  [x]
  (if (fs/exists? x)
    (if (fs/directory? x)
      (fs/delete-dir x)
      (fs/delete x))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.annotate.nbq" name="bcbio.variation.annotate.nbq"><h1 class="project-name">bcbio.variation.annotate.nbq</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>GATK annotator that calculates Mean Neighboring Base Quality (NBQ) for variants.</p>

<p>  The motivation for this annotation is that regional base quality influences whether
  a call is correct. The Atlas2 paper describes the metric in more detail:</p>

<p>  http://www.biomedcentral.com/1471-2105/13/8/abstract</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.annotate.nbq
  (:import [org.broadinstitute.sting.gatk.walkers.annotator.interfaces.InfoFieldAnnotation]
           [org.broadinstitute.sting.utils.codecs.vcf VCFInfoHeaderLine VCFHeaderLineType])
  (:require [incanter.stats :as istats])
  (:gen-class
   :name bcbio.variation.annotate.nbq.MeanNeighboringBaseQuality
   :extends org.broadinstitute.sting.gatk.walkers.annotator.interfaces.InfoFieldAnnotation))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(def flank-bp 5)</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -getKeyNames
  [_]
  [&quot;NBQ&quot;])</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -getDescriptions
  [_]
  [(VCFInfoHeaderLine. &quot;NBQ&quot; 1 VCFHeaderLineType/Float
                       (format &quot;Mean Neighboring Base Quality, includes %sbp on both sides&quot;
                               flank-bp))])</pre></td></tr><tr><td class="docs"><p>Provide Mean Neighboring Base Quality calculations at a position.</p>

<pre><code>- Get a pileup for each sample context.
- Use pileup to retrieve reads and current offsets.
- Get quality from reads and pull out qualities in surrounding region
- Calculate mean and return.
</code></pre>
</td><td class="codes"><pre class="brush: clojure">(defn -annotate
  [_ _ _ _ contexts _]
  (letfn [(get-pileup [context]
            (if (.hasExtendedEventPileup context)
              (.getExtendedEventPileup context)
              (.getBasePileup context)))
          (neighbor-qualities [[offset read]]
            (let [quals (-&gt; read .getBaseQualities vec)]
              (map #(nth quals % nil) (range (- offset flank-bp) (+ offset flank-bp)))))
          (pileup-qualities [pileup]
            (map neighbor-qualities (map vector (.getOffsets pileup) (.getReads pileup))))]
    {&quot;NBQ&quot; (-&gt;&gt; contexts
                vals
                (map get-pileup)
                (map pileup-qualities)
                flatten
                (remove nil?)
                istats/mean
                (format &quot;%.2f&quot;))}))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.annotation" name="bcbio.variation.annotation"><h1 class="project-name">bcbio.variation.annotation</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Annotate variant calls with metrics for assessing false positives
  http://www.broadinstitute.org/gsa/wiki/index.php/VariantAnnotator</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.annotation
  (:use [bcbio.variation.utils.cgmetrics :only [add-cgmetrics]])
  (:require [fs.core :as fs]
            [bcbio.run.itx :as itx]
            [bcbio.run.broad :as broad]))</pre></td></tr><tr><td class="docs"><p>Standard annotations applied to variants</p>
</td><td class="codes"><pre class="brush: clojure">(def  std-annotations
  [&quot;AlleleBalance&quot; &quot;BaseQualityRankSumTest&quot; &quot;DepthOfCoverage&quot;
   &quot;FisherStrand&quot; &quot;GCContent&quot; &quot;HaplotypeScore&quot; &quot;HomopolymerRun&quot;
   &quot;MappingQualityRankSumTest&quot; &quot;MappingQualityZero&quot;
   &quot;MeanNeighboringBaseQuality&quot; &quot;QualByDepth&quot;
   &quot;ReadPosRankSumTest&quot; &quot;RMSMappingQuality&quot;
   &quot;DepthPerAlleleBySample&quot;])</pre></td></tr><tr><td class="docs"><p>Add GATK annotation metrics to variant calls.</p>
</td><td class="codes"><pre class="brush: clojure">(defn add-gatk-annotations
  [in-vcf align-bam ref &amp; {:keys [out-dir intervals]}]
  {:pre [(not (nil? align-bam))]}
  (let [file-info {:out-vcf (itx/add-file-part in-vcf &quot;annotated&quot; out-dir)}
        args (concat [&quot;-R&quot; ref
                      &quot;-I&quot; align-bam
                      &quot;--variant&quot; in-vcf
                      &quot;-o&quot; :out-vcf]
                     (reduce #(concat %1 [&quot;-A&quot; %2]) [] std-annotations)
                     (broad/gatk-cl-intersect-intervals intervals ref :vcf in-vcf))]
    (broad/index-bam align-bam)
    (broad/run-gatk &quot;VariantAnnotator&quot; args file-info {:out [:out-vcf]})
    (:out-vcf file-info)))</pre></td></tr><tr><td class="docs"><p>Flexible addition of additions to a variant file.
  Handles GATK annotations and Complete Genomics metrics.</p>
</td><td class="codes"><pre class="brush: clojure">(defn add-variant-annotations
  [vcf-file bam-file ref-file call &amp; {:keys [out-dir intervals]}]
  (let [x (get call :annotate &quot;&quot;)
        ann (if (true? x) &quot;gatk&quot; x)]
    (cond
     (and (= ann &quot;gatk&quot;) (not (nil? bam-file)))
     (add-gatk-annotations vcf-file bam-file ref-file :out-dir out-dir :intervals intervals)
     (.contains ann &quot;masterVar&quot;)
     (add-cgmetrics vcf-file ann ref-file :out-dir out-dir)
     :else vcf-file)))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.api.metrics" name="bcbio.variation.api.metrics"><h1 class="project-name">bcbio.variation.api.metrics</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Provide high level API for accessing variant associated metrics.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.api.metrics
  (:import [org.jfree.data.statistics HistogramDataset HistogramType])
  (:use [ordered.map :only [ordered-map]]
        [bcbio.variation.filter.classify :only [get-vc-attrs]]
        [bcbio.variation.variantcontext :only [get-vcf-header get-vcf-source parse-vcf]]))</pre></td></tr><tr><td class="docs"><p>Metrics to expose, ranked in order of priority with default min/max values.</p>
</td><td class="codes"><pre class="brush: clojure">(def ^{:doc 
       :private true}
  expose-metrics
  (ordered-map &quot;QUAL&quot; [0.0 100000.0]
               &quot;DP&quot; [0.0 5000.0]
               &quot;MQ&quot; [0.0 75.0]
               &quot;QD&quot; [0.0 200.0]
               &quot;HaplotypeScore&quot; [0.0 250.0]))</pre></td></tr><tr><td class="docs"><p>Default metrics that are always available.</p>
</td><td class="codes"><pre class="brush: clojure">(def ^{:doc  :private true}
  default-metrics
  [{:id &quot;QUAL&quot; :desc &quot;Variant quality score, phred-scaled&quot;}])</pre></td></tr><tr><td class="docs"><p>Retrieve metrics available for variant input file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn available-metrics
  [vcf-file]
  (letfn [(convert-header [line]
            {:id (.getID line)
             :desc (.getDescription line)})]
    (let [metrics-order (reduce (fn [coll [i x]] (assoc coll x i))
                                {} (map-indexed vector (keys expose-metrics)))]
      (-&gt;&gt; (get-vcf-header vcf-file)
           .getMetaData
           (filter #(= &quot;INFO&quot; (.getKey %)))
           (filter #(contains? expose-metrics (.getID %)))
           (map convert-header)
           (concat default-metrics)
           (sort-by #(get metrics-order (:id %)))))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- get-histogram-bins
  [items n bin-min bin-max]
  &quot;Retrieve values binned into a histogram using JFree Chart.&quot;
  (let [ds (doto (HistogramDataset.)
             (.setType HistogramType/RELATIVE_FREQUENCY)
             (.addSeries 0 (double-array items) n bin-min bin-max))]
    {:x (map #(.getXValue ds 0 %) (range (.getItemCount ds 0)))
     :y (map #(.getYValue ds 0 %) (range (.getItemCount ds 0)))}))</pre></td></tr><tr><td class="docs"><p>Retrieve raw metrics values from input VCF for provided keys.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-raw-metrics
  [ks vcf-file ref-file]
  (with-open [vcf-source (get-vcf-source vcf-file ref-file)]
    (reduce (fn [coll vc]
              (reduce (fn [inner-coll [key val]]
                        (assoc inner-coll key
                               (cons val (get inner-coll key))))
                      coll (get-vc-attrs vc (keys coll))))
            (zipmap ks (repeat [])) (parse-vcf vcf-source))))</pre></td></tr><tr><td class="docs"><p>Remove nil values and empty input metrics.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- clean-raw-metrics
  [raw]
  (reduce (fn [coll [k vs]]
            (let [clean-vs (remove nil? vs)]
              (if (empty? clean-vs)
                coll
                (assoc coll k clean-vs))))
          {} raw))</pre></td></tr><tr><td class="docs"><p>Bin metrics in preparation for histogram display using predefined min-max boundaries.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- prepare-plot-metrics
  [metric raw]
  (let [bins 20
        [bin-min bin-max] (get expose-metrics metric)
        data (get-histogram-bins raw bins bin-min bin-max)]
    {:vals (:y data)
     :bin-width (- (second (:x data)) (first (:x data)))
     :x-scale {:type :linear
               :domain [bin-min bin-max]}
     :y-scale {:type :linear}}))</pre></td></tr><tr><td class="docs"><p>Provide metrics for a VCF file ready for plotting and visualization.</p>
</td><td class="codes"><pre class="brush: clojure">(defn plot-ready-metrics
  [vcf-file ref-file &amp; {:keys [metrics]}]
  (let [plot-metrics (if (nil? metrics) (available-metrics vcf-file) metrics)
        raw-metrics (clean-raw-metrics
                     (get-raw-metrics (map :id plot-metrics) vcf-file ref-file))]
    {:filename vcf-file
     :created-on (java.util.Date.)
     :metrics (map #(merge % (prepare-plot-metrics (:id %) (get raw-metrics (:id %))))
                   (remove #(nil? (get raw-metrics (:id %))) plot-metrics))}))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.callable" name="bcbio.variation.callable"><h1 class="project-name">bcbio.variation.callable</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Identify callable bases from a BAM alignment file.
  Help differentiate positions where we can not assess variation</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.callable
  (:import [org.broad.tribble.bed BEDCodec]
           [org.broad.tribble.index IndexFactory]
           [org.broad.tribble.source BasicFeatureSource])
  (:use [clojure.java.io]
        [bcbio.align.ref :only [sort-bed-file]])
  (:require [clojure.string :as string]
            [fs.core :as fs]
            [bcbio.run.itx :as itx]
            [bcbio.run.broad :as broad]))</pre></td></tr><tr><td class="docs"><p>Identify callable bases from the provided alignment file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn identify-callable
  [align-bam ref &amp; {:keys [out-dir intervals]}]
  (let [base-dir (if (or (nil? out-dir)
                         (fs/writeable? (fs/parent align-bam)))
                   (fs/parent align-bam)
                   out-dir)
        base-fname (str (file base-dir (-&gt; align-bam fs/base-name itx/file-root)))
        file-info {:out-bed (format &quot;%s-callable.bed&quot; base-fname)
                   :out-summary (format &quot;%s-callable-summary.txt&quot; base-fname)}
        args (concat [&quot;-R&quot; ref
                      &quot;-I&quot; align-bam
                      &quot;--out&quot; :out-bed
                      &quot;--summary&quot; :out-summary]
                     (broad/gatk-cl-intersect-intervals intervals ref))]
    (if-not (fs/exists? base-dir)
      (fs/mkdirs base-dir))
    (broad/index-bam align-bam)
    (broad/run-gatk &quot;CallableLoci&quot; args file-info {:out [:out-bed :out-summary]})
    (:out-bed file-info)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn features-in-region [source space start end]
  (for [f (.query source space start end)]
    {:chr (.getChr f)
     :start (.getStart f)
     :end (.getEnd f)
     :name (.getName f)
     :score (.getScore f)
     :strand (.getStrand f)}))</pre></td></tr><tr><td class="docs"><p>Provide tribble feature source for a BED formatted file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-bed-source
  [bed-file ref-file]
  (let [batch-size 500
        work-bed (sort-bed-file bed-file ref-file)
        idx (IndexFactory/createIntervalIndex (file work-bed) (BEDCodec.) batch-size)]
    (BasicFeatureSource. work-bed idx (BEDCodec.))))</pre></td></tr><tr><td class="docs"><p>Create BED file of callable regions from the BAM alignment file.
  Pass the callable BED to GATK for subsetting based on callable intervals.
  Since the callable output is 1-based inclusive, this converts to 0-based
  intervals on output.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-callable-bed
  [align-bam ref &amp; {:keys [out-dir intervals]}]
  (let [orig-bed-file (identify-callable align-bam ref :out-dir out-dir
                                         :intervals intervals)
        out-file (itx/add-file-part orig-bed-file &quot;intervals&quot;)]
    (with-open [source (get-bed-source orig-bed-file ref)
                wtr (writer out-file)]
      (doseq [f (.iterator source)]
        (when (= (.getName f) &quot;CALLABLE&quot;)
          (.write wtr (format &quot;%s\t%s\t%s\n&quot; (.getChr f)
                              (- (.getStart f) 2) (.getEnd f))))))
    out-file))</pre></td></tr><tr><td class="docs"><h2>Multiple callables</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Provide callable checker for potentially multiple inputs</p>
</td><td class="codes"><pre class="brush: clojure">(defprotocol CallableChecker
  (has-callers? [this])
  (is-callable? [this space start end]))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defrecord BamCallable [sources check-fn]
  CallableChecker
  (has-callers? [_]
    (not (empty? sources)))
  (is-callable? [_ space start end]
    (letfn [(source-is-callable? [source space start end]
              (if (&lt;= start end)
                (&gt; (count (features-in-region source space start end)) 0)
                false))]
      (if (empty? sources)
        true
        (check-fn #(source-is-callable? % space start end) sources))))
  java.io.Closeable
  (close [_]
    (doseq [x sources]
      (.close x))))</pre></td></tr><tr><td class="docs"><p>Retrieve generalized callabilitu checkers that handles multiple file inputs.
  Checks if a chromosome start end region is callable based on reads in input BAM files.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-callable-checker
  [bam-files ref &amp; {:keys [out-dir intervals check-fn]
                 :or {check-fn some}}]
  (let [work-bam-files (remove nil? (if (coll? bam-files) bam-files [bam-files]))
        sources (map #(-&gt; (get-callable-bed % ref :out-dir out-dir :intervals intervals)
                          (get-bed-source ref))
                     work-bam-files)]
    (BamCallable. sources check-fn)))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.combine" name="bcbio.variation.combine"><h1 class="project-name">bcbio.variation.combine</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Combine variant files, handling no-calls versus reference calls</p>

<ol>
<li>Combine the variants to create a merged set of positions to call at</li>
<li>For each variant file:
  a. Generate callability at each position
  b. Combine original calls with merged positions
  c. Walk through each no-call and set as reference if callable</li>
</ol>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.combine
  (:use [bcbio.variation.complex :only [normalize-variants]]
        [bcbio.variation.haploid :only [diploid-calls-to-haploid]]
        [bcbio.variation.normalize :only [prep-vcf clean-problem-vcf]]
        [bcbio.variation.phasing :only [is-haploid?]]
        [bcbio.variation.variantcontext :only [get-vcf-header]])
  (:require [fs.core :as fs]
            [clojure.string :as string]
            [bcbio.run.itx :as itx]
            [bcbio.run.broad :as broad]))</pre></td></tr><tr><td class="docs"><p>Combine multiple variant files with GATK CombineVariants.
   Only correctly handles all-by-all comparisons with the same ploidy level.</p>
</td><td class="codes"><pre class="brush: clojure">(defn combine-variants
  [vcfs ref &amp; {:keys [merge-type out-dir intervals unsafe name-map base-ext check-ploidy? quiet-out?]
               :or {merge-type :unique
                    unsafe false
                    name-map {}
                    check-ploidy? true}}]
  (when (and check-ploidy?
             (&gt; (count (set (remove nil? (map #(is-haploid? % ref) vcfs)))) 1))
    (throw (Exception. (format &quot;Haploid and non-haploid combinations not supported: %s %s&quot;
                               (vec vcfs) (vec (map #(is-haploid? % ref) vcfs))))))
  (letfn [(unique-name [i f]
            (if quiet-out?
              (str &quot;v&quot; i)
              (get name-map f
                   (-&gt; f fs/base-name itx/file-root))))]
    (let [base-dir (if (nil? out-dir) (fs/parent (first vcfs)) out-dir)
          full-base-name (-&gt; vcfs first fs/base-name itx/remove-zip-ext)
          base-name (if (nil? base-ext) full-base-name
                        (format &quot;%s-%s.vcf&quot; (first (string/split full-base-name #&quot;-&quot;))
                                base-ext))
          file-info {:out-vcf (str (fs/file base-dir
                                            (itx/add-file-part base-name
                                                               (case merge-type
                                                                     :minimal &quot;mincombine&quot;
                                                                     :full &quot;fullcombine&quot;
                                                                     &quot;combine&quot;))))}
          args (concat [&quot;-R&quot; ref
                        &quot;-o&quot; :out-vcf
                        &quot;--rod_priority_list&quot; (string/join &quot;,&quot; (map-indexed unique-name vcfs))]
                       (if unsafe [&quot;--unsafe&quot; &quot;ALLOW_SEQ_DICT_INCOMPATIBILITY&quot;] [])
                       (if quiet-out? [&quot;--suppressCommandLineHeader&quot; &quot;--setKey&quot; &quot;null&quot;] [])
                       (flatten (map-indexed #(list (str &quot;--variant:&quot; (unique-name %1 %2)) %2) vcfs))
                       (broad/gatk-cl-intersect-intervals intervals ref)
                       (case merge-type
                             :full [&quot;--genotypemergeoption&quot; &quot;PRIORITIZE&quot;]
                             :unique [&quot;--genotypemergeoption&quot; &quot;UNIQUIFY&quot;]
                             :minimal [&quot;--sites_only&quot; &quot;--minimalVCF&quot;]))]
      (if-not (fs/exists? base-dir)
        (fs/mkdirs base-dir))
      (broad/run-gatk &quot;CombineVariants&quot; args file-info {:out [:out-vcf]})
      (:out-vcf file-info))))</pre></td></tr><tr><td class="docs"><p>Check if the input VCF file has multiple genotyped samples.</p>
</td><td class="codes"><pre class="brush: clojure">(defn multiple-samples?
  [in-file &amp; {:keys [sample]}]
  (let [samples (-&gt; in-file get-vcf-header .getGenotypeSamples)]
    (or (&gt; (count samples) 1)
        (and (not (nil? sample))
             (not (contains? (set samples) sample))))))</pre></td></tr><tr><td class="docs"><p>Retrieve the sample name in a provided VCF file, allowing for partial matches.</p>
</td><td class="codes"><pre class="brush: clojure">(defn vcf-sample-name
  [sample in-vcf ref-file]
  (letfn [(sample-match [x choices]
            (let [do-match (filter #(when (.contains % x) %) choices)]
              (when (= 1 (count do-match))
                (first do-match))))]
    (let [vcf-samples (-&gt; in-vcf get-vcf-header .getGenotypeSamples set)]
      (if (contains? vcf-samples sample)
        sample
        (sample-match sample vcf-samples)))))</pre></td></tr><tr><td class="docs"><p>Select only the sample of interest from input VCF files.</p>
</td><td class="codes"><pre class="brush: clojure">(defn select-by-sample
  [sample in-file name ref &amp; {:keys [out-dir intervals remove-refcalls]
                              :or {remove-refcalls false}}]
  (let [base-dir (if (nil? out-dir) (fs/parent in-file) out-dir)
        file-info {:out-vcf (str (fs/file base-dir
                                          (format &quot;%s-%s.vcf&quot; sample name)))}
        args (concat [&quot;-R&quot; ref
                      &quot;--sample_name&quot; (vcf-sample-name sample in-file ref)
                      &quot;--variant&quot; in-file
                      &quot;--unsafe&quot; &quot;ALLOW_SEQ_DICT_INCOMPATIBILITY&quot;
                      &quot;--out&quot; :out-vcf]
                     (if remove-refcalls [&quot;--excludeNonVariants&quot; &quot;--excludeFiltered&quot;] [])
                     (broad/gatk-cl-intersect-intervals intervals ref))]
    (if-not (fs/exists? base-dir)
      (fs/mkdirs base-dir))
    (broad/run-gatk &quot;SelectVariants&quot; args file-info {:out [:out-vcf]})
    (:out-vcf file-info)))</pre></td></tr><tr><td class="docs"><p>Check if interval BED files overlap with current analysis genome build.
  This is useful when an input VCF is from an alternate genome and needs
  conversion. In this case we shouldn't yet be using interval selection.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- genome-safe-intervals
  [intervals ref exp]
  (if (or (nil? ref) (= ref (:ref exp)))
    intervals
    []))</pre></td></tr><tr><td class="docs"><p>Prepare input file for comparisons based on configuration:
    - Selecting a single sample from multi-sample files
    - Resorting and fixing chromosome naming
    - Removing reference call genotypes
   This organizes the logic which get convoluted for different cases.
   The approach is to select a single sample and remove refcalls if we have
   a multiple sample file, so the sample name will be correct.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- dirty-prep-work
  [in-file call exp intervals out-dir out-fname]
  (letfn [(run-sample-select [in-file ref ext]
            (select-by-sample (:sample exp) in-file (str (:name call) ext)
                              ref :out-dir out-dir
                              :intervals (genome-safe-intervals intervals ref exp)
                              :remove-refcalls (get call :remove-refcalls false)))]
    (let [sample-file (if (multiple-samples? in-file)
                        (run-sample-select in-file (get call :ref (:ref exp)) &quot;&quot;)
                        in-file)
          prep-file (if (true? (:prep call))
                      (prep-vcf sample-file (:ref exp) (:sample exp) :out-dir out-dir
                                :out-fname out-fname :orig-ref-file (:ref call)
                                :config call)
                      sample-file)
          hap-file (if (true? (:make-haploid call))
                     (diploid-calls-to-haploid prep-file (:ref exp) :out-dir out-dir)
                     prep-file)
          noref-file (if (or (and (not (multiple-samples? in-file)) (:remove-refcalls call))
                             (and (not (nil? (:ref call))) (not (empty? intervals))))
                       (run-sample-select hap-file (:ref exp) &quot;-noref&quot;)
                       hap-file)]
      noref-file)))</pre></td></tr><tr><td class="docs"><p>Prepare call information for VCF comparisons by normalizing through GATK.
  Handles:</p>

<ol>
<li>Combining multiple input files</li>
<li>Fixing reference and sample information.</li>
<li>Splitting combined MNPs into phased SNPs</li>
</ol>
</td><td class="codes"><pre class="brush: clojure">(defn gatk-normalize
  [call exp intervals out-dir transition]
  (if-not (fs/exists? out-dir)
    (fs/mkdirs out-dir))
  (letfn [(merge-call-files [call in-files]
            (let [ref (get call :ref (:ref exp))]
              (combine-variants in-files ref
                                :merge-type :full :out-dir out-dir
                                :intervals (genome-safe-intervals intervals ref exp)
                                :unsafe true)))]
    (let [out-fname (format &quot;%s-%s.vcf&quot; (:sample exp) (:name call))
          in-files (if (coll? (:file call)) (:file call) [(:file call)])
          _ (transition :clean (str &quot;Cleaning input VCF: &quot; (:name call)))
          clean-files (vec (map #(if-not (:preclean call) %
                                         (clean-problem-vcf % :out-dir out-dir))
                                in-files))
          _ (transition :merge (str &quot;Merging multiple input files: &quot; (:name call)))
          merge-file (if (&gt; (count clean-files) 1)
                       (merge-call-files call clean-files)
                       (first clean-files))
          _ (transition :prep (str &quot;Prepare VCF, resorting to genome build: &quot; (:name call)))
          prep-file (dirty-prep-work merge-file call exp intervals out-dir out-fname)]
      (transition :normalize (str &quot;Normalize MNP and indel variants: &quot; (:name call)))
      (assoc call :file (if (true? (get call :normalize true))
                          (normalize-variants prep-file (:ref exp) out-dir
                                              :out-fname out-fname)
                          prep-file)))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.compare" name="bcbio.variation.compare"><h1 class="project-name">bcbio.variation.compare</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Generate comparisons between two sets of variant calls.
   Utilizes GATK walkers to generate detailed and summary statistics
   about two sets of calls:</p>

<ul>
<li>Identify non-callable regions with CallableLociWalker</li>
<li>Combine variants from two samples</li>
<li>Use VariantEval to calculate overall concordance statistics</li>
<li>Provide output for concordant and discordant regions for
 detailed investigation</li>
</ul>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.compare
  (:use [clojure.java.io]
        [clojure.math.combinatorics :only [combinations]]
        [ordered.map :only [ordered-map]]
        [bcbio.align.reorder :only [reorder-bam]]
        [bcbio.variation.annotation :only [add-variant-annotations]]
        [bcbio.variation.callable :only [get-callable-bed]]
        [bcbio.variation.combine :only [combine-variants gatk-normalize]]
        [bcbio.variation.config :only [load-config do-transition]]
        [bcbio.variation.evaluate :only [calc-variant-eval-metrics]]
        [bcbio.variation.filter :only [variant-filter pipeline-recalibration]]
        [bcbio.variation.metrics :only [vcf-stats write-summary-table]]
        [bcbio.variation.multiple :only [prep-cmp-name-lookup pipeline-compare-multiple]]
        [bcbio.variation.phasing :only [is-haploid? compare-two-vcf-phased]]
        [bcbio.variation.report :only [concordance-report-metrics
                                       write-concordance-metrics
                                       write-scoring-table
                                       top-level-metrics
                                       write-classification-metrics
                                       write-sv-metrics]]
        [bcbio.variation.recall :only [create-merged]]
        [bcbio.variation.structural :only [compare-sv-pipeline]]
        [bcbio.variation.validate :only [pipeline-validate]]
        [bcbio.variation.variantcontext :only [parse-vcf write-vcf-w-template
                                               get-vcf-source]])
  (:require [clojure.string :as string]
            [clojure.data.csv :as csv]
            [fs.core :as fs]
            [bcbio.run.itx :as itx]
            [bcbio.run.broad :as broad]))</pre></td></tr><tr><td class="docs"><h2>Variance assessment</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Variant comparison producing 3 files: concordant and both directions discordant</p>
</td><td class="codes"><pre class="brush: clojure">(defn select-by-concordance
  [sample call1 call2 ref &amp; {:keys [out-dir intervals]}]
  (let [base-dir (if (nil? out-dir) (fs/parent (:file call1)) out-dir)]
    (if-not (fs/exists? base-dir)
      (fs/mkdirs base-dir))
    (doall
     (for [[c1 c2 cmp-type] [[call1 call2 &quot;concordance&quot;]
                             [call1 call2 &quot;discordance&quot;]
                             [call2 call1 &quot;discordance&quot;]]]
       (let [file-info {:out-vcf (str (fs/file base-dir
                                               (format &quot;%s-%s-%s-%s.vcf&quot;
                                                       sample (:name c1) (:name c2) cmp-type)))}
             args (concat
                   [&quot;-R&quot; ref
                    &quot;--sample_name&quot; sample
                    &quot;--variant&quot; (:file c1)
                    (str &quot;--&quot; cmp-type) (:file c2)
                    &quot;--out&quot; :out-vcf]
                   (broad/gatk-cl-intersect-intervals intervals ref))]
         (broad/run-gatk &quot;SelectVariants&quot; args file-info {:out [:out-vcf]})
         (:out-vcf file-info))))))</pre></td></tr><tr><td class="docs"><h2>Custom parsing and combinations</h2>

<p>Utilizes GATK VariantContexts</p>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Lazy stream of VariantContexts categorized by concordant/discordant matching.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- vc-by-match-category
  [vcf-source]
  (letfn [(genotype-alleles [g]
            (vec (map #(.toString %) (:alleles g))))
          (is-concordant? [vc]
            (= (-&gt; (map genotype-alleles (:genotypes vc))
                   set
                   count)
               1))]
    (for [vc (parse-vcf vcf-source)]
      [(if (is-concordant? vc) :concordant :discordant)
       (:vc vc)])))</pre></td></tr><tr><td class="docs"><p>Provide concordant and discordant variants for two variant files.</p>
</td><td class="codes"><pre class="brush: clojure">(defn split-variants-by-match
  [vcf1 vcf2 ref]
  (let [combo-file (combine-variants [vcf1 vcf2] ref)
        out-map {:concordant (itx/add-file-part combo-file &quot;concordant&quot;)
                 :discordant (itx/add-file-part combo-file &quot;discordant&quot;)}]
    (if-not (fs/exists? (:concordant out-map))
      (with-open [combo-vcf-s (get-vcf-source combo-file ref)]
        (write-vcf-w-template combo-file out-map (vc-by-match-category combo-vcf-s)
                              ref)))
    out-map))</pre></td></tr><tr><td class="docs"><h2>Top-level</h2>

<p>Process a directory of variant calls from multiple
sources, generating a summary of concordance plus detailed metrics
differences for tweaking filters.</p>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- get-summary-writer [config config-file ext]
  (if-not (nil? (get-in config [:dir :out]))
    (do
      (if-not (fs/exists? (get-in config [:dir :out]))
        (fs/mkdirs (get-in config :dir :out)))
      (writer (str (fs/file (get-in config [:dir :out])
                            (format &quot;%s-%s&quot;
                                    (itx/file-root (fs/base-name config-file)) ext)))))
    (writer System/out)))</pre></td></tr><tr><td class="docs"><p>Retrieve BAM files associated with alignments, normalizing if needed.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- prepare-input-bams
  [exp out-dir]
  (let [call-bams (map (fn [c] [(get c :align (:align exp)) c]) (:calls exp))]
    (map (fn [[b c]] (when-not (nil? b)
                     (reorder-bam b (:ref exp) c exp :out-dir out-dir)))
         call-bams)))</pre></td></tr><tr><td class="docs"><p>Prepare merged and annotated VCF files for an experiment.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- prepare-vcf-calls
  [exp config]
  (let [out-dir (get-in config [:dir :prep] (get-in config [:dir :out]))
        transition (partial do-transition config)
        align-bams (prepare-input-bams exp out-dir)
        all-intervals (remove nil? (map :intervals (cons exp (:calls exp))))
        start-vcfs (vec (map #(gatk-normalize % exp all-intervals out-dir transition)
                             (:calls exp)))
        _ (transition :combine &quot;Creating merged VCF files for all comparisons&quot;)
        merged-vcfs (create-merged (map :file start-vcfs) align-bams (:calls exp)
                                   (:ref exp) :out-dir out-dir
                                   :intervals all-intervals)
        _ (transition :annotate &quot;Annotate VCFs with metrics&quot;)
        ann-vcfs (map (fn [[v b c]]
                        (add-variant-annotations v b (:ref exp) c :out-dir out-dir
                                                 :intervals all-intervals))
                      (map vector merged-vcfs align-bams (:calls exp)))
        _ (transition :filter &quot;Post annotation filtering&quot;)
        filter-vcfs (map (fn [[v c]] (if-not (nil? (:filters c))
                                       (variant-filter v (:filters c) (:ref exp))
                                       v))
                         (map vector ann-vcfs (:calls exp)))]
    (map (fn [[c v b]] (-&gt; c
                           (assoc :file v)
                           (assoc :align b)))
         (map vector (:calls exp) filter-vcfs align-bams))))</pre></td></tr><tr><td class="docs"><p>Compare two standard VCF files based on the supplied configuration.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- compare-two-vcf-standard
  [c1 c2 exp config]
  (letfn [(callable-intervals [exp c1 c2]
            (let [out-dir (get-in config [:dir :prep] (get-in config [:dir :out]))]
              (remove nil? (cons (:intervals exp)
                                 (map #(when-not (nil? (:align %))
                                         (get-callable-bed (:align %) (:ref exp)
                                                           :out-dir out-dir))
                                      [c1 c2])))))
          (discordant-name [x]
            (format &quot;%s-discordant&quot; (:name x)))
          (zipmap-ordered [xs1 xs2]
            (apply ordered-map (interleave xs1 xs2)))]
    (let [c-files (select-by-concordance (:sample exp) c1 c2 (:ref exp)
                                         :out-dir (get-in config [:dir :out])
                                         :intervals (:intervals exp))
          eval (calc-variant-eval-metrics (:sample exp) (:file c1) (:file c2) (:ref exp)
                                          :out-base (first c-files)
                                          :intervals (:intervals exp))
          c-eval (calc-variant-eval-metrics (:sample exp) (:file c1) (:file c2) (:ref exp)
                                            :out-base (itx/add-file-part (first c-files) &quot;callable&quot;)
                                            :intervals (callable-intervals exp c1 c2))]
      {:c-files (zipmap-ordered (map keyword
                                     [&quot;concordant&quot; (discordant-name c1) (discordant-name c2)])
                                c-files)
       :c1 c1 :c2 c2 :exp exp :dir (config :dir)
       :metrics (concordance-report-metrics (:sample exp) eval)
       :callable-metrics (concordance-report-metrics (:sample exp) c-eval)})))</pre></td></tr><tr><td class="docs"><p>Compare two VCF files, handling standard and haploid specific comparisons.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- compare-two-vcf
  [c1 c2 exp config]
  (do-transition config :compare (format &quot;Comparing VCFs: %s vs %s&quot; (:name c1) (:name c2)))
  (let [[c1 c2 sv-cmp] (if-not (:mod c1)
                         (compare-sv-pipeline c1 c2 exp config)
                         [c1 c2 {}])
        phased-vcfs (group-by #(-&gt; % :file (is-haploid? (:ref exp))) [c1 c2])
        out-cmp (if (get phased-vcfs true)
                  (compare-two-vcf-phased phased-vcfs exp config)
                  (compare-two-vcf-standard c1 c2 exp config))]
    (assoc out-cmp :c-files (reduce (fn [coll [k v]] (assoc coll k v))
                                    (:c-files out-cmp) sv-cmp))))</pre></td></tr><tr><td class="docs"><h2>Customizable finalizer comparisons</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Run a post-pairwise comparison function, returning updated comparison details,</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti run-finalizer
  (fn [cmps finalizer exp config] (-&gt; finalizer :method keyword)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod run-finalizer :recal-filter
  [&amp; args]
  (apply pipeline-recalibration args))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod run-finalizer :multiple
  [&amp; args]
  (apply pipeline-compare-multiple args))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod run-finalizer :validate
  [&amp; args]
  (apply pipeline-validate args))</pre></td></tr><tr><td class="docs"><p>Finalize all comparisons with finished initial pass data.</p>
</td><td class="codes"><pre class="brush: clojure">(defn finalize-comparisons
  [cmps exp config]
  (letfn [(add-summary [x]
            (-&gt; x
                (assoc :exp exp)
                (#(assoc % :summary (top-level-metrics %)))))
          (update-w-finalizer [cur-cmps finalizer]
            &quot;Update the current comparisons with a defined finalizer.&quot;
            (do-transition config :finalize
                           (format &quot;Finalize %s: %s&quot; (:method finalizer)
                                   (let [t (:target finalizer)]
                                     (if (coll? t) (string/join &quot;, &quot; t) t))))
            (let [updated-cmp (run-finalizer cur-cmps finalizer exp config)]
              (assoc cur-cmps (map #(get-in updated-cmp [% :name]) [:c1 :c2])
                     (if-not (:re-compare updated-cmp) updated-cmp
                             (compare-two-vcf (:c1 updated-cmp) (:c2 updated-cmp) exp config)))))]
    (-&gt;&gt; (reduce update-w-finalizer
                 (prep-cmp-name-lookup cmps) (:finalize exp))
         vals
         (map add-summary))))</pre></td></tr><tr><td class="docs"><h2>Top-level</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Perform comparison between variant calls using inputs from YAML config.</p>
</td><td class="codes"><pre class="brush: clojure">(defn variant-comparison-from-config
  [config-file]
  (let [config (load-config config-file)
        comparisons (flatten
                     (for [exp (:experiments config)]
                       (let [cmps (for [[c1 c2] (combinations (prepare-vcf-calls exp config) 2)]
                                    (compare-two-vcf c1 c2 exp config))]
                         (finalize-comparisons cmps exp config))))]
    (do-transition config :summary &quot;Summarize comparisons&quot;)
    (with-open [w (get-summary-writer config config-file &quot;summary.txt&quot;)
                w2 (get-summary-writer config config-file &quot;files.csv&quot;)]
      (csv/write-csv w2 [[&quot;call1&quot; &quot;call2&quot; &quot;type&quot; &quot;fname&quot;]])
      (doseq [x comparisons]
        (.write w (format &quot;* %s : %s vs %s\n&quot; (-&gt; x :exp :sample)
                          (-&gt; x :c1 :name) (-&gt; x :c2 :name)))
        (write-scoring-table (:metrics x) (get-in x [:summary :sv]) w)
        (write-concordance-metrics (:summary x) w)
        (when-let [sv-info (get-in x [:summary :sv])]
          (write-sv-metrics sv-info w))
        (when (get-in x [:c1 :mod])
          (write-classification-metrics x w))
        (doseq [[k f] (:c-files x)]
          (.write w (format &quot;** %s\n&quot; (name k)))
          (csv/write-csv w2 [[(get-in x [:c1 :name]) (get-in x [:c2 :name]) (name k)
                              (string/replace-first f (str (get-in config [:dir :out]) &quot;/&quot;) &quot;&quot;)]])
          (write-summary-table (vcf-stats f (get-in x [:exp :ref])) :wrtr w))))
    (with-open [w (get-summary-writer config config-file &quot;summary.csv&quot;)]
      (doseq [[i [x cmp-orig]] (map-indexed vector (map (juxt identity :summary) comparisons))]
        (let [header (concat (take 1 (keys cmp-orig)) [:call1 :call2] (nnext (keys cmp-orig)))
              cmp (-&gt; cmp-orig
                      (dissoc :ftypes)
                      (assoc :call1 (-&gt; x :c1 :name))
                      (assoc :call2 (-&gt; x :c2 :name)))]
          (when (= i 0)
            (.write w (format &quot;%s\n&quot; (string/join &quot;,&quot; (map name header)))))
          (.write w (format &quot;%s\n&quot; (string/join &quot;,&quot; (for [v (map #(get cmp %) header)]
                                                      (if (map? v) (:total v) v))))))))
    (do-transition config :finished &quot;Finished&quot;)
    comparisons))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -main [config-file]
  (variant-comparison-from-config config-file)
  nil)</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.complex" name="bcbio.variation.complex"><h1 class="project-name">bcbio.variation.complex</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Handle complex variations representations: multi-nucleotide
   polymorphisms and indels.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.complex
  (:import [org.broadinstitute.sting.utils.variantcontext Allele
            VariantContextBuilder GenotypesContext Genotype
            VariantContextUtils]
           [org.biojava3.core.sequence DNASequence]
           [org.biojava3.alignment Alignments])
  (:use [clojure.set :only [union]]
        [ordered.set :only [ordered-set]]
        [bcbio.variation.variantcontext :only [parse-vcf write-vcf-w-template
                                               get-vcf-source]])
  (:require [clojure.string :as string]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><h2>Multi-nucleotide polymorphisms (MNPs)</h2>

<p>Split into single variant primitives.</p>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Do a set of alleles have any variants at a position.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- has-variant-base?
  [alleles i]
  (&gt; (count (set (map #(nth % i nil) alleles)))
     1))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- get-vc-alleles [vc]
  (map #(.getBaseString %) (cons (:ref-allele vc) (:alt-alleles vc))))</pre></td></tr><tr><td class="docs"><p>Identify complex indels that can be split into multiple calls.</p>
</td><td class="codes"><pre class="brush: clojure">(defn is-multi-indel?
  [vc]
  (letfn [(monomorphic-alleles? [vc]
            (= 1 (-&gt;&gt; (get-vc-alleles vc)
                      (map set)
                      (apply union)
                      count)))]
    (and (= &quot;INDEL&quot; (:type vc))
         (and (&gt; (.length (:ref-allele vc)) 1)
              (&gt; (apply max (map #(.length %) (:alt-alleles vc))) 1)
              (not (monomorphic-alleles? vc))))))</pre></td></tr><tr><td class="docs"><p>Detect single call SNP variants within a MNP genotype.
  Handles reference no-variant padding bases on the 5' end of
  the sequence, writing only variants at the adjusted positions.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- split-alleles
  [vc alleles]
  (letfn [(mnp-ref-padding [ref-allele vc]
            {:post [(&gt;= % 0)]}
            (- (inc (- (:end vc) (:start vc)))
               (count (string/replace ref-allele &quot;-&quot; &quot;&quot;))))
          (contains-indel? [alleles i]
            (contains? (set (map #(str (nth % i)) alleles)) &quot;-&quot;))
          (is-start-indel? [alleles start pos]
            (and (= 0 start)
                 (some empty? (map #(string/replace (subs % start pos) &quot;-&quot; &quot;&quot;) alleles))))
          (extend-indels [alleles i]
            (if-not (contains-indel? alleles i) 
              {:start i :end (inc i)}
              {:start (max (dec i) 0)
               :end (inc (last (take-while #(or (contains-indel? alleles %) (is-start-indel? alleles i %))
                                           (range i (count (first alleles))))))}))
          (extract-variants [alleles pos ref-pad]
            (let [{:keys [start end]} (extend-indels alleles pos)
                  str-alleles (map #(-&gt; (str (subs % start end))
                                        (string/replace &quot;-&quot; &quot;&quot;))
                                   alleles)
                  cur-alleles (map-indexed (fn [i x] (Allele/create x (= 0 i)))
                                           (into (ordered-set) str-alleles))]
              {:offset (+ start ref-pad)
               :end end
               :size (dec (.length (first cur-alleles)))
               :ref-allele (first cur-alleles)
               :alleles (rest cur-alleles)}))]
    (let [ref-pad (mnp-ref-padding (first alleles) vc)]
      (remove nil?
              (loop [i 0 final []]
                (cond
                 (&gt; i (-&gt; alleles first count)) final
                 (has-variant-base? alleles i)
                 (let [next-var (extract-variants alleles i ref-pad)]
                   (recur (:end next-var) (conj final next-var)))
                 :else (recur (inc i) final)))))))</pre></td></tr><tr><td class="docs"><p>Retrieve a new genotype with the given alleles.
   Creates a single genotype from the VariantContext, copying the existing
   genotype and substituting in the provided alleles and phasing information.</p>
</td><td class="codes"><pre class="brush: clojure">(defn genotype-w-alleles
  [vc alleles is-phased]
  (let [genotype (first (.getGenotypes vc))]
    (doto (-&gt; vc .getGenotypes GenotypesContext/copy)
      (.replace
       (Genotype. (.getSampleName genotype)
                  alleles
                  (.getLog10PError genotype)
                  (if (.filtersWereApplied genotype) (.getFilters genotype) nil)
                  (.getAttributes genotype)
                  is-phased)))))</pre></td></tr><tr><td class="docs"><p>Create a new VariantContext as a subset of an existing variant.
   <code>allele-info</code> specifies the location size and alleles for the new variant:
   <code>{:offset :size :ref-allele :alleles}</code></p>
</td><td class="codes"><pre class="brush: clojure">(defn- new-split-vc
  [vc i allele-info]
  (let [pos (+ (:offset allele-info) (.getStart vc))]
    (-&gt; (VariantContextBuilder. vc)
        (.start pos)
        (.stop (+ pos (get allele-info :size 0)))
        (.genotypes (genotype-w-alleles vc (:alleles allele-info) (&gt; i 0)))
        (.alleles (set (cons (:ref-allele allele-info) (:alleles allele-info))))
        (.make))))</pre></td></tr><tr><td class="docs"><p>Split a MNP into individual alleles</p>
</td><td class="codes"><pre class="brush: clojure">(defn- split-mnp
  [vc]
  {:pre [(= 1 (:num-samples vc))]}
  (let [alleles (split-alleles vc (get-vc-alleles vc))]
    (map (fn [[i x]] (new-split-vc (:vc vc) i x)) (map-indexed vector alleles))))</pre></td></tr><tr><td class="docs"><h2>Indels</h2>

<p>Create a normalized representation for comparison.</p>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Perform alignment of input sequences using BioJava.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- multiple-alignment
  [seqs]
  (map #(.getSequenceAsString %)
       (-&gt; (map #(DNASequence. %) seqs)
           (Alignments/getMultipleSequenceAlignment (to-array []))
           .getAlignedSequences)))</pre></td></tr><tr><td class="docs"><p>Ensure reference alignment gaps have consistent GAP schemes.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- fix-ref-alignment-gaps
  [alleles]
  (letfn [(has-5-gaps? [x] (.startsWith x &quot;-&quot;))
          (has-3-gaps? [x] (.endsWith x &quot;-&quot;))
          (has-internal-gaps? [x] (and (&gt; (count x) 2)
                                       (.contains (subs x 1 (dec (count x))) &quot;-&quot;)))
          (make-3-gap-only [x]
            (let [nogap-x (string/replace x &quot;-&quot; &quot;&quot;)]
              (string/join &quot;&quot; (cons nogap-x
                                    (repeat (- (count x) (count nogap-x)) &quot;-&quot;)))))]
    (let [ref-allele (first alleles)]
      (cons (if (or (has-internal-gaps? ref-allele)
                    (and (has-5-gaps? ref-allele) (has-3-gaps? (second alleles))))
              (make-3-gap-only ref-allele)
              ref-allele)
            (map #(if (has-internal-gaps? %) (make-3-gap-only %) %) (rest alleles))))))</pre></td></tr><tr><td class="docs"><p>Split complex indels into individual variant components.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- split-complex-indel
  [vc]
  {:pre [(= 1 (:num-samples vc))]}
  (let [alleles (split-alleles vc (-&gt; (get-vc-alleles vc)
                                      multiple-alignment
                                      fix-ref-alignment-gaps))]
    (map (fn [[i x]] (new-split-vc (:vc vc) i x)) (map-indexed vector alleles))))</pre></td></tr><tr><td class="docs"><p>Remove extra variant bases, if necessary, from 5' end of indels.
  Checks both called alleles and potential alleles for extra 5' padding
  removing this if not needed to distinguish any potential alleles.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- maybe-strip-indel
  [vc]
  {:pre [(= 1 (:num-samples vc))]}
  (letfn [(strip-indel [vc i alleles]
            (let [start-pos (- i 1)
                  ref-allele (subs (first alleles) start-pos)
                  cur-alleles (map #(Allele/create (subs % start-pos)
                                                   (= ref-allele (subs % start-pos)))
                                   alleles)]
              (new-split-vc vc 0 {:offset i
                                  :size (- (count ref-allele) 1)
                                  :ref-allele (first cur-alleles)
                                  :alleles (rest cur-alleles)})))
          (variant-allele-pos [input-alleles]
            (let [str-alleles (map #(.getBaseString %) input-alleles)
                  first-var-i (first (filter #(has-variant-base? str-alleles %)
                                     (range (apply max (map count str-alleles)))))]
              [str-alleles first-var-i]))]
    (let [[orig-alleles first-var-i] (variant-allele-pos (cons (:ref-allele vc)
                                                               (-&gt; vc :genotypes first :alleles)))
          [_ nocall-i] (variant-allele-pos (cons (:ref-allele vc) (:alt-alleles vc)))]
      (if (or (nil? first-var-i) (= first-var-i 0)
              (nil? nocall-i) (= nocall-i 0))
        (:vc vc)
        (strip-indel (:vc vc) first-var-i orig-alleles)))))</pre></td></tr><tr><td class="docs"><h2>VCF file conversion</h2>

<p>Process entire files, normalizing complex variations</p>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Lazy list of variant context with MNPs split into single genotypes and indels stripped.
  mnp-blockers is a lookup dictionary of positions overlapped by MNPs.
  Variant representations can have a MNP and also a single SNP representing
  the same information. In this case we ignore SNPs overlapping a MNP region
  and rely on MNP splitting to resolve the SNPs.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-normalized-vcs
  [vc-iter mnp-blockers]
  (letfn [(overlaps-previous-mnp? [vc blockers]
            (contains? (get blockers (:chr vc) #{}) (:start vc)))
          (add-mnp-info [coll vc]
            (let [prev-check 10000] ;; bp to check upstream for overlaps
              (if (or (= &quot;MNP&quot; (:type vc)) (is-multi-indel? vc))
                (assoc coll (:chr vc)
                       (union (set (remove #(&lt; % (- (:start vc) prev-check))
                                           (get coll (:chr vc) #{})))
                              (set (range (:start vc)
                                          (+ (:start vc) (apply max (map count (get-vc-alleles vc))))))))
                coll)))
          (process-vc [vc blockers]
            (if (overlaps-previous-mnp? vc blockers)
              []
              (condp = (:type vc)
                &quot;MNP&quot; (split-mnp vc)
                &quot;INDEL&quot; (if (is-multi-indel? vc)
                          (split-complex-indel vc)
                          [(maybe-strip-indel vc)])
                [(:vc vc)])))
          (add-normalized-vcs [vcs blockers]
            (when (seq vcs)
              (concat (process-vc (first vcs) blockers)
                      (get-normalized-vcs (rest vcs) (add-mnp-info blockers (first vcs))))))]
    (lazy-seq (add-normalized-vcs vc-iter mnp-blockers))))</pre></td></tr><tr><td class="docs"><p>Convert MNPs and indels into normalized representation.</p>
</td><td class="codes"><pre class="brush: clojure">(defn normalize-variants
  ([in-file ref]
     (normalize-variants in-file ref nil))
  ([in-file ref out-dir &amp; {:keys [out-fname]}]
     (let [base-name (if (nil? out-fname) (itx/remove-zip-ext in-file) out-fname)
           out-file (itx/add-file-part base-name &quot;nomnp&quot; out-dir)]
       (when (itx/needs-run? out-file)
         (with-open [vcf-source (get-vcf-source in-file ref)]
           (write-vcf-w-template in-file {:out out-file}
                                 (get-normalized-vcs (parse-vcf vcf-source) {})
                                 ref)))
       out-file)))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.config" name="bcbio.variation.config"><h1 class="project-name">bcbio.variation.config</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Load and prepare inputs from YAML configuration files.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.config
  (:use [clojure.java.io]
        [clj-time.local :only [format-local-time local-now]])
  (:require [clojure.string :as string]
            [clojure.tools.logging :as log]
            [clj-yaml.core :as yaml]
            [fs.core :as fs]
            [pallet.algo.fsm.fsm :as fsm-base]
            [pallet.algo.fsm.fsm-dsl :as fsm]
            [pallet.algo.fsm.event-machine :as event-machine]))</pre></td></tr><tr><td class="docs"><h2>Logging</h2>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- get-log-file [config]
  (let [out-dir (get-in config [:dir :out])]
    (when-not (nil? out-dir)
      (when-not (fs/exists? out-dir)
        (fs/mkdirs out-dir))
      (file out-dir &quot;processing-status.log&quot;))))</pre></td></tr><tr><td class="docs"><p>Retrieve current processing status information from state machine log file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-log-status
  [config]
  (when-let [log-file (get-log-file config)]
    (when (fs/exists? log-file)
      (with-open [rdr (reader log-file)]
        (let [[_ state-str info-str] (string/split (last (line-seq rdr)) #&quot; :: &quot;)]
          (-&gt; (read-string info-str)
              (assoc :state (read-string (last (string/split state-str #&quot; &quot;))))))))))</pre></td></tr><tr><td class="docs"><p>Define a finite state machine of transitions during comparison processes.</p>
</td><td class="codes"><pre class="brush: clojure">(defn prep-comparison-fsm
  [config]
  (let [out-file (get-log-file config)]
    (letfn [(log-transition [_ new-state]
              (let [out (format &quot;State %s :: %s&quot; (:state-kw new-state)
                                (:state-data new-state))]
                (log/log :info out)
                (when out-file
                  (spit out-file (str (format-local-time (local-now) :date-hour-minute-second)
                                      &quot; :: &quot; out &quot;\n&quot;) :append true))))]
      (log-transition nil {:state-kw :begin :state-data {:desc &quot;Starting variation analysis&quot;}})
      (event-machine/event-machine
       (fsm/event-machine-config
        (fsm/using-fsm-features (fsm-base/with-transition-observer log-transition))
        (fsm/initial-state :begin)
        (fsm/initial-state-data {})
        (fsm/state :begin
                   (fsm/valid-transitions :clean))
        (fsm/state :clean
                   (fsm/valid-transitions :merge))
        (fsm/state :merge
                   (fsm/valid-transitions :prep))
        (fsm/state :prep
                   (fsm/valid-transitions :normalize))
        (fsm/state :normalize
                   (fsm/valid-transitions :combine :clean))
        (fsm/state :combine
                   (fsm/valid-transitions :annotate))
        (fsm/state :annotate
                   (fsm/valid-transitions :filter))
        (fsm/state :filter
                   (fsm/valid-transitions :compare))
        (fsm/state :compare
                   (fsm/valid-transitions :compare :finalize :summary :clean :finished))
        (fsm/state :finalize
                   (fsm/valid-transitions :finalize :compare :summary :clean))
        (fsm/state :summary
                   (fsm/valid-transitions :finished :clean))
        (fsm/state :finished))))))</pre></td></tr><tr><td class="docs"><p>Perform a transition on configured finite state machine moving to the provided state</p>
</td><td class="codes"><pre class="brush: clojure">(defn do-transition
  [config state desc]
  ((get-in config [:fsm :transition]) #(assoc % :state-kw state
                                              :state-data {:desc desc})))</pre></td></tr><tr><td class="docs"><h2>Configuration</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Add files of interest in a directory with the given extension.
  This allows batch processing of directories.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- add-dir-files
  [config exts]
  (letfn [(files-from-dir [dir]
            (-&gt;&gt; (fs/list-dir dir)
                 (filter #(contains? exts (fs/extension %)))
                 (map #(str (fs/file dir %)))))
          (process-call [call]
            (if-let [dir (:dir call)]
              (assoc call :file (files-from-dir dir))
              call))
          (process-exp [exp]
            (assoc exp :calls (map process-call (:calls exp))))]
    (assoc config :experiments
           (map process-exp (:experiments config)))))</pre></td></tr><tr><td class="docs"><p>Do not allow duplicate names in experiments.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- no-duplicate-names?
  [config]
  (letfn [(exp-no-duplicate? [exp]
            (every? (fn [[_ x]] (= 1 x)) (frequencies (map :name (:calls exp)))))]
    (every? exp-no-duplicate? (:experiments config))))</pre></td></tr><tr><td class="docs"><p>Load configuration file, handling conversion of relative to absolute paths.</p>
</td><td class="codes"><pre class="brush: clojure">(defn load-config
  [config-file]
  {:post [(no-duplicate-names? %)]}
  (let [config (-&gt; config-file slurp yaml/parse-string)
        base-dir (fs/file (get-in config [:dir :base] &quot;.&quot;))
        to-process #{[:dir :out] [:dir :prep]
                     [:experiments :ref] [:experiments :intervals]
                     [:experiments :align] [:experiments :calls :file]
                     [:experiments :calls :align] [:experiments :calls :annotate]
                     [:experiments :calls :dir]}]
    (letfn [(make-absolute [x]
              (if (.isAbsolute (file x))
                x
                (str (fs/file base-dir x))))
            (maybe-process [val path]
              (if (contains? to-process path)
                (cond
                 (seq? val) (map make-absolute val)
                 (string? val) (make-absolute val)
                 :else val)
                val))
            (update-tree [config path]
              (cond (map? config)
                    (reduce (fn [item [k v]]
                              (assoc item k (cond
                                             (map? v) (update-tree v (conj path k))
                                             (seq? v) (map #(update-tree % (conj path k)) v)
                                             :else (maybe-process v (conj path k)))))
                            config
                            (vec config))
                    (contains? to-process path) (maybe-process config path)
                    :else config))]
      (-&gt; config
          (update-tree [])
          (add-dir-files #{&quot;.vcf&quot;})
          (#(assoc % :fsm (prep-comparison-fsm %)))))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.core" name="bcbio.variation.core"><h1 class="project-name">bcbio.variation.core</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.core
  (:import [org.broadinstitute.sting.gatk CommandLineGATK])
  (:gen-class))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -main [&amp; args]
  (CommandLineGATK/main (into-array (if-not (nil? args) args [&quot;-h&quot;]))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.evaluate" name="bcbio.variation.evaluate"><h1 class="project-name">bcbio.variation.evaluate</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Provide high level summary evaluation of variant results, building off GATK VariantEval.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.evaluate
  (:import [org.broadinstitute.sting.gatk.report GATKReport])
  (:use [clojure.java.io]
        [ordered.map :only [ordered-map]])
  (:require [clojure.string :as string]
            [doric.core :as doric]
            [bcbio.run.itx :as itx]
            [bcbio.run.broad :as broad]))</pre></td></tr><tr><td class="docs"><p>Compare two variant files with GenotypeConcordance in VariantEval</p>
</td><td class="codes"><pre class="brush: clojure">(defn calc-variant-eval-metrics
  [sample vcf1 vcf2 ref &amp; {:keys [out-base intervals]}]
  (let [file-info {:out-eval (str (itx/file-root (if (nil? out-base) vcf1 out-base)) &quot;.eval&quot;)}
        args (concat
              [&quot;-R&quot; ref
               &quot;--out&quot; :out-eval
               &quot;--eval&quot; vcf1
               &quot;--comp&quot; vcf2
               &quot;--sample&quot; sample
               &quot;--doNotUseAllStandardModules&quot;
               &quot;--evalModule&quot; &quot;CompOverlap&quot;
               &quot;--evalModule&quot; &quot;CountVariants&quot;
               &quot;--evalModule&quot; &quot;GenotypeConcordance&quot;
               &quot;--evalModule&quot; &quot;TiTvVariantEvaluator&quot;
               &quot;--evalModule&quot; &quot;ValidationReport&quot;
               &quot;--stratificationModule&quot; &quot;Sample&quot;
               &quot;--stratificationModule&quot; &quot;Filter&quot;]
              (broad/gatk-cl-intersect-intervals intervals ref))]
    (broad/run-gatk &quot;VariantEval&quot; args file-info {:out [:out-eval]})
    (:out-eval file-info)))</pre></td></tr><tr><td class="docs"><p>Run VariantEval providing summary information for a VCF file</p>
</td><td class="codes"><pre class="brush: clojure">(defn- calc-summary-eval-metrics
  [vcf ref dbsnp intervals cmp-interval-file]
  (let [file-info {:out-eval (str (itx/file-root vcf) &quot;-summary.eval&quot;)}
        args (concat
              [&quot;-R&quot; ref
               &quot;--out&quot; :out-eval
               &quot;--eval&quot; vcf
               &quot;--doNotUseAllStandardModules&quot;
               &quot;--evalModule&quot; &quot;CompOverlap&quot;
               &quot;--evalModule&quot; &quot;CountVariants&quot;
               &quot;--evalModule&quot; &quot;ThetaVariantEvaluator&quot;
               &quot;--evalModule&quot; &quot;TiTvVariantEvaluator&quot;
               &quot;--evalModule&quot; &quot;ValidationReport&quot;
               &quot;--evalModule&quot; &quot;VariantSummary&quot;
               &quot;--stratificationModule&quot; &quot;Filter&quot;]
              (broad/gatk-cl-intersect-intervals intervals ref)
              (if (nil? dbsnp) [] [&quot;--dbsnp&quot; dbsnp])
              (if (nil? cmp-interval-file)
                []
                [&quot;--stratificationModule&quot; &quot;IntervalStratification&quot;
                 &quot;--stratIntervals&quot; cmp-interval-file]))]
    (broad/run-gatk &quot;VariantEval&quot; args file-info {:out [:out-eval]})
    (:out-eval file-info)))</pre></td></tr><tr><td class="docs"><p>Parses a GATK output table and filters based on supplied input function.</p>
</td><td class="codes"><pre class="brush: clojure">(defn organize-gatk-report-table
  [eval-file table-name filter-fn]
  (let [cols (-&gt; (GATKReport. (file eval-file))
                 (.getTable table-name)
                 .getColumns
                 rest)
        headers (map #(-&gt; % (.getColumnName) keyword) cols)]
    (-&gt;&gt; (for [i (range (count (.values (first cols))))]
           (zipmap headers
                   (map #(nth (vec (.values %)) i) cols)))
         (filter filter-fn))))</pre></td></tr><tr><td class="docs"><p>Provide high level summary metrics of a single variant file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn summary-eval-metrics
  [vcf ref &amp; {:keys [intervals cmp-intervals dbsnp]}]
  (let [group-metrics (concat [:Novelty] (if intervals [:IntervalStratification] []))
        val-metrics [:nSamples :nProcessedLoci :nSNPs :TiTvRatio :TiTvRatioPerSample
                     :nSNPsPerSample :SNPNoveltyRate]
        count-metrics [:nSNPs :nInsertions :nDeletions :nHets :nHomVar :hetHomRatio]]
    (letfn [(all-called? [x]
              (and (= (:Filter x) &quot;called&quot;)
                   (contains? #{nil &quot;all&quot;} (:Sample x))))
            (select-keys-ordered [metrics coll]
              (ordered-map (map (fn [x] [x (get coll x)]) metrics)))
            (get-table-info [eval-file table metrics]
              (-&gt;&gt; (organize-gatk-report-table eval-file table all-called?)
                   (map (partial select-keys-ordered metrics))))
            (merge-line [vals]
              (reduce (fn [outer tbl-vals]
                        (reduce (fn [inner [k v]]
                                  (assoc inner k v))
                                outer (remove #(contains? (set group-metrics) %1) tbl-vals)))
                      (first vals) (rest vals)))
            (merge-tables [&amp; tbls]
              (map merge-line
                   (partition (count tbls) (apply interleave tbls))))]
      (let [eval-file (calc-summary-eval-metrics vcf ref dbsnp
                                                 intervals cmp-intervals)]
        (merge-tables
         (get-table-info eval-file &quot;CountVariants&quot; (concat group-metrics count-metrics))
         (get-table-info eval-file &quot;VariantSummary&quot; (concat group-metrics val-metrics)))))))</pre></td></tr><tr><td class="docs"><p>Write high level summary metrics to CSV file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn write-summary-eval-metrics
  [vcf ref &amp; {:keys [intervals cmp-intervals dbsnp]}]
  (let [out-file (str (itx/file-root vcf) &quot;-summary.csv&quot;)]
    (let [metrics (summary-eval-metrics vcf ref :intervals intervals :cmp-intervals cmp-intervals
                                        :dbsnp dbsnp)]
      (with-open [wtr (writer out-file)]
        (.write wtr (str (string/join &quot;,&quot; (map name (-&gt; metrics first keys))) &quot;\n&quot;))
        (doseq [xs metrics]
          (.write wtr (str (string/join &quot;,&quot; (vals xs)) &quot;\n&quot;)))))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -main
  ([vcf ref dbsnp intervals cmp-intervals]
     (write-summary-eval-metrics vcf ref :intervals intervals :cmp-intervals cmp-intervals
                                 :dbsnp dbsnp))
  ([vcf ref dbsnp cmp-intervals]
     (write-summary-eval-metrics vcf ref :cmp-intervals cmp-intervals
                                 :dbsnp dbsnp))
  ([vcf ref dbsnp]
     (write-summary-eval-metrics vcf ref :dbsnp dbsnp)))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.filter" name="bcbio.variation.filter"><h1 class="project-name">bcbio.variation.filter</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Filter variant calls according to supplied criteria.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.filter
  (:import [org.broadinstitute.sting.utils.variantcontext
            VariantContextBuilder])
  (:use [clojure.string :only [split]]
        [bcbio.variation.filter.classify :only [pipeline-classify-filter]]
        [bcbio.variation.multiple :only [multiple-overlap-analysis remove-mod-name]]
        [bcbio.variation.variantcontext :only [parse-vcf write-vcf-w-template
                                               get-vcf-source]])
  (:require [bcbio.run.broad :as broad]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn jexl-from-config [jexl-filters]
  &quot;Retrieve GATK JEXL commandline expressions from filters.&quot;
  (letfn [(jexl-args [x]
            [&quot;--filterName&quot; (str (first (split x #&quot;\s+&quot;)) &quot;Filter&quot;)
             &quot;--filterExpression&quot; x])]
    (flatten (map jexl-args jexl-filters))))</pre></td></tr><tr><td class="docs"><p>Perform hard variant filtering with supplied JEXL expression criteria.</p>
</td><td class="codes"><pre class="brush: clojure">(defn variant-filter
  [in-vcf jexl-filters ref]
  (let [file-info {:out-vcf (itx/add-file-part in-vcf &quot;filter&quot;)}
        args (concat [&quot;-R&quot; ref
                      &quot;--variant&quot; in-vcf
                      &quot;-o&quot; :out-vcf
                      &quot;-l&quot; &quot;ERROR&quot;]
                      (jexl-from-config jexl-filters))]
    (broad/run-gatk &quot;VariantFiltration&quot; args file-info {:out [:out-vcf]})
    (:out-vcf file-info)))</pre></td></tr><tr><td class="docs"><p>Perform the variant recalibration step with input training VCF files.
  training-vcfs is a list of <code>{:file vcf-file :name name-to-use :prior probability}</code></p>
</td><td class="codes"><pre class="brush: clojure">(defn- variant-recalibration
  [in-vcf training-vcfs annotations ref &amp; {:keys [lenient]}]
  (let [base-out (itx/file-root in-vcf)
        file-info {:out-recal (str base-out &quot;.recal&quot;)
                   :out-tranch (str base-out &quot;.tranches&quot;)
                   :out-r (str base-out &quot;-recalplots.R&quot;)}
        args (concat [&quot;-R&quot; ref
                      &quot;-input&quot; in-vcf
                      &quot;-recalFile&quot; :out-recal
                      &quot;-tranchesFile&quot; :out-tranch
                      &quot;-rscriptFile&quot; :out-r
                      &quot;--mode&quot; &quot;BOTH&quot;]
                     (if lenient
                       [&quot;--percentBadVariants&quot; &quot;0.05&quot;
                        &quot;--maxGaussians&quot; &quot;4&quot;]
                       [&quot;--percentBadVariants&quot; &quot;0.03&quot;
                        &quot;--maxGaussians&quot; &quot;10&quot;])
                     (flatten (map (fn [x] [&quot;-an&quot; x]) annotations))
                     (flatten (map (fn [x] [(str &quot;-resource:&quot; (:name x)
                                                 &quot;,known=true&quot;
                                                 &quot;,training=true&quot;
                                                 &quot;,truth=&quot; (:truth x)
                                                 &quot;,prior=&quot; (:prior x)
                                                 &quot;,bad=&quot; (:bad x))
                                            (:file x)])
                                   training-vcfs)))]
    (broad/run-gatk &quot;VariantRecalibrator&quot; args file-info {:out [:out-recal :out-tranch]})
    file-info))</pre></td></tr><tr><td class="docs"><p>Apply variant recalibration to input VCF.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- apply-recalibration
  [in-vcf recal-files ref]
  (let [file-info {:out-vcf (itx/add-file-part in-vcf &quot;recalfilter&quot;)}
        args [&quot;-R&quot; ref
              &quot;-input&quot; in-vcf
              &quot;--ts_filter_level&quot; &quot;99.0&quot;
              &quot;--mode&quot; &quot;BOTH&quot;
              &quot;-tranchesFile&quot; (:out-tranch recal-files)
              &quot;-recalFile&quot; (:out-recal recal-files)
              &quot;-o&quot; :out-vcf]]
    (broad/run-gatk &quot;ApplyRecalibration&quot; args file-info {:out [:out-vcf]})
    (:out-vcf file-info)))</pre></td></tr><tr><td class="docs"><p>Perform filtration using variant recalibration based on known variations.
  Training-vcfs is a list of true training sites along with associated
  probability and name.</p>
</td><td class="codes"><pre class="brush: clojure">(defn variant-recal-filter
  [in-vcf training-vcfs annotations ref &amp; {:keys [lenient]}]
  (let [recal-files (variant-recalibration in-vcf training-vcfs annotations ref :lenient lenient)]
    (apply-recalibration in-vcf recal-files ref)))</pre></td></tr><tr><td class="docs"><p>Remove any filter information in the supplied file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn remove-cur-filters
  [in-vcf ref]
  (letfn [(remove-vc-filter [vc]
            [:out (-&gt; (VariantContextBuilder. (:vc vc))
                      (.passFilters)
                      (.make))])]
    (let [out-file (itx/add-file-part in-vcf &quot;nofilter&quot;)]
      (when (itx/needs-run? out-file)
        (with-open [vcf-source (get-vcf-source in-vcf ref)]
          (write-vcf-w-template in-vcf {:out out-file}
                                (map remove-vc-filter (parse-vcf vcf-source))
                                ref)))
      out-file)))</pre></td></tr><tr><td class="docs"><p>Check if a comparison set is only pairwise and not multiple.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- pairwise-only?
  [cmp-names]
  (= 1 (count (set (map (fn [xs] (vec (map remove-mod-name xs))) cmp-names)))))</pre></td></tr><tr><td class="docs"><p>Retrieve training information for GATK recalibration:
   - No support specified: use the target comparison
   - Support specified and a specific comparison pair
   - Support specified as a single target: use target versus all comparison</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-train-info
  [cmps-by-name support config]
  (let [support (if (and (not (coll? support)) (pairwise-only? (keys cmps-by-name)))
                  (first (keys cmps-by-name))
                  support)
        support-vcfs (if (coll? support)
                       (take 2 (-&gt; cmps-by-name (get support) :c-files vals))
                       (let [x (multiple-overlap-analysis cmps-by-name config support)]
                         [(:true-positives x) (:false-positives x)]))]
      [{:file (first support-vcfs)
        :name &quot;concordant&quot;
        :truth &quot;true&quot;
        :bad &quot;false&quot;
        :prior 10.0}
       {:file (second support-vcfs)
        :name &quot;discordant&quot;
        :truth &quot;false&quot;
        :bad &quot;true&quot;
        :prior 10.0}]))</pre></td></tr><tr><td class="docs"><p>Perform variant recalibration and filtration as part of processing pipeline.</p>
</td><td class="codes"><pre class="brush: clojure">(defn pipeline-recalibration
  [cmps-by-name finalizer exp config]
  (let [init-target (get cmps-by-name (:target finalizer)
                         (get cmps-by-name (reverse (:target finalizer))))
        all-params (let [x (:params finalizer)] (if (map? x) [x] x))]
    (reduce (fn [target [params fkey]]
              (let [in-vcf (remove-cur-filters (-&gt; target fkey :file) (:ref exp))
                    train-info (get-train-info cmps-by-name
                                               (get params :support (:target finalizer))
                                               config)]
                (-&gt; target
                    (assoc-in [fkey :file]
                              (-&gt; in-vcf
                                  (#(if-let [anns (:annotations params)]
                                      (variant-recal-filter % train-info
                                                            anns (:ref exp)
                                                            :lenient (:lenient params))
                                      %))
                                  (#(if-let [hard-filters (:filters params)]
                                      (variant-filter % hard-filters (:ref exp))
                                      %))
                                  (#(if-not (:classifiers params) %
                                            (pipeline-classify-filter % train-info
                                                                      (:ref exp) params)))))
                    (#(assoc-in % [fkey :name] (format &quot;%s-%s&quot; (get-in % [fkey :name]) &quot;recal&quot;)))
                    (assoc-in [fkey :mod] &quot;recal&quot;)
                    (assoc :re-compare true))))
            init-target (map vector all-params [:c1 :c2]))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.filter.classify" name="bcbio.variation.filter.classify"><h1 class="project-name">bcbio.variation.filter.classify</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Provide classification based filtering for variants.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.filter.classify
  (:import [org.broadinstitute.sting.utils.variantcontext VariantContextBuilder]
           [org.broadinstitute.sting.utils.codecs.vcf VCFHeader VCFInfoHeaderLine
            VCFHeaderLineType VCFFilterHeaderLine])
  (:use [ordered.set :only [ordered-set]]
        [clj-ml.utils :only [serialize-to-file deserialize-from-file]]
        [clj-ml.data :only [make-dataset dataset-set-class make-instance]]
        [clj-ml.classifiers :only [make-classifier classifier-train
                                   classifier-evaluate classifier-classify]]
        [bcbio.variation.variantcontext :only [parse-vcf write-vcf-w-template
                                               get-vcf-source]])
  (:require [clojure.string :as string]
            [incanter.stats :as stats]
            [fs.core :as fs]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><h2>Normalized attribute access</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Generalized retrieval of attributes from variant with a single genotype.</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti get-vc-attr
  (fn [vc attr] attr))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-vc-attr &quot;AD&quot;
  [vc attr]
  {:pre [(= 1 (:num-samples vc))
         (contains? #{1 2} (-&gt; vc :genotypes first :alleles count))]}
  &quot;AD: Allelic depth for ref and alt alleles. Converted to percent
   deviation from expected for haploid/diploid calls.
   Also calculates allele depth from AO and DP used by FreeBayes.
   AO is the count of the alternative allele.&quot;
  (letfn [(calc-expected [g ref-count allele-count]
            {:pre [(not (neg? ref-count))]}
            (when (or (pos? ref-count) (pos? allele-count))
              (when-let [e-pct (get {&quot;HOM_VAR&quot; 1.0 &quot;HET&quot; 0.5 &quot;HOM_REF&quot; 0.0} (:type g))]
                (Math/abs (- e-pct (/ allele-count (+ allele-count ref-count)))))))
          (from-ad [g]
            (let [ads (map #(Float/parseFloat %) (string/split (get-in g [:attributes attr]) #&quot;,&quot;))
                  alleles (cons (:ref-allele vc) (:alt-alleles vc))
                  ref-count (first ads)
                  allele-count (apply + (map #(nth ads (.indexOf alleles %)) (set (:alleles g))))]
              (calc-expected g ref-count allele-count)))
          (from-ao [g]
            (let [alt-count (Float/parseFloat (get-in g [:attributes &quot;AO&quot;]))
                  total-count (Float/parseFloat (get-in g [:attributes &quot;DP&quot;]))]
              (calc-expected g (- total-count alt-count) alt-count)))]
    (let [g (-&gt; vc :genotypes first)]
      (cond
       (get-in g [:attributes &quot;AO&quot;]) (from-ao g)
       (get-in g [:attributes attr]) (from-ad g)
       :else nil
       ;; (println (format &quot;AD not found in attributes %s %s %s&quot;
       ;;                  (:attributes g) (:chr vc) (:start vc)))
       ))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-vc-attr &quot;QUAL&quot;
  [vc attr]
  (:qual vc))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-vc-attr :default
  [vc attr]
  (let [x (get-in vc [:attributes attr])]
    (when-not (nil? x)
      (try (Float/parseFloat x)
           (catch java.lang.NumberFormatException _ x)))))</pre></td></tr><tr><td class="docs"><p>Retrieve attributes from variants independent of location.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-vc-attrs
  [vc attrs]
  (zipmap attrs (map (partial get-vc-attr vc) attrs)))</pre></td></tr><tr><td class="docs"><p>Retrieve quantile ranges of attributes for min/max normalization.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-vc-attr-ranges
  [attrs in-vcf ref]
  (letfn [(get-quartiles [[k v]]
            [k (stats/quantile v :probs [0.05 0.95])])]
    (with-open [vcf-s (get-vcf-source in-vcf ref)]
      (-&gt;&gt; (reduce (fn [coll vc]
                    (reduce (fn [icoll [k v]]
                              (assoc icoll k (cons v (get icoll k))))
                            coll (get-vc-attrs vc attrs)))
                  (zipmap attrs (repeat [])) (parse-vcf vcf-s))
           (map get-quartiles)
           (into {})))))</pre></td></tr><tr><td class="docs"><p>Normalized attributes for each variant context in an input file.</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti get-vc-attrs-normalized
  (fn [_ _ _ config] (keyword (get config :normalize &quot;default&quot;))))</pre></td></tr><tr><td class="docs"><p>Min-max normalization</p>
</td><td class="codes"><pre class="brush: clojure">(defmethod get-vc-attrs-normalized :minmax
  [attrs in-vcf ref config]
  (letfn [(min-max-norm [x [minv maxv]]
            (let [safe-maxv (if (= minv maxv) (inc maxv) maxv)
                  trunc-score-max (if (&lt; x safe-maxv) x safe-maxv)
                  trunc-score (if (&gt; trunc-score-max minv) trunc-score-max minv)]
              (/ (- trunc-score minv) (- safe-maxv minv))))
          (min-max-norm-ranges [mm-ranges [k v]]
            [k (min-max-norm v (get mm-ranges k))])]
    (let [mm-ranges (get-vc-attr-ranges attrs in-vcf ref)]
      (fn [vc]
        (-&gt;&gt; (get-vc-attrs vc attrs)
             (map (partial min-max-norm-ranges mm-ranges))
             (into {}))))))</pre></td></tr><tr><td class="docs"><p>No normalization</p>
</td><td class="codes"><pre class="brush: clojure">(defmethod get-vc-attrs-normalized :default
  [attrs in-vcf ref config]
  (fn [vc]
    (into {} (get-vc-attrs vc attrs))))</pre></td></tr><tr><td class="docs"><h2>Linear classifier</h2>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- get-vc-inputs
  [attrs normalizer group vc]
  (let [n-vals (normalizer vc)]
    (conj (vec (map #(get n-vals %) attrs)) group)))</pre></td></tr><tr><td class="docs"><p>Retrieve normalized training inputs from VCF file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-train-inputs
  [group in-vcf attrs normalizer ref]
  (with-open [vcf-s (get-vcf-source in-vcf ref)]
    (doall (map (partial get-vc-inputs attrs normalizer group)
                (parse-vcf vcf-s)))))</pre></td></tr><tr><td class="docs"><p>Do the work of training a variant classifier.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- train-vcf-classifier
  [attrs base-vcf true-vcf false-vcf ref config]
  (let [normalizer (get-vc-attrs-normalized attrs base-vcf ref config)
        ds (make-dataset &quot;ds&quot; (conj (vec attrs) {:c [:a :b]})
                      (concat (get-train-inputs :a true-vcf attrs normalizer ref)
                              (get-train-inputs :b false-vcf attrs normalizer ref))
                      {:class :c})
        c (classifier-train (make-classifier :support-vector-machine :smo) ds)]
    ;(println &quot;Evaluate&quot; (classifier-evaluate c :dataset ds ds))
    c))</pre></td></tr><tr><td class="docs"><p>Provide a variant classifier based on provided attributes and true/false examples.</p>
</td><td class="codes"><pre class="brush: clojure">(defn build-vcf-classifier
  [attrs base-vcf true-vcf false-vcf ref config]
  (let [out-file (str (itx/file-root base-vcf) &quot;-classifier.bin&quot;)]
    (if-not (itx/needs-run? out-file)
      (deserialize-from-file out-file)
      (let [classifier (train-vcf-classifier attrs base-vcf true-vcf false-vcf ref
                                             config)]
        (serialize-to-file classifier out-file)
        classifier))))</pre></td></tr><tr><td class="docs"><p>Add details on the filtering to the VCF file header.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- add-cfilter-header
  [attrs]
  (fn [_ header]
    (let [desc (str &quot;Classification score based on true/false positives for: &quot;
                    (string/join &quot;, &quot; attrs))
          new #{(VCFInfoHeaderLine. &quot;CSCORE&quot; 1 VCFHeaderLineType/Float desc)
                (VCFFilterHeaderLine. &quot;CScoreFilter&quot; &quot;Based on classifcation CSCORE&quot;)}]
      (VCFHeader. (apply ordered-set (concat (.getMetaData header) new))
                  (.getGenotypeSamples header)))))</pre></td></tr><tr><td class="docs"><p>Update a variant context with filter information from classifier.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- filter-vc
  [classifier normalizer config vc]
  (let [attrs (vec (:classifiers config))
        score (-&gt; (make-dataset &quot;ds&quot; (conj attrs :c)
                                 [(get-vc-inputs attrs normalizer -1 vc)]
                                 {:class :c})
                  (make-instance (assoc (normalizer vc) :c -1))
                  (#(classifier-classify classifier %)))]
    (-&gt; (VariantContextBuilder. (:vc vc))
        (.attributes (assoc (:attributes vc) &quot;CSCORE&quot; score))
        (.filters (when (&lt; score (get config :min-cscore 0.5))
                    #{&quot;CScoreFilter&quot;}))
        .make)))</pre></td></tr><tr><td class="docs"><p>Filter an input VCF file using a trained classifer on true/false variants.</p>
</td><td class="codes"><pre class="brush: clojure">(defn filter-vcf-w-classifier
  [base-vcf true-vcf false-vcf ref config]
  (let [out-file (itx/add-file-part base-vcf &quot;cfilter&quot;)
        c (build-vcf-classifier (:classifiers config) base-vcf
                                true-vcf false-vcf ref config)
        normalizer (get-vc-attrs-normalized (:classifiers config) base-vcf ref config)]
    (when (itx/needs-run? out-file)
      (println &quot;Filter VCF with&quot; (str c))
      (with-open [vcf-s (get-vcf-source base-vcf ref)]
        (write-vcf-w-template base-vcf {:out out-file}
                              (map (partial filter-vc c normalizer config)
                                   (parse-vcf vcf-s))
                              ref :header-update-fn (add-cfilter-header (:classifiers config)))))
    out-file))</pre></td></tr><tr><td class="docs"><p>Fit VCF classification-based filtering into analysis pipeline.</p>
</td><td class="codes"><pre class="brush: clojure">(defn pipeline-classify-filter
  [in-vcf train-info ref config]
  (letfn [(get-train-vcf [type]
            (-&gt; (filter #(= type (:name %)) train-info)
                       first
                       :file))]
    (filter-vcf-w-classifier in-vcf (get-train-vcf &quot;concordant&quot;)
                             (get-train-vcf &quot;discordant&quot;) ref config)))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.haploid" name="bcbio.variation.haploid"><h1 class="project-name">bcbio.variation.haploid</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Convert diploid variants from GATK into haploid calls based on genotype likelihoods.
  We assess diploid GATK calls based on the phred-normalized likelihood (PL). Lower variant
  PLs are likely to be true and included. The GATK documentation contains a detailed example
  of the format and interpretation:
  http://www.broadinstitute.org/gsa/wiki/index.php/
  Understanding<em>the</em>Unified<em>Genotyper%27s</em>VCF<em>files#How</em>genotypes<em>are</em>represented<em>in</em>a_VCF</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.haploid
  (:import [org.broadinstitute.sting.utils.variantcontext 
            VariantContextBuilder GenotypesContext Genotype])
  (:use [clojure.java.io]
        [bcbio.variation.variantcontext :only [parse-vcf get-vcf-source write-vcf-w-template]])
  (:require [clojure.string :as string]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><h2>Convert diploid -> haploid</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Threshold to include a heterozygous allele as a haploid homozygote variant.</p>
</td><td class="codes"><pre class="brush: clojure">(def 
  haploid-thresh 1e-5)</pre></td></tr><tr><td class="docs"><p>Retrieve updated genotype with haploid allele.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-haploid-genotype
  [vc]
  (let [g (-&gt; vc :genotypes first)]
    (letfn [(maybe-variant-haploid [g]
              (when (.hasLikelihoods g)
                (let [in-map (-&gt; (.getLikelihoods g) (.getAsMap true))
                      variant-prob (get (zipmap (map #(.name %) (keys in-map)) (vals in-map))
                                        &quot;HOM_VAR&quot;)]
                  (when (&gt; variant-prob haploid-thresh)
                    (first (filter #(and (.isNonReference %) (.isCalled %))
                                   (.getAlleles g)))))))
            (extract-mixed-allele [alleles]
              (let [ready (remove #(.isNoCall %) alleles)]
                (when (= 1 (count ready))
                  (first ready))))
            (get-haploid-allele [g]
              (case (:type g)
                &quot;HOM_VAR&quot; (first (:alleles g))
                &quot;MIXED&quot; (extract-mixed-allele (:alleles g))
                &quot;HET&quot; (maybe-variant-haploid (:genotype g))
                nil))]
      (when-let [allele (get-haploid-allele g)]
        (doto (-&gt; vc :vc .getGenotypes GenotypesContext/copy)
          (.replace (Genotype/modifyAlleles (:genotype g) [allele])))))))</pre></td></tr><tr><td class="docs"><p>Convert diploid allele to haploid variant.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- convert-to-haploid
  [vc]
  {:pre (= 1 (:num-samples vc))}
  (if-let [genotype (get-haploid-genotype vc)]
    [:haploid (-&gt; (VariantContextBuilder. (:vc vc))
                  (.genotypes genotype)
                  (.make))]
    [:unchanged (:vc vc)]))</pre></td></tr><tr><td class="docs"><p>Convert set of diploid GATK calls on a haploid genome based on likelihoods.</p>
</td><td class="codes"><pre class="brush: clojure">(defn diploid-calls-to-haploid
  [vcf ref &amp; {:keys [out-dir]}]
  (let [out-files {:haploid (itx/add-file-part vcf &quot;haploid&quot; out-dir)
                   :unchanged (itx/add-file-part vcf &quot;nonhaploid&quot; out-dir)}]
    (when (itx/needs-run? (vals out-files))
      (with-open [vcf-source (get-vcf-source vcf ref)]
        (write-vcf-w-template vcf out-files
                              (map convert-to-haploid (parse-vcf vcf-source))
                              ref)))
    (:haploid out-files)))</pre></td></tr><tr><td class="docs"><h2>Examine diploid metrics</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Write phred likelihoods for het calls to be haploid variants.</p>
</td><td class="codes"><pre class="brush: clojure">(defn write-het-variant-pls
  [vcf-file ref-file &amp; attrs]
  (letfn [(get-pl [vc]
            (let [g (-&gt; vc :genotypes first :genotype)]
              (when (.hasLikelihoods g)
                (let [in-map (-&gt; (.getLikelihoods g) (.getAsMap true))]
                  (get (zipmap (map #(.name %) (keys in-map)) (vals in-map))
                       &quot;HOM_VAR&quot;)))))]
  (let [out-file (str (itx/file-root vcf-file) &quot;-het-pls.csv&quot;)]
    (with-open [vcf-source (get-vcf-source vcf-file ref-file)
                wtr (writer out-file)]
      (doseq [val (-&gt;&gt; (parse-vcf vcf-source)
                       (filter #(= &quot;HET&quot; (-&gt; % :genotypes first :type)))
                       (map get-pl)
                       (remove nil?))]
        (.write wtr (str (string/join &quot;,&quot; (cons val attrs)) &quot;\n&quot;))))
    out-file)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -main
  [vcf ref]
  (diploid-calls-to-haploid vcf ref))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.metrics" name="bcbio.variation.metrics"><h1 class="project-name">bcbio.variation.metrics</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Accumulate and analyze metrics associated with each variant.
   This provides summaries intended to identify characteristic
   metrics to use for filtering.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.metrics
  (:use [clojure.java.io]
        [clojure.set]
        [bcbio.variation.variantcontext :only [parse-vcf get-vcf-source]]
        [clojure.string :only [split-lines]]
        [clj-ml.data :only [make-dataset]]
        [clj-ml.classifiers :only [make-classifier classifier-train]]
        [ordered.set :only [ordered-set]])
  (:require [incanter.stats :as istats]
            [doric.core :as doric]))</pre></td></tr><tr><td class="docs"><h2>Convenience functions</h2>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- to-float [x]
  (if (number? x)
    x
    (try
      (Float/parseFloat x)
      (catch Exception e nil))))</pre></td></tr><tr><td class="docs"><p>Check if a VariantContext is not filtered.</p>
</td><td class="codes"><pre class="brush: clojure">(defn passes-filter?
  [vc]
  (= (count (:filters vc)) 0))</pre></td></tr><tr><td class="docs"><p>Check if a variant context is not filter and is not a reference call.</p>
</td><td class="codes"><pre class="brush: clojure">(defn nonref-passes-filter?
  [vc]
  (and (passes-filter? vc)
       (every? #(contains? #{&quot;HET&quot; &quot;HOM_VAR&quot;} (:type %)) (:genotypes vc))))</pre></td></tr><tr><td class="docs"><p>Retrieve numeric metrics associated with VariantContext.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-vc-metrics
  [vc]
  (reduce (fn [coll [k v]]
            (if-let [num-v (to-float v)]
              (assoc coll k num-v)
              coll))
   {}
   (assoc (:attributes vc) &quot;QUAL&quot; (:qual vc))))</pre></td></tr><tr><td class="docs"><h2>Summary metrics</h2>

<p>Provide a summary-style presentation of distribution of metrics values.</p>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(def header [{:name :metric}
             {:name :count}
             {:name :min :format #(format &quot;%.2f&quot; %)}
             {:name :pct25 :format #(format &quot;%.2f&quot; %)}
             {:name :median :format #(format &quot;%.2f&quot; %)}
             {:name :pct75 :format #(format &quot;%.2f&quot; %)}
             {:name :max :format #(format &quot;%.2f&quot; %)}])</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn summary-stats [key vals]
  &quot;Provide summary statistics on a list of values.&quot;
  (zipmap (map :name header)
          (concat [key (count vals)]
                  (istats/quantile vals))))</pre></td></tr><tr><td class="docs"><p>Accumulate raw statistics associated with variant calls from input VCF.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- raw-vcf-stats
  [vcf-file ref-file]
  (letfn [(collect-attributes [collect [k v]]
            (if-not (nil? (to-float v))
              (assoc collect k (cons (to-float v) (get collect k [])))
              collect))
          (collect-vc [collect vc]
            (assoc (reduce collect-attributes collect (:attributes vc))
              &quot;QUAL&quot; (cons (:qual vc)
                           (get collect &quot;QUAL&quot; []))))]
    (with-open [vcf-source (get-vcf-source vcf-file ref-file)]
      (reduce collect-vc {} (filter passes-filter? (parse-vcf vcf-source))))))</pre></td></tr><tr><td class="docs"><p>Collect summary statistics associated with variant calls.</p>
</td><td class="codes"><pre class="brush: clojure">(defn vcf-stats
  [vcf-file ref-file]
  (let [raw-stats (raw-vcf-stats vcf-file ref-file)]
    (map #(apply summary-stats %) (sort-by first raw-stats))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn write-summary-table [stats &amp; {:keys [wrtr]
                                    :or {wrtr (writer System/out)}}]
  (.write wrtr (str (doric/table header stats) &quot;\n&quot;)))</pre></td></tr><tr><td class="docs"><h2>Classify</h2>

<p>Provide metrics for files in preparation for automated
classification.</p>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Collect classification metrics from a single VCF file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-file-metrics
  [ref-file vcf-file]
  (letfn [(has-nil-names [metrics all-metrics all-names]
            (let [test-names (union (-&gt; metrics keys set) all-names)]
              (apply union
                     (map (fn [xs] (set (keep #(when (nil? (get xs %)) %) test-names)))
                          (cons metrics (take-last 10 all-metrics))))))
          (classifier-metrics [coll vc]
            (let [cur-metrics (get-vc-metrics vc)]
              (-&gt; coll
                  (assoc :rows (cons cur-metrics (:rows coll)))
                  (assoc :names (union (-&gt; cur-metrics keys set) (:names coll)))
                  (assoc :nil-names (union (has-nil-names cur-metrics (:rows coll) (:names coll))
                                           (:nil-names coll))))))
          (prep-table [{rows :rows names :names nil-names :nil-names}]
            (let [sort-names (sort (vec names))]
              {:cols sort-names
               :with-nil-cols nil-names
               :rows (map (fn [x]
                            (map #(get x %) sort-names))
                          rows)}))]
    (with-open [vcf-source (get-vcf-source vcf-file ref-file)]
      (prep-table
       (reduce classifier-metrics {:rows [] :names #{} :nil-names #{}}
               (filter passes-filter? (parse-vcf vcf-source)))))))</pre></td></tr><tr><td class="docs"><p>Collect metrics from multiple vcf files into tables suitable for
  classification algorithms.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-vcf-classifier-metrics
  [ref-file vcf-files &amp; {:keys [remove-nil-cols]
                         :or {remove-nil-cols true}}]
  (letfn [(get-shared-cols [xs]
            (-&gt; (apply intersection (map #(set (:cols %)) xs))
                sort
                vec))
          (filter-by-cols [orig-cols want-cols]
            (let [check-cols (set want-cols)
                  want (set (keep-indexed #(if (contains? check-cols %2) %1) orig-cols))]
              (fn [xs]
                (keep-indexed #(when (contains? want %1) %2) xs))))
          (subset-file-metrics [shared-cols nil-cols {cols :cols rows :rows}]
            (let [ready-cols (if-not remove-nil-cols shared-cols
                                     (remove #(contains? nil-cols %) shared-cols))
                  row-filter (filter-by-cols cols ready-cols)]
              {:cols ready-cols
               :rows (remove #(not= (count %) (count ready-cols)) (map row-filter rows))}))]
    (let [file-metrics (map (partial get-file-metrics ref-file) vcf-files)
          shared-cols (get-shared-cols file-metrics)
          nil-cols (apply union (map #(set (:with-nil-cols %)) file-metrics))]
      (map (partial subset-file-metrics shared-cols nil-cols) file-metrics))))</pre></td></tr><tr><td class="docs"><p>Retrieve classification metrics from a tree based classifier.
  Metric ordering is relative to the usefulness in classifying.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- parse-classifier-nodes
  [classifier metrics]
  (-&gt;&gt; classifier
       .graph
       split-lines
       (map #(re-find #&quot;label=\&quot;(\w+)\&quot;&quot; %))
       (map second)
       flatten
       (remove nil?)
       (filter #(contains? (set metrics) %))
       (apply ordered-set)))</pre></td></tr><tr><td class="docs"><p>Classify VCF files with INFO metrics using a decision tree classifier.</p>
</td><td class="codes"><pre class="brush: clojure">(defn classify-decision-tree
  [metrics]
  (letfn [(prep-one-dataset [rows i]
            (map #(conj (vec %) (str i)) rows))
          (prep-dataset [metrics]
            (make-dataset &quot;ds&quot; (conj (-&gt; metrics first :cols vec)
                                     {:c (map str (range (count metrics)))})
                          (apply concat (map-indexed #(prep-one-dataset (:rows %2) %1) metrics))
                          {:class :c}))]
    (let [ds (prep-dataset metrics)
          c (-&gt; (make-classifier :decision-tree :c45)
                (classifier-train ds))]
      (vec (parse-classifier-nodes c (-&gt; metrics first :cols))))))</pre></td></tr><tr><td class="docs"><p>Merge multiple classification approaches into a set of final metrics.
  <code>in-metrics</code> contains ordered best metric classifiers from the different
  approaches. Returns interleaved metrics ranked by present in these
  classifiers. </p>
</td><td class="codes"><pre class="brush: clojure">(defn merge-classified-metrics
  [in-metrics]
  (loop [cur in-metrics
         final (ordered-set)]
    (if (every? empty? cur)
      {:top-metrics (vec final)}
      (recur (map rest cur)
             (reduce #(conj %1 %2) final (remove nil? (map first cur)))))))</pre></td></tr><tr><td class="docs"><p>Apply machine learning/classification approaches to distinguish useful
  metrics distinguishing VCF files.</p>
</td><td class="codes"><pre class="brush: clojure">(defn ml-on-vcf-metrics
  [ref-file vcf-files]
  (letfn [(run-classifier [remove-nil-cols]
            (-&gt; (get-vcf-classifier-metrics ref-file vcf-files :remove-nil-cols remove-nil-cols)
                classify-decision-tree))]
    (merge-classified-metrics (map run-classifier [true false]))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.multiple" name="bcbio.variation.multiple"><h1 class="project-name">bcbio.variation.multiple</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Handle useful comparisons from multiple variation calling approaches.
  High level API to consolidate pairwise variant comparisons.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.multiple
  (:use [clojure.set :only [union]]
        [ordered.map :only [ordered-map]]
        [bcbio.variation.annotation :only [add-variant-annotations]]
        [bcbio.variation.callable :only [get-callable-checker is-callable? has-callers?]]
        [bcbio.variation.combine :only [combine-variants]]
        [bcbio.variation.metrics :only [nonref-passes-filter?]]
        [bcbio.variation.variantcontext :only [parse-vcf get-vcf-retriever
                                               get-vcf-source write-vcf-w-template]])
  (:require [clojure.string :as string]
            [fs.core :as fs]
            [bcbio.run.itx :as itx]
            [bcbio.run.broad :as broad]))</pre></td></tr><tr><td class="docs"><h2>Utility functions</h2>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn remove-mod-name [x &amp; {:keys [mods] :or {mods [&quot;recal&quot;]}}]
  &quot;Removes modification names from an approach name.&quot;
  (reduce (fn [final mod]
            (string/replace final (str &quot;-&quot; mod) ))
          x mods))</pre></td></tr><tr><td class="docs"><p>Lookup map of comparisons by method names.
   - ignore: a list of method names to ignore when creating the lookup map.
   - remove-mods?: Flag to remove naming modifications. This
                   will replace original comparisons with recalibrated.</p>
</td><td class="codes"><pre class="brush: clojure">(defn prep-cmp-name-lookup
  [cmps &amp; {:keys [ignore remove-mods?] :or {ignore #{}}}]
  (reduce (fn [m x]
            (let [names (map #(let [n (get-in x [% :name])]
                                (if-not remove-mods? n
                                        (remove-mod-name n :mods [(get-in x [% :mod])])))
                             [:c1 :c2])]
              (if (some #(contains? ignore %) names) m
                  (assoc m names x))))
          (ordered-map)
          cmps))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- not-target? [target-name xs]
  (not (contains? (set (map remove-mod-name xs)) target-name)))</pre></td></tr><tr><td class="docs"><h2>Prepare multi-overlap sets</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Select samples based on name of a 'set' from CombineVariants.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- select-variant-by-set
  [vcf-in ref set-name &amp; {:keys [out-dir allow-partial?]}]
  (let [file-info {:out-vcf (itx/add-file-part vcf-in set-name out-dir)}
        args [&quot;-R&quot; ref
              &quot;-o&quot; :out-vcf
              &quot;--variant&quot; vcf-in
              &quot;-select&quot; (if allow-partial?
                          (format &quot;vc.getAttributeAsString('set','').contains('%s')&quot;
                                  set-name)
                          (format &quot;set == '%s'&quot; set-name))]]
    (broad/run-gatk &quot;SelectVariants&quot; args file-info {:out [:out-vcf]})
    (:out-vcf file-info)))</pre></td></tr><tr><td class="docs"><p>Create VCF of the intersection of all concordant calls.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- gen-all-concordant
  [cmps-by-name ref out-dir config &amp; {:keys [do-include? base-ext]
                                  :or {base-ext &quot;multiall&quot;}}]
  (let [concordant-map (reduce (fn [m [k v]]
                                 (if (or (nil? do-include?) (do-include? k))
                                   (assoc m (get-in v [:c-files :concordant]) (string/join &quot;-&quot; k))
                                   m))
                               (ordered-map) cmps-by-name)
        union-vcf (combine-variants (keys concordant-map) ref :merge-type :full :out-dir out-dir
                                    :name-map concordant-map :base-ext base-ext)]
    {:union union-vcf
     :intersection (select-variant-by-set union-vcf ref &quot;Intersection&quot;)}))</pre></td></tr><tr><td class="docs"><p>Generate false positives: discordant calls also called in other samples.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- gen-target-fps
  [target-cmps target-name other-conc-vcf ref out-dir]
  (letfn [(check-shared [fetch any-callable]
            (fn [x]
              (and (nonref-passes-filter? x)
                   (if (has-callers? any-callable)
                     (is-callable? any-callable (:chr x) (:start x) (:end x))
                     (not (empty? (fetch (:chr x) (:start x) (:end x))))))))
          (get-shared-discordant [xs fetch any-callable]
            (let [pass-and-shared? (check-shared fetch any-callable)]
              (map :vc (filter pass-and-shared? xs))))]
    (let [disc-vcfs (remove nil? (map (fn [v]
                                        (get-in v [:c-files
                                                   (keyword (format &quot;%s-discordant&quot; target-name))]))
                                      (vals target-cmps)))
          disc-vcf (-&gt; (combine-variants disc-vcfs ref :merge-type :full :out-dir out-dir
                                         :base-ext (format &quot;dis%s&quot; target-name))
                       (select-variant-by-set ref &quot;Intersection&quot;))
          out-file (itx/add-file-part disc-vcf &quot;shared&quot;)
          align-bams (-&gt;&gt; (vals target-cmps)
                          (map (juxt :c1 :c2))
                          flatten
                          (map :align)
                          (remove nil?))]
      (with-open [disc-source (get-vcf-source disc-vcf ref)
                  other-source (get-vcf-source other-conc-vcf ref)
                  call-source (get-callable-checker align-bams ref
                                                    :out-dir (str (fs/parent out-dir)))]
        (let [vrn-fetch (get-vcf-retriever other-source)]
          (write-vcf-w-template disc-vcf {:out out-file}
                                (get-shared-discordant (parse-vcf disc-source)
                                                       vrn-fetch call-source)
                                ref)))
      out-file)))</pre></td></tr><tr><td class="docs"><p>Create files of false negatives and positives from target-name.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- gen-target-problems
  [target-name target-call cmps-by-name true-p-vcf ref out-dir config]
  (let [notarget-concordant (gen-all-concordant cmps-by-name ref out-dir config
                                                :do-include? (partial not-target? target-name)
                                                :base-ext (format &quot;multino%s&quot; target-name))]
    {:false-negatives
     (-&gt; (combine-variants [true-p-vcf (:intersection notarget-concordant)]
                           ref :merge-type :full :out-dir out-dir
                           :name-map {true-p-vcf &quot;truep&quot;
                                      (:intersection notarget-concordant) target-name}
                           :base-ext (format &quot;multiall-no%s&quot; target-name))
         (select-variant-by-set ref target-name)
         (add-variant-annotations (:align target-call) ref target-call :out-dir out-dir))
     :false-positives (gen-target-fps (remove #(not-target? target-name (first %))
                                              cmps-by-name)
                                      target-name (:union notarget-concordant)
                                      ref out-dir)}))</pre></td></tr><tr><td class="docs"><p>Provide high level concordance overlap comparisons for multiple call approaches.
  Organizes relative to the given target name generating:
   - VCF of calls concordant in all methods: intersection of all concordant calls.
     These are true positives.
   - VCF of calls discordant in the target method, but concordant in the remainder:
     the intersection of all concordant pairs not including target-name minus the
     overall intersection of concordants. These are false negatives.
   - VCF of non-ref calls discordant in the target method and called in any of the other
     methods. We restrict to shared calls to avoid penalizing unique calls.
     These are false positives.</p>
</td><td class="codes"><pre class="brush: clojure">(defn multiple-overlap-analysis
  [cmps config target-name &amp; {:keys [dirname ignore] :or {dirname &quot;multiple&quot;
                                                          ignore #{}}}]
  (let [cmps-by-name (prep-cmp-name-lookup (if (map? cmps) (vals cmps) cmps)
                                           :ignore (union ignore #{&quot;all&quot; &quot;validate&quot;}))
        out-dir (str (fs/file (get-in config [:dir :prep] (get-in config [:dir :out]))
                              dirname))
        ref (-&gt; cmps-by-name vals first :exp :ref)
        target-call (-&gt;&gt; cmps-by-name
                         (remove #(not-target? target-name (first %)))
                         first
                         second
                         ((juxt :c1 :c2))
                         (filter #(= (remove-mod-name (:name %)) target-name))
                         first)]
    (when-not (fs/exists? out-dir)
      (fs/mkdirs out-dir))
    (let [all-overlap (gen-all-concordant cmps-by-name ref out-dir config)
          true-p-vcf (add-variant-annotations (:intersection all-overlap) (:align target-call)
                                              ref target-call :out-dir out-dir)
          target-problems (gen-target-problems target-name target-call cmps-by-name
                                               true-p-vcf ref out-dir config)]
      (ordered-map :true-positives true-p-vcf
                   :false-negatives (:false-negatives target-problems)
                   :false-positives (:false-positives target-problems)
                   :target-overlaps (-&gt; all-overlap
                                        :union
                                        (select-variant-by-set ref target-name :allow-partial? true)
                                        (add-variant-annotations (:align target-call) ref
                                                                 target-call :out-dir out-dir))))))</pre></td></tr><tr><td class="docs"><p>Perform high level pipeline comparison of a target with multiple experiments.</p>
</td><td class="codes"><pre class="brush: clojure">(defn pipeline-compare-multiple
  [cmps finalizer exp config]
  (let [analysis (multiple-overlap-analysis cmps config (:target finalizer)
                                            :ignore (set (get finalizer :ignore #{})))]
    {:c-files analysis
     :c1 {:name (:target finalizer)}
     :c2 {:name &quot;all&quot;}
     :exp exp :dir (config :dir)}))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.normalize" name="bcbio.variation.normalize"><h1 class="project-name">bcbio.variation.normalize</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Prepare a VCF file for comparison by normalizing chromosome names,
  sort order, sample name, and genotype representation.
  This handles the work of making slightly different representations
  match, enabling VCF comparisons.
  Currently implemented for human only, with hooks to generalize for other
  organisms.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.normalize
  (:import [org.broadinstitute.sting.utils.variantcontext VariantContextBuilder Genotype]
           [org.broadinstitute.sting.utils.codecs.vcf VCFHeader]
           [org.broad.tribble.readers AsciiLineReader])
  (:use [clojure.java.io]
        [bcbio.variation.variantcontext :only [write-vcf-w-template
                                               get-vcf-source
                                               get-vcf-retriever
                                               get-vcf-line-parser
                                               from-genotype]]
        [bcbio.align.ref :only [get-seq-dict get-seq-name-map]]
        [bcbio.variation.structural :only [nochange-alt?]]
        [ordered.map :only (ordered-map)]
        [ordered.set :only (ordered-set)])
  (:require [clojure.string :as string]
            [bcbio.run.itx :as itx]
            [fs.core :as fs]))</pre></td></tr><tr><td class="docs"><h2>Chromosome name remapping</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Provide mapping from variant chromosome names to reference
keyed on the organism name. Currently only a human GRCh37 remap.</p>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmulti chr-name-remap (fn [type &amp; args] type))</pre></td></tr><tr><td class="docs"><p>Function to retrieve hg19 information. Requires korma and
  mysql connector.</p>
</td><td class="codes"><pre class="brush: clojure">(comment
(defn- get-hg19-map
  []
  (defdb db (mysql {:db &quot;hg19&quot;
                    :user &quot;genome&quot;
                    :host &quot;genome-mysql.cse.ucsc.edu&quot;}))
  (defentity ucscToEnsembl)
  (-&gt;&gt; (select ucscToEnsembl)
       (map (juxt :ucsc :ensembl))
       (into {}))))</pre></td></tr><tr><td class="docs"><p>Cached version of hg19 map to avoid having to make database connections</p>
</td><td class="codes"><pre class="brush: clojure">(def hg19-map
  {&quot;chrM&quot; &quot;MT&quot; &quot;chrMT&quot; &quot;MT&quot; &quot;chrUn_gl000211&quot; &quot;GL000211&quot;, &quot;chrUn_gl000222&quot; &quot;GL000222&quot;,
   &quot;chrUn_gl000233&quot; &quot;GL000233&quot;, &quot;chrUn_gl000244&quot; &quot;GL000244&quot;, &quot;chrUn_gl000212&quot; &quot;GL000212&quot;,
   &quot;chrUn_gl000223&quot; &quot;GL000223&quot;, &quot;chrUn_gl000234&quot; &quot;GL000234&quot;, &quot;chrUn_gl000245&quot; &quot;GL000245&quot;,
   &quot;chrUn_gl000213&quot; &quot;GL000213&quot;, &quot;chrUn_gl000224&quot; &quot;GL000224&quot;, &quot;chrUn_gl000235&quot; &quot;GL000235&quot;,
   &quot;chrUn_gl000246&quot; &quot;GL000246&quot;, &quot;chr6_mcf_hap5&quot; &quot;HSCHR6_MHC_MCF&quot;, &quot;chrUn_gl000214&quot; &quot;GL000214&quot;,
   &quot;chrUn_gl000225&quot; &quot;GL000225&quot;, &quot;chrUn_gl000236&quot; &quot;GL000236&quot;, &quot;chrUn_gl000247&quot; &quot;GL000247&quot;,
   &quot;chr1&quot; &quot;1&quot;, &quot;chr6_cox_hap2&quot; &quot;HSCHR6_MHC_COX&quot;, &quot;chrUn_gl000215&quot; &quot;GL000215&quot;,
   &quot;chrUn_gl000226&quot; &quot;GL000226&quot;, &quot;chrUn_gl000237&quot; &quot;GL000237&quot;, &quot;chrUn_gl000248&quot; &quot;GL000248&quot;,
   &quot;chr2&quot; &quot;2&quot;, &quot;chrUn_gl000216&quot; &quot;GL000216&quot;, &quot;chrUn_gl000227&quot; &quot;GL000227&quot;,
   &quot;chrUn_gl000238&quot; &quot;GL000238&quot;, &quot;chrUn_gl000249&quot; &quot;GL000249&quot;, &quot;chr3&quot; &quot;3&quot;,
   &quot;chrUn_gl000217&quot; &quot;GL000217&quot;, &quot;chrUn_gl000228&quot; &quot;GL000228&quot;, &quot;chrUn_gl000239&quot; &quot;GL000239&quot;,
   &quot;chr9_gl000201_random&quot; &quot;GL000201&quot;, &quot;chr4&quot; &quot;4&quot;, &quot;chr11_gl000202_random&quot; &quot;GL000202&quot;,
   &quot;chrUn_gl000218&quot; &quot;GL000218&quot;, &quot;chrUn_gl000229&quot; &quot;GL000229&quot;, &quot;chr9_gl000200_random&quot; &quot;GL000200&quot;,
   &quot;chr19_gl000209_random&quot; &quot;GL000209&quot;, &quot;chr5&quot; &quot;5&quot;, &quot;chrUn_gl000219&quot; &quot;GL000219&quot;,
   &quot;chr1_gl000192_random&quot; &quot;GL000192&quot;, &quot;chr18_gl000207_random&quot; &quot;GL000207&quot;, &quot;chr6&quot; &quot;6&quot;,
   &quot;chr21_gl000210_random&quot; &quot;GL000210&quot;, &quot;chr17_gl000206_random&quot; &quot;GL000206&quot;,
   &quot;chr9_gl000199_random&quot; &quot;GL000199&quot;, &quot;chr1_gl000191_random&quot; &quot;GL000191&quot;,
   &quot;chr4_gl000194_random&quot; &quot;GL000194&quot;, &quot;chr19_gl000208_random&quot; &quot;GL000208&quot;,
   &quot;chr17_gl000205_random&quot; &quot;GL000205&quot;, &quot;chr7&quot; &quot;7&quot;, &quot;chr9_gl000198_random&quot; &quot;GL000198&quot;,
   &quot;chr8_gl000197_random&quot; &quot;GL000197&quot;, &quot;chr4_gl000193_random&quot; &quot;GL000193&quot;,
   &quot;chr17_gl000204_random&quot; &quot;GL000204&quot;, &quot;chr8&quot; &quot;8&quot;, &quot;chrX&quot; &quot;X&quot;, &quot;chr8_gl000196_random&quot; &quot;GL000196&quot;,
   &quot;chr7_gl000195_random&quot; &quot;GL000195&quot;, &quot;chr20&quot; &quot;20&quot;, &quot;chr9&quot; &quot;9&quot;, &quot;chrY&quot; &quot;Y&quot;,
   &quot;chr17_gl000203_random&quot; &quot;GL000203&quot;, &quot;chr10&quot; &quot;10&quot;, &quot;chr21&quot; &quot;21&quot;, &quot;chr6_dbb_hap3&quot; &quot;HSCHR6_MHC_DBB&quot;,
   &quot;chr11&quot; &quot;11&quot;, &quot;chr22&quot; &quot;22&quot;, &quot;chr6_ssto_hap7&quot; &quot;HSCHR6_MHC_SSTO&quot;, &quot;chr17_ctg5_hap1&quot; &quot;HSCHR17_1&quot;,
   &quot;chr12&quot; &quot;12&quot;, &quot;chr13&quot; &quot;13&quot;, &quot;chr14&quot; &quot;14&quot;, &quot;chr15&quot; &quot;15&quot;, &quot;chr16&quot; &quot;16&quot;,
   &quot;chr6_mann_hap4&quot; &quot;HSCHR6_MHC_MANN&quot;, &quot;chr17&quot; &quot;17&quot;, &quot;chr18&quot; &quot;18&quot;, &quot;chr19&quot; &quot;19&quot;,
   &quot;chr6_qbl_hap6&quot; &quot;HSCHR6_MHC_QBL&quot;, &quot;chr6_apd_hap1&quot; &quot;HSCHR6_MHC_APD&quot;,
   &quot;chrUn_gl000240&quot; &quot;GL000240&quot;, &quot;chrUn_gl000230&quot; &quot;GL000230&quot;, &quot;chrUn_gl000241&quot; &quot;GL000241&quot;,
   &quot;chr4_ctg9_hap1&quot; &quot;HSCHR4_1&quot;, &quot;chrUn_gl000220&quot; &quot;GL000220&quot;, &quot;chrUn_gl000231&quot; &quot;GL000231&quot;,
   &quot;chrUn_gl000242&quot; &quot;GL000242&quot;, &quot;chrUn_gl000221&quot; &quot;GL000221&quot;, &quot;chrUn_gl000232&quot; &quot;GL000232&quot;,
   &quot;chrUn_gl000243&quot; &quot;GL000243&quot;})</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod chr-name-remap :GRCh37
  [_ ref-chrs vcf-chrs]
  (letfn [(maybe-remap-name [x]
            {:post [(contains? ref-chrs %)]}
            (if (contains? ref-chrs x)
              x
              (get hg19-map x)))]
    (zipmap vcf-chrs
            (map maybe-remap-name vcf-chrs))))</pre></td></tr><tr><td class="docs"><h2>Resort and normalize variants</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Build a new variant context with updated sample name and normalized alleles.
  Based on :prep-allele-count in the configuration updates haploid allele calls. This
  normalizes the representation in Mitochondrial and Y chromosomes which are
  haploid but are often represented as diploid with a single call.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- fix-vc
  [sample config orig]
  (letfn [(update-genotype-sample [vc]
            (if (= 1 (count (.getGenotypes vc)))
              (let [g (first (.getGenotypes vc))]
                [(Genotype/modifyName g sample)])
              (.getGenotypes vc)))
          (normalize-allele-calls [g]
            {:pre [(contains? #{1 (:prep-allele-count config)} (count (.getAlleles g)))]}
            (if (= (count (.getAlleles g)) (:prep-allele-count config)) g
                (Genotype/modifyAlleles g (repeat (:prep-allele-count config)
                                                  (first (.getAlleles g))))))]
    (-&gt; orig
        (assoc :vc
          (-&gt; (VariantContextBuilder. (:vc orig))
              (.genotypes (map normalize-allele-calls (update-genotype-sample (:vc orig))))
              .make)))))</pre></td></tr><tr><td class="docs"><p>Check if a variant has a non-informative no-call genotype.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- no-call-genotype?
  [vc]
  (if-not (= 1 (:num-samples vc)) false
          (contains? #{&quot;NO_CALL&quot; &quot;MIXED&quot; &quot;HOM_REF&quot;}
                     (-&gt; vc :genotypes first :type))))</pre></td></tr><tr><td class="docs"><p>Sort stream of line inputs by position.
  Requires loading the entire file into memory during the sort-by phase
  so will not work on massive files. Should be feasible with files
  split by chromosome.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- sort-by-position
  [line-seq]
  (letfn [(add-position [line]
            (let [[chrom start] (take 2 (string/split line #&quot;\t&quot;))]
              [[chrom (Integer/parseInt start)] line]))]
    (-&gt;&gt; line-seq
         (map add-position)
         (sort-by first)
         (map second))))</pre></td></tr><tr><td class="docs"><p>Provide genotype calls for structural variants to a single ref call.
  Structural variants often don't have proper genotype references since
  individual haplotypes are not called. This makes them a single reference
  if not specified or mixed.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- normalize-sv-genotype
  [config sample orig]
  (letfn [(maybe-fix-vc [g alt-allele]
            (if (= &quot;MIXED&quot; (:type g))
              (Genotype/modifyAlleles (:genotype g)
                                      (remove #(.isNoCall %) (:alleles g)))
              (:genotype g)))
          (ref-vc-genotype [gs alt-allele]
            (case (count gs)
              0 [(Genotype. sample [alt-allele])]
              1 [(maybe-fix-vc (first gs) alt-allele)]
              (map :genotype gs)))]
    (if (:prep-sv-genotype config)
      (let [new-gs (ref-vc-genotype (:genotypes orig)
                                   (first (:alt-alleles orig)))]
        (-&gt; orig
            (assoc :vc
                   (-&gt; (VariantContextBuilder. (:vc orig))
                       (.genotypes new-gs)
                       .make))
            (assoc :genotypes (map from-genotype new-gs))))
      orig)))</pre></td></tr><tr><td class="docs"><p>Provide VariantContexts ordered by chromosome and normalized.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- ordered-vc-iter
  [rdr vcf-decoder sample config]
  (-&gt;&gt; rdr
       line-seq
       (#(if (:prep-sort-pos config) (sort-by-position %) %))
       (remove nochange-alt?)
       (map vcf-decoder)
       (map (partial normalize-sv-genotype config sample))
       (remove no-call-genotype?)
       (map (partial fix-vc sample config))
       (map :vc)))</pre></td></tr><tr><td class="docs"><p>Provide fixes to VCF input lines that do not require VariantContext parsing.
  Fixes:
    - INFO lines with empty attributes (starting with ';'), found in
      Complete Genomics VCF files
    - Chromosome renaming.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- fix-vcf-line
  [line ref-info config]
  (letfn [(empty-attribute-info [info]
            (if (.startsWith info &quot;;&quot;)
              (subs info 1)
              info))
          (fix-info [xs]
            (assoc xs 7 (-&gt; (nth xs 7)
                            empty-attribute-info)))
          (fix-chrom [new xs]
            (assoc xs 0 new))]
    (let [parts (string/split line #&quot;\t&quot;)
          cur-chrom (first (vals
                            (chr-name-remap (:prep-org config) ref-info [(first parts)])))]
      {:chrom cur-chrom
       :line (-&gt;&gt; parts
                  (fix-chrom cur-chrom)
                  fix-info
                  (string/join &quot;\t&quot;))})))</pre></td></tr><tr><td class="docs"><p>Split input VCF into separate files by chromosome, returning a map of file names.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- vcf-by-chrom
  [vcf-file ref-file tmp-dir config]
  (letfn [(ref-chr-files [ref-file]
            (into (ordered-map)
                  (map (fn [x] [(.getSequenceName x)
                                (str (fs/file tmp-dir (str &quot;prep&quot; (.getSequenceName x) &quot;.vcf&quot;)))])
                       (-&gt; ref-file get-seq-dict .getSequences))))
          (write-by-chrom [ref-wrtrs line]
            (let [line-info (fix-vcf-line line ref-wrtrs config)]
              (.write (get ref-wrtrs (:chrom line-info))
                      (str (:line line-info) &quot;\n&quot;))))]
    (let [ref-chrs (ref-chr-files ref-file)
          ref-wrtrs (zipmap (keys ref-chrs) (map writer (vals ref-chrs)))]
      (with-open [rdr (reader vcf-file)]
        (-&gt;&gt; rdr
             line-seq
             (drop-while #(.startsWith % &quot;#&quot;))
             (map (partial write-by-chrom ref-wrtrs))
             doall)
        (doseq [x (vals ref-wrtrs)]
          (.close x)))
      ref-chrs)))</pre></td></tr><tr><td class="docs"><h2>Top level functionality to manage inputs and writing.</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Update header information, removing contig and adding sample names.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- update-header
  [sample config]
  (letfn [(clean-metadata [header]
            (apply ordered-set (remove #(= &quot;contig&quot; (.getKey %)) (.getMetaData header))))]
    (fn [_ header]
      (case (count (.getGenotypeSamples header))
        1 (VCFHeader. (clean-metadata header) (ordered-set sample))
        0 (if (:sv-genotype config)
            (VCFHeader. (clean-metadata header) (ordered-set sample))
            (VCFHeader. (clean-metadata header) #{}))
        header))))</pre></td></tr><tr><td class="docs"><p>Write VCF file with correctly ordered and cleaned variants.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- write-prepped-vcf
  [vcf-file out-info ref-file sample config]
  (itx/with-temp-dir [tmp-dir (fs/parent (:out out-info))]
    (let [reader-by-chr (into (ordered-map) (map (fn [[k v]] [k (reader v)])
                                                 (vcf-by-chrom vcf-file ref-file tmp-dir config)))]
      (with-open [vcf-reader (AsciiLineReader. (input-stream vcf-file))]
        (let [vcf-decoder (get-vcf-line-parser vcf-reader)]
          (write-vcf-w-template vcf-file out-info
                                (flatten
                                 (for [rdr (vals reader-by-chr)]
                                   (ordered-vc-iter rdr vcf-decoder sample config)))
                                ref-file
                                :header-update-fn (update-header sample config))))
      (doseq [x (vals reader-by-chr)]
        (.close x)))))</pre></td></tr><tr><td class="docs"><p>Prepare VCF for comparison by normalizing high level attributes
  Assumes by position sorting of variants in the input VCF. Chromosomes do
  not require a specific order, but positions internal to a chromosome do.
  Currently configured for human preparation.</p>
</td><td class="codes"><pre class="brush: clojure">(defn prep-vcf
  [in-vcf-file ref-file sample &amp; {:keys [out-dir out-fname config]
                                  :or {config {}}}]
  (let [config (merge-with #(or %1 %2) config
                           {:prep-org :GRCh37 :prep-allele-count 2
                            :prep-sort-pos false :prep-sv-genotype false})
        base-name (if (nil? out-fname) (itx/remove-zip-ext in-vcf-file) out-fname)
        out-file (itx/add-file-part base-name &quot;prep&quot; out-dir)]
    (when (itx/needs-run? out-file)
      (write-prepped-vcf in-vcf-file {:out out-file} ref-file sample config))
    out-file))</pre></td></tr><tr><td class="docs"><p>Choose a reference genome for a variant file from set of choices.</p>
</td><td class="codes"><pre class="brush: clojure">(defn pick-best-ref
  [vcf refs]
  (letfn [(get-vcf-contig [fname]
            (with-open [rdr (reader fname)]
              (-&gt;&gt; (line-seq rdr)
                   (drop-while #(.startsWith % &quot;#&quot;))
                   first
                   (#(string/split % #&quot;\t&quot;))
                   first)))
          (has-contig? [contig ref-file]
            (contains?
             (set (keys (get-seq-name-map ref-file)))
             contig))]
    (let [test-contig (get-vcf-contig vcf)]
      (first (filter (partial has-contig? test-contig) refs)))))</pre></td></tr><tr><td class="docs"><h2>Remove problem characters</h2>

<p>Handle cleanup for VCF files before feeding to any verifying parser.</p>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Clean VCF file which GATK parsers cannot handle due to illegal characters.
  Fixes:
    - Gap characters (-) found in REF or ALT indels.
    - Filter out call with extra N padding on 5' side of indels.
    - Removes spaces in INFO fields.</p>
</td><td class="codes"><pre class="brush: clojure">(defn clean-problem-vcf
  [in-vcf-file &amp; {:keys [out-dir]}]
  (letfn [(fix-bad-alt-header [x]
            (str &quot;##ALT=&lt;ID&quot; (string/replace-first x &quot;##ALT=Type&quot; &quot;&quot;) &quot;&gt;&quot;))
          (clean-header [x]
            (cond
             (.startsWith x &quot;##ALT=Type=&quot;) (fix-bad-alt-header x)
             :else x))
          (remove-gap [n xs]
            (assoc xs n
                   (string/replace (nth xs n) &quot;-&quot; &quot;&quot;)))
          (is-5pad-n? [xs]
            (let [ref (nth xs 3)
                  alt (nth xs 4)]
              (and (= ref &quot;N&quot;) (.startsWith alt &quot;N&quot;) (&gt; (count alt) 1))))
          (remove-5pad-n [xs]
            (if (is-5pad-n? xs) [] xs))
          (fix-info-spaces [xs]
            (assoc xs 7
                   (string/replace (nth xs 7) &quot; &quot; &quot;_&quot;)))
          (clean-line [line]
            (if (.startsWith line &quot;#&quot;)
              (clean-header line)
              (-&gt;&gt; (string/split line #&quot;\t&quot;)
                   (remove-gap 3)
                   (remove-gap 4)
                   (fix-info-spaces)
                   (remove-5pad-n)
                   (string/join &quot;\t&quot;))))]
    (let [out-file (itx/add-file-part in-vcf-file &quot;preclean&quot; out-dir)]
      (when (itx/needs-run? out-file)
        (with-open [rdr (reader in-vcf-file)
                    wtr (writer out-file)]
          (doall
           (map #(.write wtr (str % &quot;\n&quot;))
                (remove empty? (map clean-line (line-seq rdr)))))))
      out-file)))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.phasing" name="bcbio.variation.phasing"><h1 class="project-name">bcbio.variation.phasing</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Support phased haplotype comparisons between variant calls.
   Compares a phased set of calls versus haploid reference calls.</p>

<p>   The comparison logic is:</p>

<ul>
<li>Group calls into regions based on phasing</li>
<li>For each phase region:
<ul><li>Determine which set of haploid alleles to compare with the reference</li>
<li>With each position in this haploid:
<ul><li>Compare to reference allele</li>
<li>If mismatch and alternate allele matches reference, then phasing error</li>
<li>If mismatch and neither allele matches, then calling error</li></ul></li></ul></li>
</ul>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.phasing
  (:import [org.broadinstitute.sting.utils.interval IntervalUtils IntervalSetRule]
           [org.broadinstitute.sting.utils GenomeLocParser GenomeLoc])
  (:use [bcbio.variation.callable :only [get-bed-source features-in-region]]
        [bcbio.variation.structural :only [prep-itree get-itree-overlap
                                           remove-itree-vc get-itree-all]]
        [bcbio.variation.variantcontext :only [parse-vcf get-vcf-retriever get-vcf-source
                                               write-vcf-w-template]]
        [bcbio.align.ref :only [get-seq-dict]]
        [ordered.map :only [ordered-map]])
  (:require [fs.core :as fs]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><h2>Find phased haplotypes in VCF</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Check for phasing on a single genotype variant context based on:
   - variant has a single allele
   - variant has phasing specified (VCF | notation)
   - variant range overlaps previous variant (overlapping indels)</p>
</td><td class="codes"><pre class="brush: clojure">(defn- is-phased?
  [vc prev-vc bed-s]
  {:pre [(= 1 (:num-samples vc))]}
  (letfn [(safe-same-regions? [[a b]]
            (if (not-any? nil? [a b]) (= a b) true))
          (same-regions? [prev cur]
            (if (or (nil? bed-s) (instance? java.io.StringReader bed-s))
              true
              (safe-same-regions?
               (map #((juxt :chr :start :end)
                      (first (features-in-region bed-s (:chr %) (:start %) (:end %))))
                    [prev cur]))))]
    (let [g (-&gt; vc :genotypes first)]
      (and (= (:chr vc) (:chr prev-vc))
           (same-regions? prev-vc vc)
           (or (= 1 (count (:alleles g)))
               (.isPhased (:genotype g))
               (&lt;= (:start vc) (:end prev-vc)))))))</pre></td></tr><tr><td class="docs"><p>Separate phased haplotypes provided in diploid input genome.
   We split at each phase break, returning a lazy list of variant
   contexts grouped into phases.</p>
</td><td class="codes"><pre class="brush: clojure">(defn parse-phased-haplotypes
  [vcf-source &amp; {:keys [bed-source]}]
  (let [prev (atom nil)]
    (letfn [(split-at-phased [vc]
              (let [continue-phase (or (nil? @prev)
                                       (is-phased? vc @prev bed-source))]
                (reset! prev vc)
                continue-phase))]
      (partition-by split-at-phased (parse-vcf vcf-source)))))</pre></td></tr><tr><td class="docs"><h2>Compare phased variants</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Retrieve the item with the highest count in the supplied list.
  We break ties by sorting by the actual list items</p>
</td><td class="codes"><pre class="brush: clojure">(defn highest-count
  [xs]
  (-&gt;&gt; (frequencies xs)
       (sort-by val &gt;)
       (partition-by second)
       first
       (sort-by first)
       ffirst))</pre></td></tr><tr><td class="docs"><p>Convenience function to get alleles for a single genotype variant context.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-alleles
  [vc]
  {:pre [(= 1 (:num-samples vc))]}
  (-&gt; vc :genotypes first :alleles))</pre></td></tr><tr><td class="docs"><p>Determine allele index where the variant context matches haploid reference.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- matching-allele
  [vc ref-vcs]
  {:pre [(every? #(= 1 (:num-samples %)) ref-vcs)
         (= 1 (:num-samples vc))]}
  (if (empty? ref-vcs)
    (.indexOf (get-alleles vc) (:ref-allele vc))
    (highest-count
     (remove neg?
             (map #(.indexOf (get-alleles vc) (-&gt; % get-alleles first)) ref-vcs)))))</pre></td></tr><tr><td class="docs"><p>Compare the haploid allele of a variant against the expected call.</p>
</td><td class="codes"><pre class="brush: clojure">(defn cmp-allele-to-expected
  [vc e-vc i]
  (letfn [(is-ref-allele? [x]
            (apply = (map #(.getBaseString (% x)) [:cmp :ref])))
          (get-cmp-allele [i x]
            {:ref (:ref-allele x)
             :cmp (nth (get-alleles x) i)})
          (get-all-alleles [x]
            (map #(get-cmp-allele % x) (range (count (get-alleles x)))))]
    (let [e-allele (when-not (nil? e-vc)
                     (get-cmp-allele 0 e-vc))
          call-hap (when-not (or (nil? i) (nil? vc) (neg? i))
                     (get-cmp-allele i vc))]
      (cond
       (nil? call-hap) :discordant
       (and (is-ref-allele? call-hap)
            (or (nil? e-allele)
                (= e-allele call-hap))) :ref-concordant
       (nil? e-allele) :discordant
       (= e-allele call-hap) :concordant
       (some (partial = e-allele) (get-all-alleles vc)) :phasing-error
       :else :discordant))))</pre></td></tr><tr><td class="docs"><p>Retrieve the type of a set of variants involved in a comparison.</p>

<ul>
<li><code>:indel</code> -- insertions or deletions of more than 1bp</li>
<li><code>:snp</code> -- Single nucleotide changes or single basepair changes</li>
<li><code>:unknown</code> -- Other classs of variations (structural)</li>
</ul>
</td><td class="codes"><pre class="brush: clojure">(defn get-variant-type
  [vcs]
  (letfn [(is-indel? [x]
            (= &quot;INDEL&quot; (:type x)))
          (is-multi-indel? [x]
            (and (is-indel? x)
                 (not-every? #(contains? #{0 1} %)
                             (map #(-&gt; % .getBaseString count) (cons (:ref-allele x)
                                                                     (:alt-alleles x))))))
          (is-snp? [x]
            (= &quot;SNP&quot; (:type x)))]
    (cond
     (some is-multi-indel? vcs) :indel
     (some is-indel? vcs) :snp
     (every? is-snp? vcs) :snp
     :else :unknown)))</pre></td></tr><tr><td class="docs"><p>Determine if the variant has a non-matching heterozygous alternative allele.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- nomatch-het-alt?
  [vc e-vc]
  {:pre [(not (nil? vc))]}
  (let [match-allele-i (matching-allele vc (if (nil? e-vc) [] [e-vc]))
        no-match-alleles (remove nil? (map-indexed
                                       (fn [i x] (if-not (= i match-allele-i) x))
                                       (get-alleles vc)))]
    (and (= &quot;HET&quot; (-&gt; vc :genotypes first :type))
         (not-every? #(.isReference %) no-match-alleles))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- deleted-bases
  [vc]
  (letfn [(is-deletion? [vc]
            (and (= (:type vc) &quot;INDEL&quot;)
                 (pos? (.length (:ref-allele vc)))))]
    (if (is-deletion? vc)
      (map vector (repeat (:chr vc)) (range (:start vc) (inc (:end vc))))
      [])))</pre></td></tr><tr><td class="docs"><p>Provide metrics for comparison of haploid expected alleles to variant calls.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- comparison-metrics
  [cmp-itree i e-vc]
  (let [cmp-vc (-&gt;&gt; (get-itree-overlap cmp-itree (:chr e-vc) (:start e-vc) (:end e-vc))
                    (filter #(= (:start %) (:start e-vc)))
                    first)]
    {:comparison (cmp-allele-to-expected cmp-vc e-vc i)
     :variant-type (get-variant-type [cmp-vc e-vc])
     :nomatch-het-alt (when-not (nil? cmp-vc) (nomatch-het-alt? cmp-vc e-vc))
     :start (if (nil? cmp-vc) (:start e-vc) (:start cmp-vc))
     :end (:end cmp-vc)
     :end-ref (:end e-vc)
     :deleted (deleted-bases e-vc)
     :vc (:vc cmp-vc)
     :ref-vc (:vc e-vc)}))</pre></td></tr><tr><td class="docs"><p>Provide scoring metrics for a phased region against expected haplotype variants.
    - Fetch all expected variants in the phased region.
    - Iterate over expected variants comparing to the called variants:
       - Keep IntervalTree of called variants, removing variants as evaluated.
       - Keep coordinates of expected deletion regions.
    - Add discordant variants for extra calls not in expected variants, avoiding
      variants in deleted regions.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- score-phased-region
  [expect-fetch vcs]
  (let [vc-itree (atom (prep-itree vcs :start :end))]
    (letfn [(get-ref-vcs [x]
              (expect-fetch (:chr x) (:start x) (:end x)))
            (ref-match-allele [x]
              (matching-allele x (expect-fetch (:chr x) (:start x) (:end x))))
            (get-regional-expected-vcs
              [itree]
              {:pre [(= 1 (count (keys itree)))]}
              (let [[chr tree] (first itree)]
                (let [start (-&gt; tree .min .getStart)]
                  (-&gt;&gt; (expect-fetch chr start (dec (-&gt; tree .max .getEnd)))
                       (remove #(&lt; (:start %) start))
                       (sort-by :start)))))
            (compare-and-update [cmp-i info e-vc]
              (let [cmp (comparison-metrics @vc-itree cmp-i e-vc)]
                (reset! vc-itree (remove-itree-vc @vc-itree (:chr e-vc)
                                                  (:start cmp) (:end cmp)))
                (-&gt; info
                    (assoc :out (cons cmp (:out info)))
                    (assoc :deleted (concat (:deleted info) (:deleted cmp))))))
            (in-deleted-region? [regions vc]
              (contains? regions [(:chr vc) (:start vc)]))
            (add-unmapped-cmps [cmp-i info]
              (concat (:out info)
                      (map (fn [vc] {:comparison (cmp-allele-to-expected vc nil cmp-i)
                                     :variant-type (get-variant-type [vc])
                                     :nomatch-het-alt (nomatch-het-alt? vc nil)
                                     :start (:start vc)
                                     :vc (:vc vc)
                                     :ref-vc nil})
                           (remove (partial in-deleted-region? (set (:deleted info)))
                                   (get-itree-all @vc-itree)))))]
      (let [cmp-allele-i (highest-count (remove #(or (nil? %) (neg? %))
                                                (map ref-match-allele vcs)))]
        (-&gt;&gt; (reduce (partial compare-and-update cmp-allele-i)
                     {:deleted [] :out []}
                     (get-regional-expected-vcs @vc-itree))
             (add-unmapped-cmps cmp-allele-i)
             (sort-by :start))))))</pre></td></tr><tr><td class="docs"><p>Score a called VCF against expected haploid variants based on phased regions.
  Partitions phased regions into blocks of two concurrent regions. For each block:
   - Evaluate second region with standard scoring: expected to called
   - Collect expected variants in the intervening region between phased blocks,
     these are missing in the called and reported as errors.</p>
</td><td class="codes"><pre class="brush: clojure">(defn score-phased-calls
  [call-vcf-s expect-vcf-s &amp; {:keys [bed-source]}]
  (let [expect-retriever (get-vcf-retriever expect-vcf-s)
        prev (atom nil)]
    (letfn [(get-intervene-expect [region1 region2]
              (let [vc1 (last region1)
                    vc2 (first region2)
                    filter-end (if (nil? vc1) (dec (:start vc2)) (:end vc1))
                    vcs (cond
                         (nil? vc1)
                         (expect-retriever (:chr vc2) 0 (dec (:start vc2)))
                         (not= (:chr vc1) (:chr vc2))
                         (concat (expect-retriever (:chr vc1) (inc (:end vc1)) 1e10)
                                 (expect-retriever (:chr vc2) 0 (dec (:start vc2))))
                         :else
                         (expect-retriever (:chr vc1) (inc (:end vc1))
                                           (dec (:start vc2))))]
                (-&gt;&gt; vcs
                     (remove #(&lt; (:start %) filter-end))
                     (map (fn [x] {:comparison :discordant
                                   :variant-type (get-variant-type [x])
                                   :nomatch-het-alt false
                                   :start (:start x)
                                   :vc nil
                                   :ref-vc (:vc x)}))
                     (sort-by :start))))
            (score-phased-and-intervene [region]
              (let [out (concat (get-intervene-expect @prev region)
                                (score-phased-region expect-retriever region))]
                (reset! prev region)
                out))]
      (map score-phased-and-intervene (parse-phased-haplotypes call-vcf-s
                                                               :bed-source bed-source)))))</pre></td></tr><tr><td class="docs"><h2>Summarize phased comparisons</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Write concordant and discordant variants to VCF output files.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- write-concordance-output
  [vc-info to-capture sample-name base-info other-info out-dir ref]
  (let [base-dir (if (nil? out-dir) (fs/parent (:file base-info)) out-dir)
        gen-file-name (fn [x] (str (fs/file base-dir (format &quot;%s-%s-%s-%s.vcf&quot;
                                                             sample-name (:name base-info)
                                                             (:name other-info) (name x)))))
        out-files (apply ordered-map (flatten (map (juxt identity gen-file-name)
                                                   to-capture)))]
    (if-not (fs/exists? base-dir)
      (fs/mkdirs base-dir))
    (when (itx/needs-run? (vals out-files))
      (write-vcf-w-template (:file base-info) out-files
                            (filter #(contains? (set to-capture) (first %))
                                    (map (juxt :comparison :vc)
                                         (flatten vc-info)))
                            ref))
    out-files))</pre></td></tr><tr><td class="docs"><p>Provide counts for comparison: entire region plus user specified regions</p>
</td><td class="codes"><pre class="brush: clojure">(defn count-comparison-bases
  [total-bed call-bed ref-file]
  (letfn [(feature-size [x]
            (cond
             (instance? GenomeLoc x) (- (.getStop x) (dec (.getStart x)))
             :else (- (.getEnd x) (dec (.getStart x)))))
          (count-bases [xs]
            (apply + (map feature-size xs)))
          (genome-loc-list [x]
            (let [parser (GenomeLocParser. (get-seq-dict ref-file))]
              (with-open [bed-source (get-bed-source x ref-file)]
                (-&gt;&gt; bed-source
                     .iterator
                     (map #(.createGenomeLoc parser %))
                     doall))))
          (merge-intervals [x y]
            (IntervalUtils/mergeListsBySetOperator (genome-loc-list x)
                                                   (genome-loc-list y)
                                                   IntervalSetRule/INTERSECTION))]
    (with-open [bed-source (get-bed-source total-bed ref-file)]
      (let [total (count-bases (.iterator bed-source))
            compared (if (or (nil? call-bed) (= total-bed call-bed)) total
                         (count-bases (merge-intervals total-bed call-bed)))]
        {:percent (* 100.0 (/ compared total))
         :compared compared
         :total total}))))</pre></td></tr><tr><td class="docs"><p>Collect summary metrics for concordant/discordant and phasing calls</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-phasing-metrics
  [vc-info exp-interval-file call-interval-file ref-file]
  (letfn [(count-nomatch-het-alt [xs]
            (count (filter #(and (contains? #{:concordant :ref-concordant} (:comparison %))
                                 (:nomatch-het-alt %))
                           (flatten vc-info))))
          (blank-count-dict []
            {:snp 0 :indel 0})
          (add-current-count [coll x]
            (let [cur-val (map x [:comparison :variant-type])]
              (assoc-in coll cur-val (inc (get-in coll cur-val)))))]
    (reduce add-current-count
            {:haplotype-blocks (count vc-info)
             :total-bases (count-comparison-bases exp-interval-file call-interval-file ref-file)
             :nonmatch-het-alt (count-nomatch-het-alt vc-info)
             :concordant (blank-count-dict)
             :ref-concordant (blank-count-dict)
             :discordant (blank-count-dict)
             :phasing-error (blank-count-dict)}
            (flatten vc-info))))</pre></td></tr><tr><td class="docs"><h2>Entry point for phased haploid VCF comparisons</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Compare two VCF files including phasing with a haplotype reference
  Handle grading special case as well as standard comparisons.</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti compare-two-vcf-phased
  (fn [_ exp _] (keyword (get exp :approach &quot;compare&quot;))))</pre></td></tr><tr><td class="docs"><p>Convert comparisons into ready to write keywords for grading.
  Deals with discordant comparisons where the competition call
  is missing.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- convert-cmps-to-grade
  [cmps]
  (letfn [(check-missing-discordant [x]
            (if (and (= (:comparison x) :discordant)
                     (nil? (:vc x)))
              (-&gt; x
                  (assoc :comparison :discordant-missing)
                  (assoc :vc (:ref-vc x)))
              x))]
    (map check-missing-discordant (flatten cmps))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod compare-two-vcf-phased :grade
  [phased-calls exp config]
  {:pre [(= 1 (count (get phased-calls true)))
         (= 1 (count (get phased-calls false)))]}
  (let [ref (first (get phased-calls true))
        call (first (get phased-calls false))]
    (with-open [ref-vcf-s (get-vcf-source (:file ref) (:ref exp))
                call-vcf-s (get-vcf-source (:file call) (:ref exp))
                bed-s (if-let [f (get call :intervals (:intervals exp))]
                        (get-bed-source f (:ref exp)) (java.io.StringReader. &quot;&quot;))]
      (let [compared-calls (score-phased-calls call-vcf-s ref-vcf-s :bed-source bed-s)]
        {:c-files (write-concordance-output (convert-cmps-to-grade compared-calls)
                                            [:concordant :discordant
                                             :discordant-missing :phasing-error]
                                            (:sample exp) call ref
                                            (get-in config [:dir :out]) (:ref exp))
         :metrics (get-phasing-metrics compared-calls (:intervals exp)
                                       (:intervals call) (:ref exp))
         :c1 call :c2 ref :sample (:sample exp) :exp exp :dir (:dir config)}))))</pre></td></tr><tr><td class="docs"><p>Convert stream of variant context haploid comparison to standard,
  keyed by :concordant and :discordant-name keywords.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- convert-cmps-to-compare
  [name1 name2 cmps]
  (letfn [(update-keyword [coll x]
            (let [ref-x (-&gt; x
                            (assoc :vc (:ref-vc x))
                            (dissoc :ref-vc))
                  [dis-kw1 dis-kw2] (map #(keyword (format &quot;%s-discordant&quot; %)) [name1 name2])]
              (case (:comparison x)
                :concordant (conj coll ref-x)
                (:discordant :phasing-error) (-&gt; coll
                                                 (conj (assoc x :comparison dis-kw2))
                                                 (conj (assoc ref-x :comparison dis-kw1)))
                coll)))
          (update-keyword-hapblock [xs]
            (remove #(or (nil? %) (nil? (:vc %)))
                    (reduce update-keyword [] xs)))]
    (map update-keyword-hapblock cmps)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod compare-two-vcf-phased :compare
  [phased-calls exp config]
  {:pre [(= 2 (count (flatten (vals phased-calls))))
         (pos? (count (get phased-calls true)))]}
  (let [cmp1 (first (get phased-calls true))
        cmp2 (if-let [nophased (get phased-calls false)]
               (first nophased)
               (second (get phased-calls true)))
        to-capture (concat [:concordant]
                           (map #(keyword (format &quot;%s-discordant&quot; (:name %)))
                                [cmp1 cmp2]))]
    (with-open [vcf1-s (get-vcf-source (:file cmp1) (:ref exp))
                vcf2-s (get-vcf-source (:file cmp2) (:ref exp))
                bed-s (if-let [f (get cmp2 :intervals (:intervals exp))]
                        (get-bed-source f (:ref exp)) (java.io.StringReader. &quot;&quot;))]
      {:c-files (-&gt; (convert-cmps-to-compare (:name cmp1) (:name cmp2)
                                             (score-phased-calls vcf2-s vcf1-s
                                                                 :bed-source bed-s))
                    (write-concordance-output to-capture (:sample exp) cmp1 cmp2
                                              (get-in config [:dir :out]) (:ref exp)))
         :c1 cmp1 :c2 cmp2 :sample (:sample exp) :exp exp :dir (:dir config)})))</pre></td></tr><tr><td class="docs"><h2>Utility functions</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Is the provided VCF file a haploid genome (one genotype or all homozygous).
  Samples the first set of variants, checking for haploid calls.</p>
</td><td class="codes"><pre class="brush: clojure">(defn is-haploid?
  [vcf-file ref-file]
  (let [sample-size 1000]
    (letfn [(is-vc-haploid? [vc]
              (when-not (= 0 (:num-samples vc))
                (or (= 1 (apply max (map #(count (:alleles %)) (:genotypes vc))))
                    (contains? #{&quot;HOM_REF&quot; &quot;HOM_VAR&quot;} (:type vc)))))]
      (with-open [vcf-source (get-vcf-source vcf-file ref-file)]
        (let [vcf-iter (parse-vcf vcf-source)]
          (when-not (empty? vcf-iter)
            (every? is-vc-haploid? (take sample-size vcf-iter))))))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.recall" name="bcbio.variation.recall"><h1 class="project-name">bcbio.variation.recall</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Recall batched sets of variants containing no-call regions.
  Combined variant calls from batches contain regions called in
  some samples but not others. The approach:
    - Split sample into called and no-call variants
    - Re-call the no-call variants using the UnifiedGenotyper
    - Merge previously called and re-called into final set.
  http://www.broadinstitute.org/gsa/wiki/index.php/Merging<em>batched</em>call_sets</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.recall
  (:import [org.broadinstitute.sting.utils.variantcontext
            Genotype VariantContextBuilder GenotypesContext]
           [org.broadinstitute.sting.utils.codecs.vcf VCFHeader])
  (:use [clojure.java.io]
        [ordered.map :only [ordered-map]]
        [ordered.set :only [ordered-set]]
        [bcbio.variation.callable :only [get-callable-checker is-callable?]]
        [bcbio.variation.combine :only [combine-variants multiple-samples?]]
        [bcbio.variation.config :only [load-config]]
        [bcbio.variation.variantcontext :only [parse-vcf write-vcf-w-template get-vcf-source
                                               get-vcf-header]])
  (:require [clojure.string :as string]
            [fs.core :as fs]
            [bcbio.run.itx :as itx]
            [bcbio.run.broad :as broad]))</pre></td></tr><tr><td class="docs"><p>Provide split VCFs of call and no-call variants for the given sample.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- split-nocalls
  [in-vcf sample ref out-dir]
  (letfn [(sample-only-vc [vc]
            (-&gt; (VariantContextBuilder. vc)
                (.genotypes (GenotypesContext/create
                             (into-array [(-&gt; vc .getGenotypes (.get sample))])))
                (.attributes {})
                (.make)))
          (split-nocall-vc [vc]
            (when (empty? (:filters vc))
              (let [cur-vc (sample-only-vc (:vc vc))]
                [(if (.isNoCall (-&gt; cur-vc .getGenotypes (.get sample))) :nocall :called)
                 cur-vc])))
          (set-header-to-sample [sample _ header]
            (VCFHeader. (.getMetaData header) (ordered-set sample)))]
    (let [sample-str (if (.contains in-vcf sample) &quot;&quot; (str sample &quot;-&quot;))
          out {:called (itx/add-file-part in-vcf (str sample-str &quot;called&quot;) out-dir)
               :nocall (itx/add-file-part in-vcf (str sample-str &quot;nocall&quot;) out-dir)}]
      (when (itx/needs-run? (vals out))
        (with-open [in-vcf-s (get-vcf-source in-vcf ref)]
          (write-vcf-w-template in-vcf out
                                (remove nil? (map split-nocall-vc (parse-vcf in-vcf-s)))
                                ref
                                :header-update-fn (partial set-header-to-sample sample))))
      out)))</pre></td></tr><tr><td class="docs"><p>Do UnifiedGenotyper calling at known variation alleles.</p>
</td><td class="codes"><pre class="brush: clojure">(defn call-at-known-alleles
  [site-vcf align-bam ref &amp; {:keys [cores]}]
  (let [file-info {:out-vcf (itx/add-file-part site-vcf &quot;wrefs&quot;)}
        annotations [&quot;DepthPerAlleleBySample&quot;]
        args (concat [&quot;-R&quot; ref
                      &quot;-o&quot; :out-vcf
                      &quot;-I&quot; align-bam
                      &quot;--alleles&quot; site-vcf
                      &quot;-L&quot; site-vcf
                      &quot;--genotyping_mode&quot; &quot;GENOTYPE_GIVEN_ALLELES&quot;
                      &quot;--output_mode&quot; &quot;EMIT_ALL_SITES&quot;
                      &quot;-stand_call_conf&quot; &quot;0.0&quot;
                      &quot;--genotype_likelihoods_model&quot; &quot;BOTH&quot;]
                     (if cores [&quot;-nt&quot; (str cores)] [])
                     (reduce #(concat %1 [&quot;-A&quot; %2]) [] annotations))]
    (broad/index-bam align-bam)
    (broad/run-gatk &quot;UnifiedGenotyper&quot; args file-info {:out [:out-vcf]})
    (:out-vcf file-info)))</pre></td></tr><tr><td class="docs"><p>Recall variations at no-calls in a sample using UnifiedGenotyper.</p>
</td><td class="codes"><pre class="brush: clojure">(defn recall-nocalls
  [in-vcf sample align-bam ref &amp; {:keys [out-dir cores]}]
  (let [sample-str (if (.contains in-vcf sample) &quot;&quot; (str sample &quot;-&quot;))
        out-file (itx/add-file-part in-vcf (str sample-str &quot;wrefs&quot;) out-dir)]
    (when (itx/needs-run? out-file)
      (let [{:keys [called nocall]} (split-nocalls in-vcf sample ref out-dir)
            ready-nocall (call-at-known-alleles nocall align-bam ref :cores cores)
            combine-out (combine-variants [called ready-nocall] ref :merge-type :full
                                          :quiet-out? true)]
        (fs/rename combine-out out-file)
        (fs/rename (str combine-out &quot;.idx&quot;) (str out-file &quot;.idx&quot;))))
    out-file))</pre></td></tr><tr><td class="docs"><p>Create merged VCF files with no-call/ref-calls for each of the inputs.
  Works at a higher level than <code>recall-nocalls</code> and does the work of
  preparing a set of all merged variants, then re-calling at non-missing positions.</p>
</td><td class="codes"><pre class="brush: clojure">(defn create-merged
  [vcfs align-bams vcf-configs ref &amp; {:keys [out-dir intervals cores]}]
  (letfn [(merge-vcf [vcf sample all-vcf align-bam ref]
            (let [ready-vcf (combine-variants [vcf all-vcf] ref
                                              :merge-type :full :intervals intervals
                                              :out-dir out-dir :check-ploidy? false)]
              (recall-nocalls ready-vcf sample align-bam ref :out-dir out-dir
                              :cores cores)))]
    (let [merged (combine-variants vcfs ref :merge-type :minimal :intervals intervals
                                   :out-dir out-dir :check-ploidy? false)]
      (map (fn [[v b vcf-config]]
             (if (and (get vcf-config :refcalls false)
                      (not (nil? b)))
               (merge-vcf v (:name vcf-config) merged b ref)
               v))
           (map vector vcfs align-bams vcf-configs)))))</pre></td></tr><tr><td class="docs"><p>Split VCF line into shared attributes and sample specific genotypes.
  By default removes shared attributes which are no longer valid for split file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- split-vcf-sample-line
  ([line remove-info-attrs?]
     (let [parts (string/split line #&quot;\t&quot;)
           orig-shared (vec (take 9 parts))
           shared (if remove-info-attrs? (assoc orig-shared 7 &quot;.&quot;) orig-shared)]
       (for [s (drop 9 parts)] (conj shared s))))
  ([line]
     (split-vcf-sample-line line true)))</pre></td></tr><tr><td class="docs"><p>Split a multi-sample file to individual samples: writing the header.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- split-vcf-to-samples-header
  [vcf-iter out-files]
  (letfn [(not-chrom? [l] (not (.startsWith l &quot;#CHROM&quot;)))]
    (let [std-header (string/join &quot;\n&quot; (take-while not-chrom? vcf-iter))]
      (doseq [[i xs] (map-indexed vector (-&gt; (drop-while not-chrom? vcf-iter)
                                             first
                                             (split-vcf-sample-line false)))]
        (spit (get out-files i)
              (str std-header &quot;\n&quot; (string/join &quot;\t&quot; xs) &quot;\n&quot;))))))</pre></td></tr><tr><td class="docs"><p>Split multi-sample file to individual samples: variant lines
  Avoids opening all output handles, instead writing to individual files.
  Blocks writes into groups to reduce opening file penalties.</p>
</td><td class="codes"><pre class="brush: clojure">(defn split-vcf-to-samples-variants
  [vcf-iter out-files]
  (let [block-size 1000]
    (doseq [lines (partition-all block-size (drop-while #(.startsWith % &quot;#&quot;) vcf-iter))]
      (let [sample-lines (reduce (fn [coll l]
                                   (reduce (fn [inner-coll [i xs]]
                                             (assoc inner-coll i (conj (get inner-coll i [])
                                                                       (string/join &quot;\t&quot; xs))))
                                           coll (map-indexed vector (split-vcf-sample-line l))))
                                 {} lines)]
        (doseq [[i xs] sample-lines]
          (spit (get out-files i)
                (str (string/join &quot;\n&quot; xs) &quot;\n&quot;)
                :append true))))))</pre></td></tr><tr><td class="docs"><p>Create individual sample variant files from input VCF.</p>
</td><td class="codes"><pre class="brush: clojure">(defn split-vcf-to-samples
  [vcf-file &amp; {:keys [out-dir]}]
  (let [samples (-&gt; vcf-file get-vcf-header .getGenotypeSamples)
        out-files (into (ordered-map) (map (fn [x] [x (itx/add-file-part vcf-file x out-dir)])
                                           samples))]
    (when (itx/needs-run? (vals out-files))
      (with-open [rdr (reader vcf-file)]
        (itx/with-tx-files [tx-out-files out-files (keys out-files) []]
          (let [line-iter (line-seq rdr)]
            (split-vcf-to-samples-header line-iter (vec (vals tx-out-files)))
            (split-vcf-to-samples-variants line-iter (vec (vals tx-out-files)))))))
    out-files))</pre></td></tr><tr><td class="docs"><p>Split multiple sample inputs into individual samples before processing.
  This helps reduce the load on selecting from huge multi-sample files.
  Returns a list of configured calls with multi-samples set to individually
  separated input files.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- split-config-multi
  [calls ref out-dir]
  (let [multi-files (filter multiple-samples? (set (map :file calls)))
        cur-samples (set (map :name calls))]
    (vals
     (reduce (fn [coll vcf]
               (reduce (fn [inner-coll [sample split-vcf]]
                         (if (contains? cur-samples sample)
                           (assoc-in inner-coll [sample :file] split-vcf)
                           inner-coll))
                       coll (split-vcf-to-samples vcf :out-dir out-dir)))
             (into (ordered-map) (map (fn [x] [(:name x) x]) calls))
             multi-files))))</pre></td></tr><tr><td class="docs"><p>Provide a cleaned VCF file without sample genotype information.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- remove-sample-info
  [in-vcf out-dir]
  (letfn [(split-variant-line [line]
            (-&gt;&gt; (string/split line #&quot;\t&quot;)
                 (take 8)
                 (string/join &quot;\t&quot;)))
          (process-line [line]
            (cond
             (.startsWith line &quot;##fileformat&quot;) line
             (.startsWith line &quot;##INFO&quot;) line
             (.startsWith line &quot;#CHROM&quot;) (split-variant-line line)
             (.startsWith line &quot;#&quot;) nil
             :else (split-variant-line line)))]
    (let [out-file (itx/add-file-part in-vcf &quot;nosamples&quot; out-dir)]
      (when (itx/needs-run? out-file)
        (with-open [rdr (reader in-vcf)
                    wtr (writer out-file)]
          (doseq [line (map process-line (line-seq rdr))]
            (when line
              (.write wtr (str line &quot;\n&quot;))))))
      out-file)))</pre></td></tr><tr><td class="docs"><p>Combine large numbers of variants via batches to avoid memory issues.</p>
</td><td class="codes"><pre class="brush: clojure">(defn batch-combine-variants
  [vcfs ref &amp; {:keys [merge-type out-dir intervals unsafe name-map
                      base-ext check-ploidy? quiet-out? batch-size]
               :or {merge-type :unique
                    unsafe false
                    name-map {}
                    check-ploidy? true
                    batch-size 100}}]
  (letfn [(combine-w-args [xs]
            (combine-variants xs ref :merge-type merge-type :out-dir out-dir
                              :intervals intervals :unsafe unsafe :name-map name-map
                              :base-ext base-ext :check-ploidy? check-ploidy?
                              :quiet-out? quiet-out?))]
    (let [batch-vcfs (map combine-w-args (partition-all batch-size vcfs))]
      (combine-w-args batch-vcfs))))</pre></td></tr><tr><td class="docs"><p>Perform recalling on all specific inputs in an experiment</p>
</td><td class="codes"><pre class="brush: clojure">(defn- do-recall-exp
  [exp out-dir config]
  (let [recall-vcfs (map (fn [call]
                           (recall-nocalls (:file call) (:name call) (:align call)
                                           (:ref exp) :out-dir out-dir
                                           :cores (get-in config [:resources :cores])))
                         (split-config-multi (:calls exp) (:ref exp) out-dir))
        clean-multi (map #(remove-sample-info % out-dir)
                         (filter multiple-samples? (set (map :file (:calls exp)))))]
    (println (count recall-vcfs))
    (batch-combine-variants (concat clean-multi recall-vcfs) (:ref exp) :merge-type :full
                            :quiet-out? true :check-ploidy? false)))</pre></td></tr><tr><td class="docs"><p>Convert no-calls into callable reference and real no-calls.
  Older functionality to re-call as reference when region is callable.
  Prefer <code>recall-nocalls</code></p>
</td><td class="codes"><pre class="brush: clojure">(defn convert-no-calls-w-callability
  [in-vcf align-bam ref &amp; {:keys [out-dir intervals num-alleles]}]
  (letfn [(ref-genotype [g vc]
            (doto (-&gt; vc :vc .getGenotypes GenotypesContext/copy)
              (.replace
               (Genotype/modifyAlleles (:genotype g)
                                       (repeat (if (nil? num-alleles)
                                                 (count (:alleles g))
                                                 num-alleles)
                                               (:ref-allele vc))))))
          (maybe-callable-vc [vc call-source]
            {:pre (= 1 (:num-samples vc))}
            (let [g (-&gt; vc :genotypes first)]
              (if (.isNoCall (-&gt; g :alleles first))
                (if (is-callable? call-source (:chr vc) (:start vc) (:end vc))
                  (-&gt; (VariantContextBuilder. (:vc vc))
                      (.genotypes (ref-genotype g vc))
                      (.make))
                  (-&gt; (VariantContextBuilder. (:vc vc))
                      (.filters #{&quot;NotCallable&quot;})
                      (.make)))
                (:vc vc))))
          (convert-vcs [vcf-source call-source]
            (for [vc (parse-vcf vcf-source)]
              [:out (maybe-callable-vc vc call-source)]))]
    (let [out-file (itx/add-file-part in-vcf &quot;wrefs&quot;)]
      (when (itx/needs-run? out-file)
        (with-open [in-vcf-s (get-vcf-source in-vcf ref)
                    call-source (get-callable-checker align-bam ref :out-dir out-dir
                                                      :intervals intervals)]
          (write-vcf-w-template in-vcf {:out out-file}
                                (convert-vcs in-vcf-s call-source) ref)))
      out-file)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -main [config-file]
  (let [config (load-config config-file)
        out-dir (get-in config [:dir :out])]
    (doseq [exp (:experiments config)]
      (do-recall-exp exp out-dir config))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.report" name="bcbio.variation.report"><h1 class="project-name">bcbio.variation.report</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Parse and provide detailed information from GATKReport outputs.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.report
  (:import [org.broadinstitute.sting.gatk.report GATKReport])
  (:use [ordered.map :only [ordered-map]]
        [clojure.math.combinatorics :only [cartesian-product]]
        [bcbio.variation.variantcontext :only [parse-vcf get-vcf-retriever
                                               get-vcf-source]]
        [bcbio.variation.callable :only [get-callable-checker is-callable?]]
        [bcbio.variation.evaluate :only [organize-gatk-report-table]]
        [bcbio.variation.metrics :only [ml-on-vcf-metrics passes-filter? nonref-passes-filter?]])
  (:require [doric.core :as doric]
            [clojure.string :as string]))</pre></td></tr><tr><td class="docs"><p>Retrieve high level concordance metrics from GATK VariantEval report.</p>
</td><td class="codes"><pre class="brush: clojure">(defn concordance-report-metrics
  [sample in-file]
  (letfn [(sample-in-row? [x]
            (and (= (:Sample x) sample)
                 (= (:Novelty x) &quot;all&quot;)
                 (= (:Filter x) &quot;called&quot;)))]
    (-&gt;&gt; (organize-gatk-report-table in-file &quot;GenotypeConcordance&quot; sample-in-row?)
         (map (fn [x] [(keyword (:variable x)) (:value x)]))
         (into {}))))</pre></td></tr><tr><td class="docs"><p>Count variants that pass an optional checker function.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- count-variants
  [f ref-file check?]
  (with-open [vcf-source (get-vcf-source f ref-file)]
    (count (filter check? (parse-vcf vcf-source)))))</pre></td></tr><tr><td class="docs"><p>Provide metrics to distinguish types of discordance in a comparison.
  These identify variants which differ due to being missing in one variant
  call versus calls present in both with different genotypes.</p>
</td><td class="codes"><pre class="brush: clojure">(defn discordance-metrics
  [file1 file2 ref-file]
  (with-open [file2-source (get-vcf-source file2 ref-file)
              file1-source (get-vcf-source file1 ref-file)]
    (let [vrn-fetch (get-vcf-retriever file2-source)]
      (reduce (fn [coll vc]
                (let [other-vcs (vrn-fetch (:chr vc) (:start vc) (:end vc))
                      vc-type (if-not (empty? other-vcs) :total :unique)]
                  (assoc coll vc-type (inc (get coll vc-type)))))
              {:total 0 :unique 0}
              (parse-vcf file1-source)))))</pre></td></tr><tr><td class="docs"><p>Calculate count of variant in input file without coverage in the comparison.</p>
</td><td class="codes"><pre class="brush: clojure">(defn nocoverage-count
  [in-vcf ref-file compare-kw compared]
  (let [out-dir (get-in compared [:dir :prep] (get-in compared [:dir :out]))
        align-file (get-in compared [compare-kw :align]
                           (get-in compared [:exp :align]))]
    (when-not (nil? align-file)
      (with-open [call-source (get-callable-checker align-file (-&gt; compared :exp :ref)
                                                    :out-dir out-dir)]
        (count-variants in-vcf ref-file
                        #(is-callable? call-source (:chr %) (:start %) (:end %)))))))</pre></td></tr><tr><td class="docs"><p>Retrieve expected summary level from configuration</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-summary-level
  [config]
  (letfn [(level-from-string [x]
            (case (when-not (nil? x) (string/lower-case x))
              &quot;quick&quot; :quick
              &quot;full&quot; :full
              :standard))
          (get-string-level [config to-try]
            (loop [cur-try to-try]
              (if (empty? cur-try) nil
                  (let [cur-level (get-in config (first cur-try))]
                    (if-not (nil? cur-level) cur-level
                            (recur (rest cur-try)))))))]
    (let [to-check (cartesian-product [:exp :c1 :c2 :call] [:summary-level])]
      (level-from-string (get-string-level config to-check)))))</pre></td></tr><tr><td class="docs"><p>Retrieve structural variation metrics from SV concordance files.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-sv-metrics
  [finfo ref]
  (reduce (fn [coll [kw vcf-file]]
            (assoc coll kw
                   (ordered-map
                    :total (count-variants vcf-file ref passes-filter?))))
          (ordered-map) finfo))</pre></td></tr><tr><td class="docs"><p>Provide one-line summary of similarity metrics for a VCF comparison.</p>
</td><td class="codes"><pre class="brush: clojure">(defn top-level-metrics
  [compared]
  (let [sum-level (get-summary-level compared)
        ref-file (get-in compared [:exp :ref])]
    (letfn [(vrn-type-passes-filter [vrn-type]
              (fn [vc]
                (and (passes-filter? vc)
                     (contains? vrn-type (:type vc)))))
            (all-vrn-counts [fname cmp-kw compared]
              (let [base {:total (count-variants fname ref-file passes-filter?)}]
                (if (= sum-level :quick) base
                    (assoc base
                      :nocoverage (nocoverage-count fname ref-file cmp-kw compared)
                      :snp (count-variants fname ref-file
                                                (vrn-type-passes-filter #{&quot;SNP&quot;}))
                      :indel (count-variants fname ref-file
                                             (vrn-type-passes-filter #{&quot;INDEL&quot;}))))))]
      (let [c-files (-&gt; compared :c-files vals)
            base
            (ordered-map
             :sample (-&gt; compared :exp :sample)
             :ftypes (take 3 (-&gt; compared :c-files keys))
             :sv (let [xs (-&gt;&gt; (:c-files compared)
                               (drop-while #(not= (first %) :sv-concordant))
                               (take 3))]
                   (when-not (empty? xs)
                     (get-sv-metrics xs ref-file)))
             :genotype_concordance (-&gt; compared :metrics :percent_overall_genotype_concordance)
             :callable_concordance (-&gt; compared :callable-metrics
                                       :percent_overall_genotype_concordance)
             :nonref_discrepency (-&gt; compared :metrics :percent_non_reference_discrepancy_rate)
             :nonref_sensitivity (-&gt; compared :metrics :percent_non_reference_sensitivity)
             :concordant (all-vrn-counts (first c-files) nil compared)
             :nonref_concordant (count-variants (first c-files) ref-file
                                                nonref-passes-filter?)
             :discordant1 (all-vrn-counts (second c-files) :c2 compared)
             :discordant2 (when (&gt; (count c-files) 2) (all-vrn-counts (nth c-files 2) :c1 compared))
             :discordant_both (when (&gt; (count c-files) 2)
                                (apply discordance-metrics (conj (vec (take 2 (rest c-files)))
                                                                 ref-file))))]
        (if-not (= sum-level :full) base
            (assoc base
              :ml_metrics (ml-on-vcf-metrics ref-file (take 2 c-files))))))))</pre></td></tr><tr><td class="docs"><p>Calculate an overall accuracy score from input metrics.
  The accuracy logic is:
  (#correctly aligned bases / (#correctly aligned bases +
                               1*(simple substitutions and indels) +
                               2*(larger errors))).</p>
</td><td class="codes"><pre class="brush: clojure">(defn calc-accuracy
  [metrics error-items]
  (letfn [(get-penalty [[error-type call-type]]
            (case call-type
              :snp 1
              :indel 2
              :sv 2))]
    (let [error-items (cartesian-product error-items [:snp :indel :sv])
          error-score (apply + (map #(* (get-in metrics % 0) (get-penalty %)) error-items))
          total-bases (get-in metrics [:total-bases :compared] 1)]
      (float
       (* 100.0 (/ total-bases (+ total-bases error-score)))))))</pre></td></tr><tr><td class="docs"><p>Summary table of high level variables and scoring metrics for comparison.</p>
</td><td class="codes"><pre class="brush: clojure">(defn prep-scoring-table
  [metrics sv-stats]
  (let [to-write (ordered-map :accuracy &quot;Accuracy score&quot;
                              :accuracy-phasing &quot;Accuracy score, including phasing&quot;
                              [:total-bases :percent] &quot;Completeness&quot;
                              [:total-bases :compared] &quot;Total bases scored&quot;
                              [:total-bases :total] &quot;Possible evaluation bases&quot;
                              [:discordant :snp] &quot;Discordant SNPs&quot;
                              [:discordant :indel] &quot;Discordant indels&quot;
                              [:discordant :sv] &quot;Discordant structural variants&quot;
                              [:phasing-error :snp] &quot;Phasing Error SNPs&quot;
                              [:phasing-error :indel] &quot;Phasing Error indels&quot;
                              :haplotype-blocks &quot;Phased haplotype blocks&quot;
                              ;:nonmatch-het-alt &quot;Non-matching heterozygous alternative alleles&quot;)
        sv-metrics (assoc-in metrics [:discordant :sv]
                             (apply + (map #(get % :total 0) (rest (vals sv-stats)))))
        s-metrics (-&gt; sv-metrics
                      (assoc :accuracy (calc-accuracy metrics [:discordant]))
                      (assoc :accuracy-phasing (calc-accuracy metrics [:discordant :phasing-error])))
        need-percents {:accuracy 3
                       :accuracy-phasing 3
                       [:total-bases :percent] 2}]
    (letfn [(prep-row [[k x]]
              (let [val (if (coll? k) (get-in s-metrics k) (get s-metrics k))]
                {:metric x
                 :value (if (contains? need-percents k)
                          (format (str &quot;%.&quot; (get need-percents k) &quot;f&quot;) val)
                          val)}))]
      (map prep-row to-write))))</pre></td></tr><tr><td class="docs"><p>Write high level metrics table in readable format.</p>
</td><td class="codes"><pre class="brush: clojure">(defn write-scoring-table
  [metrics sv-stats wrtr]
  (when-not (or (nil? metrics)
                (nil? (get-in metrics [:total-bases :total])))
    (.write wrtr (str (doric/table [:metric :value] (prep-scoring-table metrics sv-stats))
                      &quot;\n&quot;))))</pre></td></tr><tr><td class="docs"><p>Summary table of metrics for assessing the score of a variant comparison.</p>
</td><td class="codes"><pre class="brush: clojure">(defn write-concordance-metrics
  [metrics wrtr]
  (letfn [(metrics-info [ftype-i &amp; kvs]
            (if (&lt;= (count (:ftypes metrics)) ftype-i)
              []
              (let [cur-name (name (nth (:ftypes metrics) ftype-i))]
                (apply concat
                       (map (fn [[k v]] [k (str cur-name &quot;: &quot; v)]) (partition 2 kvs))))))]
    (let [to-write (apply ordered-map
                          (concat [:genotype_concordance &quot;Overall genotype concordance&quot;
                                   :callable_concordance &quot;Callable genotype concordance&quot;
                                   :nonref_discrepency &quot;Non-reference discrepancy rate&quot;
                                   :nonref_sensitivity &quot;Non-reference sensitivity&quot;]
                                  (metrics-info 0
                                                [:concordant :total] &quot;total&quot;
                                                :nonref_concordant &quot;non-reference&quot;
                                                [:concordant :snp] &quot;SNPs&quot;
                                                [:concordant :indel] &quot;indels&quot;)
                                  (metrics-info 1
                                                [:discordant1 :total] &quot;total&quot;
                                                [:discordant1 :nocoverage] &quot;unique&quot;
                                                [:discordant1 :snp] &quot;SNPs&quot;
                                                [:discordant1 :indel] &quot;indels&quot;)
                                  (metrics-info 2
                                                [:discordant2 :total] &quot;total&quot;
                                                [:discordant2 :nocoverage] &quot;unique&quot;
                                                [:discordant2 :snp] &quot;SNPs&quot;
                                                [:discordant2 :indel] &quot;indels&quot;)
                                  [[:discordant_both :total] &quot;Shared discordant&quot;
                                   [:ml_metrics :top-metrics] &quot;Classification metrics&quot;]))]
      (letfn [(get-value [[k metric]]
                (when-let [val (if (coll? k) (get-in metrics k) (get metrics k))]
                  {:metric metric :value val}))]
        (.write wrtr (str (doric/table [:metric :value] (remove nil? (map get-value to-write)))
                          &quot;\n&quot;))))))</pre></td></tr><tr><td class="docs"><p>Summary table of structural variation comparions.</p>
</td><td class="codes"><pre class="brush: clojure">(defn write-sv-metrics
  [sv-metrics wrtr]
  (letfn [(get-values [[base xs]]
            (map (fn [[inner-kw val]]
                   {:metric (str (name base) &quot;: &quot; (name inner-kw))
                    :value val})
                 xs))]
    (.write wrtr &quot;** Structural variation\n&quot;)
    (.write wrtr (str (doric/table [:metric :value]
                                   (-&gt;&gt; (map get-values sv-metrics)
                                        flatten
                                        (remove nil?)))
                      &quot;\n&quot;))))</pre></td></tr><tr><td class="docs"><h2>Classification metrics</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Summary table of classification metrics from GATK variant recalibration.</p>
</td><td class="codes"><pre class="brush: clojure">(defn write-classification-metrics
  [cmp-info wrtr]
  (letfn [(get-metric-counts [in-vcf]
            (with-open [vcf-source (get-vcf-source in-vcf (get-in cmp-info [:exp :ref]))]
              (reduce (fn [coll vc]
                        (let [culprit (get-in vc [:attributes &quot;culprit&quot;])]
                          (if (or (nil? culprit) (= (count (:filters vc)) 0)) coll
                              (assoc coll culprit (inc (get coll culprit 0))))))
                      {} (parse-vcf vcf-source))))
          (get-recal-metrics [in-vcf]
            (sort-by :count &gt;
                     (map (fn [[m c]] {:metric m :count c}) (get-metric-counts in-vcf))))]
    (.write wrtr &quot;** GATK recalibration filter metrics\n&quot;)
    (doseq [call (map (partial get cmp-info) [:c1 :c2])]
      (when (= (:mod call) &quot;recal&quot;)
        (.write wrtr (str (doric/table [:metric :count]
                                       (get-recal-metrics (:file call)))
                          &quot;\n&quot;))))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.structural" name="bcbio.variation.structural"><h1 class="project-name">bcbio.variation.structural</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Handle structural variations for larger insertions, deletions and
  genome rearrangements.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.structural
  (:import [org.broadinstitute.sting.utils.codecs.vcf VCFCodec]
           [org.broadinstitute.sting.utils.variantcontext VariantContextBuilder
            Allele]
           [java.io StringReader]
           [net.sf.picard.util IntervalTree])
  (:use [clojure.set :only [intersection]]
        [ordered.map :only [ordered-map]]
        [bcbio.variation.variantcontext :only [get-vcf-source parse-vcf
                                               from-vc write-vcf-w-template]]
        [bcbio.variation.callable :only [get-bed-source]])
  (:require [clojure.string :as string]
            [fs.core :as fs]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><h2>Interval tree lookup</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Retrieve an Interval with the specified start/end keywords.</p>
</td><td class="codes"><pre class="brush: clojure">(defn prep-itree
  [vc-iter start-kw end-kw]
  (reduce (fn [coll vc]
            (assoc coll (:chr vc)
                   (doto (get coll (:chr vc) (IntervalTree.))
                     (.put (get vc start-kw) (inc (get vc end-kw)) vc))))
          (ordered-map) vc-iter))</pre></td></tr><tr><td class="docs"><p>Convert IntervalTree Iterator into clojure seq.
  Catch deleted sequences and continue ignoring the deleted node.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- itree-seq
  [iter]
  (lazy-seq
   (when (.hasNext iter)
     (try
       (cons (.getValue (.next iter)) (itree-seq iter))
       (catch java.util.ConcurrentModificationException e
         (itree-seq iter))))))</pre></td></tr><tr><td class="docs"><p>Lazy sequence of items that overlap a region in a nested IntervalTree.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-itree-overlap
  [itree chrom start end]
  (let [chr-itree (get itree chrom)]
    (if (nil? chr-itree)
      []
      (itree-seq (.overlappers chr-itree start end)))))</pre></td></tr><tr><td class="docs"><p>Lazy sequence of all items in an IntervalTree.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-itree-all
  [itree]
  (flatten
   (for [item (vals itree)]
     (sort-by :start
              (itree-seq (.iterator item))))))</pre></td></tr><tr><td class="docs"><p>Remove variant context from an IntervalTree</p>
</td><td class="codes"><pre class="brush: clojure">(defn remove-itree-vc
  [itree chr start end]
  (if (not-any? nil? [chr start end])
    (assoc itree chr
           (doto (get itree chr)
             (.remove start (inc end))))
    itree))</pre></td></tr><tr><td class="docs"><h2>Structural variation helpers</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Determine the type of a structural variant. Expected types are:</p>

<pre><code>- DEL: Deletion
- INS: Insertion
- DUP: Duplication
- INV: Inversion
- BND: Breakpoint end; paired with second variant
- CNV: Copy number variation
- nil: Not a structural variant.
</code></pre>
</td><td class="codes"><pre class="brush: clojure">(defn get-sv-type
  [vc params]
  (letfn [(max-allele-size [vc]
            (apply max (map #(.length %) (cons (:ref-allele vc) (:alt-alleles vc)))))
          (indel-type [vc]
            (if (&gt; (.length (:ref-allele vc))
                   (apply max (map #(.length %) (:alt-alleles vc)))) :DEL :INS))
          (sv-type-from-symbol [allele]
            (-&gt;&gt; allele
                 (re-find #&quot;^&lt;(\w+)(:|&gt;)&quot; )
                 second
                 keyword))
          (alt-sv-type [vc]
            (let [allele (-&gt; vc :alt-alleles first .getDisplayString)]
              (cond
               (.startsWith allele &quot;&lt;&quot;) (sv-type-from-symbol allele)
               (or (.contains allele &quot;[&quot;)
                   (.contains allele &quot;]&quot;)) :BND)))]
    (cond
     (and (= &quot;INDEL&quot; (:type vc))
          (&gt; (max-allele-size vc) (get params :min-indel 10))) (indel-type vc)
     (= &quot;SYMBOLIC&quot; (:type vc)) (alt-sv-type vc)
     :else nil)))</pre></td></tr><tr><td class="docs"><p>Check a VCF input line for identical REF and ALT calls</p>
</td><td class="codes"><pre class="brush: clojure">(defn nochange-alt?
  [line]
  (let [parts (string/split line #&quot;\t&quot;)]
    (= (nth parts 3) (nth parts 4))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn structural-vcfcodec []
  &quot;Provide VCFCodec decoder that returns structural variants.
  Check SV inputs for validity, fixing or filtering where possible.
  Fixes:
    - identical ref/alt calls: an apparent SV no-call&quot;
  (letfn [(check-sv-line [line]
            (cond
             (.startsWith line &quot;#&quot;) line
             (nochange-alt? line) nil
             :else line))]
    (proxy [VCFCodec] []
      (decode [line]
        (when-let [work-line (check-sv-line line)]
          (when-let [vc (proxy-super decode work-line)]
            vc)))
      (decodeLoc [line]
        (when-let [work-line (check-sv-line line)]
          (when-let [vc (proxy-super decode work-line)]
            vc))))))</pre></td></tr><tr><td class="docs"><p>Retrieve normalized integer values from an attribute.</p>
</td><td class="codes"><pre class="brush: clojure">(defn value-from-attr
  ([vc attr-name]
     (value-from-attr vc attr-name 0))
  ([vc attr-name attr-index]
      (-&gt; vc
          :attributes
          (get attr-name (repeat (inc attr-index) &quot;0&quot;))
          (#(if (string? %) [%] %))
          (nth attr-index)
          (Integer/parseInt)
          Math/abs)))</pre></td></tr><tr><td class="docs"><h2>Concordance checking</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Check if coordinates from two structural variants overlap.
  Considered an overlap if the two confidence intervals
  have shared bases.</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti sv-ends-overlap?
  (fn [[end1 end2]] (type end1)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod sv-ends-overlap? clojure.lang.PersistentVector
  [[[s1 e1] [s2 e2]]]
  (seq (intersection (set (range s1 (inc e1)))
                     (set (range s2 (inc e2))))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod sv-ends-overlap? java.lang.String
  [[end1 end2]]
  (= end1 end2))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- length-from-svlen [x] (value-from-attr x &quot;SVLEN&quot;))</pre></td></tr><tr><td class="docs"><p>Length of insertion variation, handling ALT allele, INSEQ
  and well-known named insertions.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- insertion-length
  [x]
  (letfn [(get-insseq [x]
            (-&gt; x :attributes (get &quot;INSSEQ&quot;)))
          (length-by-insert-name [alt-allele]
            (cond
             (.startsWith alt-allele &quot;&lt;INS:ME:&quot;) (-&gt; alt-allele
                                                     (subs 1 (dec (count alt-allele)))
                                                     (string/split #&quot;:&quot;)
                                                     last)
             :else (throw (Exception. (str &quot;Unknown insert allele&quot; alt-allele)))))
          (get-allele-insert [x]
            (let [alt-allele (-&gt; x :alt-alleles first .getDisplayString)]
              (if (.startsWith alt-allele &quot;&lt;&quot;)
                (length-by-insert-name alt-allele)
                (dec (count alt-allele)))))]
    (if-let [seq (get-insseq x)]
      (count seq)
      (get-allele-insert x))))</pre></td></tr><tr><td class="docs"><p>Length of deletion variations, handling SVLEN and allele specifications.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- deletion-length
  [vc]
  (let [svlen (length-from-svlen vc)]
    (if (pos? svlen)
      svlen
      (- (-&gt; vc :ref-allele .length)
         (apply min (map #(.length %) (:alt-alleles vc)))))))</pre></td></tr><tr><td class="docs"><p>Length of duplication variation, handling SVLEN and END.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- duplication-length
  [x]
  (max (length-from-svlen x)
       (- (value-from-attr x &quot;END&quot;) (:start x))))</pre></td></tr><tr><td class="docs"><p>Retrieve length of a structural variant for different variation types.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-sv-length
  [vc]
  (case (:sv-type vc)
         :DEL (deletion-length vc)
         :INS (insertion-length vc)
         :INV (length-from-svlen vc)
         :DUP (duplication-length vc)
         :CNV (duplication-length vc)
         :BND 0
         (throw (Exception. (str &quot;Structural variant type not handled: &quot;
                                 (:sv-type vc))))))</pre></td></tr><tr><td class="docs"><p>Retrieve start and end with confidence intervals for a variation.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-ci-start-end
  [vc params &amp; {:keys [allow-named?]}]
  (letfn [(get-ci-range [orig attr default-ci]
            (let [left-ci (value-from-attr vc attr 0)
                  right-ci (value-from-attr vc attr 1)]
              [(- orig (if (pos? left-ci) left-ci default-ci))
               (+ orig (if (pos? right-ci) right-ci default-ci))]))
          (get-default-ci [length]
            (let [default (if-let [x (-&gt; (:default-cis params) first second)] x 0)
                  by-length (when-not (string? length)
                              (second (first (drop-while #(&lt; (first %) length)
                                                         (:default-cis params)))))]
              (if-not (nil? by-length) by-length default)))]
    (let [start (:start vc)
          length (get-sv-length vc)
          default-ci (get-default-ci length)
          end (cond
               (and allow-named? (string? length)) length
               (string? length) (:end vc)
               :else (max (+ start length) (:end vc)))]
      [(get-ci-range start &quot;CIPOS&quot; default-ci)
       (if (string? end) end
           (get-ci-range end &quot;CIEND&quot; default-ci))])))</pre></td></tr><tr><td class="docs"><p>Check for concordance of variants based on reported length:
  handles deletions, inversions. insertions and duplications.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- sv-len-concordant?
  [sv1 sv2 params]
  (every? sv-ends-overlap?
          (partition 2 (interleave (get-ci-start-end sv1 params :allow-named? true)
                                   (get-ci-start-end sv2 params :allow-named? true)))))</pre></td></tr><tr><td class="docs"><p>Check if structural variants are concordant.</p>
</td><td class="codes"><pre class="brush: clojure">(defn sv-concordant?
  [params sv1 sv2]
  (and (apply = (map :sv-type [sv1 sv2]))
       (case (:sv-type sv1)
         (:DEL :INS :INV :DUP) (sv-len-concordant? sv1 sv2 params)
         :BND false
         (throw (Exception. (str &quot;Structural variant type not handled: &quot;
                                 (:sv-type sv1)))))))</pre></td></tr><tr><td class="docs"><h2>Parsing structural variants</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Parse VCF file returning structural variants with confidence intervals.
  The :out-format keyword specifies how to return the parsed structural variants:
   - :itree -- Interval tree for variant lookup by chromosome and start/end.
   - default -- List of variants (non-lazy).</p>
</td><td class="codes"><pre class="brush: clojure">(defn parse-vcf-sv
  [vcf-file ref-file &amp; {:keys [out-format interval-file params]
                        :or {params {}}}]
  (letfn [(updated-sv-vc [cur-vc]
            (when-let [sv-type (get-sv-type cur-vc params)]
              (let [[start-cis end-cis] (get-ci-start-end (assoc cur-vc :sv-type sv-type)
                                                          params)]
                (-&gt; cur-vc
                    (assoc :start-ci (first start-cis))
                    (assoc :end-ci (second end-cis))
                    (assoc :sv-type sv-type)))))
          (in-intervals? [bed-source vc]
            (or (instance? StringReader bed-source)
                (not (nil? (first (.query bed-source (:chr vc) (:start-ci vc) (:end-ci vc)))))))]
    (with-open [vcf-source (get-vcf-source vcf-file ref-file :codec (structural-vcfcodec))
                bed-source (if-not (nil? interval-file) (get-bed-source interval-file ref-file)
                                   (StringReader. &quot;&quot;))]
      (let [vs-iter (filter (partial in-intervals? bed-source)
                            (keep updated-sv-vc (parse-vcf vcf-source)))]
        (case out-format
          :itree (prep-itree vs-iter :start-ci :end-ci)
          (vec vs-iter))))))</pre></td></tr><tr><td class="docs"><p>Compare two structural variant files, returning variant contexts keyed by concordance.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- find-concordant-svs
  [fname1 fname2 disc-kwds ref interval-file params]
  (let [cmp-tree (atom (parse-vcf-sv fname2 ref :out-format :itree :interval-file interval-file
                                     :params params))]
    (letfn [(check-sv-concordance [vc]
              (let [matches (filter (partial sv-concordant? params vc)
                                    (get-itree-overlap @cmp-tree (:chr vc)
                                                       (:start-ci vc) (inc (:end-ci vc))))]
                (doseq [m-vc matches]
                  (reset! cmp-tree (remove-itree-vc @cmp-tree (:chr m-vc)
                                                    (:start m-vc) (:end m-vc))))
                [(if (seq matches) :sv-concordant (:1 disc-kwds)) (:vc vc)]))
            (remaining-cmp-svs [itree]
              (partition 2
                         (interleave (repeat (:2 disc-kwds)) (map :vc (get-itree-all itree)))))]
      (concat
       (map check-sv-concordance (parse-vcf-sv fname1 ref :interval-file interval-file
                                               :params params))
       (remaining-cmp-svs @cmp-tree)))))</pre></td></tr><tr><td class="docs"><p>Retrieve list of non-structural variants in the provided input file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn find-non-svs
  [kwd vcf-source params]
  (-&gt;&gt; (parse-vcf vcf-source)
       (filter #(nil? (get-sv-type % params)))
       (map :vc)
       (interleave (repeat kwd))
       (partition 2)))</pre></td></tr><tr><td class="docs"><p>Compare structural variants, producing concordant and discordant outputs</p>
</td><td class="codes"><pre class="brush: clojure">(defn compare-sv
  [sample c1 c2 ref &amp; {:keys [out-dir interval-file params]
                       :or {params {}}}]
  (let [base-out (str (fs/file (if (nil? out-dir) (fs/parent (:file c1)) out-dir)
                               (str sample &quot;-%s-%s-%s.vcf&quot;)))
        disc-kwds {:1 (keyword (str &quot;sv-&quot; (:name c1) &quot;-discordant&quot;))
                   :2 (keyword (str &quot;sv-&quot; (:name c2) &quot;-discordant&quot;))}
        out-files (ordered-map
                   :sv-concordant (format base-out (:name c1) (:name c2) &quot;svconcordance&quot;)
                   (:1 disc-kwds) (format base-out (:name c1) (:name c2) &quot;svdiscordance&quot;)
                   (:2 disc-kwds) (format base-out (:name c2) (:name c1) &quot;svdiscordance&quot;)
                   :nosv1 (itx/add-file-part (:file c1) &quot;nosv&quot; out-dir)
                   :nosv2 (itx/add-file-part (:file c2) &quot;nosv&quot; out-dir))]
    (when (itx/needs-run? (vals out-files))
      (with-open [vcf1-s (get-vcf-source (:file c1) ref :codec (structural-vcfcodec))
                  vcf2-s (get-vcf-source (:file c2) ref :codec (structural-vcfcodec))]
        (write-vcf-w-template (:file c1) out-files
                              (concat
                               (find-concordant-svs (:file c1) (:file c2) disc-kwds
                                                    ref interval-file params)
                               (find-non-svs :nosv1 vcf1-s params)
                               (find-non-svs :nosv2 vcf2-s params))
                              ref))
      ;; Remove SV VCF indexes since they use alternative Codecs
      (doseq [fname (vals out-files)]
        (let [x (str fname &quot;.idx&quot;)]
          (if (fs/exists? x)
            (fs/delete x)))))
    out-files))</pre></td></tr><tr><td class="docs"><p>Handle input decomposition running SV detection through the standard pipeline.</p>
</td><td class="codes"><pre class="brush: clojure">(defn compare-sv-pipeline
  [c1 c2 exp config]
  (let [out-dir (get-in config [:dir :prep] (get-in config [:dir :out]))
        intervals (get c1 :intervals (get c2 :intervals (:intervals exp)))
        params (get exp :params {:min-indel 10 :default-cis [[100 10] [1000 200] [1e6 500]]})
        out-files (compare-sv (:sample exp) c1 c2 (:ref exp) :out-dir out-dir
                              :interval-file intervals :params params)]
    [(assoc c1 :file (:nosv1 out-files))
     (assoc c2 :file (:nosv2 out-files))
     (-&gt; out-files
         (dissoc :nosv1)
         (dissoc :nosv2))]))</pre></td></tr><tr><td class="docs"><h2>Utility functions</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Lazy stream of structural variants overlapping in both inputs.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- find-overlapping-svs
  [f1 f2 ref params]
  (letfn [(find-overlaps [cmp-tree vc]
            (when-let [cmp-vc (first (get-itree-overlap cmp-tree (:chr vc)
                                                        (:start-ci vc) (inc (:end-ci vc))))]
              [:out1 (:vc vc) :out2 (:vc cmp-vc)]))]
    (let [cmp-tree (parse-vcf-sv f2 ref :out-format :itree :params params)]
      (-&gt;&gt; (parse-vcf-sv f1 ref :params params)
           (map (partial find-overlaps cmp-tree))
           (remove nil?)
           flatten
           (partition 2)))))</pre></td></tr><tr><td class="docs"><p>Prepare VCF files of only overlapping structural variants present in both.</p>
</td><td class="codes"><pre class="brush: clojure">(defn overlapping-svs
  [f1 f2 ref params]
  (let [out-files {:out1 (itx/add-file-part f1 &quot;overlap&quot;)
                   :out2 (itx/add-file-part f2 &quot;overlap&quot;)}]
    (when (itx/needs-run? (vals out-files))
      (write-vcf-w-template f1 out-files (find-overlapping-svs f1 f2 ref params) ref))
    out-files))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.utils.background" name="bcbio.variation.utils.background"><h1 class="project-name">bcbio.variation.utils.background</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Prepare annotated VCF files to use as background for variant calling and recalibration.
  Batch variant calling and recalibration with GATK improves resulting calls. This
  provides a ready to use set of calls to batch with a single sample using 1000 genomes data.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.utils.background
  (:use [clojure.java.io]
        [bcbio.variation.config :only [load-config]]
        [bcbio.variation.combine :only [select-by-sample combine-variants]]
        [bcbio.variation.annotation :only [add-gatk-annotations]])
  (:require [clojure.java.shell :as shell]
            [clojure.string :as string]
            [fs.core :as fs]
            [aws.sdk.s3 :as s3]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><h2>Combine and annotate VCFs</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Download BAM file and index for a sample from 1000 genomes FTP.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- download-sample-bam
  [sample ftp-config out-dir]
  (letfn [(download [url fname]
            (when-not (fs/exists? fname)
              (println &quot;Downloading&quot; url &quot;to&quot; fname)
              (shell/with-sh-dir out-dir
                (shell/sh &quot;wget&quot; &quot;-O&quot; fname url))))]
    (let [dl-url (format (:bam-url ftp-config) sample sample)
          local-file (str (fs/file out-dir (string/replace (fs/base-name dl-url) &quot;.*&quot; &quot;&quot;)))]
      (download dl-url local-file)
      (download (str dl-url &quot;.bai&quot;) (str local-file &quot;.bai&quot;))
      local-file)))</pre></td></tr><tr><td class="docs"><p>Check if a file exists, also checking for gzipped versions.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- gzip-needs-run?
  [x]
  (every? itx/needs-run? [x (str x &quot;.gz&quot;)]))</pre></td></tr><tr><td class="docs"><p>Annotate genome sample VCFs with GATK metrics.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- annotate-sample
  [sample-info ref ftp-config prep-dir out-dir]
  (let [final-file (str (fs/file out-dir (format &quot;%s-annotated.vcf&quot; (:sample sample-info))))]
    (when (gzip-needs-run? final-file)
      (let [sample-bam (download-sample-bam (:sample sample-info) ftp-config prep-dir)
            ann-vcf (add-gatk-annotations (:file sample-info) sample-bam ref)]
        (fs/rename ann-vcf final-file)
        (itx/remove-path sample-bam)))
    final-file))</pre></td></tr><tr><td class="docs"><p>Combine sample VCFs split by chromosome.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- combine-samples
  [sample-info ref out-dir]
  (letfn [(combine-sample [[name xs]]
            {:sample name
             :file (combine-variants (map :file xs) ref :merge-type :full
                                     :out-dir out-dir)})]
    (map combine-sample
         (group-by :sample (flatten sample-info)))))</pre></td></tr><tr><td class="docs"><h2>Subset VCF by sample</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Download chromosome VCF from 1000 genomes for processing.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- download-chrom-vcf
  [chrom ftp-config out-dir]
  (letfn [(download-vcf [url fname]
            (println &quot;Downloading&quot; url &quot;to&quot; fname)
            (shell/with-sh-dir out-dir
              (shell/sh &quot;wget&quot; &quot;-O&quot; fname url)
              (shell/sh &quot;gunzip&quot; (str (fs/base-name fname)))))]
    (let [dl-url (format (:vcf-url ftp-config) chrom)
          local-file (str (fs/file out-dir (fs/base-name dl-url)))
          final-file (itx/remove-zip-ext local-file)]
      (when-not (fs/exists? final-file)
        (download-vcf dl-url local-file))
      final-file)))</pre></td></tr><tr><td class="docs"><p>Select samples from input 1000 genomes chromosome VCF.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- select-samples-at-chrom
  [chrom samples ref ftp-config out-dir]
  (let [sample-info (map (fn [x] {:sample x
                                  :file (str (fs/file out-dir (format &quot;%s-%s.vcf&quot; x chrom)))})
                         samples)]
    (when (apply itx/needs-run? (map :file sample-info))
      (let [chrom-vcf (download-chrom-vcf chrom ftp-config out-dir)]
        (doseq [sample samples]
          (select-by-sample sample chrom-vcf chrom ref :out-dir out-dir
                            :remove-refcalls true))
        (itx/remove-path chrom-vcf)))
    sample-info))</pre></td></tr><tr><td class="docs"><h2>Create combined background file</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Prepare combined VCF file with background information from multiple inputs.</p>
</td><td class="codes"><pre class="brush: clojure">(defn prep-combined-background
  [vcfs config]
  (letfn [(maybe-bgzip-vcf [x]
            (first (filter fs/exists? [x (str x &quot;.gz&quot;)])))]
    (let [out-dir (get-in config [:dir :out])
          out-file (str (fs/file out-dir (get-in config [:upload :combined-vcf])))]
      (when (gzip-needs-run? out-file)
        (-&gt; (combine-variants (map maybe-bgzip-vcf vcfs) (:ref config)
                              :merge-type :full :out-dir out-dir)
            (fs/rename out-file)))
      out-file)))</pre></td></tr><tr><td class="docs"><h2>Tabix prep and upload</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Prep VCF for tabix access by bgzipping and indexing.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- tabix-prep-vcf
  [vcf]
  (let [out-dir (str (fs/parent vcf))
        vcf-gz (str vcf &quot;.gz&quot;)
        tbi-gz (str vcf-gz &quot;.tbi&quot;)]
    (shell/with-sh-dir out-dir
      (when (itx/needs-run? vcf-gz)
        (shell/sh &quot;bgzip&quot; (str (fs/base-name vcf))))
      (when (itx/needs-run? tbi-gz)
        (shell/sh &quot;tabix&quot; &quot;-p&quot; &quot;vcf&quot; (str (fs/base-name vcf-gz)))))
    [vcf-gz tbi-gz]))</pre></td></tr><tr><td class="docs"><p>Upload prepared sample VCF bgzipped and tabix indexed.</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti upload-result-vcf
  (fn [_ config] (keyword (get-in config [:upload :target]))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod upload-result-vcf :s3
  [vcf config]
  (let [cred {:access-key (System/getenv &quot;AWS_ACCESS_KEY_ID&quot;)
              :secret-key (System/getenv &quot;AWS_SECRET_ACCESS_KEY&quot;)}
        bucket (get-in config [:upload :bucket])]
    (when-not (s3/bucket-exists? cred bucket)
      (s3/create-bucket cred bucket)
      (s3/update-bucket-acl cred bucket (s3/grant :all-users :read)))
    (doseq [fname (tabix-prep-vcf vcf)]
      (let [s3-key (format &quot;%s/%s&quot; (get-in config [:upload :folder])
                           (str (fs/base-name fname)))]
        (when-not (s3/object-exists? cred bucket s3-key)
          (s3/put-object cred bucket s3-key (file fname))
          (s3/update-object-acl cred bucket s3-key
                                (s3/grant :all-users :read)))
        (println s3-key)))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn make-work-dirs [config]
  (doseq [dir-name (-&gt; config :dir keys)]
    (let [cur-dir (get-in config [:dir dir-name])]
      (when-not (fs/exists? cur-dir)
        (fs/mkdirs cur-dir)))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -main [config-file]
  (let [config (load-config config-file)]
    (make-work-dirs config)
    (let [prep-dir (get-in config [:dir :prep])
          samples (map #(select-samples-at-chrom % (:genomes config) (:ref config)
                                                 (:ftp config) prep-dir)
                                        (get-in config [:ftp :chromosomes]))
          combo-samples (combine-samples samples (:ref config) prep-dir)
          ann-samples (map #(annotate-sample % (:ref config) (:ftp config)
                                             prep-dir (get-in config [:dir :out]))
                           (sort-by :sample combo-samples))]
      (doseq [ready-vcf (cons (prep-combined-background ann-samples config)
                              ann-samples)]
        (upload-result-vcf ready-vcf config)))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.utils.cgmetrics" name="bcbio.variation.utils.cgmetrics"><h1 class="project-name">bcbio.variation.utils.cgmetrics</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Add metrics from Complete Genomics masterVar file to a VCF.
  This updates a converted VCF from Complete Genomics with metrics information
  allowing assessment and filtering.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.utils.cgmetrics
  (:import [org.broadinstitute.sting.utils.variantcontext VariantContextBuilder]
           [org.broadinstitute.sting.utils.codecs.vcf VCFHeader VCFInfoHeaderLine
            VCFHeaderLineCount VCFHeaderLineType])
  (:use [clojure.java.io]
        [ordered.set :only (ordered-set)]
        [bcbio.variation.normalize :only [hg19-map]]
        [bcbio.variation.variantcontext :only [parse-vcf write-vcf-w-template
                                               get-vcf-source]])
  (:require [clojure.data.csv :as csv]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><p>Get lookup dictionary of CG variant metrics by position.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-masterVar-metrics
  [in-file]
  (letfn [(variant-score [line name]
            (let [alleles [&quot;1&quot; &quot;2&quot;]]
              (/ (apply + (map #(Float/parseFloat (get line (format &quot;allele%sVarScore%s&quot; % name)))
                               alleles))
                 (count alleles))))
          (allele-balance [line]
            (/ (Float/parseFloat (get line &quot;referenceAlleleReadCount&quot;))
               (Float/parseFloat (get line &quot;totalReadCount&quot;))))]
    (with-open [rdr (reader in-file)]
      (let [csv-iter (drop-while #(&lt; (count %) 3)
                                 (csv/read-csv rdr :separator \tab))
            header (first csv-iter)]
        (reduce (fn [coll xs]
                  (let [line (zipmap header xs)]
                    (assoc coll [(get hg19-map (get line &quot;chromosome&quot;))
                                 (inc (Integer/parseInt (get line &quot;begin&quot;)))]
                           {:depth (get line &quot;totalReadCount&quot;)
                            :qual-eaf (variant-score line &quot;EAF&quot;)
                            :qual-vaf (variant-score line &quot;VAF&quot;)
                            :ab (allele-balance line)})))
                {} (rest csv-iter))))))</pre></td></tr><tr><td class="docs"><p>Provide iterator of variants with CG metrics added</p>
</td><td class="codes"><pre class="brush: clojure">(defn- add-cgmetrics-iter
  [vcf-source metrics]
  (letfn [(update-cgmetrics [vc x]
            (-&gt; (VariantContextBuilder. (:vc vc))
                (.attributes (assoc (:attributes vc)
                               &quot;DPCALL&quot; (:depth x)
                               &quot;AB&quot; (:ab x)
                               &quot;QUALEAF&quot; (:qual-eaf x)
                               &quot;QUALVAF&quot; (:qual-vaf x)))
                .make))]
    (map (fn [vc]
           (if-let [cur-metrics (get metrics [(:chr vc) (:start vc)])]
             (update-cgmetrics vc cur-metrics)
             (:vc vc)))
         (parse-vcf vcf-source))))</pre></td></tr><tr><td class="docs"><p>Add CG metrics definitions to the VCF input header.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- add-cgmetrics-header
  [_ header]
  (let [new #{(VCFInfoHeaderLine. &quot;DPCALL&quot; 1
                                  VCFHeaderLineType/Integer &quot;Total depth used for calls&quot;)
              (VCFInfoHeaderLine. &quot;QUALEAF&quot; 1
                                  VCFHeaderLineType/Float
                                  &quot;Variant quality under equal allele fraction model (EAF)&quot;)
              (VCFInfoHeaderLine. &quot;QUALVAF&quot; 1
                                  VCFHeaderLineType/Float
                                  &quot;Variant quality under maximum likelihood variable allele fraction model (VAF)&quot;)
              (VCFInfoHeaderLine. &quot;AB&quot; 1
                                  VCFHeaderLineType/Float &quot;Allele Balance&quot;)}]
    (VCFHeader. (apply ordered-set (concat (.getMetaData header) new))
                (.getGenotypeSamples header))))</pre></td></tr><tr><td class="docs"><p>Add metrics from Complete Genomics masterVar file to VCF.</p>
</td><td class="codes"><pre class="brush: clojure">(defn add-cgmetrics
  [vcf-file mastervar-file ref-file &amp; {:keys [out-dir]}]
  (let [out-file (itx/add-file-part vcf-file &quot;cgmetrics&quot; out-dir)]
    (when (itx/needs-run? out-file)
      (with-open [vcf-source (get-vcf-source vcf-file ref-file)]
        (write-vcf-w-template vcf-file {:out out-file}
                              (add-cgmetrics-iter vcf-source
                                                  (get-masterVar-metrics mastervar-file))
                              ref-file :header-update-fn add-cgmetrics-header)))
    out-file))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.utils.gms" name="bcbio.variation.utils.gms"><h1 class="project-name">bcbio.variation.utils.gms</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Build reference Genomic Mappability Score (GMS) variant file.
  Uses full GMS files to generate VCF of potentially problematic low-GMS regions:
  http://sourceforge.net/apps/mediawiki/gma-bio/index.php</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.utils.gms
  (:import [org.broadinstitute.sting.utils.variantcontext VariantContextBuilder Allele]
           [org.broadinstitute.sting.utils.codecs.vcf StandardVCFWriter VCFHeader
            VCFInfoHeaderLine VCFHeaderLineCount VCFHeaderLineType])
  (:use [clojure.java.io]
        [ordered.map :only [ordered-map]]
        [bcbio.align.ref :only [get-seq-dict]]
        [bcbio.variation.combine :only [combine-variants]]
        [bcbio.variation.config :only [load-config]]
        [bcbio.variation.normalize :only [hg19-map]]
        [bcbio.variation.utils.background :only [make-work-dirs]])
  (:require [clojure.java.shell :as shell]
            [clojure.string :as string]
            [fs.core :as fs]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><p>Download GMS data for all technologies at a chromosome.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- download-chrom-gms-data
  [chrom ftp-config out-dir]
  (letfn [(download-gms [chrom tech]
            (let [dl-url (format (:gms-url ftp-config) (:genome-build ftp-config)
                                 tech chrom)
                  final-file (itx/add-file-part (itx/remove-zip-ext (fs/base-name dl-url))
                                                tech out-dir)
                  dl-file (str final-file &quot;.gz&quot;)]
              (when (itx/needs-run? final-file)
                (shell/with-sh-dir out-dir
                  (println (format &quot;Downloading %s to %s&quot; dl-url dl-file))
                  (shell/sh &quot;wget&quot; &quot;-O&quot; dl-file dl-url)
                  (shell/sh &quot;gunzip&quot; dl-file)))
              final-file))]
    (into (ordered-map)
          (map (juxt identity (partial download-gms chrom))
               (:technologies ftp-config)))))</pre></td></tr><tr><td class="docs"><p>Retrieve chromosome, position and GMS score for line in a GMS file</p>
</td><td class="codes"><pre class="brush: clojure">(defn- parse-gms-line
  [line]
  (let [[chrom pos base _ _ score] (string/split line #&quot;\t&quot;)]
    {:chrom chrom
     :pos (Integer/parseInt pos)
     :base base
     :score (Float/parseFloat score)}))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- low-gms-score? [config gms-data]
  (let [thresh (get config :max-gms-score 50.0)]
    (and (&gt; (:score gms-data) 0.0)
         (&lt; (:score gms-data) thresh))))</pre></td></tr><tr><td class="docs"><p>Prepare variant context from set of GMS scores</p>
</td><td class="codes"><pre class="brush: clojure">(defn- gms-scores-to-vc
  [techs scores]
  (let [contig (get hg19-map (-&gt; scores first :chrom))
        all-pos (filter pos? (map :pos scores))
        pos (if (= 1 (count (set all-pos)))
              (first all-pos)
              (throw (Exception. (str &quot;Multiple positions found: &quot; all-pos))))
        base (-&gt;&gt; (map :base scores)
                  (filter #(not= % &quot;*&quot;))
                  first)]
    (when-not (or (zero? pos) (nil? base))
      (-&gt; (VariantContextBuilder. contig contig pos pos [(Allele/create base true)])
          (.attributes (reduce (fn [coll [tech score]]
                                 (assoc coll (str &quot;GMS_&quot; tech) (:score score)))
                               {} (map vector techs scores)))
          (.make)))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- get-vcf-header [techs]
  (VCFHeader. (set
               (map #(VCFInfoHeaderLine. (format &quot;GMS_%s&quot; %) 1
                                         VCFHeaderLineType/Float
                                         (format &quot;Genome Mappability Score: %s&quot; %))
                    techs))))</pre></td></tr><tr><td class="docs"><p>Prepare an output VCF of low GMS values at the provided chromosome.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- prepare-vcf-at-chrom
  [chrom ftp-config ref out-dir]
  (let [out-file (file out-dir (format &quot;lowgms-scores-%s.vcf&quot; chrom))]
    (when (itx/needs-run? out-file)
      (let [gms-files (download-chrom-gms-data chrom ftp-config out-dir)
            readers (map reader (vals gms-files))]
        (with-open [writer (StandardVCFWriter. (file out-file) (get-seq-dict ref))]
          (.writeHeader writer (get-vcf-header (keys gms-files)))
          (loop [line-iters (-&gt;&gt; (map line-seq readers)
                                 (map (fn [x] (drop-while #(.startsWith % &quot;#&quot;) x))))]
            (when-not (or (empty? (first line-iters))
                          (some nil? (map first line-iters)))
              (let [cur-gms (map (comp parse-gms-line first) line-iters)]
                (when (some (partial low-gms-score? ftp-config) cur-gms)
                  (when-let [vc (gms-scores-to-vc (keys gms-files) cur-gms)]
                    (.add writer vc))))
              (recur (map rest line-iters))))
          (doseq [x readers]
            (.close x)))
        (doseq [x (vals gms-files)]
          (itx/remove-path x))))
    (str out-file)))</pre></td></tr><tr><td class="docs"><p>Prepare individual chromosome VCF files with low GMS data by sequencing technology.</p>
</td><td class="codes"><pre class="brush: clojure">(defn prepare-gms-vcfs
  [config]
  (let [ref (:ref config)
        out-dir (get-in config [:dir :out])
        gms-by-chrom (doall (map #(prepare-vcf-at-chrom % (:ftp config) ref out-dir)
                                  (get-in config [:ftp :chromosomes])))]
    (println gms-by-chrom)
    (combine-variants gms-by-chrom ref :merge-type :full :out-dir out-dir
                      :quiet-out? true))
  (shutdown-agents))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -main [config-file]
  (let [config (load-config config-file)]
    (make-work-dirs config)
    (prepare-gms-vcfs config)))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.utils.popfreq" name="bcbio.variation.utils.popfreq"><h1 class="project-name">bcbio.variation.utils.popfreq</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Associate population allele frequency with a list of variants.
  Annotates the original file with population frequencies based on rs IDs.
  Arguments:
    - original VCF file
    - attribute ID to include population frequencies in file (ie. GMAF)
    - Description of new frequency for VCF header
    - population VCF file
    - attribute ID to use for frequencies from population file (ie. AF)
    - reference genome FASTA file</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.utils.popfreq
  (:import [org.broadinstitute.sting.utils.variantcontext VariantContextBuilder]
           [org.broadinstitute.sting.utils.codecs.vcf VCFHeader VCFInfoHeaderLine
            VCFHeaderLineCount VCFHeaderLineType])
  (:use [ordered.set :only [ordered-set]]
        [bcbio.variation.config :only [load-config]]
        [bcbio.variation.combine :only [combine-variants]]
        [bcbio.variation.variantcontext :only [parse-vcf write-vcf-w-template
                                               get-vcf-source]])
  (:require [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><p>Retrieve all rsIDs from the input vcf-file</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-rsids
  [vcf-file ref]
  (with-open [vcf-source (get-vcf-source vcf-file ref)]
    (set (remove nil? (map :id (parse-vcf vcf-source))))))</pre></td></tr><tr><td class="docs"><p>Retrieve allele frequencies from population VCF for IDs of interest.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-allele-freqs
  [vcf-file ref want-ids targets]
  (println &quot;Retrieving allele freqs&quot; (count want-ids) targets)
  (with-open [vcf-source (get-vcf-source vcf-file ref)]
    (reduce (fn [coll vc]
              (if (and (not (nil? (:id vc)))
                       (contains? want-ids (:id vc)))
                (assoc coll (:id vc) (zipmap (map :new-id targets)
                                             (map #(get-in vc [:attributes (:orig-id %)] 0.0)
                                                  targets)))
                coll))
            {} (parse-vcf vcf-source))))</pre></td></tr><tr><td class="docs"><p>Lazy generator of variant contexts with added population frequencies.</p>
</td><td class="codes"><pre class="brush: clojure">(defn add-pop-freqs
  [vcf-source allele-freqs ann-ids]
  (letfn [(update-allele-freq [vc new-freqs]
            (-&gt; (VariantContextBuilder. (:vc vc))
                (.attributes (reduce (fn [coll cur-id]
                                       (assoc coll cur-id (get new-freqs cur-id 0.0)))
                                     (:attributes vc) ann-ids))
                .make))]
    (map #(update-allele-freq % (get allele-freqs (:id %) {}))
         (parse-vcf vcf-source))))</pre></td></tr><tr><td class="docs"><p>Add new population frequency information to the VCF input header if needed.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- add-popfreq-header
  [new-ids]
  (letfn [(header-has-id? [header test-id]
            (contains? (set (map #(when (= &quot;INFO&quot; (.getKey %))
                                    (.getID %)) (.getMetaData header)))
                       test-id))]
    (fn [_ header]
      (let [new (-&gt;&gt; new-ids
                     (remove #(header-has-id? header (:new-id %)))
                     (map #(VCFInfoHeaderLine. (:new-id %) 1
                                               VCFHeaderLineType/Float (:desc %)))
                     set)]
        (VCFHeader. (apply ordered-set (concat (.getMetaData header) new))
                    (.getGenotypeSamples header))))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- add-annotations
  [call ref out-dir]
  (let [orig-vcf (if (coll? (:file call))
                   (combine-variants (:file call) ref :out-dir out-dir :merge-type :full)
                   (:file call))
        out-file (itx/add-file-part orig-vcf &quot;popfreq&quot; out-dir)
        allele-freqs (get-allele-freqs (get-in call [:annotate :file]) ref
                                       (get-rsids orig-vcf ref)
                                       (get-in call [:annotate :targets]))]
    (if (itx/needs-run? out-file)
      (with-open [vcf-source (get-vcf-source orig-vcf ref)]
        (write-vcf-w-template orig-vcf {:out out-file}
                              (add-pop-freqs vcf-source allele-freqs
                                             (map :new-id (get-in call [:annotate :targets])))
                              ref
                              :header-update-fn
                              (add-popfreq-header (get-in call [:annotate :targets])))))
    out-file))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -main [config-file]
  (let [config (load-config config-file)]
    (doseq [exp (:experiments config)]
      (doseq [call (:calls exp)]
        (add-annotations call (:ref exp) (get-in config [:dir :out]))))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.utils.summarize" name="bcbio.variation.utils.summarize"><h1 class="project-name">bcbio.variation.utils.summarize</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Collapse a multi-sample VCF file into a CSV, R data.frame ready, parameter summary.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.utils.summarize
  (:use [clojure.java.io]
        [ordered.map :only [ordered-map]]
        [bcbio.variation.callable :only [get-bed-source features-in-region]]
        [bcbio.variation.config :only [load-config]]
        [bcbio.variation.metrics :only [passes-filter?]]
        [bcbio.variation.variantcontext :only [parse-vcf get-vcf-source]])
  (:require [clojure.string :as string]
            [clojure.data.csv :as csv]
            [incanter.stats :as istats]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><p>Provide sample information from variant genotypes.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- flatten-vc-samples
  [out vc attrs]
  (let [variant-types [&quot;HET&quot; &quot;HOM_VAR&quot;]]
    (letfn [(add-variant-totals [out gs]
              (let [counts (frequencies (map :type gs))]
                (reduce (fn [coll [k v]] (assoc coll k v))
                        out (map (fn [k] [k (get counts k 0)])
                                 variant-types))))
            (get-attr-avg [k gs]
              (istats/mean (-&gt;&gt; gs
                                (filter #(contains? (set variant-types) (:type %)))
                                (map #(get-in % [:attributes k]))
                                (remove nil?)
                                (map #(Float/parseFloat %)))))
            (add-attr-avgs [out gs attrs]
              (reduce (fn [coll k] (assoc coll (str k &quot;_sample_mean&quot;)
                                          (get-attr-avg k gs)))
                      out attrs))]
      (-&gt; out
          (add-variant-totals (:genotypes vc))
          (add-attr-avgs (:genotypes vc) attrs)))))</pre></td></tr><tr><td class="docs"><p>Prepare attributes for feeding into flattened table</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti prep-attribute
  (fn [attr value default] attr))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod prep-attribute &quot;set&quot;
  [attr value default]
  (cond
   (= value &quot;Intersection&quot;) default
   (= value &quot;FilteredInAll&quot;) 0
   (nil? value) 0
   :else (count (string/split value #&quot;\-&quot;))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod prep-attribute :default
  [_ value _]
  value)</pre></td></tr><tr><td class="docs"><p>Extract attributes of interest from INFO field of variant.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- flatten-vc-attrs
  [out vc attrs defaults]
  (reduce (fn [coll k] (assoc coll k (prep-attribute k (get-in vc [:attributes k])
                                                     (get defaults (keyword k)))))
          out attrs))</pre></td></tr><tr><td class="docs"><p>Check for presence of the variant in predefined intervals.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- flatten-vc-intervals
  [out vc intervals]
  (letfn [(check-intervals [vc bed-s]
            (if (empty? (features-in-region bed-s (:chr vc) (:start vc) (:end vc))) 0 1))]
    (reduce (fn [coll interval]
              (assoc coll (:name interval) (check-intervals vc (:source interval))))
            out intervals)))</pre></td></tr><tr><td class="docs"><p>Provide tabular variant representation with provided attributes and sample information.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- flatten-vc
  [config vc]
  (-&gt; (reduce (fn [coll k] (assoc coll k (get vc k)))
              (ordered-map) [:chr :start :id :type :qual])
      (flatten-vc-intervals vc (get config :intervals []))
      (flatten-vc-attrs vc (:attrs config) (get config :attrs-defaults {}))
      (flatten-vc-samples vc (:sample-attrs config))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- add-interval-retrievers
  [config ref]
  (letfn [(add-int-retriever [coll]
            (assoc coll :source (get-bed-source (:file coll) ref)))]
    (assoc config :intervals (map add-int-retriever (:intervals config)))))</pre></td></tr><tr><td class="docs"><p>Convert a VCF input to flattened CSV table with provided attributes.</p>
</td><td class="codes"><pre class="brush: clojure">(defn vcf-to-table
  [vcf ref config]
  (let [out-file (str (itx/file-root vcf) &quot;-variantsum.csv&quot;)]
    (when (itx/needs-run? out-file)
      (with-open [vcf-source (get-vcf-source vcf ref)
                  wtr (writer out-file)]
        (doseq [[i out] (map-indexed vector
                                     (map (partial flatten-vc (add-interval-retrievers config ref))
                                          (filter passes-filter? (parse-vcf vcf-source))))]
          (when (= i 0)
            (csv/write-csv wtr [(map name (keys out))]))
          (csv/write-csv wtr [(vals out)])
          (.flush wtr))))
    out-file))</pre></td></tr><tr><td class="docs"><p>Prep a set of VCF to table conversions from input configuration file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn vcf-to-table-config
  [config-file]
  (let [config (load-config config-file)]
    (doall
     (flatten
      (for [exp (:experiments config)]
        (for [call (:calls exp)]
          (vcf-to-table (:file call) (:ref exp) (:summary call))))))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -main [config-file]
  (vcf-to-table-config config-file))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.validate" name="bcbio.variation.validate"><h1 class="project-name">bcbio.variation.validate</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Combine calls from a multiple technology comparison to produce a set of final
  variants plus a list for validation. The inputs are:
   - Target technology: The outlier technology for picking additional targets. This
     should be well understood enough to set threshold for validation.
   - Validation info: Details for prepping a set of variants for validation
      - thresholds: min and max thresholds for validation
      - approach: validation along the full range of thresholds, or validate top variants
      - count: total number of variants for validation.
  Produces:
   - Final calls
       - calls that overlap in all of the technologies
       - calls that overlap in all but the target, where the target technology quality
         is below the validation threshold.
   - Validate calls
       - calls that overlap in all but the target and fall below configurable threshold.
         These are either sampled from the distribution or picked off the top.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.validate
  (:use [ordered.map :only [ordered-map]]
        [bcbio.variation.combine :only [combine-variants]]
        [bcbio.variation.multiple :only [prep-cmp-name-lookup
                                         multiple-overlap-analysis]]
        [bcbio.variation.variantcontext :only [parse-vcf get-vcf-source
                                               write-vcf-w-template]])
  (:require [bcbio.run.broad :as broad]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><p>Base functionality for subsetting a file with SelectVariants.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- select-by-general
  [select-args ext in-vcf ref]
  (let [file-info {:out-vcf (itx/add-file-part in-vcf ext)}
        args (concat [&quot;-R&quot; ref
                      &quot;--variant&quot; in-vcf
                      &quot;-o&quot; :out-vcf]
                      select-args)]
    (broad/run-gatk &quot;SelectVariants&quot; args file-info {:out [:out-vcf]})
    (:out-vcf file-info)))</pre></td></tr><tr><td class="docs"><p>Subset a VCF file with specific hard filters.</p>
</td><td class="codes"><pre class="brush: clojure">(defn select-by-filters
  [filters in-vcf ext ref]
  (select-by-general (interleave (repeat &quot;--select_expressions&quot;) filters)
                     ext in-vcf ref))</pre></td></tr><tr><td class="docs"><h2>Validation targets by random sampling</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Subset a VCF file with a random number of variants.</p>
</td><td class="codes"><pre class="brush: clojure">(defn select-by-random
  [count in-vcf ref]
  (select-by-general [&quot;--select_random_number&quot; count] &quot;randsubset&quot; in-vcf ref))</pre></td></tr><tr><td class="docs"><p>Select set of variants to validate from total set of potentials.</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti get-to-validate
  (fn [in-vcf finalizer ref] (keyword (get-in finalizer [:params :validate :approach]))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-to-validate :random
  [in-vcf finalizer ref]
  (select-by-random (get-in finalizer [:params :validate :count]) in-vcf ref))</pre></td></tr><tr><td class="docs"><p>Provide function to extract metric used in sorting from a variant context.
  Returns a list with the first being the count of items found in set overlap
  and the second the metric to sort by. Currently only handles a single metric
  for sorting.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- extract-sort-metrics
  [finalizer]
  {:pre [(= 1 (count (get-in finalizer [:params :validate :top-metric])))]}
  (let [metric (get-in finalizer [:params :validate :top-metric 0 :name])
        mod (get-in finalizer [:params :validate :top-metric 0 :mod])]
    (fn [vc]
      (let [base (-&gt; vc :attributes (get metric &quot;-1000.0&quot;) (Float/parseFloat))]
        [(count (re-seq (re-pattern (:target finalizer))
                           (-&gt; vc :attributes (get &quot;set&quot; &quot;&quot;))))
         (if mod (* mod base) base)]))))</pre></td></tr><tr><td class="docs"><p>Retrieve top variants sorted by metrics of interest.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-top-variants
  [vcf-file finalizer ref]
  (with-open [vcf-source (get-vcf-source vcf-file ref)]
    (let [metric-gettr (extract-sort-metrics finalizer)]
      (set
       (map (juxt :chr :start)
            (take (get-in finalizer [:params :validate :count])
                  (reverse
                   (sort-by metric-gettr (parse-vcf vcf-source)))))))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-to-validate :top
  [in-vcf finalizer ref]
  (let [out-file (itx/add-file-part in-vcf &quot;topsubset&quot;)]
    (when (itx/needs-run? out-file)
      (let [to-keep (get-top-variants in-vcf finalizer ref)]
        (with-open [vcf-source (get-vcf-source in-vcf ref)]
          (write-vcf-w-template in-vcf {:out out-file}
                                (map :vc
                                     (filter #(contains? to-keep ((juxt :chr :start) %))
                                             (parse-vcf vcf-source)))
                                ref))))
    out-file))</pre></td></tr><tr><td class="docs"><p>Prepare files of calls: finalized and validation targets.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-final-and-tovalidate
  [cmps finalizer config]
  (let [cmps-by-name (prep-cmp-name-lookup (vals cmps) :remove-mods? true
                                           :ignore #{&quot;all&quot; &quot;validate&quot;})
        ref (-&gt; cmps-by-name vals first :exp :ref)
        multi-prep (multiple-overlap-analysis cmps-by-name config (:target finalizer)
                                              :dirname &quot;validate&quot;)]
    (ordered-map
     :final (if-let [keep-filters (get-in finalizer [:params :filters :keep])]
              (combine-variants [(:true-positives multi-prep)
                                 (select-by-filters keep-filters (:false-negatives multi-prep)
                                                    &quot;keepsubset&quot; ref)]
                                ref :merge-type :full)
              (:true-positives multi-prep))
     :validate (get-to-validate
                (let [orig (:target-overlaps multi-prep)]
                  (if-let [val-filters (get-in finalizer [:params :filters :validate])]
                    (select-by-filters val-filters orig &quot;checksubset&quot; ref)
                    orig))
                finalizer ref))))</pre></td></tr><tr><td class="docs"><p>High level pipeline entry for producing final and to-validate call sets.</p>
</td><td class="codes"><pre class="brush: clojure">(defn pipeline-validate
  [cmps finalizer exp config]
  {:c-files (get-final-and-tovalidate cmps finalizer config)
   :c1 {:name (:target finalizer)}
   :c2 {:name &quot;validate&quot;}
   :exp exp :dir (:dir config)})</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.variantcontext" name="bcbio.variation.variantcontext"><h1 class="project-name">bcbio.variation.variantcontext</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Helper functions to retrieve information from GATK VariantContext
   objects, which represent variant data stored in VCF files.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.variantcontext
  (:import [org.broad.tribble.index IndexFactory]
           [org.broad.tribble.source BasicFeatureSource]
           [org.broad.tribble.readers AsciiLineReader]
           [org.broadinstitute.sting.utils.codecs.vcf VCFCodec StandardVCFWriter]
           [org.broadinstitute.sting.gatk.refdata.tracks RMDTrackBuilder]
           [org.broadinstitute.sting.gatk.arguments ValidationExclusion$TYPE])
  (:use [clojure.java.io]
        [lazymap.core :only [lazy-hash-map]]
        [bcbio.align.ref :only [get-seq-dict]])
  (:require [clojure.string :as string]
            [bcbio.run.itx :as itx]))</pre></td></tr><tr><td class="docs"><h2>Represent VariantContext objects</h2>

<p>Provide simple map-based access to important attributes of
VariantContexts. There are 3 useful levels of abstraction:</p>

<ul>
<li>VariantContext: Details about a variation. This captures a
single line in a VCF file</li>
<li>Genotype: An individual genotype for a sample, at a variant position.</li>
<li>Allele: The actual alleles at a genotype.</li>
</ul>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Represent a sample genotype including alleles.
   :genotype stores the original java genotype object for direct access.</p>
</td><td class="codes"><pre class="brush: clojure">(defn from-genotype
  [g]
  (lazy-hash-map
   :sample-name (.getSampleName g)
   :qual (.getPhredScaledQual g)
   :type (-&gt; g .getType .name)
   :attributes (into {} (.getAttributes g))
   :alleles (vec (.getAlleles g))
   :genotype g))</pre></td></tr><tr><td class="docs"><p>Provide a top level map of information from a variant context.
   :vc stores the original java VariantContext object for direct access.</p>
</td><td class="codes"><pre class="brush: clojure">(defn from-vc
  [vc]
  (lazy-hash-map
   :chr (.getChr vc)
   :start (.getStart vc)
   :end (.getEnd vc)
   :id (when (.hasID vc) (.getID vc))
   :ref-allele (.getReference vc)
   :alt-alleles (vec (.getAlternateAlleles vc))
   :type (-&gt; vc .getType .name)
   :filters (set (.getFilters vc))
   :attributes (into {} (.getAttributes vc))
   :qual (.getPhredScaledQual vc)
   :num-samples (.getNSamples vc)
   :genotypes (map from-genotype
                   (-&gt; vc .getGenotypes .toArray vec))
   :vc vc))</pre></td></tr><tr><td class="docs"><h2>Parsing VCF files</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Create a Tribble FeatureSource for VCF file.
   Handles indexing and parsing of VCF into VariantContexts.
   We treat gzipped files as tabix indexed VCFs.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-vcf-source
  [in-file ref-file &amp; {:keys [ensure-safe codec]}]
  (let [cur-codec (if (nil? codec) (VCFCodec.) codec)]
    (if (.endsWith in-file &quot;.gz&quot;)
      (BasicFeatureSource/getFeatureSource in-file cur-codec false)
      (let [validate (when (false? ensure-safe)
                       ValidationExclusion$TYPE/ALLOW_SEQ_DICT_INCOMPATIBILITY)
            idx (.loadIndex (RMDTrackBuilder. (get-seq-dict ref-file) nil validate)
                            (file in-file) cur-codec)]
        (BasicFeatureSource. (.getAbsolutePath (file in-file)) idx cur-codec)))))</pre></td></tr><tr><td class="docs"><p>Indexed VCF file retrieval.
   Returns function that fetches all variants in a region (chromosome:start-end)</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-vcf-retriever
  [vcf-source]
  (fn [chr start end]
    (map from-vc (iterator-seq (.query vcf-source chr start end)))))</pre></td></tr><tr><td class="docs"><p>Lazy iterator of VariantContext information from VCF file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn parse-vcf
  [vcf-source]
  (map from-vc (iterator-seq (.iterator vcf-source))))</pre></td></tr><tr><td class="docs"><p>Retrieve parser to do line-by-line parsing of VCF files.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-vcf-line-parser
  [vcf-reader]
  (let [codec (VCFCodec.)]
    (.readHeader codec vcf-reader)
    (fn [line]
      (from-vc (.decode codec line)))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- line-vcf-parser
  [vcf]
  (let [parser (with-open [rdr (AsciiLineReader. (input-stream vcf))]
                 (get-vcf-line-parser rdr))]
    (map parser (drop-while #(.startsWith % &quot;#&quot;) (line-seq (reader vcf))))))</pre></td></tr><tr><td class="docs"><p>Retrieve header from input VCF file.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-vcf-header
  [vcf-file]
  (with-open [vcf-reader (AsciiLineReader. (input-stream vcf-file))]
    (.readHeader (VCFCodec.) vcf-reader)))</pre></td></tr><tr><td class="docs"><h2>Writing VCF files</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Write VCF output files starting with an original input template VCF.
   Handles writing to multiple VCF files simultaneously with the different
   file handles represented as keywords. This allows lazy splitting of VCF files:
   <code>vc-iter</code> is a lazy sequence of <code>(writer-keyword variant-context)</code>.
   <code>out-file-map</code> is a map of writer-keywords to output filenames.</p>
</td><td class="codes"><pre class="brush: clojure">(defn write-vcf-w-template
  [tmpl-file out-file-map vc-iter ref &amp; {:keys [header-update-fn]}]
  (letfn [(make-vcf-writer [f ref]
            (StandardVCFWriter. (file f) (get-seq-dict ref) true))
          (convert-to-output [info]
            [(if (and (coll? info) (= 2 (count info))) (first info) :out)
             (if (coll? info) (last info) info)])]
    (itx/with-tx-files [tx-out-files out-file-map (keys out-file-map) [&quot;.idx&quot;]]
      (let [tmpl-header (get-vcf-header tmpl-file)
            writer-map (zipmap (keys tx-out-files)
                               (map #(make-vcf-writer % ref) (vals tx-out-files)))]
        (doseq [[key out-vcf] writer-map]
          (.writeHeader out-vcf (if-not (nil? header-update-fn)
                                  (header-update-fn key tmpl-header)
                                  tmpl-header)))
        (doseq [[fkey item] (map convert-to-output vc-iter)]
          (.add (get writer-map fkey) item))
        (doseq [x (vals writer-map)]
          (.close x))))))</pre></td></tr><tr><td class="docs"><p>Write VCF file from input using a filter function.</p>
</td><td class="codes"><pre class="brush: clojure">(defn write-vcf-from-filter
  [vcf ref out-part passes?]
  (with-open [source (get-vcf-source vcf ref)]
    (write-vcf-w-template vcf {:out (itx/add-file-part vcf out-part)}
                          (map :vc (filter passes? (parse-vcf source)))
                          ref)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -main [vcf ref approach]
  (with-open [vcf-s (get-vcf-source vcf ref)]
    (letfn [(item-iter []
              (case approach
                &quot;line&quot; (map :vc (line-vcf-parser vcf))
                &quot;gatk&quot; (iterator-seq (.iterator vcf-s))
                &quot;orig&quot; (map :vc (parse-vcf vcf-s))))]
      (write-vcf-w-template vcf {:out &quot;vctest.vcf&quot;} (item-iter) ref)
      ;; (doseq [[i x] (map-indexed vector (item-iter))]
      ;;   (when (= 0 (mod i 10000))
      ;;      (println x))))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.vcfwalker" name="bcbio.variation.vcfwalker"><h1 class="project-name">bcbio.variation.vcfwalker</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Simple walker to parse a VCF file and display distribution of call
  quality scores</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.vcfwalker
  (:import [bcbio.variation BaseVariantWalker])
  (:use [bcbio.variation.variantcontext :only [from-vc]])
  (:require ;[incanter.charts :as icharts]
            [incanter.core :as icore])
  (:gen-class
   :name bcbio.variation.vcfwalker.VcfSimpleStatsWalker
   :extends bcbio.variation.BaseVariantWalker))</pre></td></tr><tr><td class="docs"><p>Retrieve VariantContexts and extract the variant quality score.</p>
</td><td class="codes"><pre class="brush: clojure">(defn -map
  [this tracker ref context]
  (if-not (nil? tracker)
    (for [vc (map from-vc
                    (.getValues tracker (.variants (.invrns this))
                                (.getLocation context)))]
      (:qual vc))))</pre></td></tr><tr><td class="docs"><p>Initialize an empty list to collect our quality information</p>
</td><td class="codes"><pre class="brush: clojure">(defn -reduceInit
  [this]
  [])</pre></td></tr><tr><td class="docs"><p>Add current quality information to the collected list.</p>
</td><td class="codes"><pre class="brush: clojure">(defn -reduce
  [this cur coll]
  (if-not (nil? cur)
    (vec (flatten [coll cur]))
    coll))</pre></td></tr><tr><td class="docs"><p>Plot histogram of quality scores.</p>
</td><td class="codes"><pre class="brush: clojure">(defn -onTraversalDone
  [this result]
  (println result))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.web.db" name="bcbio.variation.web.db"><h1 class="project-name">bcbio.variation.web.db</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Provide basic persistence of user files and processes in local DB.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.web.db
  (:require [clojure.string :as string]
            [clojure.java.jdbc :as sql]
            [fs.core :as fs]))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- get-db [fname &amp; {:as opts}]
  &quot;Retrieve SQLite database connection&quot;
  (merge
   {:classname &quot;org.sqlite.JDBC&quot;
    :subprotocol &quot;sqlite&quot;
    :subname fname}
   opts))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- create-user-tables []
  (sql/create-table :analysis
                    [:analysis_id :text &quot;PRIMARY KEY&quot;]
                    [:username :text]
                    [:type :text]
                    [:description :text]
                    [:location :text]
                    [:created :timestamp &quot;NOT NULL&quot; &quot;DEFAULT CURRENT_TIMESTAMP&quot;])
  (sql/create-table :files
                    [:analysis_id :text]
                    [:name :text]
                    [:location :text]))</pre></td></tr><tr><td class="docs"><p>Prepare input database for storing user and file information in SQLite.</p>
</td><td class="codes"><pre class="brush: clojure">(defn prepare-web-db
  [db-file]
  (when-not (fs/exists? db-file)
    (sql/with-connection (get-db db-file :create true)
      (sql/transaction
       (create-user-tables))))
  db-file)</pre></td></tr><tr><td class="docs"><p>Retrieve list of analyses run for a specific user and analysis type</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-analyses
  [username atype db-file]
  (sql/with-connection (get-db db-file)
    (sql/with-query-results rows
      [&quot;SELECT * FROM analysis WHERE username = ? AND type = ? ORDER BY created DESC&quot;
       username atype]
      (vec (map #(assoc % :created (java.sql.Timestamp. (:created %))) rows)))))</pre></td></tr><tr><td class="docs"><p>Add an analysis and associated files to the database.</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti add-analysis
  (fn [info _] (:type info)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod add-analysis :scoring
  [info db-file]
  (letfn [(get-analysis-files [info]
            (map (fn [[k f]]
                   {:analysis_id (:analysis_id info)
                    :name (name k)
                    :location (string/replace f (str (:location info) &quot;/&quot;) &quot;&quot;)})
                 (:files info)))]
    (sql/with-connection (get-db db-file)
      (sql/transaction
       (sql/insert-record :analysis (-&gt; info
                                        (dissoc :files)
                                        (assoc :created (java.sql.Timestamp. (.getTime (java.util.Date.))))))
       (doseq [x (get-analysis-files info)]
         (sql/insert-record :files x))))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.web.process" name="bcbio.variation.web.process"><h1 class="project-name">bcbio.variation.web.process</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Run scoring analysis, handling preparation of input files and run configuration.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.web.process
  (:import [java.util.UUID])
  (:use [clojure.java.io]
        [ordered.map :only [ordered-map]]
        [bcbio.variation.combine :only [combine-variants]]
        [bcbio.variation.compare :only [variant-comparison-from-config]]
        [bcbio.variation.normalize :only [pick-best-ref]]
        [bcbio.variation.report :only [prep-scoring-table]]
        [bcbio.variation.web.shared :only [web-config]])
  (:require [clojure.string :as string]
            [clj-yaml.core :as yaml]
            [doric.core :as doric]
            [fs.core :as fs]
            [hiccup.core :as hiccup]
            [noir.session :as session]
            [noir.response :as response]
            [net.cgrand.enlive-html :as html]
            [clj-genomespace.core :as gs]
            [bcbio.variation.web.db :as db]))</pre></td></tr><tr><td class="docs"><h2>Run scoring based on inputs from web or API</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Create configuration for processing inputs using references supplied in config.</p>
</td><td class="codes"><pre class="brush: clojure">(defn create-work-config
  [work-info config]
  (if-not (fs/exists? (:dir work-info))
    (fs/mkdirs (:dir work-info)))
  (let [config-file (str (fs/file (:dir work-info) &quot;process.yaml&quot;))
        ref (first (filter #(= (:sample %) (:sample work-info))
                           (:ref config)))
        contestant-vcf (if-let [x (get-in work-info [:in-files :variant-file])]
                         (str x)
                         (:default-compare ref))]
    (-&gt;&gt; {:dir {:out (str (fs/file (:dir work-info) &quot;grading&quot;))
                :prep (str (fs/file (:dir work-info) &quot;grading&quot; &quot;prep&quot;))}
          :experiments [{:sample (:sample ref)
                         :ref (:genome ref)
                         :intervals (:intervals ref)
                         :approach &quot;grade&quot;
                         :calls [{:name &quot;reference&quot;
                                  :file (:variants ref)
                                  :remove-refcalls true
                                  :normalize true
                                  :refcalls false}
                                 {:name &quot;contestant&quot;
                                  :prep true
                                  :preclean true
                                  :remove-refcalls true
                                  :ref (pick-best-ref contestant-vcf (cons (:genome ref)
                                                                           (:genome-alts ref)))
                                  :file contestant-vcf
                                  :intervals (if-let [x (get-in work-info [:in-files :region-file])]
                                               (str x)
                                               (:intervals ref))}]}]}
         yaml/generate-string
         (spit config-file))
    config-file))</pre></td></tr><tr><td class="docs"><p>Generate a summary table of scoring results.</p>
</td><td class="codes"><pre class="brush: clojure">(defn html-summary-table
  [comparisons]
  (let [scoring-table (prep-scoring-table (:metrics comparisons)
                                          (get-in comparisons [:summary :sv]))]
    (apply str
           (-&gt; (str (doric/table ^{:format doric/html} [:metric :value] scoring-table))
               java.io.StringReader.
               html/html-resource
               (html/transform [:table] (html/set-attr :class &quot;table table-condensed&quot;))
               html/emit*))))</pre></td></tr><tr><td class="docs"><p>Update main page HTML with specified content</p>
</td><td class="codes"><pre class="brush: clojure">(defn- base-page-w-content
  [new-hiccup-html]
  (let [html-dir (get-in @web-config [:dir :html-root])]
    (apply str (html/emit*
                (html/transform (html/html-resource (fs/file html-dir &quot;index.html&quot;))
                                [:div#main-content]
                                (-&gt; new-hiccup-html
                                    java.io.StringReader.
                                    html/html-resource
                                    html/content))))))</pre></td></tr><tr><td class="docs"><p>Generate summary of scoring results for display.</p>
</td><td class="codes"><pre class="brush: clojure">(defn html-scoring-summary
  [comparisons run-id]
  (hiccup/html
   [:h3 &quot;Summary&quot;]
   [:div {:id &quot;score-table&quot;}
    (html-summary-table comparisons)]
   [:h3 &quot;Variant files in VCF format&quot;]
   [:div {:id &quot;variant-file-download&quot;}
    [:ul
     (for [[key txt] [[&quot;concordant&quot; &quot;Concordant variants&quot;]
                      [&quot;discordant&quot; &quot;Discordant variants&quot;]
                      [&quot;discordant-missing&quot; &quot;Missing variants&quot;]
                      [&quot;phasing&quot; &quot;Variants with phasing errors&quot;]]]
       [:li [:a {:href (format &quot;/scorefile/%s/%s&quot; run-id key)} txt]])]]))</pre></td></tr><tr><td class="docs"><p>Update main page HTML with content for scoring.</p>
</td><td class="codes"><pre class="brush: clojure">(defn scoring-html
  [run-id]
  (let [html-dir (get-in @web-config [:dir :html-root])
        template-dir (str (fs/file html-dir &quot;template&quot;))]
    (base-page-w-content 
     (hiccup/html
      [:div {:id &quot;scoring-in-process&quot;}
       [:h3 &quot;Status&quot;]
       [:div {:id &quot;scoring-status&quot;} &quot;Downloading input files&quot;]
       [:div {:class &quot;progress&quot;}
        [:div {:id &quot;scoring-progress&quot;
               :class &quot;bar&quot; :style &quot;width: 0%&quot;}]]
       (slurp (fs/file template-dir &quot;scoring.html&quot;))
       [:script {:src &quot;js/score.js&quot;}]
       [:script (format &quot;bcbio.variation.score.update_run_status('%s');&quot;
                        run-id)]]))))</pre></td></tr><tr><td class="docs"><p>Update main page with list of performed analyses.</p>
</td><td class="codes"><pre class="brush: clojure">(defn analyses-html
  [username]
  (base-page-w-content
   (hiccup/html
    (if (nil? username)
      [:p &quot;Please login to display previously run analyses.&quot;]
      [:div {:id &quot;user-analyses&quot; :class &quot;container&quot;}
       [:h3 &quot;Previous analyses&quot;]
       [:ul {:class &quot;nav nav-tabs nav-stacked&quot;}
        (map (fn [x]
               [:li
                [:a {:href &quot;#&quot; :id (:analysis_id x)}
                 (format &quot;%s -- %s&quot; (:description x)
                         (-&gt; (java.text.SimpleDateFormat. &quot;dd MMM yyyy HH:mm&quot; )
                             (.format (:created x))))]])
             (db/get-analyses username :scoring (:db @web-config)))]
       [:script {:src &quot;js/score.js&quot;}]
       [:script &quot;bcbio.variation.analyses.display_analyses()&quot;]]))))</pre></td></tr><tr><td class="docs"><p>Upload output files to GenomeSpace.</p>
</td><td class="codes"><pre class="brush: clojure">(defn upload-results
  [gs-client work-info comparison]
  (let [out-files (map #(get-in comparison [:c-files %])
                       [:concordant :discordant :discordant-missing :phasing-error])
        summary-file (str (fs/file (:dir work-info)
                                   (format &quot;%s-scoring.txt&quot;
                                           (get-in comparison [:summary :sample]))))]
    (with-open [wtr (writer summary-file)]
      (.write wtr (str (doric/table [:metric :value]
                                    (prep-scoring-table (:metrics comparison)
                                                        (get-in comparison [:summary :sv])))
                       &quot;\n&quot;)))
    (doseq [fname (cons summary-file out-files)]
      (gs/upload gs-client (:upload-dir work-info) fname))))</pre></td></tr><tr><td class="docs"><p>Merge standard and structural variant outputs into final set of upload files.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- prepare-final-files
  [comparisons]
  (letfn [(merge-files-into [comparisons orig-kw addin-kw]
            (let [ref (get-in comparisons [:c1 :ref])
                  orig (get-in comparisons [:c-files orig-kw])
                  addin (get-in comparisons [:c-files addin-kw])
                  combine-vcf (combine-variants [orig addin] ref :merge-type :full
                                                :quiet-out? true)]
              (fs/rename combine-vcf orig)
              (fs/rename (str combine-vcf &quot;.idx&quot;) (str orig &quot;.idx&quot;))))]
      (merge-files-into comparisons :concordant :sv-concordant)
      (merge-files-into comparisons :discordant :sv-contestant-discordant)
      (merge-files-into comparisons :discordant-missing :sv-reference-discordant)))</pre></td></tr><tr><td class="docs"><p>Run scoring analysis from details provided in current session.</p>
</td><td class="codes"><pre class="brush: clojure">(defn run-scoring-analysis
  [work-info]
  (let [gs-client (session/get :gs-client)
        process-config (create-work-config work-info @web-config)
        comparisons (first (variant-comparison-from-config process-config))]
    (prepare-final-files comparisons)
    (when-not (or (nil? gs-client) (nil? (:upload-dir work-info)))
      (upload-results gs-client work-info comparisons))
    (spit (file (:dir work-info) &quot;scoring-summary.html&quot;)
          (html-scoring-summary comparisons (:id work-info)))
    (when-let [username (session/get :username)]
      (db/add-analysis {:username username :files (:c-files comparisons)
                        :analysis_id (:id work-info)
                        :description (format &quot;%s: %s&quot; (:sample comparisons)
                                             (fs/base-name (-&gt; comparisons :exp :calls second :file)))
                        :location (:dir work-info) :type :scoring}
                       (:db @web-config)))))</pre></td></tr><tr><td class="docs"><p>Prepare working directory, downloading input files.</p>
</td><td class="codes"><pre class="brush: clojure">(defmulti get-input-files
  (fn [work-info params]
    (let [gs-info (:gs-variant-file params)]
      (if (or (nil? gs-info) (empty? gs-info)) :upload :gs))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-input-files :upload
  [work-info params]
  (letfn [(download-file [tmp-dir params kw]
            (let [cur-param (get params kw)
                  out-file (fs/file tmp-dir (:filename cur-param))]
              [kw (when (&gt; (:size cur-param) 0)
                    (copy (:tempfile cur-param) out-file)
                    (str out-file))]))]
    (into {} (map (partial download-file (:dir work-info) params)
                  [:variant-file :region-file]))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defmethod get-input-files :gs
  [work-info params]
  (letfn [(gs-do-download [gs-file tmp-dir]
            (let [local-file (fs/file tmp-dir (fs/base-name gs-file))]
              (when-not (fs/exists? local-file)
                (gs/download (session/get :gs-client)
                             (str (fs/parent gs-file))
                             (str (fs/base-name gs-file))
                             tmp-dir))
              local-file))
          (gs-download [tmp-dir params kw]
            (let [gs-file (get params (keyword (str &quot;gs-&quot; (name kw))))]
              [kw (when-not (or (nil? gs-file) (empty? gs-file))
                    (gs-do-download gs-file tmp-dir))]))]
    (into {} (map (partial gs-download (:dir work-info) params)
                  [:variant-file :region-file]))))</pre></td></tr><tr><td class="docs"><p>Download form-supplied input files and start scoring analysis.</p>
</td><td class="codes"><pre class="brush: clojure">(defn run-scoring
  [orig-work-info params]
  (letfn [(add-upload-dir [work-info params]
            (let [remote-fname (:gs-variant-file params)]
              (if-not (or (nil? remote-fname) (empty? remote-fname))
                (assoc work-info :upload-dir (str (fs/parent remote-fname)))
                work-info)))]
    (let [work-info (-&gt; orig-work-info
                        (add-upload-dir params)
                        (assoc :sample (:comparison-genome params))
                        (assoc :in-files (get-input-files orig-work-info params)))]
      (run-scoring-analysis work-info))))</pre></td></tr><tr><td class="docs"><p>Prep directory for scoring analysis.</p>
</td><td class="codes"><pre class="brush: clojure">(defn prep-scoring
  [params]
  (letfn [(prep-tmp-dir []
            (let [tmp-dir (get-in @web-config [:dir :work])
                  work-id (str (java.util.UUID/randomUUID))
                  cur-dir (fs/file tmp-dir work-id)]
              (fs/mkdirs cur-dir)
              {:id work-id :dir (str cur-dir)
               :sample (:comparison-genome params)}))]
    (let [work-info (prep-tmp-dir)]
      (session/put! :work-info (assoc (session/get :work-info (ordered-map))
                                 (:id work-info) work-info))
      {:work-info work-info
       :out-html (scoring-html (:id work-info))})))</pre></td></tr><tr><td class="docs"><h2>File retrieval from processing</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Retrieve run information from stored database or current session.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- get-run-info
  [run-id username]
  (println &quot;***&quot; username)
  (if (nil? username)
    (let [work-info (get (session/get :work-info) run-id)]
      [(:sample work-info) (:dir work-info)])
    (let [work-info (-&gt;&gt; (db/get-analyses username :scoring (:db @web-config))
                         (filter #(= run-id (:analysis_id %)))
                         first)
          sample-name (when-not (nil? work-info)
                        (first (string/split (:description work-info) #&quot;:&quot;)))]
      [sample-name (:location work-info)])))</pre></td></tr><tr><td class="docs"><p>Retrieve processed output file for web display.</p>
</td><td class="codes"><pre class="brush: clojure">(defn get-variant-file
  [run-id name username]
  (letfn [(sample-file [sample-name ext]
            (let [base-name &quot;contestant-reference&quot;]
              (format &quot;%s-%s-%s&quot; sample-name base-name ext)))]
    (let [[sample-name base-dir] (get-run-info run-id username)
          file-map {&quot;concordant&quot; (sample-file sample-name &quot;concordant.vcf&quot;)
                    &quot;discordant&quot; (sample-file sample-name &quot;discordant.vcf&quot;)
                    &quot;discordant-missing&quot; (sample-file sample-name &quot;discordant-missing.vcf&quot;)
                    &quot;phasing&quot; (sample-file sample-name &quot;phasing-error.vcf&quot;)}
          work-dir (when-not (nil? base-dir) (fs/file base-dir &quot;grading&quot;))
          name (get file-map name)
          fname (if-not (or (nil? work-dir)
                            (nil? name)) (str (fs/file work-dir name)))]
      (response/content-type &quot;text/plain&quot;
                             (if (and (not (nil? fname)) (fs/exists? fname))
                               (slurp fname)
                               &quot;Variant file not found&quot;)))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.web.server" name="bcbio.variation.web.server"><h1 class="project-name">bcbio.variation.web.server</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Server providing routes for serving up static pages.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.web.server
  (:use [clojure.java.io]
        [noir.core :only [defpage]]
        [noir.fetch.remotes :only [defremote]]
        [bcbio.variation.config :only [get-log-status]]
        [bcbio.variation.web.db :only [prepare-web-db get-analyses]]
        [bcbio.variation.web.shared :only [web-config]]
        [ring.middleware file anti-forgery file-info])
  (:require [clojure.string :as string]
            [clj-yaml.core :as yaml]
            [fs.core :as fs]
            [noir.server :as server]
            [noir.session :as session]
            [clj-genomespace.core :as gs]
            [bcbio.variation.web.process :as web-process]))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- cur-gs-client []
  (when-let [gs-client (session/get :gs-client)]
    (when (gs/logged-in? gs-client)
      gs-client)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defremote login [{:keys [username password]}]
  (when-let [gs-client (gs/get-client username :password password)]
    (session/put! :username username)
    (session/put! :gs-client gs-client)
    username))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defremote logout []
  (session/remove! :username)
  (session/remove! :gs-client)
  nil)</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defremote get-username []
  (when (cur-gs-client)
    (session/get :username)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defremote get-genomes []
  (map (fn [x] {:value (:sample x)
                :text (format &quot;%s (%s)&quot; (:sample x) (:description x))})
       (:ref @web-config)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- prep-gs-path [x]
  {:full x
   :name (last (string/split x #&quot;/&quot;))})</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defremote list-external-dirs []
  (if-let [gs-client (cur-gs-client)]
    (map prep-gs-path (gs/list-dirs gs-client &quot;.&quot;))
    []))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defremote list-external-files [dir ftype]
  (if-let [gs-client (cur-gs-client)]
    (map prep-gs-path (gs/list-files gs-client dir ftype))
    []))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defremote get-status [run-id]
  (get-log-status {:dir {:out (-&gt; (session/get :work-info)
                                  (get run-id)
                                  :dir
                                  (file &quot;grading&quot;))}}))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defremote get-summary [run-id]
  (when-let [out-dir (if-let [username (get-username)]
                       (-&gt;&gt; (get-analyses username :scoring (:db @web-config))
                            (filter #(= run-id (:analysis_id %)))
                            first
                            :location)
                       (-&gt; (session/get :work-info)
                           (get run-id)
                           :dir))]
    (let [summary-file (file out-dir &quot;scoring-summary.html&quot;)]
      (when (fs/exists? summary-file)
        (slurp summary-file)))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defpage &quot;/analyses&quot; {}
  (web-process/analyses-html (get-username)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defpage [:post &quot;/score&quot;] {:as params}
  (let [{:keys [work-info out-html]} (web-process/prep-scoring params)]
    (future (web-process/run-scoring work-info params))
    out-html))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defpage &quot;/scorefile/:runid/:name&quot; {:keys [runid name]}
  (web-process/get-variant-file runid name (get-username)))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn -main
  ([config-file]
     (-main config-file &quot;8080&quot;))
  ([config-file port]
     (let [config (-&gt; config-file slurp yaml/parse-string)]
       (reset! web-config (assoc config :db
                                 (prepare-web-db (str (fs/file (get-in config [:dir :work]) &quot;analyses.db&quot;)))))
       (server/add-middleware wrap-file (get-in @web-config [:dir :html-root]))
       ;;(server/add-middleware wrap-file-info)
       ;;(server/add-middleware wrap-anti-forgery)
       (server/start (Integer/parseInt port)))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.web.shared" name="bcbio.variation.web.shared"><h1 class="project-name">bcbio.variation.web.shared</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Shared functionality useful across multiple pages.</p>
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.web.shared)</pre></td></tr><tr><td class="docs"><p>Web configuration, loaded from input YAML file</p>
</td><td class="codes"><pre class="brush: clojure">(def 
  web-config (atom nil))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.analyses" name="bcbio.variation.analyses"><h1 class="project-name">bcbio.variation.analyses</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Interactive functionality for display of older analyses.</p>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.analyses
  (:require [domina :as domina]
            [domina.css :as css]
            [domina.events :as events]
            [fetch.remotes :as remotes])
  (:require-macros [fetch.macros :as fm]))</pre></td></tr><tr><td class="docs"><p>Update page with details from a selected analysis.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- display-selected-analysis
  [analysis-id]
  (fm/remote (get-summary analysis-id) [sum-html]
             (domina/set-html! (domina/by-id &quot;user-analyses&quot;)
                               sum-html)))</pre></td></tr><tr><td class="docs"><p>Correctly set the top level navigation toolbar.</p>
</td><td class="codes"><pre class="brush: clojure">(defn ^:export display-analyses
  []
  (events/listen! (-&gt; (domina/by-id &quot;user-analyses&quot;)
                      (css/sel &quot;ul&quot;)
                      domina/children)
                  :click (fn [evt]
                           (display-selected-analysis (domina/attr (events/target evt) :id))
                           (events/prevent-default evt))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.login" name="bcbio.variation.login"><h1 class="project-name">bcbio.variation.login</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Handle login and logout management.</p>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.login
  (:use [domina.events :only [listen! prevent-default]]
        [domina.css :only [sel]]
        [domina.xpath :only [xpath]]
        [bcbio.variation.score :only [set-upload-active set-gs-active]])
  (:require [domina :as domina]
            [fetch.remotes :as remotes]
            [crate.core :as crate])
  (:require-macros [fetch.macros :as fm]))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- form-input [content]
  [(keyword (domina/attr content &quot;name&quot;))
   (domina/value content)])</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- logged-in-html [user]
  (crate/html
   [:div {:class &quot;btn-group&quot;}
    [:button {:class &quot;btn btn-info dropdown-toggle&quot; :data-toggle &quot;dropdown&quot;}
     [:i {:class &quot;icon-user icon-white&quot; :style &quot;margin-right: 6px&quot;}]
     user
     [:span {:class &quot;caret&quot; :style &quot;margin-left: 6px&quot;}]]
    [:ul {:class &quot;dropdown-menu&quot;}
     [:li [:a {:id &quot;logout-btn&quot; :href &quot;#&quot;} &quot;Logout&quot;]]]]))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- logged-out-html []
  (crate/html
   [:form {:class &quot;navbar-form&quot;}
    [:input {:type &quot;text&quot; :name &quot;username&quot; :class &quot;input-medium&quot; :placeholder &quot;GenomeSpace Username&quot;
             :style &quot;margin-top: 2px; margin-right: 4px&quot;}]
    [:input {:type &quot;password&quot; :name &quot;password&quot; :class &quot;input-medium&quot; :placeholder &quot;Password&quot;
             :style &quot;margin-top: 2px;&quot;}]
    [:button {:type &quot;submit&quot; :id &quot;login-btn&quot; :class &quot;btn-info btn&quot;} &quot;Login&quot;]
    [:a {:class &quot;btn btn-success&quot; :href &quot;http://www.genomespace.org/register&quot; :target &quot;_blank&quot;}
     &quot;Register&quot;]]))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(declare login-listeners)</pre></td></tr><tr><td class="docs"><p>Check for logged in users, updating user management region accordingly.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- update-login
  []
  (fm/remote (get-username) [user]
             (domina/set-html! (domina/by-id &quot;user-manage&quot;)
                   (if (nil? user)
                     (logged-out-html)
                     (logged-in-html user)))
             (login-listeners)))</pre></td></tr><tr><td class="docs"><p>Add listeners for login related clicks. Updated when DOM changes.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- login-listeners
  []
  (listen! (domina/by-id &quot;login-btn&quot;)
           :click (fn [evt]
                    (let [login-vals (-&gt;&gt; (xpath &quot;//div[@id='user-manage']/form/input&quot;)
                                          (domina/nodes)
                                          (map form-input)
                                          (into {}))]
                      (fm/remote (login login-vals) [result]
                                 (if (nil? result)
                                   (js/alert &quot;Invalid username/password&quot;)
                                   (do
                                     (update-login)
                                     (set-gs-active)))))
                    (prevent-default evt)))
  (listen! (domina/by-id &quot;logout-btn&quot;)
           :click (fn [evt]
                    (fm/remote (logout) []
                               (update-login)
                               (set-upload-active))
                    (prevent-default evt))))</pre></td></tr><tr><td class="docs"><p>Catch login details, check login and update header.</p>
</td><td class="codes"><pre class="brush: clojure">(defn ^:export handle-login
  []
  (update-login))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr><tr><td class="docs"><div class="docs-header"><a class="anchor" href="#bcbio.variation.score" name="bcbio.variation.score"><h1 class="project-name">bcbio.variation.score</h1><a class="toc-link" href="#toc">toc</a></a></div></td><td class="codes" /></tr><tr><td class="docs"><p>Interactive functionality for scoring based web pages.</p>
</td><td class="codes"></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(ns bcbio.variation.score
  (:use [domina :only [set-attr! remove-attr! swap-content!]]
        [domina.css :only [sel]])
  (:require [clojure.string :as string]
            [chosen.core :as chosen]
            [crate.core :as crate]
            [domina :as domina]
            [domina.events :as events]
            [fetch.remotes :as remotes]
            [goog.dom :as dom]
            [goog.string :as gstring]
            [goog.Timer :as timer]
            [goog.net.XhrIo :as xhr])
  (:require-macros [fetch.macros :as fm]))</pre></td></tr><tr><td class="docs"><h2>Display scoring results</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Rough progress points to indicate status of processing.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- progress-percent
  [desc]
  (cond
   (gstring/startsWith desc &quot;Starting variation&quot;) 10
   (gstring/startsWith desc &quot;Prepare VCF, resorting to genome build: contestant&quot;) 15
   (gstring/startsWith desc &quot;Normalize MNP and indel variants: contestant&quot;) 60
   (gstring/startsWith desc &quot;Comparing VCFs: reference vs contestant&quot;) 75
   (gstring/startsWith desc &quot;Summarize comparisons&quot;) 90
   (gstring/startsWith desc &quot;Finished&quot;) 100
   :else nil))</pre></td></tr><tr><td class="docs"><p>Update summary page with details about running statuses.</p>
</td><td class="codes"><pre class="brush: clojure">(defn ^:export update-run-status
  [run-id]
  (fm/remote (get-status run-id) [info]
             (if (= :finished (:state info))
               (fm/remote (get-summary run-id) [sum-html]
                          (if (nil? sum-html)
                            (timer/callOnce (fn [] (update-run-status run-id)) 2000)
                             (domina/set-html! (domina/by-id &quot;scoring-in-process&quot;)
                                               sum-html)))
               (do
                 (when-not (nil? info)
                   (domina/set-html! (domina/by-id &quot;scoring-status&quot;)
                                     (crate/html [:p (:desc info)]))
                   (when-let [pct (progress-percent (:desc info))]
                     (domina/set-attr! (domina/by-id &quot;scoring-progress&quot;)
                                       :style (str &quot;width: &quot; pct &quot;%&quot;))))
                 (timer/callOnce (fn [] (update-run-status run-id)) 2000)))))</pre></td></tr><tr><td class="docs"><h2>Allow multiple upload methods</h2>
</td><td class="codes"></td></tr><tr><td class="docs"><p>Set the active type for our type of file upload.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- set-active-choice!
  [active-id]
  (-&gt; (domina/by-id &quot;upload-choices&quot;)
      (sel &quot;.active&quot;)
      (remove-attr! :class))
  (-&gt; (sel active-id)
      (set-attr! :class &quot;active&quot;)))</pre></td></tr><tr><td class="docs"><p>Update an input item for file upload input.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- add-file-input!
  [select-id]
  (domina/swap-content! (domina/by-id select-id)
                        (crate/html [:input {:class &quot;input-file&quot; :id select-id
                                             :name select-id :type &quot;file&quot;}])))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- gs-paths-to-chosen [xs]
  (map (fn [x] {:value (:full x) :text (:name x)}) xs))</pre></td></tr><tr><td class="docs"><p>Update file information based on parent</p>
</td><td class="codes"><pre class="brush: clojure">(defn- update-gs-files!
  [file-chosen file-id dir ftype]
  (let [final-form-id (string/join &quot;-&quot; (cons &quot;gs&quot; (rest (string/split file-id #&quot;-&quot;))))]
    (fm/remote (list-external-files dir ftype) [files]
               (chosen/options file-chosen (gs-paths-to-chosen files))
               (domina/set-value! (domina/by-id final-form-id) (chosen/selected file-chosen))
               (add-watch file-chosen :change
                          (fn [fname]
                            (domina/set-value! (domina/by-id final-form-id) fname))))))</pre></td></tr><tr><td class="docs"><p>Update an input item for GenomeSpace uptake.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- add-gs-input!
  [select-id ftype]
  (let [folder-id (str &quot;gsfolder-&quot; select-id)
        file-id (str &quot;gsfile-&quot; select-id)]
    (swap-content! (domina/by-id select-id)
                   (crate/html
                    [:div {:id select-id}
                     [:select {:id folder-id :data-placeholder &quot;GenomeSpace Folder&quot;}]
                     [:select {:id file-id :data-placeholder &quot;GenomeSpace File&quot;}]]))
    (let [folder-chosen (chosen/ichooseu! (str &quot;#&quot; folder-id))
          file-chosen (chosen/ichooseu! (str &quot;#&quot; file-id))]
      (fm/remote (list-external-dirs) [dirs]
                 (chosen/options folder-chosen (gs-paths-to-chosen dirs))
                 (when-let [cur-dir (chosen/selected folder-chosen)]
                   (update-gs-files! file-chosen file-id cur-dir ftype))
                 (add-watch folder-chosen :change
                            (fn [dir]
                              (update-gs-files! file-chosen file-id dir ftype)))))))</pre></td></tr><tr><td class="docs"><p>Prepare genome selector to pick analysis genome.</p>
</td><td class="codes"><pre class="brush: clojure">(defn- prep-genome-selector
  []
  (let [genome-chosen (chosen/ichooseu! &quot;#comparison-genome&quot;)]
    (fm/remote (get-genomes) [genomes]
               (chosen/options genome-chosen genomes))))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- set-upload-active []
  (set-active-choice! &quot;#menu-choice-upload&quot;)
  (add-file-input! &quot;variant-file&quot;)
  (add-file-input! &quot;region-file&quot;))</pre></td></tr><tr><td class="docs">
</td><td class="codes"><pre class="brush: clojure">(defn- set-gs-active []
  (set-active-choice! &quot;#menu-choice-gs&quot;)
  (add-gs-input! &quot;variant-file&quot; &quot;vcf&quot;)
  (add-gs-input! &quot;region-file&quot; &quot;bed&quot;))</pre></td></tr><tr><td class="docs"><p>Correctly set the active top level navigation toolbar.</p>
</td><td class="codes"><pre class="brush: clojure">(defn ^:export set-navigation
  []
  (let [loc (-&gt; (.toString window.location ())
                (string/split #&quot;/&quot;)
                last)]
    (doseq [list-item (domina/children (domina/by-id &quot;top-navbar&quot;))]
      (if (= (str &quot;/&quot; loc)
             (-&gt; (domina/children list-item)
                 first
                 (domina/attr :href)))
        (domina/set-attr! list-item :class &quot;active&quot;)
        (domina/remove-attr! list-item :class)))))</pre></td></tr><tr><td class="docs"><p>Handle generalized upload through files or GenomeSpace.</p>
</td><td class="codes"><pre class="brush: clojure">(defn ^:export upload-generalize
  []
  (prep-genome-selector)
  (fm/remote (get-username) [user]
             (when-not (nil? user)
               (set-gs-active)))
  (events/listen! (sel &quot;#file-choice-upload&quot;)
                  :click (fn [evt]
                           (set-upload-active)
                           (events/prevent-default evt)))
  (events/listen! (sel &quot;#file-choice-gs&quot;)
                  :click (fn [evt]
                           (set-gs-active)
                           (events/prevent-default evt))))</pre></td></tr><tr><td class="spacer docs">&nbsp;</td><td class="codes" /></tr></table><div class="footer">Generated by <a href="https://github.com/fogus/marginalia">Marginalia</a>.&nbsp;&nbsp;Syntax highlighting provided by Alex Gorbatchev's <a href="http://alexgorbatchev.com/SyntaxHighlighter/">SyntaxHighlighter</a></div><script type="text/javascript">SyntaxHighlighter.defaults['gutter'] = false;
       SyntaxHighlighter.all()</script></body></html>